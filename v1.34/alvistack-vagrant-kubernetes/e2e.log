  I0902 07:30:47.077117      16 e2e.go:109] Starting e2e run "aeecdebe-316c-45be-9858-11f08143cc7b" on Ginkgo node 1
Running Suite: Kubernetes e2e suite - /usr/local/bin
====================================================
Random Seed: 1756798245 - will randomize all specs

Will run 424 of 7132 specs
------------------------------
[ReportBeforeSuite] 
k8s.io/kubernetes/test/e2e/e2e_test.go:153
[ReportBeforeSuite] PASSED [0.000 seconds]
------------------------------
[SynchronizedBeforeSuite] 
k8s.io/kubernetes/test/e2e/e2e.go:69
  I0902 07:30:47.552722 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  I0902 07:30:47.562657 16 helper.go:51] Waiting up to 30m0s for all (but 0) nodes to be schedulable
  I0902 07:30:47.630948 16 e2e.go:142] Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
  I0902 07:30:47.642505 16 e2e.go:153] 3 / 3 pods ready in namespace 'kube-system' in daemonset 'cilium' (0 seconds elapsed)
  I0902 07:30:47.643085 16 e2e.go:153] 3 / 3 pods ready in namespace 'kube-system' in daemonset 'cilium-node-init' (0 seconds elapsed)
  I0902 07:30:47.643150 16 e2e.go:153] 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
  I0902 07:30:47.643184 16 e2e.go:245] e2e test version: v1.34.0
  I0902 07:30:47.645263 16 e2e.go:254] kube-apiserver version: v1.34.0
  I0902 07:30:47.645409 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  I0902 07:30:47.657122 16 e2e.go:383] Cluster IP family: ipv4
[SynchronizedBeforeSuite] PASSED [0.105 seconds]
------------------------------
S
------------------------------
[sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:94
  STEP: Creating a kubernetes client @ 09/02/25 07:30:47.925
  I0902 07:30:47.925581 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename configmap @ 09/02/25 07:30:47.928
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:30:47.983
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:30:47.99
  STEP: Creating configMap configmap-4266/configmap-test-abfb268d-1f12-48a6-9c29-4fc272e5ee6a @ 09/02/25 07:30:47.996
  STEP: Creating a pod to test consume configMaps @ 09/02/25 07:30:48.007
  STEP: Saw pod success @ 09/02/25 07:30:56.083
  I0902 07:30:56.093861 16 output.go:207] Trying to get logs from node ietha7evai9i-2 pod pod-configmaps-d6e6d7c3-d3e0-4054-a773-60026ba622b3 container env-test: <nil>
  STEP: delete the pod @ 09/02/25 07:30:56.137
  I0902 07:30:56.169841 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-4266" for this suite. @ 09/02/25 07:30:56.183
• [8.275 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined should project all components that make up the projection API [Projection] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_combined.go:44
  STEP: Creating a kubernetes client @ 09/02/25 07:30:56.202
  I0902 07:30:56.202886 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename projected @ 09/02/25 07:30:56.205
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:30:56.23
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:30:56.238
  STEP: Creating configMap with name configmap-projected-all-test-volume-5b700dea-893c-4102-9189-426657241092 @ 09/02/25 07:30:56.247
  STEP: Creating secret with name secret-projected-all-test-volume-f0d148fd-f8ce-4cff-bd85-3ed53e47b493 @ 09/02/25 07:30:56.263
  STEP: Creating a pod to test Check all projections for projected volume plugin @ 09/02/25 07:30:56.276
  STEP: Saw pod success @ 09/02/25 07:31:00.326
  I0902 07:31:00.334183 16 output.go:207] Trying to get logs from node ietha7evai9i-2 pod projected-volume-a78d038b-8a26-45c8-be38-542451ccd063 container projected-all-volume-test: <nil>
  STEP: delete the pod @ 09/02/25 07:31:00.351
  I0902 07:31:00.403268 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5257" for this suite. @ 09/02/25 07:31:00.413
• [4.226 seconds]
------------------------------
SSSS
------------------------------
[sig-auth] SubjectReview should support SubjectReview API operations [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/subjectreviews.go:50
  STEP: Creating a kubernetes client @ 09/02/25 07:31:00.431
  I0902 07:31:00.433173 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename subjectreview @ 09/02/25 07:31:00.437
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:31:00.465
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:31:00.471
  STEP: Creating a Serviceaccount "e2e" in namespace "subjectreview-6638" @ 09/02/25 07:31:00.478
  I0902 07:31:00.490528 16 subjectreviews.go:66] saUsername: "system:serviceaccount:subjectreview-6638:e2e"
  I0902 07:31:00.491905 16 subjectreviews.go:69] saGroups: []string{"system:authenticated", "system:serviceaccounts", "system:serviceaccounts:subjectreview-6638"}
  I0902 07:31:00.491948 16 subjectreviews.go:71] saUID: "53ffe6ac-2ebb-4824-a98f-3137806adc6c"
  STEP: Creating clientset to impersonate "system:serviceaccount:subjectreview-6638:e2e" @ 09/02/25 07:31:00.492
  STEP: Creating SubjectAccessReview for "system:serviceaccount:subjectreview-6638:e2e" @ 09/02/25 07:31:00.493
  I0902 07:31:00.497315 16 subjectreviews.go:102] sarResponse Status: v1.SubjectAccessReviewStatus{Allowed:false, Denied:false, Reason:"", EvaluationError:""}
  STEP: Verifying as "system:serviceaccount:subjectreview-6638:e2e" api 'list' configmaps in "subjectreview-6638" namespace @ 09/02/25 07:31:00.497
  I0902 07:31:00.504775 16 subjectreviews.go:121] SubjectAccessReview has been verified
  STEP: Creating a LocalSubjectAccessReview for "system:serviceaccount:subjectreview-6638:e2e" @ 09/02/25 07:31:00.505
  I0902 07:31:00.512503 16 subjectreviews.go:144] lsarResponse Status: v1.SubjectAccessReviewStatus{Allowed:false, Denied:false, Reason:"", EvaluationError:""}
  I0902 07:31:00.512586 16 subjectreviews.go:150] LocalSubjectAccessReview has been verified
  I0902 07:31:00.512732 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subjectreview-6638" for this suite. @ 09/02/25 07:31:00.521
• [0.102 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:195
  STEP: Creating a kubernetes client @ 09/02/25 07:31:00.536
  I0902 07:31:00.536847 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename webhook @ 09/02/25 07:31:00.539
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:31:00.566
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:31:00.571
  STEP: Setting up server cert @ 09/02/25 07:31:00.609
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 09/02/25 07:31:01.538
  STEP: Deploying the webhook pod @ 09/02/25 07:31:01.55
  STEP: Wait for the deployment to be ready @ 09/02/25 07:31:01.58
  I0902 07:31:01.599857 16 deployment.go:223] new replicaset for deployment "sample-webhook-deployment" is yet to be created
  I0902 07:31:03.626607 16 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.September, 2, 7, 31, 1, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 7, 31, 1, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.September, 2, 7, 31, 1, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 7, 31, 1, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7d44fffc8\" is progressing."}}, CollisionCount:(*int32)(nil)}
  I0902 07:31:05.635729 16 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.September, 2, 7, 31, 1, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 7, 31, 1, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.September, 2, 7, 31, 1, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 7, 31, 1, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7d44fffc8\" is progressing."}}, CollisionCount:(*int32)(nil)}
  I0902 07:31:07.636766 16 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.September, 2, 7, 31, 1, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 7, 31, 1, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.September, 2, 7, 31, 1, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 7, 31, 1, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7d44fffc8\" is progressing."}}, CollisionCount:(*int32)(nil)}
  I0902 07:31:09.636457 16 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.September, 2, 7, 31, 1, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 7, 31, 1, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.September, 2, 7, 31, 1, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 7, 31, 1, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7d44fffc8\" is progressing."}}, CollisionCount:(*int32)(nil)}
  I0902 07:31:11.635763 16 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.September, 2, 7, 31, 1, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 7, 31, 1, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.September, 2, 7, 31, 1, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 7, 31, 1, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7d44fffc8\" is progressing."}}, CollisionCount:(*int32)(nil)}
  I0902 07:31:13.640116 16 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.September, 2, 7, 31, 1, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 7, 31, 1, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.September, 2, 7, 31, 1, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 7, 31, 1, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7d44fffc8\" is progressing."}}, CollisionCount:(*int32)(nil)}
  STEP: Deploying the webhook service @ 09/02/25 07:31:15.635
  STEP: Verifying the service has paired with the endpoint @ 09/02/25 07:31:15.653
  I0902 07:31:16.653472 16 util.go:419] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the webhook via the AdmissionRegistration API @ 09/02/25 07:31:16.663
  I0902 07:31:16.714468 16 webhook.go:2701] Waiting for webhook configuration to be ready...
  STEP: create a pod that should be denied by the webhook @ 09/02/25 07:31:16.837
  STEP: create a pod that causes the webhook to hang @ 09/02/25 07:31:16.873
  STEP: create a configmap that should be denied by the webhook @ 09/02/25 07:31:26.888
  STEP: create a configmap that should be admitted by the webhook @ 09/02/25 07:31:26.947
  STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook @ 09/02/25 07:31:26.968
  STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook @ 09/02/25 07:31:26.989
  STEP: create a namespace that bypass the webhook @ 09/02/25 07:31:27.01
  STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace @ 09/02/25 07:31:27.049
  I0902 07:31:27.179058 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-9077" for this suite. @ 09/02/25 07:31:27.192
  STEP: Destroying namespace "webhook-markers-3610" for this suite. @ 09/02/25 07:31:27.208
  STEP: Destroying namespace "exempted-namespace-1612" for this suite. @ 09/02/25 07:31:27.227
• [26.710 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:191
  STEP: Creating a kubernetes client @ 09/02/25 07:31:27.251
  I0902 07:31:27.251277 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename watch @ 09/02/25 07:31:27.254
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:31:27.403
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:31:27.417
  STEP: creating a watch on configmaps @ 09/02/25 07:31:27.53
  STEP: creating a new configmap @ 09/02/25 07:31:27.551
  STEP: modifying the configmap once @ 09/02/25 07:31:27.591
  STEP: closing the watch once it receives two notifications @ 09/02/25 07:31:27.624
  I0902 07:31:27.626962 16 watch.go:426] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-5979  5b2f3a03-6f34-4025-9545-c4208e89bab9 11909 0 2025-09-02 07:31:27 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2025-09-02 07:31:27 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  I0902 07:31:27.630745 16 watch.go:426] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-5979  5b2f3a03-6f34-4025-9545-c4208e89bab9 11911 0 2025-09-02 07:31:27 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2025-09-02 07:31:27 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying the configmap a second time, while the watch is closed @ 09/02/25 07:31:27.631
  STEP: creating a new watch on configmaps from the last resource version observed by the first watch @ 09/02/25 07:31:27.655
  STEP: deleting the configmap @ 09/02/25 07:31:27.658
  STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed @ 09/02/25 07:31:27.673
  I0902 07:31:27.673469 16 watch.go:426] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-5979  5b2f3a03-6f34-4025-9545-c4208e89bab9 11913 0 2025-09-02 07:31:27 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2025-09-02 07:31:27 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0902 07:31:27.673707 16 watch.go:426] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-5979  5b2f3a03-6f34-4025-9545-c4208e89bab9 11914 0 2025-09-02 07:31:27 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2025-09-02 07:31:27 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0902 07:31:27.673887 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-5979" for this suite. @ 09/02/25 07:31:27.715
• [0.477 seconds]
------------------------------
SS
------------------------------
[sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:184
  STEP: Creating a kubernetes client @ 09/02/25 07:31:27.732
  I0902 07:31:27.732821 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename kubelet-test @ 09/02/25 07:31:27.736
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:31:27.768
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:31:27.775
  I0902 07:31:29.856674 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-2742" for this suite. @ 09/02/25 07:31:29.867
• [2.150 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:54
  STEP: Creating a kubernetes client @ 09/02/25 07:31:29.883
  I0902 07:31:29.883165 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename projected @ 09/02/25 07:31:29.885
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:31:29.915
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:31:29.921
  STEP: Creating a pod to test downward API volume plugin @ 09/02/25 07:31:29.927
  STEP: Saw pod success @ 09/02/25 07:31:54.098
  I0902 07:31:54.113746 16 output.go:207] Trying to get logs from node ietha7evai9i-3 pod downwardapi-volume-079866e4-169b-4d87-914b-9a7f4ddc6736 container client-container: <nil>
  STEP: delete the pod @ 09/02/25 07:31:54.154
  I0902 07:31:54.191731 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6770" for this suite. @ 09/02/25 07:31:54.203
• [24.345 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:767
  STEP: Creating a kubernetes client @ 09/02/25 07:31:54.235
  I0902 07:31:54.235927 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename statefulset @ 09/02/25 07:31:54.239
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:31:54.274
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:31:54.281
  STEP: Creating service test in namespace statefulset-5122 @ 09/02/25 07:31:54.287
  I0902 07:31:54.304635      16 warnings.go:110] "Warning: spec.SessionAffinity is ignored for headless services"
  STEP: Creating stateful set ss in namespace statefulset-5122 @ 09/02/25 07:31:54.306
  STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-5122 @ 09/02/25 07:31:54.327
  I0902 07:31:54.337816 16 wait.go:44] Found 0 stateful pods, waiting for 1
  I0902 07:32:04.345424 16 wait.go:54] Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
  I0902 07:32:14.345870 16 wait.go:54] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod @ 09/02/25 07:32:14.346
  I0902 07:32:14.360158 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=statefulset-5122 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0902 07:32:14.839601 16 builder.go:156] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0902 07:32:14.840387 16 builder.go:157] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0902 07:32:14.840492 16 rest.go:280] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0902 07:32:14.850855 16 wait.go:54] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
  I0902 07:32:24.851429 16 wait.go:54] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  I0902 07:32:24.851901 16 wait.go:109] Waiting for statefulset status.readyReplicas updated to 0
  I0902 07:32:24.916998 16 resource.go:151] POD   NODE            PHASE    GRACE  CONDITIONS
  I0902 07:32:24.917287 16 resource.go:158] ss-0  ietha7evai9i-3  Running         [{PodReadyToStartContainers 1 True 0001-01-01 00:00:00 +0000 UTC 2025-09-02 07:32:13 +0000 UTC  } {Initialized 1 True 0001-01-01 00:00:00 +0000 UTC 2025-09-02 07:31:54 +0000 UTC  } {Ready 1 False 0001-01-01 00:00:00 +0000 UTC 2025-09-02 07:32:15 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady 1 False 0001-01-01 00:00:00 +0000 UTC 2025-09-02 07:32:15 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled 1 True 0001-01-01 00:00:00 +0000 UTC 2025-09-02 07:31:54 +0000 UTC  }]
  I0902 07:32:24.917315 16 resource.go:158] ss-2                  Pending         []
  I0902 07:32:24.917329 16 resource.go:161] 
  I0902 07:32:24.919004 16 statefulset.go:2410] StatefulSet ss has not reached scale 3, at 2
  I0902 07:32:25.930211 16 statefulset.go:2415] Verifying statefulset ss doesn't scale past 3 for another 8.958654216s
  I0902 07:32:26.940024 16 statefulset.go:2415] Verifying statefulset ss doesn't scale past 3 for another 7.947791486s
  I0902 07:32:27.952916 16 statefulset.go:2415] Verifying statefulset ss doesn't scale past 3 for another 6.937685999s
  I0902 07:32:28.962781 16 statefulset.go:2415] Verifying statefulset ss doesn't scale past 3 for another 5.925101323s
  I0902 07:32:29.977065 16 statefulset.go:2415] Verifying statefulset ss doesn't scale past 3 for another 4.914235366s
  I0902 07:32:30.993805 16 statefulset.go:2415] Verifying statefulset ss doesn't scale past 3 for another 3.900924687s
  I0902 07:32:32.004919 16 statefulset.go:2415] Verifying statefulset ss doesn't scale past 3 for another 2.883544985s
  I0902 07:32:33.023640 16 statefulset.go:2415] Verifying statefulset ss doesn't scale past 3 for another 1.873055231s
  I0902 07:32:34.037511 16 statefulset.go:2415] Verifying statefulset ss doesn't scale past 3 for another 854.192466ms
  STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-5122 @ 09/02/25 07:32:35.038
  I0902 07:32:35.052976 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=statefulset-5122 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0902 07:32:35.403052 16 builder.go:156] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I0902 07:32:35.403427 16 builder.go:157] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0902 07:32:35.403770 16 rest.go:280] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I0902 07:32:35.404303 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=statefulset-5122 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0902 07:32:35.658114 16 builder.go:145] rc: 1
  I0902 07:32:35.659112 16 output.go:112] Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=statefulset-5122 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
  Command stdout:

  stderr:
  error: Internal error occurred: unable to upgrade connection: container not found ("webserver")

  error:
  exit status 1
  I0902 07:32:45.662076 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=statefulset-5122 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0902 07:32:45.922317 16 builder.go:156] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
  I0902 07:32:45.922791 16 builder.go:157] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0902 07:32:45.922852 16 rest.go:280] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I0902 07:32:45.924746 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=statefulset-5122 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0902 07:32:46.179160 16 builder.go:156] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
  I0902 07:32:46.179682 16 builder.go:157] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0902 07:32:46.179740 16 rest.go:280] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I0902 07:32:46.190820 16 wait.go:54] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  I0902 07:32:46.190984 16 wait.go:54] Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
  I0902 07:32:46.191011 16 wait.go:54] Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Scale down will not halt with unhealthy stateful pod @ 09/02/25 07:32:46.191
  I0902 07:32:46.200071 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=statefulset-5122 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0902 07:32:46.455228 16 builder.go:156] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0902 07:32:46.455475 16 builder.go:157] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0902 07:32:46.455829 16 rest.go:280] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0902 07:32:46.456242 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=statefulset-5122 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0902 07:32:46.722322 16 builder.go:156] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0902 07:32:46.722402 16 builder.go:157] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0902 07:32:46.722428 16 rest.go:280] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0902 07:32:46.723062 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=statefulset-5122 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0902 07:32:46.999080 16 builder.go:156] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0902 07:32:46.999170 16 builder.go:157] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0902 07:32:46.999195 16 rest.go:280] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0902 07:32:46.999239 16 wait.go:109] Waiting for statefulset status.readyReplicas updated to 0
  I0902 07:32:47.008092 16 wait.go:122] Waiting for statefulset status.readyReplicas to become 0, currently 2
  I0902 07:32:57.024587 16 wait.go:54] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  I0902 07:32:57.024729 16 wait.go:54] Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
  I0902 07:32:57.024780 16 wait.go:54] Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
  I0902 07:32:57.073129 16 resource.go:151] POD   NODE            PHASE    GRACE  CONDITIONS
  I0902 07:32:57.073307 16 resource.go:158] ss-0  ietha7evai9i-3  Running         [{PodReadyToStartContainers 1 True 0001-01-01 00:00:00 +0000 UTC 2025-09-02 07:32:13 +0000 UTC  } {Initialized 1 True 0001-01-01 00:00:00 +0000 UTC 2025-09-02 07:31:54 +0000 UTC  } {Ready 1 False 0001-01-01 00:00:00 +0000 UTC 2025-09-02 07:32:47 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady 1 False 0001-01-01 00:00:00 +0000 UTC 2025-09-02 07:32:47 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled 1 True 0001-01-01 00:00:00 +0000 UTC 2025-09-02 07:31:54 +0000 UTC  }]
  I0902 07:32:57.073376 16 resource.go:158] ss-1  ietha7evai9i-1  Running         [{PodReadyToStartContainers 1 True 0001-01-01 00:00:00 +0000 UTC 2025-09-02 07:32:40 +0000 UTC  } {Initialized 1 True 0001-01-01 00:00:00 +0000 UTC 2025-09-02 07:32:24 +0000 UTC  } {Ready 1 False 0001-01-01 00:00:00 +0000 UTC 2025-09-02 07:32:46 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady 1 False 0001-01-01 00:00:00 +0000 UTC 2025-09-02 07:32:46 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled 1 True 0001-01-01 00:00:00 +0000 UTC 2025-09-02 07:32:24 +0000 UTC  }]
  I0902 07:32:57.073438 16 resource.go:158] ss-2  ietha7evai9i-2  Running  30s    [{PodReadyToStartContainers 1 True 0001-01-01 00:00:00 +0000 UTC 2025-09-02 07:32:39 +0000 UTC  } {Initialized 1 True 0001-01-01 00:00:00 +0000 UTC 2025-09-02 07:32:24 +0000 UTC  } {Ready 1 False 0001-01-01 00:00:00 +0000 UTC 2025-09-02 07:32:47 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady 1 False 0001-01-01 00:00:00 +0000 UTC 2025-09-02 07:32:47 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled 1 True 0001-01-01 00:00:00 +0000 UTC 2025-09-02 07:32:24 +0000 UTC  }]
  I0902 07:32:57.073456 16 resource.go:161] 
  I0902 07:32:57.073475 16 statefulset.go:2410] StatefulSet ss has not reached scale 0, at 3
  I0902 07:32:58.090511 16 resource.go:151] POD   NODE            PHASE      GRACE  CONDITIONS
  I0902 07:32:58.090665 16 resource.go:158] ss-0  ietha7evai9i-3  Succeeded  30s    [{PodReadyToStartContainers 2 False 0001-01-01 00:00:00 +0000 UTC 2025-09-02 07:32:57 +0000 UTC  } {Initialized 2 True 0001-01-01 00:00:00 +0000 UTC 2025-09-02 07:31:54 +0000 UTC PodCompleted } {Ready 2 False 0001-01-01 00:00:00 +0000 UTC 2025-09-02 07:32:47 +0000 UTC PodCompleted } {ContainersReady 2 False 0001-01-01 00:00:00 +0000 UTC 2025-09-02 07:32:47 +0000 UTC PodCompleted } {PodScheduled 2 True 0001-01-01 00:00:00 +0000 UTC 2025-09-02 07:31:54 +0000 UTC  }]
  I0902 07:32:58.090719 16 resource.go:158] ss-1  ietha7evai9i-1  Succeeded  30s    [{PodReadyToStartContainers 2 False 0001-01-01 00:00:00 +0000 UTC 2025-09-02 07:32:57 +0000 UTC  } {Initialized 2 True 0001-01-01 00:00:00 +0000 UTC 2025-09-02 07:32:24 +0000 UTC PodCompleted } {Ready 2 False 0001-01-01 00:00:00 +0000 UTC 2025-09-02 07:32:46 +0000 UTC PodCompleted } {ContainersReady 2 False 0001-01-01 00:00:00 +0000 UTC 2025-09-02 07:32:46 +0000 UTC PodCompleted } {PodScheduled 2 True 0001-01-01 00:00:00 +0000 UTC 2025-09-02 07:32:24 +0000 UTC  }]
  I0902 07:32:58.090739 16 resource.go:161] 
  I0902 07:32:58.090755 16 statefulset.go:2410] StatefulSet ss has not reached scale 0, at 2
  I0902 07:32:59.100259 16 statefulset.go:2415] Verifying statefulset ss doesn't scale past 0 for another 7.954058609s
  I0902 07:33:00.107622 16 statefulset.go:2415] Verifying statefulset ss doesn't scale past 0 for another 6.944543279s
  I0902 07:33:01.117615 16 statefulset.go:2415] Verifying statefulset ss doesn't scale past 0 for another 5.937137454s
  I0902 07:33:02.127361 16 statefulset.go:2415] Verifying statefulset ss doesn't scale past 0 for another 4.926691583s
  I0902 07:33:03.135674 16 statefulset.go:2415] Verifying statefulset ss doesn't scale past 0 for another 3.91731723s
  I0902 07:33:04.145617 16 statefulset.go:2415] Verifying statefulset ss doesn't scale past 0 for another 2.909067933s
  I0902 07:33:05.154953 16 statefulset.go:2415] Verifying statefulset ss doesn't scale past 0 for another 1.899116916s
  I0902 07:33:06.164457 16 statefulset.go:2415] Verifying statefulset ss doesn't scale past 0 for another 889.75335ms
  STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-5122 @ 09/02/25 07:33:07.164
  I0902 07:33:07.176300 16 rest.go:153] Scaling statefulset ss to 0
  I0902 07:33:07.193526 16 wait.go:159] Waiting for statefulset status.replicas updated to 0
  I0902 07:33:07.202013 16 statefulset.go:136] Deleting all statefulset in ns statefulset-5122
  I0902 07:33:07.210363 16 rest.go:153] Scaling statefulset ss to 0
  I0902 07:33:07.228451 16 wait.go:159] Waiting for statefulset status.replicas updated to 0
  I0902 07:33:07.237162 16 rest.go:91] Deleting statefulset ss
  I0902 07:33:07.274882 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-5122" for this suite. @ 09/02/25 07:33:07.284
• [73.068 seconds]
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:146
  STEP: Creating a kubernetes client @ 09/02/25 07:33:07.305
  I0902 07:33:07.305353 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename custom-resource-definition @ 09/02/25 07:33:07.314
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:33:07.354
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:33:07.365
  I0902 07:33:07.377601 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  I0902 07:33:07.988929 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-9771" for this suite. @ 09/02/25 07:33:08.004
• [0.718 seconds]
------------------------------
SSSSSS
------------------------------
[sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:208
  STEP: Creating a kubernetes client @ 09/02/25 07:33:08.023
  I0902 07:33:08.023200 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename endpointslice @ 09/02/25 07:33:08.028
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:33:08.061
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:33:08.069
  STEP: referencing a single matching pod @ 09/02/25 07:33:16.272
  I0902 07:33:16.292392      16 warnings.go:110] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  STEP: referencing matching pods with named port @ 09/02/25 07:33:16.293
  I0902 07:33:16.308700      16 warnings.go:110] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  STEP: creating empty Endpoints and EndpointSlices for no matching Pods @ 09/02/25 07:33:16.309
  I0902 07:33:16.324234      16 warnings.go:110] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  STEP: recreating EndpointSlices after they've been deleted @ 09/02/25 07:33:16.324
  I0902 07:33:16.374011 16 endpointslice.go:952] EndpointSlice for Service endpointslice-4239/example-named-port not found
  I0902 07:33:18.393594      16 warnings.go:110] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  I0902 07:33:18.394156 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-4239" for this suite. @ 09/02/25 07:33:18.407
• [10.399 seconds]
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update validating webhook configurations with match conditions [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:708
  STEP: Creating a kubernetes client @ 09/02/25 07:33:18.423
  I0902 07:33:18.423433 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename webhook @ 09/02/25 07:33:18.427
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:33:18.458
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:33:18.464
  STEP: Setting up server cert @ 09/02/25 07:33:18.508
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 09/02/25 07:33:19.369
  STEP: Deploying the webhook pod @ 09/02/25 07:33:19.384
  STEP: Wait for the deployment to be ready @ 09/02/25 07:33:19.412
  I0902 07:33:19.430868 16 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 09/02/25 07:33:21.457
  STEP: Verifying the service has paired with the endpoint @ 09/02/25 07:33:21.476
  I0902 07:33:22.479807 16 util.go:419] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: creating a validating webhook with match conditions @ 09/02/25 07:33:22.49
  STEP: verifying the validating webhook match conditions @ 09/02/25 07:33:22.521
  STEP: updating the validating webhook match conditions @ 09/02/25 07:33:22.53
  STEP: verifying the validating webhook match conditions @ 09/02/25 07:33:22.551
  I0902 07:33:22.658118 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-9811" for this suite. @ 09/02/25 07:33:22.67
  STEP: Destroying namespace "webhook-markers-2895" for this suite. @ 09/02/25 07:33:22.687
• [4.279 seconds]
------------------------------
[sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1791
  STEP: Creating a kubernetes client @ 09/02/25 07:33:22.703
  I0902 07:33:22.704026 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename kubectl @ 09/02/25 07:33:22.714
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:33:22.753
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:33:22.764
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 09/02/25 07:33:22.775
  I0902 07:33:22.776360 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-3802 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4'
  I0902 07:33:23.085059 16 builder.go:156] stderr: ""
  I0902 07:33:23.085212 16 builder.go:157] stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: verifying the pod e2e-test-httpd-pod was created @ 09/02/25 07:33:23.085
  I0902 07:33:23.092589 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-3802 delete pods e2e-test-httpd-pod'
  I0902 07:33:25.043372 16 builder.go:156] stderr: ""
  I0902 07:33:25.043464 16 builder.go:157] stdout: "pod \"e2e-test-httpd-pod\" deleted from kubectl-3802 namespace\n"
  I0902 07:33:25.044066 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-3802" for this suite. @ 09/02/25 07:33:25.053
• [2.366 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:197
  STEP: Creating a kubernetes client @ 09/02/25 07:33:25.074
  I0902 07:33:25.074496 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename downward-api @ 09/02/25 07:33:25.078
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:33:25.103
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:33:25.11
  STEP: Creating a pod to test downward api env vars @ 09/02/25 07:33:25.117
  STEP: Saw pod success @ 09/02/25 07:33:31.186
  I0902 07:33:31.195784 16 output.go:207] Trying to get logs from node ietha7evai9i-3 pod downward-api-e6277a7b-c306-40fd-93ef-75055de0d16a container dapi-container: <nil>
  STEP: delete the pod @ 09/02/25 07:33:31.239
  I0902 07:33:31.273261 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-3476" for this suite. @ 09/02/25 07:33:31.284
• [6.225 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/security_context.go:170
  STEP: Creating a kubernetes client @ 09/02/25 07:33:31.299
  I0902 07:33:31.299824 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename security-context @ 09/02/25 07:33:31.303
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:33:31.328
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:33:31.336
  STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser @ 09/02/25 07:33:31.344
  STEP: Saw pod success @ 09/02/25 07:33:35.393
  I0902 07:33:35.403357 16 output.go:207] Trying to get logs from node ietha7evai9i-2 pod security-context-b9f4d9e0-9bbe-4b27-8e6c-90b306ecb098 container test-container: <nil>
  STEP: delete the pod @ 09/02/25 07:33:35.434
  I0902 07:33:35.478473 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-94" for this suite. @ 09/02/25 07:33:35.489
• [4.210 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:170
  STEP: Creating a kubernetes client @ 09/02/25 07:33:35.51
  I0902 07:33:35.510821 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename resourcequota @ 09/02/25 07:33:35.513
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:33:35.534
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:33:35.54
  STEP: Discovering how many secrets are in namespace by default @ 09/02/25 07:33:35.545
  STEP: Counting existing ResourceQuota @ 09/02/25 07:33:40.556
  STEP: Creating a ResourceQuota @ 09/02/25 07:33:45.564
  STEP: Ensuring resource quota status is calculated @ 09/02/25 07:33:45.581
  I0902 07:33:47.604696 16 resource_quota.go:2495] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc0021acf00>: 
          metadata:
            creationTimestamp: "2025-09-02T07:33:45Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: e2e.test
              operation: Update
              time: "2025-09-02T07:33:45Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
                  f:used:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: kube-controller-manager
              operation: Update
              subresource: status
              time: "2025-09-02T07:33:45Z"
            name: test-quota
            namespace: resourcequota-124
            resourceVersion: "12769"
            uid: 22c64745-d3ac-4161-a3ea-088f4c698826
          spec:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "1"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
          status:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "1"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
            used:
              configmaps: "1"
              count/replicasets.apps: "0"
              cpu: "0"
              ephemeral-storage: "0"
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "0"
              gold.storageclass.storage.k8s.io/requests.storage: "0"
              memory: "0"
              persistentvolumeclaims: "0"
              pods: "0"
              replicationcontrollers: "0"
              requests.example.com/dongle: "0"
              requests.storage: "0"
              resourcequotas: "1"
              secrets: "0"
              services: "0"
              services.loadbalancers: "0"
              services.nodeports: "0"
  STEP: Creating a Secret @ 09/02/25 07:33:47.605
  STEP: Ensuring resource quota status captures secret creation @ 09/02/25 07:33:47.634
  I0902 07:33:47.645688 16 resource_quota.go:2495] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc0022a8640>: 
          metadata:
            creationTimestamp: "2025-09-02T07:33:45Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: e2e.test
              operation: Update
              time: "2025-09-02T07:33:45Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
                  f:used:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: kube-controller-manager
              operation: Update
              subresource: status
              time: "2025-09-02T07:33:45Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:used:
                    f:secrets: {}
              manager: kube-apiserver
              operation: Update
              subresource: status
              time: "2025-09-02T07:33:47Z"
            name: test-quota
            namespace: resourcequota-124
            resourceVersion: "12776"
            uid: 22c64745-d3ac-4161-a3ea-088f4c698826
          spec:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "1"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
          status:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "1"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
            used:
              configmaps: "1"
              count/replicasets.apps: "0"
              cpu: "0"
              ephemeral-storage: "0"
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "0"
              gold.storageclass.storage.k8s.io/requests.storage: "0"
              memory: "0"
              persistentvolumeclaims: "0"
              pods: "0"
              replicationcontrollers: "0"
              requests.example.com/dongle: "0"
              requests.storage: "0"
              resourcequotas: "1"
              secrets: "1"
              services: "0"
              services.loadbalancers: "0"
              services.nodeports: "0"
  STEP: Deleting a secret @ 09/02/25 07:33:47.646
  STEP: Ensuring resource quota status released usage @ 09/02/25 07:33:47.664
  I0902 07:33:49.686219 16 resource_quota.go:2495] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc0022a9180>: 
          metadata:
            creationTimestamp: "2025-09-02T07:33:45Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: e2e.test
              operation: Update
              time: "2025-09-02T07:33:45Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
                  f:used:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: kube-controller-manager
              operation: Update
              subresource: status
              time: "2025-09-02T07:33:47Z"
            name: test-quota
            namespace: resourcequota-124
            resourceVersion: "12779"
            uid: 22c64745-d3ac-4161-a3ea-088f4c698826
          spec:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "1"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
          status:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "1"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
            used:
              configmaps: "1"
              count/replicasets.apps: "0"
              cpu: "0"
              ephemeral-storage: "0"
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "0"
              gold.storageclass.storage.k8s.io/requests.storage: "0"
              memory: "0"
              persistentvolumeclaims: "0"
              pods: "0"
              replicationcontrollers: "0"
              requests.example.com/dongle: "0"
              requests.storage: "0"
              resourcequotas: "1"
              secrets: "0"
              services: "0"
              services.loadbalancers: "0"
              services.nodeports: "0"
  I0902 07:33:49.689291 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-124" for this suite. @ 09/02/25 07:33:49.699
• [14.203 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslicemirroring.go:55
  STEP: Creating a kubernetes client @ 09/02/25 07:33:49.721
  I0902 07:33:49.721275 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename endpointslicemirroring @ 09/02/25 07:33:49.724
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:33:49.747
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:33:49.753
  STEP: mirroring a new custom Endpoint @ 09/02/25 07:33:49.784
  I0902 07:33:49.798991      16 warnings.go:110] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  I0902 07:33:49.812758 16 endpointslicemirroring.go:96] Waiting for at least 1 EndpointSlice to exist, got 0
  STEP: mirroring an update to a custom Endpoint @ 09/02/25 07:33:51.826
  I0902 07:33:51.838695      16 warnings.go:110] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  STEP: mirroring deletion of a custom Endpoint @ 09/02/25 07:33:51.866
  I0902 07:33:51.881794      16 warnings.go:110] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  I0902 07:33:51.900884 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslicemirroring-1648" for this suite. @ 09/02/25 07:33:51.929
• [2.228 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:238
  STEP: Creating a kubernetes client @ 09/02/25 07:33:51.953
  I0902 07:33:51.953644 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename crd-publish-openapi @ 09/02/25 07:33:51.958
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:33:52
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:33:52.005
  I0902 07:33:52.013067 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 09/02/25 07:33:55.458
  I0902 07:33:55.459784 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=crd-publish-openapi-3066 --namespace=crd-publish-openapi-3066 create -f -'
  I0902 07:33:55.877390 16 builder.go:156] stderr: ""
  I0902 07:33:55.877506 16 builder.go:157] stdout: "e2e-test-crd-publish-openapi-3066-2996-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
  I0902 07:33:55.878120 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=crd-publish-openapi-3066 --namespace=crd-publish-openapi-3066 delete e2e-test-crd-publish-openapi-3066-2996-crds test-cr'
  I0902 07:33:56.081645 16 builder.go:156] stderr: ""
  I0902 07:33:56.081737 16 builder.go:157] stdout: "e2e-test-crd-publish-openapi-3066-2996-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted from crd-publish-openapi-3066 namespace\n"
  I0902 07:33:56.081936 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=crd-publish-openapi-3066 --namespace=crd-publish-openapi-3066 apply -f -'
  I0902 07:33:56.276866 16 builder.go:156] stderr: ""
  I0902 07:33:56.277206 16 builder.go:157] stdout: "e2e-test-crd-publish-openapi-3066-2996-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
  I0902 07:33:56.277529 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=crd-publish-openapi-3066 --namespace=crd-publish-openapi-3066 delete e2e-test-crd-publish-openapi-3066-2996-crds test-cr'
  I0902 07:33:56.485295 16 builder.go:156] stderr: ""
  I0902 07:33:56.485402 16 builder.go:157] stdout: "e2e-test-crd-publish-openapi-3066-2996-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted from crd-publish-openapi-3066 namespace\n"
  STEP: kubectl explain works to explain CR @ 09/02/25 07:33:56.485
  I0902 07:33:56.485829 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=crd-publish-openapi-3066 explain e2e-test-crd-publish-openapi-3066-2996-crds'
  I0902 07:33:56.656989 16 builder.go:156] stderr: ""
  I0902 07:33:56.657173 16 builder.go:157] stdout: "GROUP:      crd-publish-openapi-test-unknown-in-nested.example.com\nKIND:       e2e-test-crd-publish-openapi-3066-2996-crd\nVERSION:    v1\n\nDESCRIPTION:\n    preserve-unknown-properties in nested field for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Waldo\n\n  status\t<Object>\n    Status of Waldo\n\n\n"
  I0902 07:33:59.326677 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-3066" for this suite. @ 09/02/25 07:33:59.361
• [7.432 seconds]
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:57
  STEP: Creating a kubernetes client @ 09/02/25 07:33:59.385
  I0902 07:33:59.385320 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename configmap @ 09/02/25 07:33:59.387
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:33:59.413
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:33:59.431
  STEP: Creating configMap with name configmap-test-volume-2e09ec7f-462d-451e-b931-3a7ba219c546 @ 09/02/25 07:33:59.443
  STEP: Creating a pod to test consume configMaps @ 09/02/25 07:33:59.455
  STEP: Saw pod success @ 09/02/25 07:34:03.526
  I0902 07:34:03.539160 16 output.go:207] Trying to get logs from node ietha7evai9i-2 pod pod-configmaps-6d747a73-6645-4766-aac8-7f3bf67dab71 container agnhost-container: <nil>
  STEP: delete the pod @ 09/02/25 07:34:03.577
  I0902 07:34:03.616827 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-1621" for this suite. @ 09/02/25 07:34:03.626
• [4.256 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown metadata fields of a typed object [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:115
  STEP: Creating a kubernetes client @ 09/02/25 07:34:03.641
  I0902 07:34:03.641925 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename field-validation @ 09/02/25 07:34:03.644
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:34:03.678
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:34:03.686
  STEP: apply creating a deployment @ 09/02/25 07:34:03.691
  I0902 07:34:03.722748 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-9512" for this suite. @ 09/02/25 07:34:03.732
• [0.110 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:85
  STEP: Creating a kubernetes client @ 09/02/25 07:34:03.759
  I0902 07:34:03.759403 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename pod-network-test @ 09/02/25 07:34:03.762
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:34:03.797
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:34:03.803
  STEP: Performing setup for networking test in namespace pod-network-test-6365 @ 09/02/25 07:34:03.809
  STEP: creating a selector @ 09/02/25 07:34:03.809
  STEP: Creating the service pods in kubernetes @ 09/02/25 07:34:03.809
  I0902 07:34:03.809839 16 helper.go:51] Waiting up to 10m0s for all (but 0) nodes to be schedulable
  STEP: Creating test pods @ 09/02/25 07:34:32.307
  I0902 07:34:34.356734 16 utils.go:803] Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  I0902 07:34:34.356844 16 networking.go:42] Breadth first check of 10.233.64.54 on host 192.168.121.25...
  I0902 07:34:34.374786 16 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.66.154:9080/dial?request=hostname&protocol=http&host=10.233.64.54&port=8083&tries=1'] Namespace:pod-network-test-6365 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0902 07:34:34.374883 16 exec_util.go:68] ExecWithOptions: Clientset creation
  I0902 07:34:34.375051 16 exec_util.go:84] ExecWithOptions: execute(https://10.233.0.1:443/api/v1/namespaces/pod-network-test-6365/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.66.154%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.233.64.54%26port%3D8083%26tries%3D1%27&container=webserver&stderr=true&stdout=true)
  I0902 07:34:34.538350 16 utils.go:356] Waiting for responses: map[]
  I0902 07:34:34.538429 16 utils.go:360] reached 10.233.64.54 after 0/1 tries
  I0902 07:34:34.538479 16 networking.go:42] Breadth first check of 10.233.66.6 on host 192.168.121.46...
  I0902 07:34:34.545154 16 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.66.154:9080/dial?request=hostname&protocol=http&host=10.233.66.6&port=8083&tries=1'] Namespace:pod-network-test-6365 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0902 07:34:34.545221 16 exec_util.go:68] ExecWithOptions: Clientset creation
  I0902 07:34:34.545341 16 exec_util.go:84] ExecWithOptions: execute(https://10.233.0.1:443/api/v1/namespaces/pod-network-test-6365/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.66.154%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.233.66.6%26port%3D8083%26tries%3D1%27&container=webserver&stderr=true&stdout=true)
  I0902 07:34:34.647744 16 utils.go:356] Waiting for responses: map[]
  I0902 07:34:34.647823 16 utils.go:360] reached 10.233.66.6 after 0/1 tries
  I0902 07:34:34.647846 16 networking.go:42] Breadth first check of 10.233.65.191 on host 192.168.121.52...
  I0902 07:34:34.655168 16 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.66.154:9080/dial?request=hostname&protocol=http&host=10.233.65.191&port=8083&tries=1'] Namespace:pod-network-test-6365 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0902 07:34:34.655683 16 exec_util.go:68] ExecWithOptions: Clientset creation
  I0902 07:34:34.656289 16 exec_util.go:84] ExecWithOptions: execute(https://10.233.0.1:443/api/v1/namespaces/pod-network-test-6365/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.66.154%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.233.65.191%26port%3D8083%26tries%3D1%27&container=webserver&stderr=true&stdout=true)
  I0902 07:34:34.761574 16 utils.go:356] Waiting for responses: map[]
  I0902 07:34:34.761647 16 utils.go:360] reached 10.233.65.191 after 0/1 tries
  I0902 07:34:34.761684 16 networking.go:53] Going to retry 0 out of 3 pods....
  I0902 07:34:34.761924 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-6365" for this suite. @ 09/02/25 07:34:34.772
• [31.028 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:169
  STEP: Creating a kubernetes client @ 09/02/25 07:34:34.787
  I0902 07:34:34.787398 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename container-probe @ 09/02/25 07:34:34.789
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:34:34.823
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:34:34.829
  STEP: Creating pod liveness-be65cf17-5ccf-4924-9ad2-7d2996685ba3 in namespace container-probe-5944 @ 09/02/25 07:34:34.833
  STEP: checking the pod's current state and verifying that restartCount is present @ 09/02/25 07:34:36.872
  I0902 07:34:36.879779 16 container_probe.go:1749] Initial restart count of pod liveness-be65cf17-5ccf-4924-9ad2-7d2996685ba3 is 0
  I0902 07:34:36.885768 16 container_probe.go:1759] Get pod liveness-be65cf17-5ccf-4924-9ad2-7d2996685ba3 in namespace container-probe-5944
  I0902 07:34:38.897246 16 container_probe.go:1759] Get pod liveness-be65cf17-5ccf-4924-9ad2-7d2996685ba3 in namespace container-probe-5944
  I0902 07:34:40.914382 16 container_probe.go:1759] Get pod liveness-be65cf17-5ccf-4924-9ad2-7d2996685ba3 in namespace container-probe-5944
  I0902 07:34:42.928767 16 container_probe.go:1759] Get pod liveness-be65cf17-5ccf-4924-9ad2-7d2996685ba3 in namespace container-probe-5944
  I0902 07:34:44.938602 16 container_probe.go:1759] Get pod liveness-be65cf17-5ccf-4924-9ad2-7d2996685ba3 in namespace container-probe-5944
  I0902 07:34:46.946822 16 container_probe.go:1759] Get pod liveness-be65cf17-5ccf-4924-9ad2-7d2996685ba3 in namespace container-probe-5944
  I0902 07:34:48.954884 16 container_probe.go:1759] Get pod liveness-be65cf17-5ccf-4924-9ad2-7d2996685ba3 in namespace container-probe-5944
  I0902 07:34:50.963116 16 container_probe.go:1759] Get pod liveness-be65cf17-5ccf-4924-9ad2-7d2996685ba3 in namespace container-probe-5944
  I0902 07:34:52.988650 16 container_probe.go:1759] Get pod liveness-be65cf17-5ccf-4924-9ad2-7d2996685ba3 in namespace container-probe-5944
  I0902 07:34:54.999851 16 container_probe.go:1759] Get pod liveness-be65cf17-5ccf-4924-9ad2-7d2996685ba3 in namespace container-probe-5944
  I0902 07:34:57.011336 16 container_probe.go:1759] Get pod liveness-be65cf17-5ccf-4924-9ad2-7d2996685ba3 in namespace container-probe-5944
  I0902 07:34:57.011890 16 container_probe.go:1763] Restart count of pod container-probe-5944/liveness-be65cf17-5ccf-4924-9ad2-7d2996685ba3 is now 1 (20.131422862s elapsed)
  STEP: deleting the pod @ 09/02/25 07:34:57.013
  I0902 07:34:57.039774 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-5944" for this suite. @ 09/02/25 07:34:57.051
• [22.284 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should allow to use a pod failure policy to ignore failure matching on DisruptionTarget condition [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:198
  STEP: Creating a kubernetes client @ 09/02/25 07:34:57.073
  I0902 07:34:57.073453 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename job @ 09/02/25 07:34:57.079
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:34:57.12
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:34:57.134
  STEP: Looking for a node to schedule job pods @ 09/02/25 07:34:57.142
  STEP: Creating a job @ 09/02/25 07:34:57.152
  STEP: Waiting for all the pods to be ready @ 09/02/25 07:34:57.168
  STEP: Fetch all running pods @ 09/02/25 07:35:07.278
  STEP: Evict all the Pods @ 09/02/25 07:35:07.287
  STEP: Evicting the running pod: evicted-pod-ignore-on-disruption-condition-0-l7wxd/job-5840 @ 09/02/25 07:35:07.287
  STEP: Evicting the running pod: evicted-pod-ignore-on-disruption-condition-2-kbhbz/job-5840 @ 09/02/25 07:35:07.287
  STEP: Evicting the running pod: evicted-pod-ignore-on-disruption-condition-1-sqtgg/job-5840 @ 09/02/25 07:35:07.287
  STEP: Awaiting for the pod: evicted-pod-ignore-on-disruption-condition-1-sqtgg/job-5840 to be deleted @ 09/02/25 07:35:07.36
  STEP: Awaiting for the pod: evicted-pod-ignore-on-disruption-condition-0-l7wxd/job-5840 to be deleted @ 09/02/25 07:35:07.376
  STEP: Awaiting for the pod: evicted-pod-ignore-on-disruption-condition-2-kbhbz/job-5840 to be deleted @ 09/02/25 07:35:07.389
  STEP: Ensuring job reaches completions @ 09/02/25 07:35:11.447
  I0902 07:35:55.707345 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-5840" for this suite. @ 09/02/25 07:35:55.717
• [58.664 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:46
  STEP: Creating a kubernetes client @ 09/02/25 07:35:55.738
  I0902 07:35:55.738193 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename projected @ 09/02/25 07:35:55.74
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:35:55.766
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:35:55.775
  STEP: Creating projection with secret that has name projected-secret-test-1e673505-5517-4580-8df4-3ddeba62a6c3 @ 09/02/25 07:35:55.781
  STEP: Creating a pod to test consume secrets @ 09/02/25 07:35:55.794
  STEP: Saw pod success @ 09/02/25 07:35:59.849
  I0902 07:35:59.855904 16 output.go:207] Trying to get logs from node ietha7evai9i-2 pod pod-projected-secrets-b4dab5af-c3ab-409f-a4e7-f8fb8f41e037 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 09/02/25 07:35:59.896
  I0902 07:35:59.931740 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6697" for this suite. @ 09/02/25 07:35:59.942
• [4.261 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:257
  STEP: Creating a kubernetes client @ 09/02/25 07:35:59.999
  I0902 07:35:59.999184 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename watch @ 09/02/25 07:36:00.001
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:36:00.025
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:36:00.034
  STEP: creating a watch on configmaps with a certain label @ 09/02/25 07:36:00.039
  STEP: creating a new configmap @ 09/02/25 07:36:00.048
  STEP: modifying the configmap once @ 09/02/25 07:36:00.06
  STEP: changing the label value of the configmap @ 09/02/25 07:36:00.076
  STEP: Expecting to observe a delete notification for the watched object @ 09/02/25 07:36:00.095
  I0902 07:36:00.095478 16 watch.go:426] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-886  933a500c-29ca-4ff4-97fd-3f73020c9420 13423 0 2025-09-02 07:36:00 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2025-09-02 07:36:00 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  I0902 07:36:00.095876 16 watch.go:426] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-886  933a500c-29ca-4ff4-97fd-3f73020c9420 13424 0 2025-09-02 07:36:00 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2025-09-02 07:36:00 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0902 07:36:00.096034 16 watch.go:426] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-886  933a500c-29ca-4ff4-97fd-3f73020c9420 13425 0 2025-09-02 07:36:00 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2025-09-02 07:36:00 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying the configmap a second time @ 09/02/25 07:36:00.096
  STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements @ 09/02/25 07:36:00.114
  STEP: changing the label value of the configmap back @ 09/02/25 07:36:10.114
  STEP: modifying the configmap a third time @ 09/02/25 07:36:10.132
  STEP: deleting the configmap @ 09/02/25 07:36:10.149
  STEP: Expecting to observe an add notification for the watched object when the label value was restored @ 09/02/25 07:36:10.16
  I0902 07:36:10.160820 16 watch.go:426] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-886  933a500c-29ca-4ff4-97fd-3f73020c9420 13508 0 2025-09-02 07:36:00 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2025-09-02 07:36:10 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0902 07:36:10.161256 16 watch.go:426] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-886  933a500c-29ca-4ff4-97fd-3f73020c9420 13510 0 2025-09-02 07:36:00 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2025-09-02 07:36:10 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0902 07:36:10.161615 16 watch.go:426] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-886  933a500c-29ca-4ff4-97fd-3f73020c9420 13511 0 2025-09-02 07:36:00 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2025-09-02 07:36:10 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0902 07:36:10.161902 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-886" for this suite. @ 09/02/25 07:36:10.173
• [10.191 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:194
  STEP: Creating a kubernetes client @ 09/02/25 07:36:10.19
  I0902 07:36:10.190676 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename downward-api @ 09/02/25 07:36:10.193
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:36:10.218
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:36:10.225
  STEP: Creating a pod to test downward API volume plugin @ 09/02/25 07:36:10.228
  STEP: Saw pod success @ 09/02/25 07:36:14.278
  I0902 07:36:14.285178 16 output.go:207] Trying to get logs from node ietha7evai9i-3 pod downwardapi-volume-a51a165c-dfe4-4db3-a066-813cc1503582 container client-container: <nil>
  STEP: delete the pod @ 09/02/25 07:36:14.322
  I0902 07:36:14.368194 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-5594" for this suite. @ 09/02/25 07:36:14.381
• [4.204 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should delete a job [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:888
  STEP: Creating a kubernetes client @ 09/02/25 07:36:14.397
  I0902 07:36:14.398282 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename job @ 09/02/25 07:36:14.404
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:36:14.431
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:36:14.445
  STEP: Creating a job @ 09/02/25 07:36:14.451
  STEP: Ensuring active pods == parallelism @ 09/02/25 07:36:14.462
  STEP: delete a job @ 09/02/25 07:36:16.485
  STEP: deleting Job.batch foo in namespace job-360, will wait for the garbage collector to delete the pods @ 09/02/25 07:36:16.485
  I0902 07:36:16.564748 16 resources.go:139] Deleting Job.batch foo took: 15.881755ms
  I0902 07:36:16.665482 16 resources.go:163] Terminating Job.batch foo pods took: 100.712179ms
  STEP: Ensuring job was deleted @ 09/02/25 07:36:18.366
  I0902 07:36:18.376385 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-360" for this suite. @ 09/02/25 07:36:18.386
• [4.002 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment deployment should delete old replica sets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:122
  STEP: Creating a kubernetes client @ 09/02/25 07:36:18.399
  I0902 07:36:18.399613 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename deployment @ 09/02/25 07:36:18.401
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:36:18.428
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:36:18.433
  I0902 07:36:18.464166 16 resource.go:64] Pod name cleanup-pod: Found 0 pods out of 1
  I0902 07:36:23.478382 16 resource.go:64] Pod name cleanup-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 09/02/25 07:36:23.478
  I0902 07:36:23.478695 16 deployment.go:854] Creating deployment test-cleanup-deployment
  STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up @ 09/02/25 07:36:23.52
  I0902 07:36:25.583985 16 deployment.go:632] Deployment "test-cleanup-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=23) "test-cleanup-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-3034",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "f1d8ead5-7e74-42c9-bed6-cf59465d71fa",
      ResourceVersion: (string) (len=5) "13682",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63892395383,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892395383,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=637) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 61  67 6e 68 6f 73 74 5c 22  |me\":\"agnhost\"|
              00000160  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000170  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000180  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000190  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              000001a0  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              000001b0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001c0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              000001d0  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              000001e0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001f0  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000200  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              00000210  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              00000220  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              00000230  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000270  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892395385,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=11) "cleanup-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=11) "cleanup-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.56",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          HostnameOverride: (*string)(<nil>)
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(0),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      TerminatingReplicas: (*int32)(<nil>),
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892395383,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892395383,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892395384,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892395383,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=76) "ReplicaSet \"test-cleanup-deployment-7bc8b8949b\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0902 07:36:25.595126 16 deployment.go:40] New ReplicaSet "test-cleanup-deployment-7bc8b8949b" of Deployment "test-cleanup-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=34) "test-cleanup-deployment-7bc8b8949b",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-3034",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "09ec8ba7-ad21-44de-ae8c-0e1098d3bda1",
      ResourceVersion: (string) (len=5) "13671",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63892395383,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "7bc8b8949b"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=23) "test-cleanup-deployment",
          UID: (types.UID) (len=36) "f1d8ead5-7e74-42c9-bed6-cf59465d71fa",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892395383,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 66 31 64 38 65 61  64 35 2d 37 65 37 34 2d  |\"f1d8ead5-7e74-|
              00000120  34 32 63 39 2d 62 65 64  36 2d 63 66 35 39 34 36  |42c9-bed6-cf5946|
              00000130  35 64 37 31 66 61 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |5d71fa\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892395384,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=17) "pod-template-hash": (string) (len=10) "7bc8b8949b",
          (string) (len=4) "name": (string) (len=11) "cleanup-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=17) "pod-template-hash": (string) (len=10) "7bc8b8949b",
            (string) (len=4) "name": (string) (len=11) "cleanup-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.56",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          HostnameOverride: (*string)(<nil>)
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      TerminatingReplicas: (*int32)(<nil>),
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0902 07:36:25.606536 16 deployment.go:68] Pod "test-cleanup-deployment-7bc8b8949b-m24k9" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=40) "test-cleanup-deployment-7bc8b8949b-m24k9",
      GenerateName: (string) (len=35) "test-cleanup-deployment-7bc8b8949b-",
      Namespace: (string) (len=15) "deployment-3034",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "ab349b2d-bd9c-4b4e-a7e9-da9f29d3e6c3",
      ResourceVersion: (string) (len=5) "13670",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63892395383,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "7bc8b8949b",
        (string) (len=4) "name": (string) (len=11) "cleanup-pod"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=34) "test-cleanup-deployment-7bc8b8949b",
          UID: (types.UID) (len=36) "09ec8ba7-ad21-44de-ae8c-0e1098d3bda1",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892395383,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 30 39  65 63 38 62 61 37 2d 61  |d\":\"09ec8ba7-a|
              00000090  64 32 31 2d 34 34 64 65  2d 61 65 38 63 2d 30 65  |d21-44de-ae8c-0e|
              000000a0  31 30 39 38 64 33 62 64  61 31 5c 22 7d 22 3a 7b  |1098d3bda1\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892395384,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=852) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6f 62 73 65 72 76  |me":{},"f:observ|
              00000080  65 64 47 65 6e 65 72 61  74 69 6f 6e 22 3a 7b 7d  |edGeneration":{}|
              00000090  2c 22 66 3a 73 74 61 74  75 73 22 3a 7b 7d 2c 22  |,"f:status":{},"|
              000000a0  66 3a 74 79 70 65 22 3a  7b 7d 7d 2c 22 6b 3a 7b  |f:type":{}},"k:{|
              000000b0  5c 22 74 79 70 65 5c 22  3a 5c 22 49 6e 69 74 69  |\"type\":\"Initi|
              000000c0  61 6c 69 7a 65 64 5c 22  7d 22 3a 7b 22 2e 22 3a  |alized\"}":{".":|
              000000d0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000000f0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              00000100  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000110  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |eration":{},"f:s|
              00000120  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000130  65 22 3a 7b 7d 7d 2c 22  6b 3a 7b 5c 22 74 79 70  |e":{}},"k:{\"typ|
              00000140  65 5c 22 3a 5c 22 50 6f  64 52 65 61 64 79 54 6f  |e\":\"PodReadyTo|
              00000150  53 74 61 72 74 43 6f 6e  74 61 69 6e 65 72 73 5c  |StartContainers\|
              00000160  22 7d 22 3a 7b 22 2e 22  3a 7b 7d 2c 22 66 3a 6c  |"}":{".":{},"f:l|
              00000170  61 73 74 50 72 6f 62 65  54 69 6d 65 22 3a 7b 7d  |astProbeTime":{}|
              00000180  2c 22 66 3a 6c 61 73 74  54 72 61 6e 73 69 74 69  |,"f:lastTransiti|
              00000190  6f 6e 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6f 62  |onTime":{},"f:ob|
              000001a0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001b0  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              000001c0  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              000001d0  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              000001e0  6f 64 53 63 68 65 64 75  6c 65 64 5c 22 7d 22 3a  |odScheduled\"}":|
              000001f0  7b 22 66 3a 6f 62 73 65  72 76 65 64 47 65 6e 65  |{"f:observedGene|
              00000200  72 61 74 69 6f 6e 22 3a  7b 7d 7d 2c 22 6b 3a 7b  |ration":{}},"k:{|
              00000210  5c 22 74 79 70 65 5c 22  3a 5c 22 52 65 61 64 79  |\"type\":\"Ready|
              00000220  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000230  6c 61 73 74 50 72 6f 62  65 54 69 6d 65 22 3a 7b  |lastProbeTime":{|
              00000240  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000250  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6f  |ionTime":{},"f:o|
              00000260  62 73 65 72 76 65 64 47  65 6e 65 72 61 74 69 6f  |bservedGeneratio|
              00000270  6e 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |n":{},"f:status"|
              00000280  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000290  7d 2c 22 66 3a 63 6f 6e  74 61 69 6e 65 72 53 74  |},"f:containerSt|
              000002a0  61 74 75 73 65 73 22 3a  7b 7d 2c 22 66 3a 68 6f  |atuses":{},"f:ho|
              000002b0  73 74 49 50 22 3a 7b 7d  2c 22 66 3a 68 6f 73 74  |stIP":{},"f:host|
              000002c0  49 50 73 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |IPs":{},"f:obser|
              000002d0  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000002e0  7d 2c 22 66 3a 70 68 61  73 65 22 3a 7b 7d 2c 22  |},"f:phase":{},"|
              000002f0  66 3a 70 6f 64 49 50 22  3a 7b 7d 2c 22 66 3a 70  |f:podIP":{},"f:p|
              00000300  6f 64 49 50 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |odIPs":{".":{},"|
              00000310  6b 3a 7b 5c 22 69 70 5c  22 3a 5c 22 31 30 2e 32  |k:{\"ip\":\"10.2|
              00000320  33 33 2e 36 35 2e 32 32  35 5c 22 7d 22 3a 7b 22  |33.65.225\"}":{"|
              00000330  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              00000340  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              00000350  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-xvctv",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.56",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-xvctv",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "ietha7evai9i-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 1,
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892395384,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892395383,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892395384,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892395384,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892395383,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.52",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.121.52"
        }
      },
      PodIP: (string) (len=13) "10.233.65.225",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "10.233.65.225"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63892395383,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63892395384,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.56",
          ImageID: (string) (len=111) "registry.k8s.io/e2e-test-images/agnhost@sha256:30ffacb713aad721881f1c11a768df228bfad3dc366d268e82b02fc43511dfa4",
          ContainerID: (string) (len=72) "cri-o://630ce87aceb7e6842017bc3ceb3584c66508b2f914bce539acc5e97b8d477942",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)({
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          }),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-xvctv",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)({
            Linux: (*v1.LinuxContainerUser)({
              UID: (int64) 0,
              GID: (int64) 0,
              SupplementalGroups: ([]int64) (len=11) {
                (int64) 0,
                (int64) 1,
                (int64) 2,
                (int64) 3,
                (int64) 4,
                (int64) 6,
                (int64) 10,
                (int64) 11,
                (int64) 20,
                (int64) 26,
                (int64) 27
              }
            })
          }),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>)
    }
  }

  I0902 07:36:25.609997 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-3034" for this suite. @ 09/02/25 07:36:25.619
• [7.234 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for services [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:152
  STEP: Creating a kubernetes client @ 09/02/25 07:36:25.634
  I0902 07:36:25.634047 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename dns @ 09/02/25 07:36:25.636
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:36:25.665
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:36:25.672
  STEP: Creating a test headless service @ 09/02/25 07:36:25.678
  I0902 07:36:25.690102      16 warnings.go:110] "Warning: spec.SessionAffinity is ignored for headless services"
  STEP: Running these commands on agnhost: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9947.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/agnhost_udp@dns-test-service.dns-9947.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9947.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/agnhost_tcp@dns-test-service.dns-9947.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-9947.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/agnhost_udp@_http._tcp.dns-test-service.dns-9947.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-9947.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/agnhost_tcp@_http._tcp.dns-test-service.dns-9947.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-9947.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/agnhost_udp@_http._tcp.test-service-2.dns-9947.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-9947.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/agnhost_tcp@_http._tcp.test-service-2.dns-9947.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 72.20.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.20.72_udp@PTR;check="$$(dig +tcp +noall +answer +search 72.20.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.20.72_tcp@PTR;sleep 1; done
   @ 09/02/25 07:36:25.725
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9947.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-9947.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9947.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-9947.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-9947.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-9947.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-9947.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-9947.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-9947.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-9947.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-9947.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-9947.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 72.20.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.20.72_udp@PTR;check="$$(dig +tcp +noall +answer +search 72.20.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.20.72_tcp@PTR;sleep 1; done
   @ 09/02/25 07:36:25.725
  STEP: creating a pod to probe DNS @ 09/02/25 07:36:25.725
  STEP: submitting the pod to kubernetes @ 09/02/25 07:36:25.726
  STEP: retrieving the pod @ 09/02/25 07:36:49.948
  STEP: looking for the results for each expected name from probers @ 09/02/25 07:36:49.958
  I0902 07:36:50.096883 16 dns_common.go:546] DNS probes using dns-9947/dns-test-bc3153eb-bc68-44d7-9041-e6fbffeaed84 succeeded

  STEP: deleting the pod @ 09/02/25 07:36:50.097
  STEP: deleting the test service @ 09/02/25 07:36:50.125
  STEP: deleting the test headless service @ 09/02/25 07:36:50.225
  I0902 07:36:50.252266 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-9947" for this suite. @ 09/02/25 07:36:50.266
• [24.651 seconds]
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:189
  STEP: Creating a kubernetes client @ 09/02/25 07:36:50.285
  I0902 07:36:50.285368 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename emptydir @ 09/02/25 07:36:50.288
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:36:50.313
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:36:50.319
  STEP: Creating a pod to test emptydir 0777 on node default medium @ 09/02/25 07:36:50.323
  STEP: Saw pod success @ 09/02/25 07:36:54.388
  I0902 07:36:54.403396 16 output.go:207] Trying to get logs from node ietha7evai9i-2 pod pod-7fe9f5c0-637d-4eb7-b35f-603f4af3d3d2 container test-container: <nil>
  STEP: delete the pod @ 09/02/25 07:36:54.422
  I0902 07:36:54.468638 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-7275" for this suite. @ 09/02/25 07:36:54.482
• [4.218 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] Deployment deployment should support rollover [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:132
  STEP: Creating a kubernetes client @ 09/02/25 07:36:54.503
  I0902 07:36:54.503756 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename deployment @ 09/02/25 07:36:54.51
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:36:54.562
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:36:54.571
  I0902 07:36:54.618880 16 resource.go:64] Pod name rollover-pod: Found 0 pods out of 1
  I0902 07:36:59.691780 16 resource.go:64] Pod name rollover-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 09/02/25 07:36:59.693
  I0902 07:36:59.695071 16 deployment.go:930] Waiting for pods owned by replica set "test-rollover-controller" to become ready
  I0902 07:37:01.716736 16 deployment.go:940] Creating deployment "test-rollover-deployment"
  I0902 07:37:01.738480 16 deployment.go:953] Make sure deployment "test-rollover-deployment" performs scaling operations
  I0902 07:37:03.753414 16 deployment.go:958] Check revision of new replica set for deployment "test-rollover-deployment"
  I0902 07:37:03.771350 16 deployment.go:962] Ensure that both replica sets have 1 created replica
  I0902 07:37:03.786027 16 deployment.go:971] Rollover old replica sets for deployment "test-rollover-deployment" with new image update
  I0902 07:37:03.813798 16 deployment.go:314] Updating deployment test-rollover-deployment
  I0902 07:37:03.813910 16 deployment.go:980] Wait deployment "test-rollover-deployment" to be observed by the deployment controller
  I0902 07:37:05.832432 16 deployment.go:985] Wait for revision update of deployment "test-rollover-deployment" to 2
  I0902 07:37:05.848921 16 deployment.go:989] Make sure deployment "test-rollover-deployment" is complete
  I0902 07:37:05.863863 16 deployment.go:95] all replica sets need to contain the pod-template-hash label
  I0902 07:37:05.864385 16 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2025, time.September, 2, 7, 37, 1, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 7, 37, 1, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.September, 2, 7, 37, 5, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 7, 37, 1, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b97b67475\" is progressing."}}, CollisionCount:(*int32)(nil)}
  I0902 07:37:07.878769 16 deployment.go:95] all replica sets need to contain the pod-template-hash label
  I0902 07:37:07.878956 16 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2025, time.September, 2, 7, 37, 1, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 7, 37, 1, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.September, 2, 7, 37, 5, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 7, 37, 1, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b97b67475\" is progressing."}}, CollisionCount:(*int32)(nil)}
  I0902 07:37:09.889335 16 deployment.go:95] all replica sets need to contain the pod-template-hash label
  I0902 07:37:09.889836 16 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2025, time.September, 2, 7, 37, 1, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 7, 37, 1, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.September, 2, 7, 37, 5, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 7, 37, 1, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b97b67475\" is progressing."}}, CollisionCount:(*int32)(nil)}
  I0902 07:37:11.887979 16 deployment.go:95] all replica sets need to contain the pod-template-hash label
  I0902 07:37:11.888115 16 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2025, time.September, 2, 7, 37, 1, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 7, 37, 1, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.September, 2, 7, 37, 5, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 7, 37, 1, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b97b67475\" is progressing."}}, CollisionCount:(*int32)(nil)}
  I0902 07:37:13.880620 16 deployment.go:95] all replica sets need to contain the pod-template-hash label
  I0902 07:37:13.880741 16 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2025, time.September, 2, 7, 37, 1, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 7, 37, 1, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.September, 2, 7, 37, 5, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 7, 37, 1, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b97b67475\" is progressing."}}, CollisionCount:(*int32)(nil)}
  I0902 07:37:15.883223 16 deployment.go:95] 
  I0902 07:37:15.883340 16 deployment.go:993] Ensure that both old replica sets have no replicas
  I0902 07:37:15.919372 16 deployment.go:632] Deployment "test-rollover-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-rollover-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-6080",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "24251f78-924d-45c6-b76a-dd8d5c08e857",
      ResourceVersion: (string) (len=5) "13996",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63892395421,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892395423,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000040  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000050  2c 22 66 3a 70 72 6f 67  72 65 73 73 44 65 61 64  |,"f:progressDead|
              00000060  6c 69 6e 65 53 65 63 6f  6e 64 73 22 3a 7b 7d 2c  |lineSeconds":{},|
              00000070  22 66 3a 72 65 70 6c 69  63 61 73 22 3a 7b 7d 2c  |"f:replicas":{},|
              00000080  22 66 3a 72 65 76 69 73  69 6f 6e 48 69 73 74 6f  |"f:revisionHisto|
              00000090  72 79 4c 69 6d 69 74 22  3a 7b 7d 2c 22 66 3a 73  |ryLimit":{},"f:s|
              000000a0  65 6c 65 63 74 6f 72 22  3a 7b 7d 2c 22 66 3a 73  |elector":{},"f:s|
              000000b0  74 72 61 74 65 67 79 22  3a 7b 22 66 3a 72 6f 6c  |trategy":{"f:rol|
              000000c0  6c 69 6e 67 55 70 64 61  74 65 22 3a 7b 22 2e 22  |lingUpdate":{"."|
              000000d0  3a 7b 7d 2c 22 66 3a 6d  61 78 53 75 72 67 65 22  |:{},"f:maxSurge"|
              000000e0  3a 7b 7d 2c 22 66 3a 6d  61 78 55 6e 61 76 61 69  |:{},"f:maxUnavai|
              000000f0  6c 61 62 6c 65 22 3a 7b  7d 7d 2c 22 66 3a 74 79  |lable":{}},"f:ty|
              00000100  70 65 22 3a 7b 7d 7d 2c  22 66 3a 74 65 6d 70 6c  |pe":{}},"f:templ|
              00000110  61 74 65 22 3a 7b 22 66  3a 6d 65 74 61 64 61 74  |ate":{"f:metadat|
              00000120  61 22 3a 7b 22 66 3a 6c  61 62 65 6c 73 22 3a 7b  |a":{"f:labels":{|
              00000130  22 2e 22 3a 7b 7d 2c 22  66 3a 6e 61 6d 65 22 3a  |".":{},"f:name":|
              00000140  7b 7d 7d 7d 2c 22 66 3a  73 70 65 63 22 3a 7b 22  |{}}},"f:spec":{"|
              00000150  66 3a 63 6f 6e 74 61 69  6e 65 72 73 22 3a 7b 22  |f:containers":{"|
              00000160  6b 3a 7b 5c 22 6e 61 6d  65 5c 22 3a 5c 22 61 67  |k:{\"name\":\"ag|
              00000170  6e 68 6f 73 74 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |nhost\"}":{".":{|
              00000180  7d 2c 22 66 3a 69 6d 61  67 65 22 3a 7b 7d 2c 22  |},"f:image":{},"|
              00000190  66 3a 69 6d 61 67 65 50  75 6c 6c 50 6f 6c 69 63  |f:imagePullPolic|
              000001a0  79 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |y":{},"f:name":{|
              000001b0  7d 2c 22 66 3a 72 65 73  6f 75 72 63 65 73 22 3a  |},"f:resources":|
              000001c0  7b 7d 2c 22 66 3a 73 65  63 75 72 69 74 79 43 6f  |{},"f:securityCo|
              000001d0  6e 74 65 78 74 22 3a 7b  7d 2c 22 66 3a 74 65 72  |ntext":{},"f:ter|
              000001e0  6d 69 6e 61 74 69 6f 6e  4d 65 73 73 61 67 65 50  |minationMessageP|
              000001f0  61 74 68 22 3a 7b 7d 2c  22 66 3a 74 65 72 6d 69  |ath":{},"f:termi|
              00000200  6e 61 74 69 6f 6e 4d 65  73 73 61 67 65 50 6f 6c  |nationMessagePol|
              00000210  69 63 79 22 3a 7b 7d 7d  7d 2c 22 66 3a 64 6e 73  |icy":{}}},"f:dns|
              00000220  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 72 65  |Policy":{},"f:re|
              00000230  73 74 61 72 74 50 6f 6c  69 63 79 22 3a 7b 7d 2c  |startPolicy":{},|
              00000240  22 66 3a 73 63 68 65 64  75 6c 65 72 4e 61 6d 65  |"f:schedulerName|
              00000250  22 3a 7b 7d 2c 22 66 3a  73 65 63 75 72 69 74 79  |":{},"f:security|
              00000260  43 6f 6e 74 65 78 74 22  3a 7b 7d 2c 22 66 3a 74  |Context":{},"f:t|
              00000270  65 72 6d 69 6e 61 74 69  6f 6e 47 72 61 63 65 50  |erminationGraceP|
              00000280  65 72 69 6f 64 53 65 63  6f 6e 64 73 22 3a 7b 7d  |eriodSeconds":{}|
              00000290  7d 7d 7d 7d                                       |}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892395435,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.56",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          HostnameOverride: (*string)(<nil>)
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 0,
            StrVal: (string) ""
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 1,
            StrVal: (string) ""
          })
        })
      },
      MinReadySeconds: (int32) 10,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      TerminatingReplicas: (*int32)(<nil>),
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892395421,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892395421,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892395435,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892395421,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=77) "ReplicaSet \"test-rollover-deployment-5b97b67475\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0902 07:37:15.942846 16 deployment.go:40] New ReplicaSet "test-rollover-deployment-5b97b67475" of Deployment "test-rollover-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-rollover-deployment-5b97b67475",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-6080",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "9341fda0-783a-4edb-b880-9e051741bdad",
      ResourceVersion: (string) (len=5) "13984",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63892395423,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "5b97b67475"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2",
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "24251f78-924d-45c6-b76a-dd8d5c08e857",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892395423,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=806) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 32 34 32 35 31 66  37 38 2d 39 32 34 64 2d  |\"24251f78-924d-|
              00000120  34 35 63 36 2d 62 37 36  61 2d 64 64 38 64 35 63  |45c6-b76a-dd8d5c|
              00000130  30 38 65 38 35 37 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |08e857\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000150  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000160  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000170  2c 22 66 3a 73 65 6c 65  63 74 6f 72 22 3a 7b 7d  |,"f:selector":{}|
              00000180  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000190  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              000001a0  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              000001b0  22 66 3a 6e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 70  |"f:name":{},"f:p|
              000001c0  6f 64 2d 74 65 6d 70 6c  61 74 65 2d 68 61 73 68  |od-template-hash|
              000001d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000001e0  7b 22 66 3a 63 6f 6e 74  61 69 6e 65 72 73 22 3a  |{"f:containers":|
              000001f0  7b 22 6b 3a 7b 5c 22 6e  61 6d 65 5c 22 3a 5c 22  |{"k:{\"name\":\"|
              00000200  61 67 6e 68 6f 73 74 5c  22 7d 22 3a 7b 22 2e 22  |agnhost\"}":{"."|
              00000210  3a 7b 7d 2c 22 66 3a 69  6d 61 67 65 22 3a 7b 7d  |:{},"f:image":{}|
              00000220  2c 22 66 3a 69 6d 61 67  65 50 75 6c 6c 50 6f 6c  |,"f:imagePullPol|
              00000230  69 63 79 22 3a 7b 7d 2c  22 66 3a 6e 61 6d 65 22  |icy":{},"f:name"|
              00000240  3a 7b 7d 2c 22 66 3a 72  65 73 6f 75 72 63 65 73  |:{},"f:resources|
              00000250  22 3a 7b 7d 2c 22 66 3a  73 65 63 75 72 69 74 79  |":{},"f:security|
              00000260  43 6f 6e 74 65 78 74 22  3a 7b 7d 2c 22 66 3a 74  |Context":{},"f:t|
              00000270  65 72 6d 69 6e 61 74 69  6f 6e 4d 65 73 73 61 67  |erminationMessag|
              00000280  65 50 61 74 68 22 3a 7b  7d 2c 22 66 3a 74 65 72  |ePath":{},"f:ter|
              00000290  6d 69 6e 61 74 69 6f 6e  4d 65 73 73 61 67 65 50  |minationMessageP|
              000002a0  6f 6c 69 63 79 22 3a 7b  7d 7d 7d 2c 22 66 3a 64  |olicy":{}}},"f:d|
              000002b0  6e 73 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |nsPolicy":{},"f:|
              000002c0  72 65 73 74 61 72 74 50  6f 6c 69 63 79 22 3a 7b  |restartPolicy":{|
              000002d0  7d 2c 22 66 3a 73 63 68  65 64 75 6c 65 72 4e 61  |},"f:schedulerNa|
              000002e0  6d 65 22 3a 7b 7d 2c 22  66 3a 73 65 63 75 72 69  |me":{},"f:securi|
              000002f0  74 79 43 6f 6e 74 65 78  74 22 3a 7b 7d 2c 22 66  |tyContext":{},"f|
              00000300  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 47 72 61 63  |:terminationGrac|
              00000310  65 50 65 72 69 6f 64 53  65 63 6f 6e 64 73 22 3a  |ePeriodSeconds":|
              00000320  7b 7d 7d 7d 7d 7d                                 |{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892395435,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 10,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "5b97b67475"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "5b97b67475"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.56",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          HostnameOverride: (*string)(<nil>)
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      TerminatingReplicas: (*int32)(<nil>),
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0902 07:37:15.953700 16 deployment.go:45] All old ReplicaSets of Deployment "test-rollover-deployment":
  I0902 07:37:15.954205 16 deployment.go:48] (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-rollover-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-6080",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "8110e331-2e48-4255-9b93-d1b3687dfd6f",
      ResourceVersion: (string) (len=5) "13995",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63892395414,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=2) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "24251f78-924d-45c6-b76a-dd8d5c08e857",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892395414,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=467) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              00000030  3a 70 6f 64 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |:pod":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  73 65 6c 65 63 74 6f 72  |ec":{"f:selector|
              00000050  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000060  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000070  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              00000080  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              00000090  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              000000a0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              000000b0  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              000000c0  65 5c 22 3a 5c 22 68 74  74 70 64 5c 22 7d 22 3a  |e\":\"httpd\"}":|
              000000d0  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              000000e0  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              000000f0  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000100  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000110  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |rces":{},"f:term|
              00000120  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000130  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000140  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000150  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000160  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 72 65 73  |olicy":{},"f:res|
              00000170  74 61 72 74 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |tartPolicy":{},"|
              00000180  66 3a 73 63 68 65 64 75  6c 65 72 4e 61 6d 65 22  |f:schedulerName"|
              00000190  3a 7b 7d 2c 22 66 3a 73  65 63 75 72 69 74 79 43  |:{},"f:securityC|
              000001a0  6f 6e 74 65 78 74 22 3a  7b 7d 2c 22 66 3a 74 65  |ontext":{},"f:te|
              000001b0  72 6d 69 6e 61 74 69 6f  6e 47 72 61 63 65 50 65  |rminationGracePe|
              000001c0  72 69 6f 64 53 65 63 6f  6e 64 73 22 3a 7b 7d 7d  |riodSeconds":{}}|
              000001d0  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892395435,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=249) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 7d 2c 22 66  3a 6f 77 6e 65 72 52 65  |":{}},"f:ownerRe|
              00000090  66 65 72 65 6e 63 65 73  22 3a 7b 22 2e 22 3a 7b  |ferences":{".":{|
              000000a0  7d 2c 22 6b 3a 7b 5c 22  75 69 64 5c 22 3a 5c 22  |},"k:{\"uid\":\"|
              000000b0  32 34 32 35 31 66 37 38  2d 39 32 34 64 2d 34 35  |24251f78-924d-45|
              000000c0  63 36 2d 62 37 36 61 2d  64 64 38 64 35 63 30 38  |c6-b76a-dd8d5c08|
              000000d0  65 38 35 37 5c 22 7d 22  3a 7b 7d 7d 7d 2c 22 66  |e857\"}":{}}},"f|
              000000e0  3a 73 70 65 63 22 3a 7b  22 66 3a 72 65 70 6c 69  |:spec":{"f:repli|
              000000f0  63 61 73 22 3a 7b 7d 7d  7d                       |cas":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892395435,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod",
          (string) (len=3) "pod": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=3) "pod": (string) (len=5) "httpd",
            (string) (len=4) "name": (string) (len=12) "rollover-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          HostnameOverride: (*string)(<nil>)
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      TerminatingReplicas: (*int32)(<nil>),
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0902 07:37:15.960885 16 deployment.go:48] (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=34) "test-rollover-deployment-8fbb868dd",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-6080",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "9a445e44-3dcd-4368-8140-61bfa8c45d8a",
      ResourceVersion: (string) (len=5) "13949",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63892395421,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=9) "8fbb868dd"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "24251f78-924d-45c6-b76a-dd8d5c08e857",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892395423,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=810) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 32 34 32 35 31 66  37 38 2d 39 32 34 64 2d  |\"24251f78-924d-|
              00000120  34 35 63 36 2d 62 37 36  61 2d 64 64 38 64 35 63  |45c6-b76a-dd8d5c|
              00000130  30 38 65 38 35 37 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |08e857\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000150  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000160  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000170  2c 22 66 3a 73 65 6c 65  63 74 6f 72 22 3a 7b 7d  |,"f:selector":{}|
              00000180  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000190  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              000001a0  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              000001b0  22 66 3a 6e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 70  |"f:name":{},"f:p|
              000001c0  6f 64 2d 74 65 6d 70 6c  61 74 65 2d 68 61 73 68  |od-template-hash|
              000001d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000001e0  7b 22 66 3a 63 6f 6e 74  61 69 6e 65 72 73 22 3a  |{"f:containers":|
              000001f0  7b 22 6b 3a 7b 5c 22 6e  61 6d 65 5c 22 3a 5c 22  |{"k:{\"name\":\"|
              00000200  72 65 64 69 73 2d 73 6c  61 76 65 5c 22 7d 22 3a  |redis-slave\"}":|
              00000210  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              00000220  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              00000230  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000240  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000250  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 73 65 63 75  |rces":{},"f:secu|
              00000260  72 69 74 79 43 6f 6e 74  65 78 74 22 3a 7b 7d 2c  |rityContext":{},|
              00000270  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000280  73 73 61 67 65 50 61 74  68 22 3a 7b 7d 2c 22 66  |ssagePath":{},"f|
              00000290  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 4d 65 73 73  |:terminationMess|
              000002a0  61 67 65 50 6f 6c 69 63  79 22 3a 7b 7d 7d 7d 2c  |agePolicy":{}}},|
              000002b0  22 66 3a 64 6e 73 50 6f  6c 69 63 79 22 3a 7b 7d  |"f:dnsPolicy":{}|
              000002c0  2c 22 66 3a 72 65 73 74  61 72 74 50 6f 6c 69 63  |,"f:restartPolic|
              000002d0  79 22 3a 7b 7d 2c 22 66  3a 73 63 68 65 64 75 6c  |y":{},"f:schedul|
              000002e0  65 72 4e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 73 65  |erName":{},"f:se|
              000002f0  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000300  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000310  47 72 61 63 65 50 65 72  69 6f 64 53 65 63 6f 6e  |GracePeriodSecon|
              00000320  64 73 22 3a 7b 7d 7d 7d  7d 7d                    |ds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892395424,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 10,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=17) "pod-template-hash": (string) (len=9) "8fbb868dd",
          (string) (len=4) "name": (string) (len=12) "rollover-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=17) "pod-template-hash": (string) (len=9) "8fbb868dd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=11) "redis-slave",
              Image: (string) (len=47) "gcr.io/google_samples/gb-redisslave:nonexistent",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          HostnameOverride: (*string)(<nil>)
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      TerminatingReplicas: (*int32)(<nil>),
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0902 07:37:15.980721 16 deployment.go:68] Pod "test-rollover-deployment-5b97b67475-65h8m" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=41) "test-rollover-deployment-5b97b67475-65h8m",
      GenerateName: (string) (len=36) "test-rollover-deployment-5b97b67475-",
      Namespace: (string) (len=15) "deployment-6080",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "60337ab0-2a26-4052-8a70-8cdf3831cae0",
      ResourceVersion: (string) (len=5) "13958",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63892395423,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "5b97b67475"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=35) "test-rollover-deployment-5b97b67475",
          UID: (types.UID) (len=36) "9341fda0-783a-4edb-b880-9e051741bdad",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892395423,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 39 33  34 31 66 64 61 30 2d 37  |d\":\"9341fda0-7|
              00000090  38 33 61 2d 34 65 64 62  2d 62 38 38 30 2d 39 65  |83a-4edb-b880-9e|
              000000a0  30 35 31 37 34 31 62 64  61 64 5c 22 7d 22 3a 7b  |051741bdad\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892395425,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=850) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6f 62 73 65 72 76  |me":{},"f:observ|
              00000080  65 64 47 65 6e 65 72 61  74 69 6f 6e 22 3a 7b 7d  |edGeneration":{}|
              00000090  2c 22 66 3a 73 74 61 74  75 73 22 3a 7b 7d 2c 22  |,"f:status":{},"|
              000000a0  66 3a 74 79 70 65 22 3a  7b 7d 7d 2c 22 6b 3a 7b  |f:type":{}},"k:{|
              000000b0  5c 22 74 79 70 65 5c 22  3a 5c 22 49 6e 69 74 69  |\"type\":\"Initi|
              000000c0  61 6c 69 7a 65 64 5c 22  7d 22 3a 7b 22 2e 22 3a  |alized\"}":{".":|
              000000d0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000000f0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              00000100  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000110  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |eration":{},"f:s|
              00000120  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000130  65 22 3a 7b 7d 7d 2c 22  6b 3a 7b 5c 22 74 79 70  |e":{}},"k:{\"typ|
              00000140  65 5c 22 3a 5c 22 50 6f  64 52 65 61 64 79 54 6f  |e\":\"PodReadyTo|
              00000150  53 74 61 72 74 43 6f 6e  74 61 69 6e 65 72 73 5c  |StartContainers\|
              00000160  22 7d 22 3a 7b 22 2e 22  3a 7b 7d 2c 22 66 3a 6c  |"}":{".":{},"f:l|
              00000170  61 73 74 50 72 6f 62 65  54 69 6d 65 22 3a 7b 7d  |astProbeTime":{}|
              00000180  2c 22 66 3a 6c 61 73 74  54 72 61 6e 73 69 74 69  |,"f:lastTransiti|
              00000190  6f 6e 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6f 62  |onTime":{},"f:ob|
              000001a0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001b0  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              000001c0  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              000001d0  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              000001e0  6f 64 53 63 68 65 64 75  6c 65 64 5c 22 7d 22 3a  |odScheduled\"}":|
              000001f0  7b 22 66 3a 6f 62 73 65  72 76 65 64 47 65 6e 65  |{"f:observedGene|
              00000200  72 61 74 69 6f 6e 22 3a  7b 7d 7d 2c 22 6b 3a 7b  |ration":{}},"k:{|
              00000210  5c 22 74 79 70 65 5c 22  3a 5c 22 52 65 61 64 79  |\"type\":\"Ready|
              00000220  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000230  6c 61 73 74 50 72 6f 62  65 54 69 6d 65 22 3a 7b  |lastProbeTime":{|
              00000240  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000250  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6f  |ionTime":{},"f:o|
              00000260  62 73 65 72 76 65 64 47  65 6e 65 72 61 74 69 6f  |bservedGeneratio|
              00000270  6e 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |n":{},"f:status"|
              00000280  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000290  7d 2c 22 66 3a 63 6f 6e  74 61 69 6e 65 72 53 74  |},"f:containerSt|
              000002a0  61 74 75 73 65 73 22 3a  7b 7d 2c 22 66 3a 68 6f  |atuses":{},"f:ho|
              000002b0  73 74 49 50 22 3a 7b 7d  2c 22 66 3a 68 6f 73 74  |stIP":{},"f:host|
              000002c0  49 50 73 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |IPs":{},"f:obser|
              000002d0  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000002e0  7d 2c 22 66 3a 70 68 61  73 65 22 3a 7b 7d 2c 22  |},"f:phase":{},"|
              000002f0  66 3a 70 6f 64 49 50 22  3a 7b 7d 2c 22 66 3a 70  |f:podIP":{},"f:p|
              00000300  6f 64 49 50 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |odIPs":{".":{},"|
              00000310  6b 3a 7b 5c 22 69 70 5c  22 3a 5c 22 31 30 2e 32  |k:{\"ip\":\"10.2|
              00000320  33 33 2e 36 35 2e 37 5c  22 7d 22 3a 7b 22 2e 22  |33.65.7\"}":{"."|
              00000330  3a 7b 7d 2c 22 66 3a 69  70 22 3a 7b 7d 7d 7d 2c  |:{},"f:ip":{}}},|
              00000340  22 66 3a 73 74 61 72 74  54 69 6d 65 22 3a 7b 7d  |"f:startTime":{}|
              00000350  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-jnzxn",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.56",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-jnzxn",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "ietha7evai9i-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 1,
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892395425,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892395423,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892395425,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892395425,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892395423,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.52",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.121.52"
        }
      },
      PodIP: (string) (len=11) "10.233.65.7",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.233.65.7"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63892395423,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63892395424,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.56",
          ImageID: (string) (len=111) "registry.k8s.io/e2e-test-images/agnhost@sha256:30ffacb713aad721881f1c11a768df228bfad3dc366d268e82b02fc43511dfa4",
          ContainerID: (string) (len=72) "cri-o://0c882a25b7ccc6910b4f64d6e23492f10cb9abc31793df3cfa1fcf46836f6aea",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)({
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          }),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-jnzxn",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)({
            Linux: (*v1.LinuxContainerUser)({
              UID: (int64) 0,
              GID: (int64) 0,
              SupplementalGroups: ([]int64) (len=11) {
                (int64) 0,
                (int64) 1,
                (int64) 2,
                (int64) 3,
                (int64) 4,
                (int64) 6,
                (int64) 10,
                (int64) 11,
                (int64) 20,
                (int64) 26,
                (int64) 27
              }
            })
          }),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>)
    }
  }

  I0902 07:37:15.994976 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-6080" for this suite. @ 09/02/25 07:37:16.005
• [21.519 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:79
  STEP: Creating a kubernetes client @ 09/02/25 07:37:16.03
  I0902 07:37:16.030722 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename subpath @ 09/02/25 07:37:16.035
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:37:16.063
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:37:16.068
  STEP: Setting up data @ 09/02/25 07:37:16.076
  STEP: Creating pod pod-subpath-test-configmap-v2c7 @ 09/02/25 07:37:16.102
  STEP: Creating a pod to test atomic-volume-subpath @ 09/02/25 07:37:16.103
  STEP: Saw pod success @ 09/02/25 07:37:40.258
  I0902 07:37:40.266453 16 output.go:207] Trying to get logs from node ietha7evai9i-2 pod pod-subpath-test-configmap-v2c7 container test-container-subpath-configmap-v2c7: <nil>
  STEP: delete the pod @ 09/02/25 07:37:40.298
  STEP: Deleting pod pod-subpath-test-configmap-v2c7 @ 09/02/25 07:37:40.38
  I0902 07:37:40.381047 16 delete.go:78] Deleting pod "pod-subpath-test-configmap-v2c7" in namespace "subpath-566"
  I0902 07:37:40.396073 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-566" for this suite. @ 09/02/25 07:37:40.407
• [24.399 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] Job should mark indexes as failed when the FailIndex action is matched in podFailurePolicy [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:726
  STEP: Creating a kubernetes client @ 09/02/25 07:37:40.429
  I0902 07:37:40.429817 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename job @ 09/02/25 07:37:40.432
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:37:40.462
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:37:40.467
  STEP: Creating an indexed job with failing pods matching the FailIndex action @ 09/02/25 07:37:40.472
  STEP: Awaiting for the job to fail as all indexes are failed @ 09/02/25 07:37:40.495
  STEP: Verifying the Job status fields to ensure the upper indexes didn't execute @ 09/02/25 07:37:46.55
  I0902 07:37:46.560624 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-3783" for this suite. @ 09/02/25 07:37:46.569
• [6.154 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for pods for Subdomain [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:307
  STEP: Creating a kubernetes client @ 09/02/25 07:37:46.586
  I0902 07:37:46.586164 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename dns @ 09/02/25 07:37:46.591
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:37:46.62
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:37:46.626
  STEP: Creating a test headless service @ 09/02/25 07:37:46.631
  I0902 07:37:46.648241      16 warnings.go:110] "Warning: spec.SessionAffinity is ignored for headless services"
  STEP: Running these commands on agnhost: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9754.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/agnhost_udp@dns-querier-2.dns-test-service-2.dns-9754.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9754.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/agnhost_tcp@dns-querier-2.dns-test-service-2.dns-9754.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-9754.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/agnhost_udp@dns-test-service-2.dns-9754.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-9754.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/agnhost_tcp@dns-test-service-2.dns-9754.svc.cluster.local;sleep 1; done
   @ 09/02/25 07:37:46.649
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9754.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-9754.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9754.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-9754.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-9754.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-9754.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-9754.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-9754.svc.cluster.local;sleep 1; done
   @ 09/02/25 07:37:46.65
  STEP: creating a pod to probe DNS @ 09/02/25 07:37:46.65
  STEP: submitting the pod to kubernetes @ 09/02/25 07:37:46.651
  STEP: retrieving the pod @ 09/02/25 07:37:48.719
  STEP: looking for the results for each expected name from probers @ 09/02/25 07:37:48.73
  I0902 07:37:48.747638 16 dns_common.go:495] Unable to read agnhost_udp@dns-querier-2.dns-test-service-2.dns-9754.svc.cluster.local from pod dns-9754/dns-test-15ab3808-da21-4a58-92f0-08a43e91d188: the server could not find the requested resource (get pods dns-test-15ab3808-da21-4a58-92f0-08a43e91d188)
  I0902 07:37:48.821488 16 dns_common.go:495] Unable to read agnhost_tcp@dns-querier-2.dns-test-service-2.dns-9754.svc.cluster.local from pod dns-9754/dns-test-15ab3808-da21-4a58-92f0-08a43e91d188: the server could not find the requested resource (get pods dns-test-15ab3808-da21-4a58-92f0-08a43e91d188)
  I0902 07:37:48.851637 16 dns_common.go:495] Unable to read agnhost_udp@dns-test-service-2.dns-9754.svc.cluster.local from pod dns-9754/dns-test-15ab3808-da21-4a58-92f0-08a43e91d188: the server could not find the requested resource (get pods dns-test-15ab3808-da21-4a58-92f0-08a43e91d188)
  I0902 07:37:48.882210 16 dns_common.go:495] Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-9754.svc.cluster.local from pod dns-9754/dns-test-15ab3808-da21-4a58-92f0-08a43e91d188: the server could not find the requested resource (get pods dns-test-15ab3808-da21-4a58-92f0-08a43e91d188)
  I0902 07:37:48.934672 16 dns_common.go:506] Lookups using dns-9754/dns-test-15ab3808-da21-4a58-92f0-08a43e91d188 failed for: [agnhost_udp@dns-querier-2.dns-test-service-2.dns-9754.svc.cluster.local agnhost_tcp@dns-querier-2.dns-test-service-2.dns-9754.svc.cluster.local agnhost_udp@dns-test-service-2.dns-9754.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-9754.svc.cluster.local]

  I0902 07:37:48.950964 16 dns_common.go:514] Pod client logs for webserver: 
  I0902 07:37:48.986453 16 dns_common.go:514] Pod client logs for agnhost-querier: 
  I0902 07:37:49.012951 16 dns_common.go:514] Pod client logs for jessie-querier: 
  I0902 07:37:53.834965 16 dns_common.go:546] DNS probes using dns-9754/dns-test-15ab3808-da21-4a58-92f0-08a43e91d188 succeeded

  STEP: deleting the pod @ 09/02/25 07:37:53.835
  STEP: deleting the test headless service @ 09/02/25 07:37:53.9
  I0902 07:37:53.928265 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-9754" for this suite. @ 09/02/25 07:37:53.944
• [7.384 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job with successPolicy succeededIndexes rule should succeeded even when some indexes remain pending [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:524
  STEP: Creating a kubernetes client @ 09/02/25 07:37:53.978
  I0902 07:37:53.978624 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename job @ 09/02/25 07:37:53.981
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:37:54.015
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:37:54.024
  STEP: Creating an indexed job with successPolicy succeededIndexes rule @ 09/02/25 07:37:54.029
  STEP: Awaiting for the job to have the interim SuccessCriteriaMet with SuccessPolicy reason condition @ 09/02/25 07:37:54.042
  STEP: Ensure that the job reaches completions @ 09/02/25 07:38:00.08
  STEP: Verifying that the only appropriately index succeeded @ 09/02/25 07:38:00.102
  I0902 07:38:00.112669 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-2682" for this suite. @ 09/02/25 07:38:00.121
• [6.159 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:334
  STEP: Creating a kubernetes client @ 09/02/25 07:38:00.137
  I0902 07:38:00.137696 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename watch @ 09/02/25 07:38:00.14
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:38:00.169
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:38:00.183
  STEP: getting a starting resourceVersion @ 09/02/25 07:38:00.19
  STEP: starting a background goroutine to produce watch events @ 09/02/25 07:38:00.199
  STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order @ 09/02/25 07:38:00.199
  I0902 07:38:02.956447 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-2139" for this suite. @ 09/02/25 07:38:03.002
• [2.921 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/proxy.go:432
  STEP: Creating a kubernetes client @ 09/02/25 07:38:03.06
  I0902 07:38:03.060658 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename proxy @ 09/02/25 07:38:03.063
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:38:03.085
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:38:03.091
  I0902 07:38:03.098710 16 proxy.go:439] Creating pod...
  I0902 07:38:05.145576 16 proxy.go:463] Creating service...
  I0902 07:38:05.169612 16 proxy.go:500] Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-4642/pods/agnhost/proxy?method=DELETE
  I0902 07:38:05.193705 16 proxy.go:582] http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  I0902 07:38:05.194697 16 proxy.go:500] Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-4642/pods/agnhost/proxy?method=OPTIONS
  I0902 07:38:05.202968 16 proxy.go:582] http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  I0902 07:38:05.203105 16 proxy.go:500] Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-4642/pods/agnhost/proxy?method=PATCH
  I0902 07:38:05.211437 16 proxy.go:582] http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  I0902 07:38:05.211534 16 proxy.go:500] Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-4642/pods/agnhost/proxy?method=POST
  I0902 07:38:05.224167 16 proxy.go:582] http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  I0902 07:38:05.224257 16 proxy.go:500] Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-4642/pods/agnhost/proxy?method=PUT
  I0902 07:38:05.236157 16 proxy.go:582] http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  I0902 07:38:05.236247 16 proxy.go:511] Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-4642/services/e2e-proxy-test-service/proxy?method=DELETE
  I0902 07:38:05.255118 16 proxy.go:582] http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  I0902 07:38:05.255232 16 proxy.go:511] Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-4642/services/e2e-proxy-test-service/proxy?method=OPTIONS
  I0902 07:38:05.267085 16 proxy.go:582] http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  I0902 07:38:05.267169 16 proxy.go:511] Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-4642/services/e2e-proxy-test-service/proxy?method=PATCH
  I0902 07:38:05.286909 16 proxy.go:582] http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  I0902 07:38:05.287619 16 proxy.go:511] Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-4642/services/e2e-proxy-test-service/proxy?method=POST
  I0902 07:38:05.342029 16 proxy.go:582] http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  I0902 07:38:05.342148 16 proxy.go:511] Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-4642/services/e2e-proxy-test-service/proxy?method=PUT
  I0902 07:38:05.360894 16 proxy.go:582] http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  I0902 07:38:05.361501 16 proxy.go:531] Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-4642/pods/agnhost/proxy?method=GET
  I0902 07:38:05.371751 16 proxy.go:539] http.Client request:GET StatusCode:301
  I0902 07:38:05.372698 16 proxy.go:531] Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-4642/services/e2e-proxy-test-service/proxy?method=GET
  I0902 07:38:05.389372 16 proxy.go:539] http.Client request:GET StatusCode:301
  I0902 07:38:05.389489 16 proxy.go:531] Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-4642/pods/agnhost/proxy?method=HEAD
  I0902 07:38:05.397140 16 proxy.go:539] http.Client request:HEAD StatusCode:301
  I0902 07:38:05.397237 16 proxy.go:531] Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-4642/services/e2e-proxy-test-service/proxy?method=HEAD
  I0902 07:38:05.409037 16 proxy.go:539] http.Client request:HEAD StatusCode:301
  I0902 07:38:05.409310 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-4642" for this suite. @ 09/02/25 07:38:05.42
• [2.381 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1113
  STEP: Creating a kubernetes client @ 09/02/25 07:38:05.445
  I0902 07:38:05.445093 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename kubectl @ 09/02/25 07:38:05.45
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:38:05.486
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:38:05.496
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 09/02/25 07:38:05.508
  I0902 07:38:05.508984 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-5583 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
  I0902 07:38:05.784346 16 builder.go:156] stderr: ""
  I0902 07:38:05.784448 16 builder.go:157] stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: replace the image in the pod with server-side dry-run @ 09/02/25 07:38:05.784
  I0902 07:38:05.785957 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-5583 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.37.0-1"}]}} --dry-run=server'
  I0902 07:38:06.019985 16 builder.go:156] stderr: ""
  I0902 07:38:06.020153 16 builder.go:157] stdout: "pod/e2e-test-httpd-pod patched\n"
  STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 09/02/25 07:38:06.02
  I0902 07:38:06.032420 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-5583 delete pods e2e-test-httpd-pod'
  I0902 07:38:08.640684 16 builder.go:156] stderr: ""
  I0902 07:38:08.641032 16 builder.go:157] stdout: "pod \"e2e-test-httpd-pod\" deleted from kubectl-5583 namespace\n"
  I0902 07:38:08.642214 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-5583" for this suite. @ 09/02/25 07:38:08.657
• [3.229 seconds]
------------------------------
SS
------------------------------
[sig-cli] Kubectl client Kubectl label should update the label on a resource [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1659
  STEP: Creating a kubernetes client @ 09/02/25 07:38:08.675
  I0902 07:38:08.675359 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename kubectl @ 09/02/25 07:38:08.678
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:38:08.706
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:38:08.713
  STEP: creating the pod @ 09/02/25 07:38:08.719
  I0902 07:38:08.720126 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-2035 create -f -'
  I0902 07:38:09.106218 16 builder.go:156] stderr: ""
  I0902 07:38:09.106370 16 builder.go:157] stdout: "pod/pause created\n"
  STEP: adding the label testing-label with value testing-label-value to a pod @ 09/02/25 07:38:11.129
  I0902 07:38:11.130042 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-2035 label pods pause testing-label=testing-label-value'
  I0902 07:38:11.323333 16 builder.go:156] stderr: ""
  I0902 07:38:11.323448 16 builder.go:157] stdout: "pod/pause labeled\n"
  STEP: verifying the pod has the label testing-label with the value testing-label-value @ 09/02/25 07:38:11.323
  I0902 07:38:11.324712 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-2035 get pod pause -L testing-label'
  I0902 07:38:11.505471 16 builder.go:156] stderr: ""
  I0902 07:38:11.505611 16 builder.go:157] stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
  STEP: removing the label testing-label of a pod @ 09/02/25 07:38:11.505
  I0902 07:38:11.506015 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-2035 label pods pause testing-label-'
  I0902 07:38:11.711253 16 builder.go:156] stderr: ""
  I0902 07:38:11.711439 16 builder.go:157] stdout: "pod/pause unlabeled\n"
  STEP: verifying the pod doesn't have the label testing-label @ 09/02/25 07:38:11.711
  I0902 07:38:11.712179 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-2035 get pod pause -L testing-label'
  I0902 07:38:11.900155 16 builder.go:156] stderr: ""
  I0902 07:38:11.900457 16 builder.go:157] stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
  STEP: using delete to clean up resources @ 09/02/25 07:38:11.901
  I0902 07:38:11.901952 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-2035 delete --grace-period=0 --force -f -'
  I0902 07:38:12.107738 16 builder.go:156] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0902 07:38:12.107914 16 builder.go:157] stdout: "pod \"pause\" force deleted from kubectl-2035 namespace\n"
  I0902 07:38:12.108172 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-2035 get rc,svc -l name=pause --no-headers'
  I0902 07:38:12.301113 16 builder.go:156] stderr: "No resources found in kubectl-2035 namespace.\n"
  I0902 07:38:12.301406 16 builder.go:157] stdout: ""
  I0902 07:38:12.302007 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-2035 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  I0902 07:38:12.458303 16 builder.go:156] stderr: ""
  I0902 07:38:12.458390 16 builder.go:157] stdout: ""
  I0902 07:38:12.458907 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-2035" for this suite. @ 09/02/25 07:38:12.47
• [3.811 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:155
  STEP: Creating a kubernetes client @ 09/02/25 07:38:12.486
  I0902 07:38:12.486934 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename var-expansion @ 09/02/25 07:38:12.49
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:38:12.517
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:38:12.524
  I0902 07:38:14.579669 16 delete.go:78] Deleting pod "var-expansion-1e025265-f863-453c-a56e-0b82a990e4f6" in namespace "var-expansion-5507"
  I0902 07:38:14.599918 16 delete.go:86] Wait up to 5m0s for pod "var-expansion-1e025265-f863-453c-a56e-0b82a990e4f6" to be fully deleted
  I0902 07:38:16.620356 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-5507" for this suite. @ 09/02/25 07:38:16.631
• [4.162 seconds]
------------------------------
[sig-apps] Deployment should run the lifecycle of a Deployment [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:185
  STEP: Creating a kubernetes client @ 09/02/25 07:38:16.649
  I0902 07:38:16.649686 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename deployment @ 09/02/25 07:38:16.653
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:38:16.683
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:38:16.69
  STEP: creating a Deployment @ 09/02/25 07:38:16.711
  STEP: waiting for Deployment to be created @ 09/02/25 07:38:16.723
  STEP: waiting for all Replicas to be Ready @ 09/02/25 07:38:16.732
  I0902 07:38:16.736214 16 deployment.go:246] observed Deployment test-deployment in namespace deployment-333 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0902 07:38:16.736521 16 deployment.go:248] observed Deployment test-deployment in namespace deployment-333 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0902 07:38:16.800076 16 deployment.go:246] observed Deployment test-deployment in namespace deployment-333 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0902 07:38:16.800426 16 deployment.go:248] observed Deployment test-deployment in namespace deployment-333 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0902 07:38:16.849220 16 deployment.go:246] observed Deployment test-deployment in namespace deployment-333 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0902 07:38:16.849326 16 deployment.go:248] observed Deployment test-deployment in namespace deployment-333 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0902 07:38:16.924126 16 deployment.go:246] observed Deployment test-deployment in namespace deployment-333 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0902 07:38:16.924201 16 deployment.go:248] observed Deployment test-deployment in namespace deployment-333 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0902 07:38:18.734771 16 deployment.go:246] observed Deployment test-deployment in namespace deployment-333 with ReadyReplicas 1 and labels map[test-deployment-static:true]
  I0902 07:38:18.734862 16 deployment.go:248] observed Deployment test-deployment in namespace deployment-333 with ReadyReplicas 1 and labels map[test-deployment-static:true]
  I0902 07:38:18.758109 16 deployment.go:248] observed Deployment test-deployment in namespace deployment-333 with ReadyReplicas 2 and labels map[test-deployment-static:true]
  STEP: patching the Deployment @ 09/02/25 07:38:18.758
  I0902 07:38:18.785225 16 deployment.go:290] observed event type ADDED
  STEP: waiting for Replicas to scale @ 09/02/25 07:38:18.785
  I0902 07:38:18.789989 16 deployment.go:309] observed Deployment test-deployment in namespace deployment-333 with ReadyReplicas 0
  I0902 07:38:18.790118 16 deployment.go:311] observed Deployment test-deployment in namespace deployment-333 with ReadyReplicas 0
  I0902 07:38:18.790148 16 deployment.go:309] observed Deployment test-deployment in namespace deployment-333 with ReadyReplicas 0
  I0902 07:38:18.790216 16 deployment.go:311] observed Deployment test-deployment in namespace deployment-333 with ReadyReplicas 0
  I0902 07:38:18.791638 16 deployment.go:309] observed Deployment test-deployment in namespace deployment-333 with ReadyReplicas 0
  I0902 07:38:18.791691 16 deployment.go:311] observed Deployment test-deployment in namespace deployment-333 with ReadyReplicas 0
  I0902 07:38:18.791713 16 deployment.go:309] observed Deployment test-deployment in namespace deployment-333 with ReadyReplicas 0
  I0902 07:38:18.791751 16 deployment.go:311] observed Deployment test-deployment in namespace deployment-333 with ReadyReplicas 0
  I0902 07:38:18.791780 16 deployment.go:309] observed Deployment test-deployment in namespace deployment-333 with ReadyReplicas 1
  I0902 07:38:18.791797 16 deployment.go:311] observed Deployment test-deployment in namespace deployment-333 with ReadyReplicas 1
  I0902 07:38:18.793120 16 deployment.go:309] observed Deployment test-deployment in namespace deployment-333 with ReadyReplicas 2
  I0902 07:38:18.793183 16 deployment.go:311] observed Deployment test-deployment in namespace deployment-333 with ReadyReplicas 2
  I0902 07:38:18.793501 16 deployment.go:309] observed Deployment test-deployment in namespace deployment-333 with ReadyReplicas 2
  I0902 07:38:18.793591 16 deployment.go:311] observed Deployment test-deployment in namespace deployment-333 with ReadyReplicas 2
  I0902 07:38:18.816024 16 deployment.go:309] observed Deployment test-deployment in namespace deployment-333 with ReadyReplicas 2
  I0902 07:38:18.816478 16 deployment.go:311] observed Deployment test-deployment in namespace deployment-333 with ReadyReplicas 2
  I0902 07:38:18.883070 16 deployment.go:309] observed Deployment test-deployment in namespace deployment-333 with ReadyReplicas 2
  I0902 07:38:18.883248 16 deployment.go:311] observed Deployment test-deployment in namespace deployment-333 with ReadyReplicas 2
  I0902 07:38:18.960897 16 deployment.go:309] observed Deployment test-deployment in namespace deployment-333 with ReadyReplicas 1
  I0902 07:38:18.960975 16 deployment.go:311] observed Deployment test-deployment in namespace deployment-333 with ReadyReplicas 1
  I0902 07:38:18.985502 16 deployment.go:309] observed Deployment test-deployment in namespace deployment-333 with ReadyReplicas 1
  I0902 07:38:18.985645 16 deployment.go:311] observed Deployment test-deployment in namespace deployment-333 with ReadyReplicas 1
  I0902 07:38:20.562121 16 deployment.go:309] observed Deployment test-deployment in namespace deployment-333 with ReadyReplicas 2
  I0902 07:38:20.562204 16 deployment.go:311] observed Deployment test-deployment in namespace deployment-333 with ReadyReplicas 2
  I0902 07:38:20.611477 16 deployment.go:311] observed Deployment test-deployment in namespace deployment-333 with ReadyReplicas 1
  STEP: listing Deployments @ 09/02/25 07:38:20.611
  I0902 07:38:20.620447 16 deployment.go:327] Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
  STEP: updating the Deployment @ 09/02/25 07:38:20.62
  I0902 07:38:20.649863 16 deployment.go:360] observed Deployment test-deployment in namespace deployment-333 with ReadyReplicas 1
  STEP: fetching the DeploymentStatus @ 09/02/25 07:38:20.65
  I0902 07:38:20.671135 16 deployment.go:389] observed Deployment test-deployment in namespace deployment-333 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  I0902 07:38:20.677081 16 deployment.go:389] observed Deployment test-deployment in namespace deployment-333 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  I0902 07:38:20.767395 16 deployment.go:389] observed Deployment test-deployment in namespace deployment-333 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  I0902 07:38:20.894156 16 deployment.go:389] observed Deployment test-deployment in namespace deployment-333 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  I0902 07:38:20.917011 16 deployment.go:389] observed Deployment test-deployment in namespace deployment-333 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  I0902 07:38:20.958687 16 deployment.go:389] observed Deployment test-deployment in namespace deployment-333 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  I0902 07:38:22.810917 16 deployment.go:389] observed Deployment test-deployment in namespace deployment-333 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  I0902 07:38:22.855172 16 deployment.go:389] observed Deployment test-deployment in namespace deployment-333 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
  I0902 07:38:22.972505 16 deployment.go:389] observed Deployment test-deployment in namespace deployment-333 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  I0902 07:38:22.990079 16 deployment.go:389] observed Deployment test-deployment in namespace deployment-333 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  I0902 07:38:24.871405 16 deployment.go:389] observed Deployment test-deployment in namespace deployment-333 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
  STEP: patching the DeploymentStatus @ 09/02/25 07:38:24.968
  STEP: fetching the DeploymentStatus @ 09/02/25 07:38:25.017
  I0902 07:38:25.034649 16 deployment.go:448] observed Deployment test-deployment in namespace deployment-333 with ReadyReplicas 1
  I0902 07:38:25.036789 16 deployment.go:448] observed Deployment test-deployment in namespace deployment-333 with ReadyReplicas 1
  I0902 07:38:25.038360 16 deployment.go:448] observed Deployment test-deployment in namespace deployment-333 with ReadyReplicas 1
  I0902 07:38:25.038469 16 deployment.go:448] observed Deployment test-deployment in namespace deployment-333 with ReadyReplicas 1
  I0902 07:38:25.038519 16 deployment.go:448] observed Deployment test-deployment in namespace deployment-333 with ReadyReplicas 1
  I0902 07:38:25.039044 16 deployment.go:448] observed Deployment test-deployment in namespace deployment-333 with ReadyReplicas 1
  I0902 07:38:25.039075 16 deployment.go:448] observed Deployment test-deployment in namespace deployment-333 with ReadyReplicas 2
  I0902 07:38:25.039098 16 deployment.go:448] observed Deployment test-deployment in namespace deployment-333 with ReadyReplicas 3
  I0902 07:38:25.039876 16 deployment.go:448] observed Deployment test-deployment in namespace deployment-333 with ReadyReplicas 2
  I0902 07:38:25.040635 16 deployment.go:448] observed Deployment test-deployment in namespace deployment-333 with ReadyReplicas 2
  I0902 07:38:25.041525 16 deployment.go:448] observed Deployment test-deployment in namespace deployment-333 with ReadyReplicas 3
  STEP: deleting the Deployment @ 09/02/25 07:38:25.042
  I0902 07:38:25.079899 16 deployment.go:474] observed event type MODIFIED
  I0902 07:38:25.082017 16 deployment.go:474] observed event type MODIFIED
  I0902 07:38:25.082072 16 deployment.go:474] observed event type MODIFIED
  I0902 07:38:25.082100 16 deployment.go:474] observed event type MODIFIED
  I0902 07:38:25.082424 16 deployment.go:474] observed event type MODIFIED
  I0902 07:38:25.082767 16 deployment.go:474] observed event type MODIFIED
  I0902 07:38:25.083051 16 deployment.go:474] observed event type MODIFIED
  I0902 07:38:25.084843 16 deployment.go:474] observed event type MODIFIED
  I0902 07:38:25.085095 16 deployment.go:474] observed event type MODIFIED
  I0902 07:38:25.085330 16 deployment.go:474] observed event type MODIFIED
  I0902 07:38:25.085584 16 deployment.go:474] observed event type MODIFIED
  I0902 07:38:25.085941 16 deployment.go:474] observed event type MODIFIED
  I0902 07:38:25.085973 16 deployment.go:474] observed event type MODIFIED
  I0902 07:38:25.085994 16 deployment.go:474] observed event type MODIFIED
  I0902 07:38:25.129037 16 deployment.go:649] Log out all the ReplicaSets if there is no deployment created
  I0902 07:38:25.139903 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-333" for this suite. @ 09/02/25 07:38:25.16
• [8.535 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:78
  STEP: Creating a kubernetes client @ 09/02/25 07:38:25.184
  I0902 07:38:25.184801 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename projected @ 09/02/25 07:38:25.187
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:38:25.254
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:38:25.272
  STEP: Creating projection with secret that has name projected-secret-test-map-a8d4d126-852b-423a-8de5-53c17cfc3595 @ 09/02/25 07:38:25.289
  STEP: Creating a pod to test consume secrets @ 09/02/25 07:38:25.347
  STEP: Saw pod success @ 09/02/25 07:38:29.523
  I0902 07:38:29.530262 16 output.go:207] Trying to get logs from node ietha7evai9i-2 pod pod-projected-secrets-9db51225-85da-4b3f-bcff-7fa804f5ca78 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 09/02/25 07:38:29.547
  I0902 07:38:29.582991 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6863" for this suite. @ 09/02/25 07:38:29.596
• [4.425 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:205
  STEP: Creating a kubernetes client @ 09/02/25 07:38:29.609
  I0902 07:38:29.609838 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename secrets @ 09/02/25 07:38:29.614
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:38:29.643
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:38:29.65
  STEP: Creating secret with name s-test-opt-del-b45e997c-687e-4e16-88c6-b69ccda84c34 @ 09/02/25 07:38:29.698
  STEP: Creating secret with name s-test-opt-upd-ff48b239-2c64-4f82-9de5-fc20cdba55bb @ 09/02/25 07:38:29.708
  STEP: Creating the pod @ 09/02/25 07:38:29.742
  STEP: Deleting secret s-test-opt-del-b45e997c-687e-4e16-88c6-b69ccda84c34 @ 09/02/25 07:38:33.864
  STEP: Updating secret s-test-opt-upd-ff48b239-2c64-4f82-9de5-fc20cdba55bb @ 09/02/25 07:38:33.878
  STEP: Creating secret with name s-test-opt-create-e616539c-822e-4420-a5c7-f3916fc0d13d @ 09/02/25 07:38:33.891
  STEP: waiting to observe update in volume @ 09/02/25 07:38:33.906
  I0902 07:39:48.821062 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-1440" for this suite. @ 09/02/25 07:39:48.837
• [79.249 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:110
  STEP: Creating a kubernetes client @ 09/02/25 07:39:48.86
  I0902 07:39:48.860756 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename resourcequota @ 09/02/25 07:39:48.865
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:39:48.901
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:39:48.907
  STEP: Counting existing ResourceQuota @ 09/02/25 07:39:48.913
  STEP: Creating a ResourceQuota @ 09/02/25 07:39:53.93
  STEP: Ensuring resource quota status is calculated @ 09/02/25 07:39:53.96
  I0902 07:39:55.991530 16 resource_quota.go:2495] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc004167540>: 
          metadata:
            creationTimestamp: "2025-09-02T07:39:53Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: e2e.test
              operation: Update
              time: "2025-09-02T07:39:53Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
                  f:used:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: kube-controller-manager
              operation: Update
              subresource: status
              time: "2025-09-02T07:39:53Z"
            name: test-quota
            namespace: resourcequota-4764
            resourceVersion: "15126"
            uid: 458f3574-8cc8-42d5-8f23-3e79905ef7d7
          spec:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
          status:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
            used:
              configmaps: "1"
              count/replicasets.apps: "0"
              cpu: "0"
              ephemeral-storage: "0"
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "0"
              gold.storageclass.storage.k8s.io/requests.storage: "0"
              memory: "0"
              persistentvolumeclaims: "0"
              pods: "0"
              replicationcontrollers: "0"
              requests.example.com/dongle: "0"
              requests.storage: "0"
              resourcequotas: "1"
              secrets: "0"
              services: "0"
              services.loadbalancers: "0"
              services.nodeports: "0"
  STEP: Creating a Service @ 09/02/25 07:39:55.992
  STEP: Creating a NodePort Service @ 09/02/25 07:39:56.037
  STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota @ 09/02/25 07:39:56.099
  STEP: Ensuring resource quota status captures service creation @ 09/02/25 07:39:56.147
  I0902 07:39:56.161024 16 resource_quota.go:2495] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc00422aa00>: 
          metadata:
            creationTimestamp: "2025-09-02T07:39:53Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: e2e.test
              operation: Update
              time: "2025-09-02T07:39:53Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
                  f:used:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services.loadbalancers: {}
              manager: kube-controller-manager
              operation: Update
              subresource: status
              time: "2025-09-02T07:39:53Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:used:
                    f:services: {}
                    f:services.nodeports: {}
              manager: kube-apiserver
              operation: Update
              subresource: status
              time: "2025-09-02T07:39:56Z"
            name: test-quota
            namespace: resourcequota-4764
            resourceVersion: "15142"
            uid: 458f3574-8cc8-42d5-8f23-3e79905ef7d7
          spec:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
          status:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
            used:
              configmaps: "1"
              count/replicasets.apps: "0"
              cpu: "0"
              ephemeral-storage: "0"
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "0"
              gold.storageclass.storage.k8s.io/requests.storage: "0"
              memory: "0"
              persistentvolumeclaims: "0"
              pods: "0"
              replicationcontrollers: "0"
              requests.example.com/dongle: "0"
              requests.storage: "0"
              resourcequotas: "1"
              secrets: "0"
              services: "2"
              services.loadbalancers: "0"
              services.nodeports: "1"
  STEP: Deleting Services @ 09/02/25 07:39:56.163
  STEP: Ensuring resource quota status released usage @ 09/02/25 07:39:56.255
  I0902 07:39:56.274016 16 resource_quota.go:2495] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc00422b540>: 
          metadata:
            creationTimestamp: "2025-09-02T07:39:53Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: e2e.test
              operation: Update
              time: "2025-09-02T07:39:53Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
                  f:used:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: kube-controller-manager
              operation: Update
              subresource: status
              time: "2025-09-02T07:39:56Z"
            name: test-quota
            namespace: resourcequota-4764
            resourceVersion: "15154"
            uid: 458f3574-8cc8-42d5-8f23-3e79905ef7d7
          spec:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
          status:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
            used:
              configmaps: "1"
              count/replicasets.apps: "0"
              cpu: "0"
              ephemeral-storage: "0"
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "0"
              gold.storageclass.storage.k8s.io/requests.storage: "0"
              memory: "0"
              persistentvolumeclaims: "0"
              pods: "0"
              replicationcontrollers: "0"
              requests.example.com/dongle: "0"
              requests.storage: "0"
              resourcequotas: "1"
              secrets: "0"
              services: "0"
              services.loadbalancers: "0"
              services.nodeports: "0"
  I0902 07:39:56.276284 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-4764" for this suite. @ 09/02/25 07:39:56.291
• [7.445 seconds]
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:99
  STEP: Creating a kubernetes client @ 09/02/25 07:39:56.306
  I0902 07:39:56.306300 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename configmap @ 09/02/25 07:39:56.31
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:39:56.345
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:39:56.352
  STEP: Creating configMap with name configmap-test-volume-map-d8aec5a4-4395-4412-afc7-6c8d46510161 @ 09/02/25 07:39:56.365
  STEP: Creating a pod to test consume configMaps @ 09/02/25 07:39:56.38
  STEP: Saw pod success @ 09/02/25 07:40:00.446
  I0902 07:40:00.455636 16 output.go:207] Trying to get logs from node ietha7evai9i-2 pod pod-configmaps-e2f20e57-a6b3-4a93-a8ab-d67bbc92ed55 container agnhost-container: <nil>
  STEP: delete the pod @ 09/02/25 07:40:00.472
  I0902 07:40:00.511247 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-8616" for this suite. @ 09/02/25 07:40:00.524
• [4.232 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:52
  STEP: Creating a kubernetes client @ 09/02/25 07:40:00.538
  I0902 07:40:00.538337 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename crd-watch @ 09/02/25 07:40:00.54
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:40:00.57
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:40:00.576
  I0902 07:40:00.582822 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Creating first CR  @ 09/02/25 07:40:03.241
  I0902 07:40:03.252973 16 watch.go:426] Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2025-09-02T07:40:03Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2025-09-02T07:40:03Z]] name:name1 resourceVersion:15219 uid:2641ca00-b688-4b0c-b7c8-c7fd95dcfef8] num:map[num1:9223372036854775807 num2:1000000]]}
  STEP: Creating second CR @ 09/02/25 07:40:13.254
  I0902 07:40:13.276943 16 watch.go:426] Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2025-09-02T07:40:13Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2025-09-02T07:40:13Z]] name:name2 resourceVersion:15251 uid:2b703a64-e5ed-48d8-9138-e64138e8c24c] num:map[num1:9223372036854775807 num2:1000000]]}
  STEP: Modifying first CR @ 09/02/25 07:40:23.277
  I0902 07:40:23.291297 16 watch.go:426] Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2025-09-02T07:40:03Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2025-09-02T07:40:23Z]] name:name1 resourceVersion:15273 uid:2641ca00-b688-4b0c-b7c8-c7fd95dcfef8] num:map[num1:9223372036854775807 num2:1000000]]}
  STEP: Modifying second CR @ 09/02/25 07:40:33.292
  I0902 07:40:33.312807 16 watch.go:426] Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2025-09-02T07:40:13Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2025-09-02T07:40:33Z]] name:name2 resourceVersion:15296 uid:2b703a64-e5ed-48d8-9138-e64138e8c24c] num:map[num1:9223372036854775807 num2:1000000]]}
  STEP: Deleting first CR @ 09/02/25 07:40:43.313
  I0902 07:40:43.334003 16 watch.go:426] Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2025-09-02T07:40:03Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2025-09-02T07:40:23Z]] name:name1 resourceVersion:15318 uid:2641ca00-b688-4b0c-b7c8-c7fd95dcfef8] num:map[num1:9223372036854775807 num2:1000000]]}
  STEP: Deleting second CR @ 09/02/25 07:40:53.338
  I0902 07:40:53.379185 16 watch.go:426] Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2025-09-02T07:40:13Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2025-09-02T07:40:33Z]] name:name2 resourceVersion:15341 uid:2b703a64-e5ed-48d8-9138-e64138e8c24c] num:map[num1:9223372036854775807 num2:1000000]]}
  I0902 07:41:03.928065 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-watch-6228" for this suite. @ 09/02/25 07:41:03.95
• [63.463 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should succeed in writing subpaths in container [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:300
  STEP: Creating a kubernetes client @ 09/02/25 07:41:04.009
  I0902 07:41:04.009851 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename var-expansion @ 09/02/25 07:41:04.014
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:41:04.055
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:41:04.062
  STEP: creating the pod @ 09/02/25 07:41:04.079
  STEP: waiting for pod running @ 09/02/25 07:41:04.142
  STEP: creating a file in subpath @ 09/02/25 07:41:06.172
  I0902 07:41:06.185478 16 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-1849 PodName:var-expansion-2f907440-8ebc-42cd-baee-f6ff1841dcae ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0902 07:41:06.185582 16 exec_util.go:68] ExecWithOptions: Clientset creation
  I0902 07:41:06.185942 16 exec_util.go:84] ExecWithOptions: execute(https://10.233.0.1:443/api/v1/namespaces/var-expansion-1849/pods/var-expansion-2f907440-8ebc-42cd-baee-f6ff1841dcae/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&stderr=true&stdout=true)
  STEP: test for file in mounted path @ 09/02/25 07:41:06.282
  I0902 07:41:06.292586 16 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-1849 PodName:var-expansion-2f907440-8ebc-42cd-baee-f6ff1841dcae ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0902 07:41:06.292668 16 exec_util.go:68] ExecWithOptions: Clientset creation
  I0902 07:41:06.292760 16 exec_util.go:84] ExecWithOptions: execute(https://10.233.0.1:443/api/v1/namespaces/var-expansion-1849/pods/var-expansion-2f907440-8ebc-42cd-baee-f6ff1841dcae/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&stderr=true&stdout=true)
  STEP: updating the annotation value @ 09/02/25 07:41:06.413
  I0902 07:41:06.942976 16 pod_client.go:186] Successfully updated pod "var-expansion-2f907440-8ebc-42cd-baee-f6ff1841dcae"
  STEP: waiting for annotated pod running @ 09/02/25 07:41:06.943
  STEP: deleting the pod gracefully @ 09/02/25 07:41:06.949
  I0902 07:41:06.949465 16 delete.go:78] Deleting pod "var-expansion-2f907440-8ebc-42cd-baee-f6ff1841dcae" in namespace "var-expansion-1849"
  I0902 07:41:06.976428 16 delete.go:86] Wait up to 5m0s for pod "var-expansion-2f907440-8ebc-42cd-baee-f6ff1841dcae" to be fully deleted
  I0902 07:41:39.147744 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-1849" for this suite. @ 09/02/25 07:41:39.158
• [35.166 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Environment:NotInUserNS] [Conformance] [sig-node, NodeConformance, Environment:NotInUserNS, Conformance]
k8s.io/kubernetes/test/e2e/common/node/sysctl.go:79
  STEP: Creating a kubernetes client @ 09/02/25 07:41:39.179
  I0902 07:41:39.179382 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename sysctl @ 09/02/25 07:41:39.184
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:41:39.224
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:41:39.231
  STEP: Creating a pod with the kernel.shm_rmid_forced sysctl @ 09/02/25 07:41:39.237
  STEP: Watching for error events or started pod @ 09/02/25 07:41:39.266
  STEP: Waiting for pod completion @ 09/02/25 07:41:41.279
  STEP: Checking that the pod succeeded @ 09/02/25 07:41:43.302
  STEP: Getting logs from the pod @ 09/02/25 07:41:43.302
  STEP: Checking that the sysctl is actually updated @ 09/02/25 07:41:43.336
  I0902 07:41:43.336782 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sysctl-2306" for this suite. @ 09/02/25 07:41:43.347
• [4.191 seconds]
------------------------------
SS
------------------------------
[sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:72
  STEP: Creating a kubernetes client @ 09/02/25 07:41:43.372
  I0902 07:41:43.372159 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename container-probe @ 09/02/25 07:41:43.374
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:41:43.405
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:41:43.416
  I0902 07:42:07.619476 16 container_probe.go:92] Container started at 2025-09-02 07:41:44 +0000 UTC, pod became ready at 2025-09-02 07:42:05 +0000 UTC
  I0902 07:42:07.621285 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-566" for this suite. @ 09/02/25 07:42:07.632
• [24.277 seconds]
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:229
  STEP: Creating a kubernetes client @ 09/02/25 07:42:07.651
  I0902 07:42:07.651638 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename emptydir @ 09/02/25 07:42:07.657
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:42:07.678
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:42:07.687
  STEP: Creating Pod @ 09/02/25 07:42:07.694
  STEP: Reading file content from the nginx-container @ 09/02/25 07:42:09.733
  I0902 07:42:09.734349 16 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-1587 PodName:pod-sharedvolume-1b668e0c-a3a1-4cb0-8d37-ce5e2e086d32 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0902 07:42:09.734902 16 exec_util.go:68] ExecWithOptions: Clientset creation
  I0902 07:42:09.735615 16 exec_util.go:84] ExecWithOptions: execute(https://10.233.0.1:443/api/v1/namespaces/emptydir-1587/pods/pod-sharedvolume-1b668e0c-a3a1-4cb0-8d37-ce5e2e086d32/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&stderr=true&stdout=true)
  I0902 07:42:09.839900 16 exec_util.go:112] Exec stderr: ""
  I0902 07:42:09.840293 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-1587" for this suite. @ 09/02/25 07:42:09.851
• [2.216 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/security_context.go:135
  STEP: Creating a kubernetes client @ 09/02/25 07:42:09.868
  I0902 07:42:09.869016 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename security-context @ 09/02/25 07:42:09.873
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:42:09.906
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:42:09.911
  STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser @ 09/02/25 07:42:09.919
  STEP: Saw pod success @ 09/02/25 07:42:13.97
  I0902 07:42:13.977626 16 output.go:207] Trying to get logs from node ietha7evai9i-1 pod security-context-38534227-18c3-44a7-8716-4a976cffe759 container test-container: <nil>
  STEP: delete the pod @ 09/02/25 07:42:14.011
  I0902 07:42:14.057521 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-350" for this suite. @ 09/02/25 07:42:14.07
• [4.227 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be immutable if `immutable` field is set [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:386
  STEP: Creating a kubernetes client @ 09/02/25 07:42:14.097
  I0902 07:42:14.097742 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename secrets @ 09/02/25 07:42:14.1
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:42:14.139
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:42:14.148
  I0902 07:42:14.255851 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-6779" for this suite. @ 09/02/25 07:42:14.264
• [0.178 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] RuntimeClass should support RuntimeClasses API operations [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:194
  STEP: Creating a kubernetes client @ 09/02/25 07:42:14.276
  I0902 07:42:14.276746 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename runtimeclass @ 09/02/25 07:42:14.279
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:42:14.314
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:42:14.322
  STEP: getting /apis @ 09/02/25 07:42:14.328
  STEP: getting /apis/node.k8s.io @ 09/02/25 07:42:14.343
  STEP: getting /apis/node.k8s.io/v1 @ 09/02/25 07:42:14.364
  STEP: creating @ 09/02/25 07:42:14.37
  STEP: watching @ 09/02/25 07:42:14.405
  I0902 07:42:14.405404 16 runtimeclass.go:278] starting watch
  STEP: getting @ 09/02/25 07:42:14.426
  STEP: listing @ 09/02/25 07:42:14.438
  STEP: patching @ 09/02/25 07:42:14.444
  STEP: updating @ 09/02/25 07:42:14.455
  I0902 07:42:14.469902 16 runtimeclass.go:308] waiting for watch events with expected annotations
  STEP: deleting @ 09/02/25 07:42:14.47
  STEP: deleting a collection @ 09/02/25 07:42:14.5
  I0902 07:42:14.542970 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-8010" for this suite. @ 09/02/25 07:42:14.558
• [0.294 seconds]
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:205
  STEP: Creating a kubernetes client @ 09/02/25 07:42:14.572
  I0902 07:42:14.572980 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename daemonsets @ 09/02/25 07:42:14.577
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:42:14.604
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:42:14.616
  I0902 07:42:14.685102 16 daemon_set.go:208] Creating daemon "daemon-set" with a node selector
  STEP: Initially, daemon pods should not be running on any nodes. @ 09/02/25 07:42:14.699
  I0902 07:42:14.731881 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0902 07:42:14.732498 16 fixtures.go:136] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  STEP: Change node label to blue, check that daemon pod is launched. @ 09/02/25 07:42:14.732
  I0902 07:42:14.819627 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0902 07:42:14.819878 16 fixtures.go:131] Node ietha7evai9i-1 is running 0 daemon pod, expected 1
  I0902 07:42:15.813765 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0902 07:42:15.813909 16 fixtures.go:131] Node ietha7evai9i-1 is running 0 daemon pod, expected 1
  I0902 07:42:16.793122 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0902 07:42:16.793268 16 fixtures.go:131] Node ietha7evai9i-1 is running 0 daemon pod, expected 1
  I0902 07:42:17.795841 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0902 07:42:17.795916 16 fixtures.go:136] Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
  STEP: Update the node label to green, and wait for daemons to be unscheduled @ 09/02/25 07:42:17.803
  I0902 07:42:17.857206 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0902 07:42:17.857327 16 fixtures.go:136] Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
  I0902 07:42:18.870702 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0902 07:42:18.870780 16 fixtures.go:136] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate @ 09/02/25 07:42:18.87
  I0902 07:42:18.967458 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0902 07:42:18.967596 16 fixtures.go:131] Node ietha7evai9i-1 is running 0 daemon pod, expected 1
  I0902 07:42:19.951727 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0902 07:42:19.951829 16 fixtures.go:131] Node ietha7evai9i-1 is running 0 daemon pod, expected 1
  I0902 07:42:21.010024 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0902 07:42:21.010181 16 fixtures.go:131] Node ietha7evai9i-1 is running 0 daemon pod, expected 1
  I0902 07:42:21.953974 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0902 07:42:21.954046 16 fixtures.go:136] Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 09/02/25 07:42:21.972
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6916, will wait for the garbage collector to delete the pods @ 09/02/25 07:42:21.972
  I0902 07:42:22.048645 16 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 17.984193ms
  I0902 07:42:22.149426 16 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 100.775863ms
  I0902 07:42:23.056595 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0902 07:42:23.056664 16 fixtures.go:136] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I0902 07:42:23.067729 16 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"15780"},"items":null}

  I0902 07:42:23.074400 16 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"15780"},"items":null}

  I0902 07:42:23.134476 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-6916" for this suite. @ 09/02/25 07:42:23.146
• [8.591 seconds]
------------------------------
S
------------------------------
[sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:559
  STEP: Creating a kubernetes client @ 09/02/25 07:42:23.163
  I0902 07:42:23.163892 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename svcaccounts @ 09/02/25 07:42:23.166
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:42:23.2
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:42:23.216
  I0902 07:42:23.263860 16 service_accounts.go:646] created pod
  STEP: Saw pod success @ 09/02/25 07:42:27.328
  I0902 07:42:57.328362 16 service_accounts.go:652] polling logs
  I0902 07:42:57.357337 16 service_accounts.go:662] Pod logs: 
  I0902 07:42:24.231573       1 log.go:245] OK: Got token
  I0902 07:42:24.232862       1 log.go:245] validating with in-cluster discovery
  I0902 07:42:24.234366       1 log.go:245] OK: got issuer https://kubernetes.default.svc.cluster.local
  I0902 07:42:24.234473       1 log.go:245] Full, not-validated claims: 
  openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-9353:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:(*jwt.NumericDate)(0xc0000ad818), NotBefore:(*jwt.NumericDate)(0xc0000ad8e0), IssuedAt:(*jwt.NumericDate)(0xc0000ad828), ID:"beb0b467-e77d-46d5-87bf-b11b3d79e32a"}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-9353", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"f8f2c132-29ad-4c0a-8254-49fe99542e90"}}}
  I0902 07:42:24.281936       1 log.go:245] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc.cluster.local
  I0902 07:42:24.305068       1 log.go:245] OK: Validated signature on JWT
  I0902 07:42:24.305324       1 log.go:245] OK: Got valid claims from token!
  I0902 07:42:24.305388       1 log.go:245] Full, validated claims: 
  &openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-9353:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:(*jwt.NumericDate)(0xc00023bac8), NotBefore:(*jwt.NumericDate)(0xc00023baf0), IssuedAt:(*jwt.NumericDate)(0xc00023bad0), ID:"beb0b467-e77d-46d5-87bf-b11b3d79e32a"}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-9353", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"f8f2c132-29ad-4c0a-8254-49fe99542e90"}}}

  I0902 07:42:57.357475 16 service_accounts.go:666] completed pod
  I0902 07:42:57.375461 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-9353" for this suite. @ 09/02/25 07:42:57.389
• [34.246 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:867
  STEP: Creating a kubernetes client @ 09/02/25 07:42:57.412
  I0902 07:42:57.412904 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename resourcequota @ 09/02/25 07:42:57.416
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:42:57.442
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:42:57.45
  STEP: Creating a ResourceQuota with best effort scope @ 09/02/25 07:42:57.455
  STEP: Ensuring ResourceQuota status is calculated @ 09/02/25 07:42:57.473
  I0902 07:42:59.492989 16 resource_quota.go:2495] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc001b3f540>: 
          metadata:
            creationTimestamp: "2025-09-02T07:42:57Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:pods: {}
                  f:scopes: {}
              manager: e2e.test
              operation: Update
              time: "2025-09-02T07:42:57Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:pods: {}
                  f:used:
                    .: {}
                    f:pods: {}
              manager: kube-controller-manager
              operation: Update
              subresource: status
              time: "2025-09-02T07:42:57Z"
            name: quota-besteffort
            namespace: resourcequota-1982
            resourceVersion: "15901"
            uid: 97b14b47-6268-4ea3-8978-65291685afaa
          spec:
            hard:
              pods: "5"
            scopes:
            - BestEffort
          status:
            hard:
              pods: "5"
            used:
              pods: "0"
  STEP: Creating a ResourceQuota with not best effort scope @ 09/02/25 07:42:59.493
  STEP: Ensuring ResourceQuota status is calculated @ 09/02/25 07:42:59.503
  I0902 07:43:01.524507 16 resource_quota.go:2495] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc001baab40>: 
          metadata:
            creationTimestamp: "2025-09-02T07:42:59Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:pods: {}
                  f:scopes: {}
              manager: e2e.test
              operation: Update
              time: "2025-09-02T07:42:59Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:pods: {}
                  f:used:
                    .: {}
                    f:pods: {}
              manager: kube-controller-manager
              operation: Update
              subresource: status
              time: "2025-09-02T07:42:59Z"
            name: quota-not-besteffort
            namespace: resourcequota-1982
            resourceVersion: "15908"
            uid: e471db63-13d9-4e9d-80c5-8040184fe8d6
          spec:
            hard:
              pods: "5"
            scopes:
            - NotBestEffort
          status:
            hard:
              pods: "5"
            used:
              pods: "0"
  STEP: Creating a best-effort pod @ 09/02/25 07:43:01.525
  STEP: Ensuring resource quota with best effort scope captures the pod usage @ 09/02/25 07:43:01.572
  I0902 07:43:01.590604 16 resource_quota.go:2495] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc001bab7c0>: 
          metadata:
            creationTimestamp: "2025-09-02T07:42:57Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:pods: {}
                  f:scopes: {}
              manager: e2e.test
              operation: Update
              time: "2025-09-02T07:42:57Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:pods: {}
                  f:used: {}
              manager: kube-controller-manager
              operation: Update
              subresource: status
              time: "2025-09-02T07:42:57Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:used:
                    f:pods: {}
              manager: kube-apiserver
              operation: Update
              subresource: status
              time: "2025-09-02T07:43:01Z"
            name: quota-besteffort
            namespace: resourcequota-1982
            resourceVersion: "15912"
            uid: 97b14b47-6268-4ea3-8978-65291685afaa
          spec:
            hard:
              pods: "5"
            scopes:
            - BestEffort
          status:
            hard:
              pods: "5"
            used:
              pods: "1"
  STEP: Ensuring resource quota with not best effort ignored the pod usage @ 09/02/25 07:43:01.591
  I0902 07:43:01.613855 16 resource_quota.go:2495] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc0018b3180>: 
          metadata:
            creationTimestamp: "2025-09-02T07:42:59Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:pods: {}
                  f:scopes: {}
              manager: e2e.test
              operation: Update
              time: "2025-09-02T07:42:59Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:pods: {}
                  f:used:
                    .: {}
                    f:pods: {}
              manager: kube-controller-manager
              operation: Update
              subresource: status
              time: "2025-09-02T07:42:59Z"
            name: quota-not-besteffort
            namespace: resourcequota-1982
            resourceVersion: "15908"
            uid: e471db63-13d9-4e9d-80c5-8040184fe8d6
          spec:
            hard:
              pods: "5"
            scopes:
            - NotBestEffort
          status:
            hard:
              pods: "5"
            used:
              pods: "0"
  STEP: Deleting the pod @ 09/02/25 07:43:01.616
  STEP: Ensuring resource quota status released the pod usage @ 09/02/25 07:43:01.657
  I0902 07:43:01.673493 16 resource_quota.go:2495] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc001c88640>: 
          metadata:
            creationTimestamp: "2025-09-02T07:42:57Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:pods: {}
                  f:scopes: {}
              manager: e2e.test
              operation: Update
              time: "2025-09-02T07:42:57Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:pods: {}
                  f:used:
                    .: {}
                    f:pods: {}
              manager: kube-controller-manager
              operation: Update
              subresource: status
              time: "2025-09-02T07:43:01Z"
            name: quota-besteffort
            namespace: resourcequota-1982
            resourceVersion: "15918"
            uid: 97b14b47-6268-4ea3-8978-65291685afaa
          spec:
            hard:
              pods: "5"
            scopes:
            - BestEffort
          status:
            hard:
              pods: "5"
            used:
              pods: "0"
  STEP: Creating a not best-effort pod @ 09/02/25 07:43:01.674
  STEP: Ensuring resource quota with not best effort scope captures the pod usage @ 09/02/25 07:43:01.708
  I0902 07:43:01.723161 16 resource_quota.go:2495] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc001c892c0>: 
          metadata:
            creationTimestamp: "2025-09-02T07:42:59Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:pods: {}
                  f:scopes: {}
              manager: e2e.test
              operation: Update
              time: "2025-09-02T07:42:59Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:pods: {}
                  f:used: {}
              manager: kube-controller-manager
              operation: Update
              subresource: status
              time: "2025-09-02T07:42:59Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:used:
                    f:pods: {}
              manager: kube-apiserver
              operation: Update
              subresource: status
              time: "2025-09-02T07:43:01Z"
            name: quota-not-besteffort
            namespace: resourcequota-1982
            resourceVersion: "15919"
            uid: e471db63-13d9-4e9d-80c5-8040184fe8d6
          spec:
            hard:
              pods: "5"
            scopes:
            - NotBestEffort
          status:
            hard:
              pods: "5"
            used:
              pods: "1"
  STEP: Ensuring resource quota with best effort scope ignored the pod usage @ 09/02/25 07:43:01.723
  I0902 07:43:01.737011 16 resource_quota.go:2495] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc001c89900>: 
          metadata:
            creationTimestamp: "2025-09-02T07:42:57Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:pods: {}
                  f:scopes: {}
              manager: e2e.test
              operation: Update
              time: "2025-09-02T07:42:57Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:pods: {}
                  f:used:
                    .: {}
                    f:pods: {}
              manager: kube-controller-manager
              operation: Update
              subresource: status
              time: "2025-09-02T07:43:01Z"
            name: quota-besteffort
            namespace: resourcequota-1982
            resourceVersion: "15918"
            uid: 97b14b47-6268-4ea3-8978-65291685afaa
          spec:
            hard:
              pods: "5"
            scopes:
            - BestEffort
          status:
            hard:
              pods: "5"
            used:
              pods: "0"
  STEP: Deleting the pod @ 09/02/25 07:43:01.737
  STEP: Ensuring resource quota status released the pod usage @ 09/02/25 07:43:01.758
  I0902 07:43:01.769527 16 resource_quota.go:2495] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc0018b3b80>: 
          metadata:
            creationTimestamp: "2025-09-02T07:42:59Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:pods: {}
                  f:scopes: {}
              manager: e2e.test
              operation: Update
              time: "2025-09-02T07:42:59Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:pods: {}
                  f:used:
                    .: {}
                    f:pods: {}
              manager: kube-controller-manager
              operation: Update
              subresource: status
              time: "2025-09-02T07:43:01Z"
            name: quota-not-besteffort
            namespace: resourcequota-1982
            resourceVersion: "15925"
            uid: e471db63-13d9-4e9d-80c5-8040184fe8d6
          spec:
            hard:
              pods: "5"
            scopes:
            - NotBestEffort
          status:
            hard:
              pods: "5"
            used:
              pods: "0"
  I0902 07:43:01.770681 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-1982" for this suite. @ 09/02/25 07:43:01.783
• [4.386 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:752
  STEP: Creating a kubernetes client @ 09/02/25 07:43:01.799
  I0902 07:43:01.799331 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename resourcequota @ 09/02/25 07:43:01.803
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:43:01.833
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:43:01.839
  STEP: Creating a ResourceQuota with terminating scope @ 09/02/25 07:43:01.847
  STEP: Ensuring ResourceQuota status is calculated @ 09/02/25 07:43:01.861
  I0902 07:43:03.881656 16 resource_quota.go:2495] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc001fc4b40>: 
          metadata:
            creationTimestamp: "2025-09-02T07:43:01Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:limits.cpu: {}
                    f:limits.memory: {}
                    f:pods: {}
                    f:requests.cpu: {}
                    f:requests.memory: {}
                  f:scopes: {}
              manager: e2e.test
              operation: Update
              time: "2025-09-02T07:43:01Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:limits.cpu: {}
                    f:limits.memory: {}
                    f:pods: {}
                    f:requests.cpu: {}
                    f:requests.memory: {}
                  f:used:
                    .: {}
                    f:limits.cpu: {}
                    f:limits.memory: {}
                    f:pods: {}
                    f:requests.cpu: {}
                    f:requests.memory: {}
              manager: kube-controller-manager
              operation: Update
              subresource: status
              time: "2025-09-02T07:43:01Z"
            name: quota-terminating
            namespace: resourcequota-8124
            resourceVersion: "15931"
            uid: c35aaf8a-a75b-4f53-ac16-b90dcb8d61f7
          spec:
            hard:
              limits.cpu: "2"
              limits.memory: 1Gi
              pods: "5"
              requests.cpu: "1"
              requests.memory: 500Mi
            scopes:
            - Terminating
          status:
            hard:
              limits.cpu: "2"
              limits.memory: 1Gi
              pods: "5"
              requests.cpu: "1"
              requests.memory: 500Mi
            used:
              limits.cpu: "0"
              limits.memory: "0"
              pods: "0"
              requests.cpu: "0"
              requests.memory: "0"
  STEP: Creating a ResourceQuota with not terminating scope @ 09/02/25 07:43:03.882
  STEP: Ensuring ResourceQuota status is calculated @ 09/02/25 07:43:03.893
  I0902 07:43:05.913214 16 resource_quota.go:2495] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc001f763c0>: 
          metadata:
            creationTimestamp: "2025-09-02T07:43:03Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:limits.cpu: {}
                    f:limits.memory: {}
                    f:pods: {}
                    f:requests.cpu: {}
                    f:requests.memory: {}
                  f:scopes: {}
              manager: e2e.test
              operation: Update
              time: "2025-09-02T07:43:03Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:limits.cpu: {}
                    f:limits.memory: {}
                    f:pods: {}
                    f:requests.cpu: {}
                    f:requests.memory: {}
                  f:used:
                    .: {}
                    f:limits.cpu: {}
                    f:limits.memory: {}
                    f:pods: {}
                    f:requests.cpu: {}
                    f:requests.memory: {}
              manager: kube-controller-manager
              operation: Update
              subresource: status
              time: "2025-09-02T07:43:03Z"
            name: quota-not-terminating
            namespace: resourcequota-8124
            resourceVersion: "15948"
            uid: 7e6bdbc2-ad34-4670-a2ae-f5d462aa91e3
          spec:
            hard:
              limits.cpu: "2"
              limits.memory: 1Gi
              pods: "5"
              requests.cpu: "1"
              requests.memory: 500Mi
            scopes:
            - NotTerminating
          status:
            hard:
              limits.cpu: "2"
              limits.memory: 1Gi
              pods: "5"
              requests.cpu: "1"
              requests.memory: 500Mi
            used:
              limits.cpu: "0"
              limits.memory: "0"
              pods: "0"
              requests.cpu: "0"
              requests.memory: "0"
  STEP: Creating a long running pod @ 09/02/25 07:43:05.913
  STEP: Ensuring resource quota with not terminating scope captures the pod usage @ 09/02/25 07:43:05.95
  I0902 07:43:05.959280 16 resource_quota.go:2495] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc001f77040>: 
          metadata:
            creationTimestamp: "2025-09-02T07:43:03Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:limits.cpu: {}
                    f:limits.memory: {}
                    f:pods: {}
                    f:requests.cpu: {}
                    f:requests.memory: {}
                  f:scopes: {}
              manager: e2e.test
              operation: Update
              time: "2025-09-02T07:43:03Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:limits.cpu: {}
                    f:limits.memory: {}
                    f:pods: {}
                    f:requests.cpu: {}
                    f:requests.memory: {}
                  f:used: {}
              manager: kube-controller-manager
              operation: Update
              subresource: status
              time: "2025-09-02T07:43:03Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:used:
                    f:limits.cpu: {}
                    f:limits.memory: {}
                    f:pods: {}
                    f:requests.cpu: {}
                    f:requests.memory: {}
              manager: kube-apiserver
              operation: Update
              subresource: status
              time: "2025-09-02T07:43:05Z"
            name: quota-not-terminating
            namespace: resourcequota-8124
            resourceVersion: "15954"
            uid: 7e6bdbc2-ad34-4670-a2ae-f5d462aa91e3
          spec:
            hard:
              limits.cpu: "2"
              limits.memory: 1Gi
              pods: "5"
              requests.cpu: "1"
              requests.memory: 500Mi
            scopes:
            - NotTerminating
          status:
            hard:
              limits.cpu: "2"
              limits.memory: 1Gi
              pods: "5"
              requests.cpu: "1"
              requests.memory: 500Mi
            used:
              limits.cpu: "1"
              limits.memory: 400Mi
              pods: "1"
              requests.cpu: 500m
              requests.memory: 200Mi
  STEP: Ensuring resource quota with terminating scope ignored the pod usage @ 09/02/25 07:43:05.96
  STEP: Deleting the pod @ 09/02/25 07:43:15.961
  STEP: Ensuring resource quota status released the pod usage @ 09/02/25 07:43:15.988
  I0902 07:43:18.006686 16 resource_quota.go:2495] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc00210c780>: 
          metadata:
            creationTimestamp: "2025-09-02T07:43:03Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:limits.cpu: {}
                    f:limits.memory: {}
                    f:pods: {}
                    f:requests.cpu: {}
                    f:requests.memory: {}
                  f:scopes: {}
              manager: e2e.test
              operation: Update
              time: "2025-09-02T07:43:03Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:limits.cpu: {}
                    f:limits.memory: {}
                    f:pods: {}
                    f:requests.cpu: {}
                    f:requests.memory: {}
                  f:used:
                    .: {}
                    f:limits.cpu: {}
                    f:limits.memory: {}
                    f:pods: {}
                    f:requests.cpu: {}
                    f:requests.memory: {}
              manager: kube-controller-manager
              operation: Update
              subresource: status
              time: "2025-09-02T07:43:15Z"
            name: quota-not-terminating
            namespace: resourcequota-8124
            resourceVersion: "15989"
            uid: 7e6bdbc2-ad34-4670-a2ae-f5d462aa91e3
          spec:
            hard:
              limits.cpu: "2"
              limits.memory: 1Gi
              pods: "5"
              requests.cpu: "1"
              requests.memory: 500Mi
            scopes:
            - NotTerminating
          status:
            hard:
              limits.cpu: "2"
              limits.memory: 1Gi
              pods: "5"
              requests.cpu: "1"
              requests.memory: 500Mi
            used:
              limits.cpu: "0"
              limits.memory: "0"
              pods: "0"
              requests.cpu: "0"
              requests.memory: "0"
  STEP: Creating a terminating pod @ 09/02/25 07:43:18.008
  STEP: Ensuring resource quota with terminating scope captures the pod usage @ 09/02/25 07:43:18.041
  I0902 07:43:18.051987 16 resource_quota.go:2495] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc002284280>: 
          metadata:
            creationTimestamp: "2025-09-02T07:43:01Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:limits.cpu: {}
                    f:limits.memory: {}
                    f:pods: {}
                    f:requests.cpu: {}
                    f:requests.memory: {}
                  f:scopes: {}
              manager: e2e.test
              operation: Update
              time: "2025-09-02T07:43:01Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:limits.cpu: {}
                    f:limits.memory: {}
                    f:pods: {}
                    f:requests.cpu: {}
                    f:requests.memory: {}
                  f:used: {}
              manager: kube-controller-manager
              operation: Update
              subresource: status
              time: "2025-09-02T07:43:01Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:used:
                    f:limits.cpu: {}
                    f:limits.memory: {}
                    f:pods: {}
                    f:requests.cpu: {}
                    f:requests.memory: {}
              manager: kube-apiserver
              operation: Update
              subresource: status
              time: "2025-09-02T07:43:18Z"
            name: quota-terminating
            namespace: resourcequota-8124
            resourceVersion: "15995"
            uid: c35aaf8a-a75b-4f53-ac16-b90dcb8d61f7
          spec:
            hard:
              limits.cpu: "2"
              limits.memory: 1Gi
              pods: "5"
              requests.cpu: "1"
              requests.memory: 500Mi
            scopes:
            - Terminating
          status:
            hard:
              limits.cpu: "2"
              limits.memory: 1Gi
              pods: "5"
              requests.cpu: "1"
              requests.memory: 500Mi
            used:
              limits.cpu: "1"
              limits.memory: 400Mi
              pods: "1"
              requests.cpu: 500m
              requests.memory: 200Mi
  STEP: Ensuring resource quota with not terminating scope ignored the pod usage @ 09/02/25 07:43:18.053
  I0902 07:43:18.071267 16 resource_quota.go:2495] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc0022848c0>: 
          metadata:
            creationTimestamp: "2025-09-02T07:43:03Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:limits.cpu: {}
                    f:limits.memory: {}
                    f:pods: {}
                    f:requests.cpu: {}
                    f:requests.memory: {}
                  f:scopes: {}
              manager: e2e.test
              operation: Update
              time: "2025-09-02T07:43:03Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:limits.cpu: {}
                    f:limits.memory: {}
                    f:pods: {}
                    f:requests.cpu: {}
                    f:requests.memory: {}
                  f:used:
                    .: {}
                    f:limits.cpu: {}
                    f:limits.memory: {}
                    f:pods: {}
                    f:requests.cpu: {}
                    f:requests.memory: {}
              manager: kube-controller-manager
              operation: Update
              subresource: status
              time: "2025-09-02T07:43:15Z"
            name: quota-not-terminating
            namespace: resourcequota-8124
            resourceVersion: "15989"
            uid: 7e6bdbc2-ad34-4670-a2ae-f5d462aa91e3
          spec:
            hard:
              limits.cpu: "2"
              limits.memory: 1Gi
              pods: "5"
              requests.cpu: "1"
              requests.memory: 500Mi
            scopes:
            - NotTerminating
          status:
            hard:
              limits.cpu: "2"
              limits.memory: 1Gi
              pods: "5"
              requests.cpu: "1"
              requests.memory: 500Mi
            used:
              limits.cpu: "0"
              limits.memory: "0"
              pods: "0"
              requests.cpu: "0"
              requests.memory: "0"
  STEP: Deleting the pod @ 09/02/25 07:43:28.076
  STEP: Ensuring resource quota status released the pod usage @ 09/02/25 07:43:28.127
  I0902 07:43:30.149769 16 resource_quota.go:2495] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc00210db80>: 
          metadata:
            creationTimestamp: "2025-09-02T07:43:01Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:limits.cpu: {}
                    f:limits.memory: {}
                    f:pods: {}
                    f:requests.cpu: {}
                    f:requests.memory: {}
                  f:scopes: {}
              manager: e2e.test
              operation: Update
              time: "2025-09-02T07:43:01Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:limits.cpu: {}
                    f:limits.memory: {}
                    f:pods: {}
                    f:requests.cpu: {}
                    f:requests.memory: {}
                  f:used:
                    .: {}
                    f:limits.cpu: {}
                    f:limits.memory: {}
                    f:pods: {}
                    f:requests.cpu: {}
                    f:requests.memory: {}
              manager: kube-controller-manager
              operation: Update
              subresource: status
              time: "2025-09-02T07:43:28Z"
            name: quota-terminating
            namespace: resourcequota-8124
            resourceVersion: "16023"
            uid: c35aaf8a-a75b-4f53-ac16-b90dcb8d61f7
          spec:
            hard:
              limits.cpu: "2"
              limits.memory: 1Gi
              pods: "5"
              requests.cpu: "1"
              requests.memory: 500Mi
            scopes:
            - Terminating
          status:
            hard:
              limits.cpu: "2"
              limits.memory: 1Gi
              pods: "5"
              requests.cpu: "1"
              requests.memory: 500Mi
            used:
              limits.cpu: "0"
              limits.memory: "0"
              pods: "0"
              requests.cpu: "0"
              requests.memory: "0"
  I0902 07:43:30.151265 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-8124" for this suite. @ 09/02/25 07:43:30.164
• [28.380 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo should scale a replication controller [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:370
  STEP: Creating a kubernetes client @ 09/02/25 07:43:30.18
  I0902 07:43:30.180430 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename kubectl @ 09/02/25 07:43:30.183
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:43:30.214
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:43:30.224
  STEP: creating a replication controller @ 09/02/25 07:43:30.23
  I0902 07:43:30.231256 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-7975 create -f -'
  I0902 07:43:30.625316 16 builder.go:156] stderr: ""
  I0902 07:43:30.625396 16 builder.go:157] stdout: "replicationcontroller/update-demo-nautilus created\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 09/02/25 07:43:30.625
  I0902 07:43:30.626063 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-7975 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0902 07:43:30.871919 16 builder.go:156] stderr: ""
  I0902 07:43:30.872335 16 builder.go:157] stdout: "update-demo-nautilus-5xsz5 update-demo-nautilus-9xrrs "
  I0902 07:43:30.872617 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-7975 get pods update-demo-nautilus-5xsz5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0902 07:43:31.062620 16 builder.go:156] stderr: ""
  I0902 07:43:31.062714 16 builder.go:157] stdout: ""
  I0902 07:43:31.062778 16 kubectl.go:2537] update-demo-nautilus-5xsz5 is created but not running
  I0902 07:43:36.066509 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-7975 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0902 07:43:36.471752 16 builder.go:156] stderr: ""
  I0902 07:43:36.471869 16 builder.go:157] stdout: "update-demo-nautilus-5xsz5 update-demo-nautilus-9xrrs "
  I0902 07:43:36.472481 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-7975 get pods update-demo-nautilus-5xsz5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0902 07:43:36.799889 16 builder.go:156] stderr: ""
  I0902 07:43:36.799972 16 builder.go:157] stdout: ""
  I0902 07:43:36.800018 16 kubectl.go:2537] update-demo-nautilus-5xsz5 is created but not running
  I0902 07:43:41.804456 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-7975 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0902 07:43:42.058689 16 builder.go:156] stderr: ""
  I0902 07:43:42.058765 16 builder.go:157] stdout: "update-demo-nautilus-5xsz5 update-demo-nautilus-9xrrs "
  I0902 07:43:42.059221 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-7975 get pods update-demo-nautilus-5xsz5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0902 07:43:42.264538 16 builder.go:156] stderr: ""
  I0902 07:43:42.265220 16 builder.go:157] stdout: ""
  I0902 07:43:42.265599 16 kubectl.go:2537] update-demo-nautilus-5xsz5 is created but not running
  I0902 07:43:47.267307 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-7975 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0902 07:43:47.767720 16 builder.go:156] stderr: ""
  I0902 07:43:47.767840 16 builder.go:157] stdout: "update-demo-nautilus-5xsz5 update-demo-nautilus-9xrrs "
  I0902 07:43:47.768079 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-7975 get pods update-demo-nautilus-5xsz5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0902 07:43:48.057947 16 builder.go:156] stderr: ""
  I0902 07:43:48.058044 16 builder.go:157] stdout: "true"
  I0902 07:43:48.058223 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-7975 get pods update-demo-nautilus-5xsz5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I0902 07:43:48.282806 16 builder.go:156] stderr: ""
  I0902 07:43:48.282878 16 builder.go:157] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0902 07:43:48.282950 16 kubectl.go:2428] validating pod update-demo-nautilus-5xsz5
  I0902 07:43:48.303065 16 kubectl.go:2448] got data: {
    "image": "nautilus.jpg"
  }

  I0902 07:43:48.303260 16 kubectl.go:2453] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0902 07:43:48.303293 16 kubectl.go:2555] update-demo-nautilus-5xsz5 is verified up and running
  I0902 07:43:48.303778 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-7975 get pods update-demo-nautilus-9xrrs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0902 07:43:48.501520 16 builder.go:156] stderr: ""
  I0902 07:43:48.501712 16 builder.go:157] stdout: ""
  I0902 07:43:48.501785 16 kubectl.go:2537] update-demo-nautilus-9xrrs is created but not running
  I0902 07:43:53.503644 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-7975 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0902 07:43:53.751252 16 builder.go:156] stderr: ""
  I0902 07:43:53.751645 16 builder.go:157] stdout: "update-demo-nautilus-5xsz5 update-demo-nautilus-9xrrs "
  I0902 07:43:53.751921 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-7975 get pods update-demo-nautilus-5xsz5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0902 07:43:53.940383 16 builder.go:156] stderr: ""
  I0902 07:43:53.940462 16 builder.go:157] stdout: "true"
  I0902 07:43:53.940768 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-7975 get pods update-demo-nautilus-5xsz5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I0902 07:43:54.121233 16 builder.go:156] stderr: ""
  I0902 07:43:54.121322 16 builder.go:157] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0902 07:43:54.121348 16 kubectl.go:2428] validating pod update-demo-nautilus-5xsz5
  I0902 07:43:54.130690 16 kubectl.go:2448] got data: {
    "image": "nautilus.jpg"
  }

  I0902 07:43:54.130889 16 kubectl.go:2453] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0902 07:43:54.131031 16 kubectl.go:2555] update-demo-nautilus-5xsz5 is verified up and running
  I0902 07:43:54.131526 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-7975 get pods update-demo-nautilus-9xrrs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0902 07:43:54.308283 16 builder.go:156] stderr: ""
  I0902 07:43:54.308372 16 builder.go:157] stdout: "true"
  I0902 07:43:54.308874 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-7975 get pods update-demo-nautilus-9xrrs -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I0902 07:43:54.481385 16 builder.go:156] stderr: ""
  I0902 07:43:54.482071 16 builder.go:157] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0902 07:43:54.482103 16 kubectl.go:2428] validating pod update-demo-nautilus-9xrrs
  I0902 07:43:54.501691 16 kubectl.go:2448] got data: {
    "image": "nautilus.jpg"
  }

  I0902 07:43:54.501837 16 kubectl.go:2453] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0902 07:43:54.501869 16 kubectl.go:2555] update-demo-nautilus-9xrrs is verified up and running
  STEP: scaling down the replication controller @ 09/02/25 07:43:54.501
  I0902 07:43:54.523111 16 kubectl.go:339] scanned /root for discovery docs: <nil>
  I0902 07:43:54.523297 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-7975 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
  I0902 07:43:55.725401 16 builder.go:156] stderr: ""
  I0902 07:43:55.725609 16 builder.go:157] stdout: "replicationcontroller/update-demo-nautilus scaled\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 09/02/25 07:43:55.725
  I0902 07:43:55.726330 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-7975 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0902 07:43:56.016899 16 builder.go:156] stderr: ""
  I0902 07:43:56.017101 16 builder.go:157] stdout: "update-demo-nautilus-5xsz5 update-demo-nautilus-9xrrs "
  STEP: Replicas for name=update-demo: expected=1 actual=2 @ 09/02/25 07:43:56.017
  I0902 07:44:01.017978 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-7975 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0902 07:44:01.184593 16 builder.go:156] stderr: ""
  I0902 07:44:01.184668 16 builder.go:157] stdout: "update-demo-nautilus-5xsz5 "
  I0902 07:44:01.185210 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-7975 get pods update-demo-nautilus-5xsz5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0902 07:44:01.355818 16 builder.go:156] stderr: ""
  I0902 07:44:01.355956 16 builder.go:157] stdout: "true"
  I0902 07:44:01.356273 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-7975 get pods update-demo-nautilus-5xsz5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I0902 07:44:01.509412 16 builder.go:156] stderr: ""
  I0902 07:44:01.509827 16 builder.go:157] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0902 07:44:01.510087 16 kubectl.go:2428] validating pod update-demo-nautilus-5xsz5
  I0902 07:44:01.520531 16 kubectl.go:2448] got data: {
    "image": "nautilus.jpg"
  }

  I0902 07:44:01.520652 16 kubectl.go:2453] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0902 07:44:01.520697 16 kubectl.go:2555] update-demo-nautilus-5xsz5 is verified up and running
  STEP: scaling up the replication controller @ 09/02/25 07:44:01.52
  I0902 07:44:01.537588 16 kubectl.go:339] scanned /root for discovery docs: <nil>
  I0902 07:44:01.537878 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-7975 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
  I0902 07:44:02.746409 16 builder.go:156] stderr: ""
  I0902 07:44:02.746503 16 builder.go:157] stdout: "replicationcontroller/update-demo-nautilus scaled\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 09/02/25 07:44:02.747
  I0902 07:44:02.747318 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-7975 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0902 07:44:02.956104 16 builder.go:156] stderr: ""
  I0902 07:44:02.956647 16 builder.go:157] stdout: "update-demo-nautilus-5xsz5 update-demo-nautilus-rngvs "
  I0902 07:44:02.957021 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-7975 get pods update-demo-nautilus-5xsz5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0902 07:44:03.128323 16 builder.go:156] stderr: ""
  I0902 07:44:03.128420 16 builder.go:157] stdout: "true"
  I0902 07:44:03.128640 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-7975 get pods update-demo-nautilus-5xsz5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I0902 07:44:03.282060 16 builder.go:156] stderr: ""
  I0902 07:44:03.282138 16 builder.go:157] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0902 07:44:03.282163 16 kubectl.go:2428] validating pod update-demo-nautilus-5xsz5
  I0902 07:44:03.291160 16 kubectl.go:2448] got data: {
    "image": "nautilus.jpg"
  }

  I0902 07:44:03.291374 16 kubectl.go:2453] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0902 07:44:03.291428 16 kubectl.go:2555] update-demo-nautilus-5xsz5 is verified up and running
  I0902 07:44:03.292229 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-7975 get pods update-demo-nautilus-rngvs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0902 07:44:03.453755 16 builder.go:156] stderr: ""
  I0902 07:44:03.453988 16 builder.go:157] stdout: "true"
  I0902 07:44:03.455001 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-7975 get pods update-demo-nautilus-rngvs -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I0902 07:44:03.624888 16 builder.go:156] stderr: ""
  I0902 07:44:03.625078 16 builder.go:157] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0902 07:44:03.625124 16 kubectl.go:2428] validating pod update-demo-nautilus-rngvs
  I0902 07:44:03.656214 16 kubectl.go:2448] got data: {
    "image": "nautilus.jpg"
  }

  I0902 07:44:03.656362 16 kubectl.go:2453] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0902 07:44:03.656391 16 kubectl.go:2555] update-demo-nautilus-rngvs is verified up and running
  STEP: using delete to clean up resources @ 09/02/25 07:44:03.656
  I0902 07:44:03.657495 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-7975 delete --grace-period=0 --force -f -'
  I0902 07:44:03.840701 16 builder.go:156] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0902 07:44:03.840907 16 builder.go:157] stdout: "replicationcontroller \"update-demo-nautilus\" force deleted from kubectl-7975 namespace\n"
  I0902 07:44:03.841901 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-7975 get rc,svc -l name=update-demo --no-headers'
  I0902 07:44:04.143014 16 builder.go:156] stderr: "No resources found in kubectl-7975 namespace.\n"
  I0902 07:44:04.143160 16 builder.go:157] stdout: ""
  I0902 07:44:04.143428 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-7975 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  I0902 07:44:04.417527 16 builder.go:156] stderr: ""
  I0902 07:44:04.417825 16 builder.go:157] stdout: ""
  I0902 07:44:04.418599 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-7975" for this suite. @ 09/02/25 07:44:04.43
• [34.266 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:942
  STEP: Creating a kubernetes client @ 09/02/25 07:44:04.45
  I0902 07:44:04.450527 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename sched-preemption @ 09/02/25 07:44:04.455
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:44:04.49
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:44:04.497
  I0902 07:44:04.535658 16 wait.go:51] Waiting up to 1m0s for all nodes to be ready
  I0902 07:45:04.550880 16 util.go:390] Waiting for terminating namespaces to be deleted...
  STEP: Creating a kubernetes client @ 09/02/25 07:45:04.562
  I0902 07:45:04.562979 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename sched-preemption-path @ 09/02/25 07:45:04.567
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:45:04.593
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:45:04.603
  I0902 07:45:04.634000 16 preemption.go:948] PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
  I0902 07:45:04.640995 16 preemption.go:954] PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
  STEP: Removing a custom resource @ 09/02/25 07:45:04.79
  STEP: Removing a custom resource @ 09/02/25 07:45:04.812
  STEP: Removing a custom resource @ 09/02/25 07:45:04.837
  I0902 07:45:04.856002 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-path-8246" for this suite. @ 09/02/25 07:45:04.866
  I0902 07:45:04.882164 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-5479" for this suite. @ 09/02/25 07:45:04.966
• [60.533 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:135
  STEP: Creating a kubernetes client @ 09/02/25 07:45:04.987
  I0902 07:45:04.987995 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename kubelet-test @ 09/02/25 07:45:04.991
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:45:05.019
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:45:05.025
  I0902 07:45:05.082925 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-4363" for this suite. @ 09/02/25 07:45:05.099
• [0.125 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for API chunking should support continue listing from the last key if the original version has been compacted away, though the list is inconsistent [Slow] [Conformance] [sig-api-machinery, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/chunking.go:144
  STEP: Creating a kubernetes client @ 09/02/25 07:45:05.114
  I0902 07:45:05.114397 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename chunking @ 09/02/25 07:45:05.116
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:45:05.143
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:45:05.148
  STEP: creating a large number of resources @ 09/02/25 07:45:05.153
  STEP: retrieving the first page @ 09/02/25 07:45:22.834
  I0902 07:45:22.901283 16 chunking.go:163] Retrieved 40/40 results with rv 16826 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTY4MjYsInN0YXJ0IjoiL3RlbXBsYXRlLTAwMzlcdTAwMDAifQ
  STEP: retrieving the second page until the token expires @ 09/02/25 07:45:22.901
  I0902 07:45:42.910215 16 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTY4MjYsInN0YXJ0IjoiL3RlbXBsYXRlLTAwMzlcdTAwMDAifQ has not expired yet
  I0902 07:46:02.909818 16 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTY4MjYsInN0YXJ0IjoiL3RlbXBsYXRlLTAwMzlcdTAwMDAifQ has not expired yet
  I0902 07:46:22.910435 16 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTY4MjYsInN0YXJ0IjoiL3RlbXBsYXRlLTAwMzlcdTAwMDAifQ has not expired yet
  I0902 07:46:42.920704 16 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTY4MjYsInN0YXJ0IjoiL3RlbXBsYXRlLTAwMzlcdTAwMDAifQ has not expired yet
  I0902 07:47:02.910439 16 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTY4MjYsInN0YXJ0IjoiL3RlbXBsYXRlLTAwMzlcdTAwMDAifQ has not expired yet
  I0902 07:47:22.911669 16 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTY4MjYsInN0YXJ0IjoiL3RlbXBsYXRlLTAwMzlcdTAwMDAifQ has not expired yet
  I0902 07:47:42.908891 16 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTY4MjYsInN0YXJ0IjoiL3RlbXBsYXRlLTAwMzlcdTAwMDAifQ has not expired yet
  I0902 07:48:02.914692 16 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTY4MjYsInN0YXJ0IjoiL3RlbXBsYXRlLTAwMzlcdTAwMDAifQ has not expired yet
  I0902 07:48:22.912587 16 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTY4MjYsInN0YXJ0IjoiL3RlbXBsYXRlLTAwMzlcdTAwMDAifQ has not expired yet
  I0902 07:48:42.915947 16 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTY4MjYsInN0YXJ0IjoiL3RlbXBsYXRlLTAwMzlcdTAwMDAifQ has not expired yet
  I0902 07:49:02.910349 16 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTY4MjYsInN0YXJ0IjoiL3RlbXBsYXRlLTAwMzlcdTAwMDAifQ has not expired yet
  I0902 07:49:22.908781 16 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTY4MjYsInN0YXJ0IjoiL3RlbXBsYXRlLTAwMzlcdTAwMDAifQ has not expired yet
  I0902 07:49:42.907980 16 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTY4MjYsInN0YXJ0IjoiL3RlbXBsYXRlLTAwMzlcdTAwMDAifQ has not expired yet
  I0902 07:50:02.930944 16 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTY4MjYsInN0YXJ0IjoiL3RlbXBsYXRlLTAwMzlcdTAwMDAifQ has not expired yet
  I0902 07:50:22.909437 16 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTY4MjYsInN0YXJ0IjoiL3RlbXBsYXRlLTAwMzlcdTAwMDAifQ has not expired yet
  I0902 07:50:42.913284 16 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTY4MjYsInN0YXJ0IjoiL3RlbXBsYXRlLTAwMzlcdTAwMDAifQ has not expired yet
  I0902 07:51:02.923817 16 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTY4MjYsInN0YXJ0IjoiL3RlbXBsYXRlLTAwMzlcdTAwMDAifQ has not expired yet
  I0902 07:51:22.911048 16 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTY4MjYsInN0YXJ0IjoiL3RlbXBsYXRlLTAwMzlcdTAwMDAifQ has not expired yet
  I0902 07:51:42.908411 16 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTY4MjYsInN0YXJ0IjoiL3RlbXBsYXRlLTAwMzlcdTAwMDAifQ has not expired yet
  I0902 07:52:02.909519 16 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTY4MjYsInN0YXJ0IjoiL3RlbXBsYXRlLTAwMzlcdTAwMDAifQ has not expired yet
  I0902 07:52:22.908707 16 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTY4MjYsInN0YXJ0IjoiL3RlbXBsYXRlLTAwMzlcdTAwMDAifQ has not expired yet
  I0902 07:52:42.913087 16 chunking.go:177] got error The provided continue parameter is too old to display a consistent list result. You can start a new list without the continue parameter, or use the continue token in this response to retrieve the remainder of the results. Continuing with the provided token results in an inconsistent list - objects that were created, modified, or deleted between the time the first chunk was returned and now may show up in the list.
  I0902 07:52:42.913196 16 chunking.go:186] Retrieved inconsistent continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6LTEsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9
  STEP: retrieving the second page again with the token received with the error message @ 09/02/25 07:52:42.913
  STEP: retrieving all remaining pages @ 09/02/25 07:52:42.924
  I0902 07:52:42.935674 16 chunking.go:221] Retrieved 40/40 results with rv 17788 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTc3ODgsInN0YXJ0IjoidGVtcGxhdGUtMDExOVx1MDAwMCJ9
  I0902 07:52:42.947308 16 chunking.go:221] Retrieved 40/40 results with rv 17788 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTc3ODgsInN0YXJ0IjoidGVtcGxhdGUtMDE1OVx1MDAwMCJ9
  I0902 07:52:42.957905 16 chunking.go:221] Retrieved 40/40 results with rv 17788 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTc3ODgsInN0YXJ0IjoidGVtcGxhdGUtMDE5OVx1MDAwMCJ9
  I0902 07:52:42.969796 16 chunking.go:221] Retrieved 40/40 results with rv 17788 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTc3ODgsInN0YXJ0IjoidGVtcGxhdGUtMDIzOVx1MDAwMCJ9
  I0902 07:52:42.982845 16 chunking.go:221] Retrieved 40/40 results with rv 17788 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTc3ODgsInN0YXJ0IjoidGVtcGxhdGUtMDI3OVx1MDAwMCJ9
  I0902 07:52:42.997799 16 chunking.go:221] Retrieved 40/40 results with rv 17788 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTc3ODgsInN0YXJ0IjoidGVtcGxhdGUtMDMxOVx1MDAwMCJ9
  I0902 07:52:43.012531 16 chunking.go:221] Retrieved 40/40 results with rv 17788 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTc3ODgsInN0YXJ0IjoidGVtcGxhdGUtMDM1OVx1MDAwMCJ9
  I0902 07:52:43.025784 16 chunking.go:221] Retrieved 40/40 results with rv 17788 and continue 
  I0902 07:52:43.027089 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "chunking-721" for this suite. @ 09/02/25 07:52:43.052
• [457.954 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:110
  STEP: Creating a kubernetes client @ 09/02/25 07:52:43.072
  I0902 07:52:43.072408 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename kubelet-test @ 09/02/25 07:52:43.077
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:52:43.119
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:52:43.127
  I0902 07:52:47.180141 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-1339" for this suite. @ 09/02/25 07:52:47.191
• [4.137 seconds]
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply a finalizer to a Namespace [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:400
  STEP: Creating a kubernetes client @ 09/02/25 07:52:47.208
  I0902 07:52:47.208937 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename namespaces @ 09/02/25 07:52:47.212
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:52:47.248
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:52:47.258
  STEP: Creating namespace "e2e-ns-p8flt" @ 09/02/25 07:52:47.266
  I0902 07:52:47.293130 16 namespace.go:411] Namespace "e2e-ns-p8flt-9825" has []v1.FinalizerName{"kubernetes"}
  STEP: Adding e2e finalizer to namespace "e2e-ns-p8flt-9825" @ 09/02/25 07:52:47.293
  I0902 07:52:47.314818 16 namespace.go:434] Namespace "e2e-ns-p8flt-9825" has []v1.FinalizerName{"kubernetes", "e2e.example.com/fakeFinalizer"}
  STEP: Removing e2e finalizer from namespace "e2e-ns-p8flt-9825" @ 09/02/25 07:52:47.314
  I0902 07:52:47.345267 16 namespace.go:463] Namespace "e2e-ns-p8flt-9825" has []v1.FinalizerName{"kubernetes"}
  I0902 07:52:47.345678 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-8751" for this suite. @ 09/02/25 07:52:47.364
  STEP: Destroying namespace "e2e-ns-p8flt-9825" for this suite. @ 09/02/25 07:52:47.385
• [0.216 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:222
  STEP: Creating a kubernetes client @ 09/02/25 07:52:47.425
  I0902 07:52:47.425324 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename downward-api @ 09/02/25 07:52:47.428
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:52:47.463
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:52:47.473
  STEP: Creating a pod to test downward API volume plugin @ 09/02/25 07:52:47.48
  STEP: Saw pod success @ 09/02/25 07:52:51.538
  I0902 07:52:51.546814 16 output.go:207] Trying to get logs from node ietha7evai9i-3 pod downwardapi-volume-00291ab9-25ba-4f61-85ce-2d23ed8ee4a0 container client-container: <nil>
  STEP: delete the pod @ 09/02/25 07:52:51.594
  I0902 07:52:51.637425 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-5807" for this suite. @ 09/02/25 07:52:51.652
• [4.244 seconds]
------------------------------
[sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:54
  STEP: Creating a kubernetes client @ 09/02/25 07:52:51.669
  I0902 07:52:51.669427 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename downward-api @ 09/02/25 07:52:51.673
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:52:51.709
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:52:51.723
  STEP: Creating a pod to test downward API volume plugin @ 09/02/25 07:52:51.737
  STEP: Saw pod success @ 09/02/25 07:52:55.828
  I0902 07:52:55.838271 16 output.go:207] Trying to get logs from node ietha7evai9i-2 pod downwardapi-volume-b80b43ab-30eb-489f-8209-d8f515ca3886 container client-container: <nil>
  STEP: delete the pod @ 09/02/25 07:52:55.898
  I0902 07:52:56.002827 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-9852" for this suite. @ 09/02/25 07:52:56.015
• [4.370 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:47
  STEP: Creating a kubernetes client @ 09/02/25 07:52:56.041
  I0902 07:52:56.041701 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename var-expansion @ 09/02/25 07:52:56.044
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:52:56.076
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:52:56.084
  STEP: Creating a pod to test env composition @ 09/02/25 07:52:56.087
  STEP: Saw pod success @ 09/02/25 07:53:00.141
  I0902 07:53:00.148256 16 output.go:207] Trying to get logs from node ietha7evai9i-2 pod var-expansion-98b610f1-c892-48a0-a99a-de31e4ed3d33 container dapi-container: <nil>
  STEP: delete the pod @ 09/02/25 07:53:00.173
  I0902 07:53:00.225539 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-7332" for this suite. @ 09/02/25 07:53:00.237
• [4.220 seconds]
------------------------------
[sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:254
  STEP: Creating a kubernetes client @ 09/02/25 07:53:00.261
  I0902 07:53:00.261815 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename namespaces @ 09/02/25 07:53:00.265
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:53:00.297
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:53:00.31
  STEP: Creating a test namespace @ 09/02/25 07:53:00.317
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:53:00.362
  STEP: Creating a service in the namespace @ 09/02/25 07:53:00.387
  STEP: Deleting the namespace @ 09/02/25 07:53:00.431
  STEP: Waiting for the namespace to be removed. @ 09/02/25 07:53:00.478
  STEP: Recreating the namespace @ 09/02/25 07:53:07.493
  STEP: Verifying there is no service in the namespace @ 09/02/25 07:53:07.549
  I0902 07:53:07.556754 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-9844" for this suite. @ 09/02/25 07:53:07.571
  STEP: Destroying namespace "nsdeletetest-742" for this suite. @ 09/02/25 07:53:07.588
  I0902 07:53:07.601260 16 framework.go:370] Namespace nsdeletetest-742 was already deleted
  STEP: Destroying namespace "nsdeletetest-1518" for this suite. @ 09/02/25 07:53:07.601
• [7.361 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:59
  STEP: Creating a kubernetes client @ 09/02/25 07:53:07.628
  I0902 07:53:07.628641 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename subpath @ 09/02/25 07:53:07.631
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:53:07.681
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:53:07.689
  STEP: Setting up data @ 09/02/25 07:53:07.696
  STEP: Creating pod pod-subpath-test-secret-tb8h @ 09/02/25 07:53:07.724
  STEP: Creating a pod to test atomic-volume-subpath @ 09/02/25 07:53:07.725
  STEP: Saw pod success @ 09/02/25 07:53:31.904
  I0902 07:53:31.914396 16 output.go:207] Trying to get logs from node ietha7evai9i-2 pod pod-subpath-test-secret-tb8h container test-container-subpath-secret-tb8h: <nil>
  STEP: delete the pod @ 09/02/25 07:53:31.936
  STEP: Deleting pod pod-subpath-test-secret-tb8h @ 09/02/25 07:53:32.001
  I0902 07:53:32.001892 16 delete.go:78] Deleting pod "pod-subpath-test-secret-tb8h" in namespace "subpath-8773"
  I0902 07:53:32.011541 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-8773" for this suite. @ 09/02/25 07:53:32.023
• [24.411 seconds]
------------------------------
S
------------------------------
[sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/hostport.go:63
  STEP: Creating a kubernetes client @ 09/02/25 07:53:32.04
  I0902 07:53:32.040149 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename hostport @ 09/02/25 07:53:32.045
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:53:32.075
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:53:32.08
  STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled @ 09/02/25 07:53:32.124
  STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 192.168.121.25 on the node which pod1 resides and expect scheduled @ 09/02/25 07:53:34.201
  STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 192.168.121.25 but use UDP protocol on the node which pod2 resides @ 09/02/25 07:53:36.243
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 @ 09/02/25 07:53:40.338
  I0902 07:53:40.338774 16 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 192.168.121.25 http://127.0.0.1:54323/hostname] Namespace:hostport-5097 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0902 07:53:40.338868 16 exec_util.go:68] ExecWithOptions: Clientset creation
  I0902 07:53:40.339206 16 exec_util.go:84] ExecWithOptions: execute(https://10.233.0.1:443/api/v1/namespaces/hostport-5097/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+192.168.121.25+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&stderr=true&stdout=true)
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 192.168.121.25, port: 54323 @ 09/02/25 07:53:40.509
  I0902 07:53:40.509528 16 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://192.168.121.25:54323/hostname] Namespace:hostport-5097 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0902 07:53:40.509600 16 exec_util.go:68] ExecWithOptions: Clientset creation
  I0902 07:53:40.509739 16 exec_util.go:84] ExecWithOptions: execute(https://10.233.0.1:443/api/v1/namespaces/hostport-5097/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F192.168.121.25%3A54323%2Fhostname&container=e2e-host-exec&stderr=true&stdout=true)
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 192.168.121.25, port: 54323 UDP @ 09/02/25 07:53:40.621
  I0902 07:53:40.621328 16 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 192.168.121.25 54323] Namespace:hostport-5097 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0902 07:53:40.621372 16 exec_util.go:68] ExecWithOptions: Clientset creation
  I0902 07:53:40.621513 16 exec_util.go:84] ExecWithOptions: execute(https://10.233.0.1:443/api/v1/namespaces/hostport-5097/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+192.168.121.25+54323&container=e2e-host-exec&stderr=true&stdout=true)
  I0902 07:53:45.751791 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "hostport-5097" for this suite. @ 09/02/25 07:53:45.765
• [13.744 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply an invalid CR with extra properties for CRD with validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:348
  STEP: Creating a kubernetes client @ 09/02/25 07:53:45.785
  I0902 07:53:45.785615 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename field-validation @ 09/02/25 07:53:45.788
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:53:45.875
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:53:45.881
  I0902 07:53:45.888981 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  W0902 07:53:45.891798      16 field_validation.go:421] props: &JSONSchemaProps{ID:,Schema:,Ref:nil,Description:,Type:object,Format:,Title:,Default:nil,Maximum:nil,ExclusiveMaximum:false,Minimum:nil,ExclusiveMinimum:false,MaxLength:nil,MinLength:nil,Pattern:,MaxItems:nil,MinItems:nil,UniqueItems:false,MultipleOf:nil,Enum:[]JSON{},MaxProperties:nil,MinProperties:nil,Required:[],Items:nil,AllOf:[]JSONSchemaProps{},OneOf:[]JSONSchemaProps{},AnyOf:[]JSONSchemaProps{},Not:nil,Properties:map[string]JSONSchemaProps{spec: {  <nil>  object   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[cronSpec:{  <nil>  string   nil <nil> false <nil> false <nil> <nil> ^(\d+|\*)(/\d+)?(\s+(\d+|\*)(/\d+)?){4}$ <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []} foo:{  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []} ports:{  <nil>  array   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] &JSONSchemaPropsOrArray{Schema:&JSONSchemaProps{ID:,Schema:,Ref:nil,Description:,Type:object,Format:,Title:,Default:nil,Maximum:nil,ExclusiveMaximum:false,Minimum:nil,ExclusiveMinimum:false,MaxLength:nil,MinLength:nil,Pattern:,MaxItems:nil,MinItems:nil,UniqueItems:false,MultipleOf:nil,Enum:[]JSON{},MaxProperties:nil,MinProperties:nil,Required:[containerPort protocol],Items:nil,AllOf:[]JSONSchemaProps{},OneOf:[]JSONSchemaProps{},AnyOf:[]JSONSchemaProps{},Not:nil,Properties:map[string]JSONSchemaProps{containerPort: {  <nil>  integer int32  nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},hostIP: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},hostPort: {  <nil>  integer int32  nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},name: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},protocol: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},},AdditionalProperties:nil,PatternProperties:map[string]JSONSchemaProps{},Dependencies:JSONSchemaDependencies{},AdditionalItems:nil,Definitions:JSONSchemaDefinitions{},ExternalDocs:nil,Example:nil,Nullable:false,XPreserveUnknownFields:nil,XEmbeddedResource:false,XIntOrString:false,XListMapKeys:[],XListType:nil,XMapType:nil,XValidations:[]ValidationRule{},},JSONSchemas:[]JSONSchemaProps{},} [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [containerPort protocol] 0xc000f95a40 <nil> []}] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},},AdditionalProperties:nil,PatternProperties:map[string]JSONSchemaProps{},Dependencies:JSONSchemaDependencies{},AdditionalItems:nil,Definitions:JSONSchemaDefinitions{},ExternalDocs:nil,Example:nil,Nullable:false,XPreserveUnknownFields:nil,XEmbeddedResource:false,XIntOrString:false,XListMapKeys:[],XListType:nil,XMapType:nil,XValidations:[]ValidationRule{},}
  I0902 07:53:45.908868      16 warnings.go:110] "Warning: unrecognized format \"int32\""
  I0902 07:53:48.621972      16 warnings.go:110] "Warning: unknown field \"alpha\""
  I0902 07:53:48.622097      16 warnings.go:110] "Warning: unknown field \"beta\""
  I0902 07:53:48.622150      16 warnings.go:110] "Warning: unknown field \"delta\""
  I0902 07:53:48.622182      16 warnings.go:110] "Warning: unknown field \"epsilon\""
  I0902 07:53:48.622209      16 warnings.go:110] "Warning: unknown field \"gamma\""
  I0902 07:53:49.217005 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-6599" for this suite. @ 09/02/25 07:53:49.227
• [3.471 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events should delete a collection of events [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/core_events.go:176
  STEP: Creating a kubernetes client @ 09/02/25 07:53:49.259
  I0902 07:53:49.259504 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename events @ 09/02/25 07:53:49.264
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:53:49.302
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:53:49.308
  STEP: Create set of events @ 09/02/25 07:53:49.314
  I0902 07:53:49.325517 16 core_events.go:198] created test-event-1
  I0902 07:53:49.341127 16 core_events.go:198] created test-event-2
  I0902 07:53:49.353190 16 core_events.go:198] created test-event-3
  STEP: get a list of Events with a label in the current namespace @ 09/02/25 07:53:49.353
  STEP: delete collection of events @ 09/02/25 07:53:49.364
  I0902 07:53:49.364731 16 core_events.go:213] requesting DeleteCollection of events
  STEP: check that the list of events matches the requested quantity @ 09/02/25 07:53:49.416
  I0902 07:53:49.416536 16 core_events.go:230] requesting list of events to confirm quantity
  I0902 07:53:49.424317 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-1068" for this suite. @ 09/02/25 07:53:49.435
• [0.191 seconds]
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:174
  STEP: Creating a kubernetes client @ 09/02/25 07:53:49.451
  I0902 07:53:49.451149 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename projected @ 09/02/25 07:53:49.453
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:53:49.481
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:53:49.487
  STEP: Creating configMap with name cm-test-opt-del-04a8f1d9-ce5b-43b4-b4df-19679c39c9ef @ 09/02/25 07:53:49.536
  STEP: Creating configMap with name cm-test-opt-upd-8669a321-76b4-4488-a55c-c4ce1494d2ce @ 09/02/25 07:53:49.549
  STEP: Creating the pod @ 09/02/25 07:53:49.56
  STEP: Deleting configmap cm-test-opt-del-04a8f1d9-ce5b-43b4-b4df-19679c39c9ef @ 09/02/25 07:53:51.719
  STEP: Updating configmap cm-test-opt-upd-8669a321-76b4-4488-a55c-c4ce1494d2ce @ 09/02/25 07:53:51.737
  STEP: Creating configMap with name cm-test-opt-create-449e4c0c-da3f-435d-828a-3d08adc2f370 @ 09/02/25 07:53:51.753
  STEP: waiting to observe update in volume @ 09/02/25 07:53:51.771
  I0902 07:55:10.883345 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4249" for this suite. @ 09/02/25 07:55:10.9
• [81.472 seconds]
------------------------------
[sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:504
  STEP: Creating a kubernetes client @ 09/02/25 07:55:10.925
  I0902 07:55:10.925649 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename configmap @ 09/02/25 07:55:10.931
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:55:11.016
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:55:11.024
  I0902 07:55:11.127264 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-8092" for this suite. @ 09/02/25 07:55:11.135
• [0.228 seconds]
------------------------------
SSSSSS
------------------------------
[sig-network] Services should complete a service status lifecycle [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3431
  STEP: Creating a kubernetes client @ 09/02/25 07:55:11.153
  I0902 07:55:11.153145 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename services @ 09/02/25 07:55:11.158
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:55:11.183
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:55:11.195
  STEP: creating a Service @ 09/02/25 07:55:11.208
  STEP: watching for the Service to be added @ 09/02/25 07:55:11.248
  I0902 07:55:11.253030 16 service.go:3483] Found Service test-service-mhnvl in namespace services-6299 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 32688}]
  I0902 07:55:11.253790 16 service.go:3490] Service test-service-mhnvl created
  STEP: Getting /status @ 09/02/25 07:55:11.254
  I0902 07:55:11.267485 16 service.go:3501] Service test-service-mhnvl has LoadBalancer: {[]}
  STEP: patching the ServiceStatus @ 09/02/25 07:55:11.267
  STEP: watching for the Service to be patched @ 09/02/25 07:55:11.287
  I0902 07:55:11.290881 16 service.go:3524] observed Service test-service-mhnvl in namespace services-6299 with annotations: map[] & LoadBalancer: {[]}
  I0902 07:55:11.291045 16 service.go:3527] Found Service test-service-mhnvl in namespace services-6299 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  0xc00136f570 []}]}
  I0902 07:55:11.291094 16 service.go:3534] Service test-service-mhnvl has service status patched
  STEP: updating the ServiceStatus @ 09/02/25 07:55:11.291
  I0902 07:55:11.317003 16 service.go:3554] updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the Service to be updated @ 09/02/25 07:55:11.317
  I0902 07:55:11.321322 16 service.go:3565] Observed Service test-service-mhnvl in namespace services-6299 with annotations: map[] & Conditions: []
  I0902 07:55:11.321657 16 service.go:3576] Observed Service test-service-mhnvl in namespace services-6299 with annotations: map[patchedstatus:true] & Conditions: []
  I0902 07:55:11.321743 16 service.go:3572] Found Service test-service-mhnvl in namespace services-6299 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  I0902 07:55:11.321776 16 service.go:3583] Service test-service-mhnvl has service status updated
  STEP: patching the service @ 09/02/25 07:55:11.321
  STEP: watching for the Service to be patched @ 09/02/25 07:55:11.35
  I0902 07:55:11.353971 16 service.go:3606] observed Service test-service-mhnvl in namespace services-6299 with labels: map[test-service-static:true]
  I0902 07:55:11.354058 16 service.go:3606] observed Service test-service-mhnvl in namespace services-6299 with labels: map[test-service-static:true]
  I0902 07:55:11.354110 16 service.go:3606] observed Service test-service-mhnvl in namespace services-6299 with labels: map[test-service-static:true]
  I0902 07:55:11.354271 16 service.go:3609] Found Service test-service-mhnvl in namespace services-6299 with labels: map[test-service:patched test-service-static:true]
  I0902 07:55:11.354321 16 service.go:3616] Service test-service-mhnvl patched
  STEP: deleting the service @ 09/02/25 07:55:11.354
  STEP: watching for the Service to be deleted @ 09/02/25 07:55:11.397
  I0902 07:55:11.401128 16 service.go:3640] Observed event: ADDED
  I0902 07:55:11.401204 16 service.go:3640] Observed event: MODIFIED
  I0902 07:55:11.401776 16 service.go:3640] Observed event: MODIFIED
  I0902 07:55:11.401835 16 service.go:3640] Observed event: MODIFIED
  I0902 07:55:11.402112 16 service.go:3636] Found Service test-service-mhnvl in namespace services-6299 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
  I0902 07:55:11.402186 16 service.go:3645] Service test-service-mhnvl deleted
  I0902 07:55:11.403062 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-6299" for this suite. @ 09/02/25 07:55:11.414
• [0.276 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should serve a basic image on each replica with a public image [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:71
  STEP: Creating a kubernetes client @ 09/02/25 07:55:11.431
  I0902 07:55:11.431785 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename replication-controller @ 09/02/25 07:55:11.434
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:55:11.461
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:55:11.466
  STEP: Creating replication controller my-hostname-basic-a6417b3d-4e04-4297-ab57-368319575f11 @ 09/02/25 07:55:11.473
  I0902 07:55:11.510175 16 resource.go:64] Pod name my-hostname-basic-a6417b3d-4e04-4297-ab57-368319575f11: Found 0 pods out of 1
  I0902 07:55:16.524532 16 resource.go:64] Pod name my-hostname-basic-a6417b3d-4e04-4297-ab57-368319575f11: Found 1 pods out of 1
  I0902 07:55:16.524783 16 rc.go:509] Ensuring all pods for ReplicationController "my-hostname-basic-a6417b3d-4e04-4297-ab57-368319575f11" are running
  I0902 07:55:16.542687 16 rc.go:525] Pod "my-hostname-basic-a6417b3d-4e04-4297-ab57-368319575f11-8xt2k" is running and ready(conditions: [{Type:PodReadyToStartContainers ObservedGeneration:1 Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2025-09-02 07:55:13 +0000 UTC Reason: Message:} {Type:Initialized ObservedGeneration:1 Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2025-09-02 07:55:11 +0000 UTC Reason: Message:} {Type:Ready ObservedGeneration:1 Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2025-09-02 07:55:13 +0000 UTC Reason: Message:} {Type:ContainersReady ObservedGeneration:1 Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2025-09-02 07:55:13 +0000 UTC Reason: Message:} {Type:PodScheduled ObservedGeneration:1 Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2025-09-02 07:55:11 +0000 UTC Reason: Message:}])
  I0902 07:55:16.542762 16 rc.go:533] Trying to dial the pod
  STEP: trying to dial each unique pod @ 09/02/25 07:55:16.542
  I0902 07:55:16.604003 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-3383" for this suite. @ 09/02/25 07:55:16.615
• [5.199 seconds]
------------------------------
[sig-network] Services should provide secure master service [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:730
  STEP: Creating a kubernetes client @ 09/02/25 07:55:16.631
  I0902 07:55:16.631335 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename services @ 09/02/25 07:55:16.635
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:55:16.664
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:55:16.674
  I0902 07:55:16.686362 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-711" for this suite. @ 09/02/25 07:55:16.716
• [0.145 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:537
  STEP: Creating a kubernetes client @ 09/02/25 07:55:16.777
  I0902 07:55:16.777890 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename pods @ 09/02/25 07:55:16.781
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:55:16.858
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:55:16.881
  I0902 07:55:16.887500 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: creating the pod @ 09/02/25 07:55:16.889
  STEP: submitting the pod to kubernetes @ 09/02/25 07:55:16.89
  I0902 07:55:19.032843 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-4207" for this suite. @ 09/02/25 07:55:19.044
• [2.279 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Serial] [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:647
  STEP: Creating a kubernetes client @ 09/02/25 07:55:19.058
  I0902 07:55:19.058493 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename gc @ 09/02/25 07:55:19.063
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:55:19.094
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:55:19.1
  STEP: create the rc @ 09/02/25 07:55:19.143
  I0902 07:55:19.152962      16 warnings.go:110] "Warning: metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]"
  STEP: delete the rc @ 09/02/25 07:55:28.207
  STEP: wait for the rc to be deleted @ 09/02/25 07:55:28.736
  I0902 07:55:31.184765 16 garbage_collector.go:678] 100 pods remaining
  I0902 07:55:31.184876 16 garbage_collector.go:685] 100 pods has nil DeletionTimestamp
  I0902 07:55:31.184925 16 garbage_collector.go:686] 
  I0902 07:55:31.640855 16 garbage_collector.go:678] 98 pods remaining
  I0902 07:55:31.640967 16 garbage_collector.go:685] 86 pods has nil DeletionTimestamp
  I0902 07:55:31.640995 16 garbage_collector.go:686] 
  I0902 07:55:32.357858 16 garbage_collector.go:678] 88 pods remaining
  I0902 07:55:32.357953 16 garbage_collector.go:685] 80 pods has nil DeletionTimestamp
  I0902 07:55:32.357970 16 garbage_collector.go:686] 
  I0902 07:55:33.182981 16 garbage_collector.go:678] 79 pods remaining
  I0902 07:55:33.183122 16 garbage_collector.go:685] 60 pods has nil DeletionTimestamp
  I0902 07:55:33.183140 16 garbage_collector.go:686] 
  I0902 07:55:34.057378 16 garbage_collector.go:678] 75 pods remaining
  I0902 07:55:34.057453 16 garbage_collector.go:685] 51 pods has nil DeletionTimestamp
  I0902 07:55:34.057470 16 garbage_collector.go:686] 
  I0902 07:55:35.132938 16 garbage_collector.go:678] 65 pods remaining
  I0902 07:55:35.133016 16 garbage_collector.go:685] 36 pods has nil DeletionTimestamp
  I0902 07:55:35.133031 16 garbage_collector.go:686] 
  I0902 07:55:36.123046 16 garbage_collector.go:678] 60 pods remaining
  I0902 07:55:36.123120 16 garbage_collector.go:685] 23 pods has nil DeletionTimestamp
  I0902 07:55:36.123136 16 garbage_collector.go:686] 
  I0902 07:55:38.251904 16 garbage_collector.go:678] 57 pods remaining
  I0902 07:55:38.252144 16 garbage_collector.go:685] 10 pods has nil DeletionTimestamp
  I0902 07:55:38.252166 16 garbage_collector.go:686] 
  I0902 07:55:39.497799 16 garbage_collector.go:678] 51 pods remaining
  I0902 07:55:39.497914 16 garbage_collector.go:685] 0 pods has nil DeletionTimestamp
  I0902 07:55:39.497934 16 garbage_collector.go:686] 
  I0902 07:55:40.002163 16 garbage_collector.go:678] 40 pods remaining
  I0902 07:55:40.002244 16 garbage_collector.go:685] 0 pods has nil DeletionTimestamp
  I0902 07:55:40.002264 16 garbage_collector.go:686] 
  I0902 07:55:40.775095 16 garbage_collector.go:678] 34 pods remaining
  I0902 07:55:40.775477 16 garbage_collector.go:685] 0 pods has nil DeletionTimestamp
  I0902 07:55:40.775510 16 garbage_collector.go:686] 
  I0902 07:55:41.202237 16 garbage_collector.go:678] 30 pods remaining
  I0902 07:55:41.202301 16 garbage_collector.go:685] 0 pods has nil DeletionTimestamp
  I0902 07:55:41.202316 16 garbage_collector.go:686] 
  I0902 07:55:42.001534 16 garbage_collector.go:678] 16 pods remaining
  I0902 07:55:42.001860 16 garbage_collector.go:685] 0 pods has nil DeletionTimestamp
  I0902 07:55:42.001904 16 garbage_collector.go:686] 
  I0902 07:55:42.773839 16 garbage_collector.go:678] 9 pods remaining
  I0902 07:55:42.773936 16 garbage_collector.go:685] 0 pods has nil DeletionTimestamp
  I0902 07:55:42.773963 16 garbage_collector.go:686] 
  STEP: Gathering metrics @ 09/02/25 07:55:43.757
  I0902 07:55:44.037853 16 garbage_collector.go:273] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I0902 07:55:44.038289 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-2049" for this suite. @ 09/02/25 07:55:44.053
• [25.043 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:890
  STEP: Creating a kubernetes client @ 09/02/25 07:55:44.104
  I0902 07:55:44.104630 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename daemonsets @ 09/02/25 07:55:44.11
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:55:44.235
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:55:44.259
  STEP: Creating simple DaemonSet "daemon-set" @ 09/02/25 07:55:44.355
  STEP: Check that daemon pods launch on every node of the cluster. @ 09/02/25 07:55:44.379
  I0902 07:55:44.434531 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0902 07:55:44.434668 16 fixtures.go:131] Node ietha7evai9i-1 is running 0 daemon pod, expected 1
  I0902 07:55:45.468173 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0902 07:55:45.468835 16 fixtures.go:131] Node ietha7evai9i-1 is running 0 daemon pod, expected 1
  I0902 07:55:46.406720 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0902 07:55:46.408094 16 fixtures.go:131] Node ietha7evai9i-1 is running 0 daemon pod, expected 1
  I0902 07:55:47.401931 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0902 07:55:47.402110 16 fixtures.go:131] Node ietha7evai9i-1 is running 0 daemon pod, expected 1
  I0902 07:55:48.411030 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0902 07:55:48.411242 16 fixtures.go:131] Node ietha7evai9i-1 is running 0 daemon pod, expected 1
  I0902 07:55:49.420721 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0902 07:55:49.420818 16 fixtures.go:131] Node ietha7evai9i-1 is running 0 daemon pod, expected 1
  I0902 07:55:50.494450 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0902 07:55:50.521851 16 fixtures.go:131] Node ietha7evai9i-1 is running 0 daemon pod, expected 1
  I0902 07:55:51.423988 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0902 07:55:51.424152 16 fixtures.go:131] Node ietha7evai9i-1 is running 0 daemon pod, expected 1
  I0902 07:55:52.421371 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0902 07:55:52.421442 16 fixtures.go:131] Node ietha7evai9i-1 is running 0 daemon pod, expected 1
  I0902 07:55:53.416922 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0902 07:55:53.417106 16 fixtures.go:131] Node ietha7evai9i-1 is running 0 daemon pod, expected 1
  I0902 07:55:54.490274 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0902 07:55:54.491461 16 fixtures.go:131] Node ietha7evai9i-1 is running 0 daemon pod, expected 1
  I0902 07:55:55.411783 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0902 07:55:55.411874 16 fixtures.go:131] Node ietha7evai9i-1 is running 0 daemon pod, expected 1
  I0902 07:55:56.417467 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0902 07:55:56.417536 16 fixtures.go:131] Node ietha7evai9i-1 is running 0 daemon pod, expected 1
  I0902 07:55:57.458618 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0902 07:55:57.458716 16 fixtures.go:131] Node ietha7evai9i-1 is running 0 daemon pod, expected 1
  I0902 07:55:58.402467 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0902 07:55:58.402875 16 fixtures.go:131] Node ietha7evai9i-1 is running 0 daemon pod, expected 1
  I0902 07:55:59.397826 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0902 07:55:59.397942 16 fixtures.go:131] Node ietha7evai9i-1 is running 0 daemon pod, expected 1
  I0902 07:56:00.400968 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0902 07:56:00.401129 16 fixtures.go:131] Node ietha7evai9i-1 is running 0 daemon pod, expected 1
  I0902 07:56:01.406074 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0902 07:56:01.406323 16 fixtures.go:131] Node ietha7evai9i-1 is running 0 daemon pod, expected 1
  I0902 07:56:02.402331 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0902 07:56:02.402423 16 fixtures.go:131] Node ietha7evai9i-1 is running 0 daemon pod, expected 1
  I0902 07:56:03.400442 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0902 07:56:03.400534 16 fixtures.go:131] Node ietha7evai9i-1 is running 0 daemon pod, expected 1
  I0902 07:56:04.420192 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0902 07:56:04.420304 16 fixtures.go:131] Node ietha7evai9i-1 is running 0 daemon pod, expected 1
  I0902 07:56:05.402510 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0902 07:56:05.402637 16 fixtures.go:131] Node ietha7evai9i-1 is running 0 daemon pod, expected 1
  I0902 07:56:06.398694 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0902 07:56:06.398791 16 fixtures.go:131] Node ietha7evai9i-1 is running 0 daemon pod, expected 1
  I0902 07:56:07.401594 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0902 07:56:07.401667 16 fixtures.go:131] Node ietha7evai9i-1 is running 0 daemon pod, expected 1
  I0902 07:56:08.414251 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0902 07:56:08.414338 16 fixtures.go:131] Node ietha7evai9i-1 is running 0 daemon pod, expected 1
  I0902 07:56:09.398270 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0902 07:56:09.398347 16 fixtures.go:131] Node ietha7evai9i-1 is running 0 daemon pod, expected 1
  I0902 07:56:10.417998 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0902 07:56:10.418126 16 fixtures.go:131] Node ietha7evai9i-1 is running 0 daemon pod, expected 1
  I0902 07:56:11.403345 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0902 07:56:11.403514 16 fixtures.go:131] Node ietha7evai9i-1 is running 0 daemon pod, expected 1
  I0902 07:56:12.400703 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0902 07:56:12.400776 16 fixtures.go:131] Node ietha7evai9i-1 is running 0 daemon pod, expected 1
  I0902 07:56:13.405253 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0902 07:56:13.405325 16 fixtures.go:131] Node ietha7evai9i-1 is running 0 daemon pod, expected 1
  I0902 07:56:14.406035 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0902 07:56:14.406110 16 fixtures.go:131] Node ietha7evai9i-1 is running 0 daemon pod, expected 1
  I0902 07:56:15.422182 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0902 07:56:15.422278 16 fixtures.go:131] Node ietha7evai9i-1 is running 0 daemon pod, expected 1
  I0902 07:56:16.397272 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0902 07:56:16.397364 16 fixtures.go:131] Node ietha7evai9i-1 is running 0 daemon pod, expected 1
  I0902 07:56:17.430326 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0902 07:56:17.430393 16 fixtures.go:131] Node ietha7evai9i-1 is running 0 daemon pod, expected 1
  I0902 07:56:18.414176 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0902 07:56:18.415463 16 fixtures.go:131] Node ietha7evai9i-1 is running 0 daemon pod, expected 1
  I0902 07:56:19.407014 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0902 07:56:19.407278 16 fixtures.go:131] Node ietha7evai9i-1 is running 0 daemon pod, expected 1
  I0902 07:56:20.409247 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0902 07:56:20.409421 16 fixtures.go:131] Node ietha7evai9i-1 is running 0 daemon pod, expected 1
  I0902 07:56:21.485096 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0902 07:56:21.485164 16 fixtures.go:131] Node ietha7evai9i-1 is running 0 daemon pod, expected 1
  I0902 07:56:22.399898 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0902 07:56:22.400003 16 fixtures.go:131] Node ietha7evai9i-1 is running 0 daemon pod, expected 1
  I0902 07:56:23.404866 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I0902 07:56:23.404956 16 fixtures.go:136] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Getting /status @ 09/02/25 07:56:23.414
  I0902 07:56:23.438186 16 daemon_set.go:927] Daemon Set daemon-set has Conditions: []
  STEP: updating the DaemonSet Status @ 09/02/25 07:56:23.438
  I0902 07:56:23.468714 16 daemon_set.go:947] updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the daemon set status to be updated @ 09/02/25 07:56:23.468
  I0902 07:56:23.479501 16 daemon_set.go:972] Observed &DaemonSet event: ADDED
  I0902 07:56:23.479964 16 daemon_set.go:972] Observed &DaemonSet event: MODIFIED
  I0902 07:56:23.480315 16 daemon_set.go:972] Observed &DaemonSet event: MODIFIED
  I0902 07:56:23.480702 16 daemon_set.go:972] Observed &DaemonSet event: MODIFIED
  I0902 07:56:23.481083 16 daemon_set.go:972] Observed &DaemonSet event: MODIFIED
  I0902 07:56:23.481203 16 daemon_set.go:965] Found daemon set daemon-set in namespace daemonsets-1785 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  I0902 07:56:23.481265 16 daemon_set.go:976] Daemon set daemon-set has an updated status
  STEP: patching the DaemonSet Status @ 09/02/25 07:56:23.481
  STEP: watching for the daemon set status to be patched @ 09/02/25 07:56:23.518
  I0902 07:56:23.524959 16 daemon_set.go:1016] Observed &DaemonSet event: ADDED
  I0902 07:56:23.525457 16 daemon_set.go:1016] Observed &DaemonSet event: MODIFIED
  I0902 07:56:23.526183 16 daemon_set.go:1016] Observed &DaemonSet event: MODIFIED
  I0902 07:56:23.526959 16 daemon_set.go:1016] Observed &DaemonSet event: MODIFIED
  I0902 07:56:23.527499 16 daemon_set.go:1016] Observed &DaemonSet event: MODIFIED
  I0902 07:56:23.527750 16 daemon_set.go:1012] Observed daemon set daemon-set in namespace daemonsets-1785 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  I0902 07:56:23.528145 16 daemon_set.go:1016] Observed &DaemonSet event: MODIFIED
  I0902 07:56:23.528274 16 daemon_set.go:1009] Found daemon set daemon-set in namespace daemonsets-1785 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
  I0902 07:56:23.528448 16 daemon_set.go:1020] Daemon set daemon-set has a patched status
  STEP: Deleting DaemonSet "daemon-set" @ 09/02/25 07:56:23.541
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1785, will wait for the garbage collector to delete the pods @ 09/02/25 07:56:23.541
  I0902 07:56:23.621704 16 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 17.137268ms
  I0902 07:56:23.822768 16 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 201.060682ms
  I0902 07:56:25.234267 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0902 07:56:25.234416 16 fixtures.go:136] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I0902 07:56:25.259241 16 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"20712"},"items":null}

  I0902 07:56:25.267763 16 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"20712"},"items":null}

  I0902 07:56:25.335888 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-1785" for this suite. @ 09/02/25 07:56:25.345
• [41.261 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:798
  STEP: Creating a kubernetes client @ 09/02/25 07:56:25.366
  I0902 07:56:25.366940 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename job @ 09/02/25 07:56:25.372
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:56:25.401
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:56:25.407
  STEP: Creating a job @ 09/02/25 07:56:25.412
  STEP: Ensuring job reaches completions @ 09/02/25 07:56:25.425
  I0902 07:56:35.497968 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-9305" for this suite. @ 09/02/25 07:56:35.515
• [10.180 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for pods for Hostname [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:263
  STEP: Creating a kubernetes client @ 09/02/25 07:56:35.547
  I0902 07:56:35.547773 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename dns @ 09/02/25 07:56:35.55
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:56:35.599
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:56:35.604
  STEP: Creating a test headless service @ 09/02/25 07:56:35.609
  I0902 07:56:35.622292      16 warnings.go:110] "Warning: spec.SessionAffinity is ignored for headless services"
  STEP: Running these commands on agnhost: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-8976.svc.cluster.local)" && echo OK > /results/agnhost_hosts@dns-querier-2.dns-test-service-2.dns-8976.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/agnhost_hosts@dns-querier-2;sleep 1; done
   @ 09/02/25 07:56:35.622
  STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-8976.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-8976.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
   @ 09/02/25 07:56:35.622
  STEP: creating a pod to probe DNS @ 09/02/25 07:56:35.622
  STEP: submitting the pod to kubernetes @ 09/02/25 07:56:35.622
  STEP: retrieving the pod @ 09/02/25 07:56:39.712
  STEP: looking for the results for each expected name from probers @ 09/02/25 07:56:39.729
  I0902 07:56:39.773756 16 dns_common.go:495] Unable to read jessie_hosts@dns-querier-2 from pod dns-8976/dns-test-6a8e6390-31fe-489d-871d-20affefe9248: the server could not find the requested resource (get pods dns-test-6a8e6390-31fe-489d-871d-20affefe9248)
  I0902 07:56:39.773865 16 dns_common.go:506] Lookups using dns-8976/dns-test-6a8e6390-31fe-489d-871d-20affefe9248 failed for: [jessie_hosts@dns-querier-2]

  I0902 07:56:39.789644 16 dns_common.go:514] Pod client logs for webserver: 
  I0902 07:56:39.804265 16 dns_common.go:514] Pod client logs for agnhost-querier: 
  I0902 07:56:39.818521 16 dns_common.go:514] Pod client logs for jessie-querier: 
  I0902 07:56:44.805425 16 dns_common.go:546] DNS probes using dns-8976/dns-test-6a8e6390-31fe-489d-871d-20affefe9248 succeeded

  STEP: deleting the pod @ 09/02/25 07:56:44.805
  STEP: deleting the test headless service @ 09/02/25 07:56:44.835
  I0902 07:56:44.891699 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-8976" for this suite. @ 09/02/25 07:56:44.904
• [9.378 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:91
  STEP: Creating a kubernetes client @ 09/02/25 07:56:44.926
  I0902 07:56:44.927023 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename subpath @ 09/02/25 07:56:44.932
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:56:45.018
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:56:45.024
  STEP: Setting up data @ 09/02/25 07:56:45.032
  STEP: Creating pod pod-subpath-test-downwardapi-tp29 @ 09/02/25 07:56:45.056
  STEP: Creating a pod to test atomic-volume-subpath @ 09/02/25 07:56:45.056
  STEP: Saw pod success @ 09/02/25 07:57:09.264
  I0902 07:57:09.273447 16 output.go:207] Trying to get logs from node ietha7evai9i-2 pod pod-subpath-test-downwardapi-tp29 container test-container-subpath-downwardapi-tp29: <nil>
  STEP: delete the pod @ 09/02/25 07:57:09.313
  STEP: Deleting pod pod-subpath-test-downwardapi-tp29 @ 09/02/25 07:57:09.361
  I0902 07:57:09.362079 16 delete.go:78] Deleting pod "pod-subpath-test-downwardapi-tp29" in namespace "subpath-1156"
  I0902 07:57:09.369451 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-1156" for this suite. @ 09/02/25 07:57:09.38
• [24.467 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] PodTemplates should replace a pod template [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/podtemplates.go:177
  STEP: Creating a kubernetes client @ 09/02/25 07:57:09.395
  I0902 07:57:09.395260 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename podtemplate @ 09/02/25 07:57:09.398
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:57:09.425
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:57:09.432
  STEP: Create a pod template @ 09/02/25 07:57:09.437
  STEP: Replace a pod template @ 09/02/25 07:57:09.449
  I0902 07:57:09.469646 16 podtemplates.go:210] Found updated podtemplate annotation: "true"

  I0902 07:57:09.469915 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-506" for this suite. @ 09/02/25 07:57:09.479
• [0.099 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:89
  STEP: Creating a kubernetes client @ 09/02/25 07:57:09.495
  I0902 07:57:09.495659 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename emptydir @ 09/02/25 07:57:09.499
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:57:09.532
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:57:09.538
  STEP: Creating a pod to test emptydir volume type on tmpfs @ 09/02/25 07:57:09.544
  STEP: Saw pod success @ 09/02/25 07:57:13.597
  I0902 07:57:13.605013 16 output.go:207] Trying to get logs from node ietha7evai9i-2 pod pod-3ea7002b-b527-4d15-8480-f1df1941a33f container test-container: <nil>
  STEP: delete the pod @ 09/02/25 07:57:13.62
  I0902 07:57:13.652050 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-4366" for this suite. @ 09/02/25 07:57:13.662
• [4.192 seconds]
------------------------------
SS
------------------------------
[sig-instrumentation] Events should manage the lifecycle of an event [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/core_events.go:58
  STEP: Creating a kubernetes client @ 09/02/25 07:57:13.689
  I0902 07:57:13.690121 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename events @ 09/02/25 07:57:13.693
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:57:13.717
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:57:13.723
  STEP: creating a test event @ 09/02/25 07:57:13.729
  STEP: listing all events in all namespaces @ 09/02/25 07:57:13.738
  STEP: patching the test event @ 09/02/25 07:57:13.751
  STEP: fetching the test event @ 09/02/25 07:57:13.765
  STEP: updating the test event @ 09/02/25 07:57:13.772
  STEP: getting the test event @ 09/02/25 07:57:13.794
  STEP: deleting the test event @ 09/02/25 07:57:13.801
  STEP: listing all events in all namespaces @ 09/02/25 07:57:13.817
  I0902 07:57:13.829529 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-1456" for this suite. @ 09/02/25 07:57:13.839
• [0.168 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should delete a collection of pods [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:850
  STEP: Creating a kubernetes client @ 09/02/25 07:57:13.857
  I0902 07:57:13.857792 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename pods @ 09/02/25 07:57:13.861
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:57:13.894
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:57:13.904
  STEP: Create set of pods @ 09/02/25 07:57:13.911
  I0902 07:57:13.928645 16 pods.go:874] created test-pod-1
  I0902 07:57:13.945234 16 pods.go:874] created test-pod-2
  I0902 07:57:13.959870 16 pods.go:874] created test-pod-3
  STEP: waiting for all 3 pods to be running @ 09/02/25 07:57:13.959
  STEP: waiting for all pods to be deleted @ 09/02/25 07:57:18.067
  I0902 07:57:18.089876 16 pods.go:1139] Pod quantity 3 is different from expected quantity 0
  I0902 07:57:19.083519 16 pods.go:1139] Pod quantity 2 is different from expected quantity 0
  I0902 07:57:20.084813 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-445" for this suite. @ 09/02/25 07:57:20.096
• [6.258 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Pods should get a host IP [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:205
  STEP: Creating a kubernetes client @ 09/02/25 07:57:20.118
  I0902 07:57:20.118698 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename pods @ 09/02/25 07:57:20.122
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:57:20.153
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:57:20.161
  STEP: creating pod @ 09/02/25 07:57:20.165
  I0902 07:57:22.244000 16 pods.go:83] Pod pod-hostip-d3917e78-9e13-444a-b1d8-af30b8d0b313 has hostIP: 192.168.121.46
  I0902 07:57:22.244245 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-6988" for this suite. @ 09/02/25 07:57:22.253
• [2.151 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:144
  STEP: Creating a kubernetes client @ 09/02/25 07:57:22.269
  I0902 07:57:22.269978 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename replicaset @ 09/02/25 07:57:22.272
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:57:22.308
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:57:22.319
  STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota @ 09/02/25 07:57:22.327
  I0902 07:57:22.361189 16 resource.go:64] Pod name sample-pod: Found 0 pods out of 1
  I0902 07:57:27.391298 16 resource.go:64] Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 09/02/25 07:57:27.391
  STEP: getting scale subresource @ 09/02/25 07:57:27.391
  STEP: updating a scale subresource @ 09/02/25 07:57:27.409
  STEP: verifying the replicaset Spec.Replicas was modified @ 09/02/25 07:57:27.428
  STEP: Patch a scale subresource @ 09/02/25 07:57:27.447
  I0902 07:57:27.493540 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-8230" for this suite. @ 09/02/25 07:57:27.53
• [5.319 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for API chunking should return chunks of results for list calls [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/chunking.go:83
  STEP: Creating a kubernetes client @ 09/02/25 07:57:27.593
  I0902 07:57:27.593977 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename chunking @ 09/02/25 07:57:27.597
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:57:27.692
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:57:27.702
  STEP: creating a large number of resources @ 09/02/25 07:57:27.721
  STEP: retrieving those results in paged fashion several times @ 09/02/25 07:57:45.344
  I0902 07:57:45.389295 16 chunking.go:98] Retrieved 17/17 results with rv 21715 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MTUsInN0YXJ0IjoiL3RlbXBsYXRlLTAwMTZcdTAwMDAifQ
  I0902 07:57:45.435045 16 chunking.go:98] Retrieved 17/17 results with rv 21715 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MTUsInN0YXJ0IjoiL3RlbXBsYXRlLTAwMzNcdTAwMDAifQ
  I0902 07:57:45.484290 16 chunking.go:98] Retrieved 17/17 results with rv 21715 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MTUsInN0YXJ0IjoiL3RlbXBsYXRlLTAwNTBcdTAwMDAifQ
  I0902 07:57:45.535787 16 chunking.go:98] Retrieved 17/17 results with rv 21715 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MTUsInN0YXJ0IjoiL3RlbXBsYXRlLTAwNjdcdTAwMDAifQ
  I0902 07:57:45.589084 16 chunking.go:98] Retrieved 17/17 results with rv 21715 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MTUsInN0YXJ0IjoiL3RlbXBsYXRlLTAwODRcdTAwMDAifQ
  I0902 07:57:45.644748 16 chunking.go:98] Retrieved 17/17 results with rv 21715 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MTUsInN0YXJ0IjoiL3RlbXBsYXRlLTAxMDFcdTAwMDAifQ
  I0902 07:57:45.684956 16 chunking.go:98] Retrieved 17/17 results with rv 21715 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MTUsInN0YXJ0IjoiL3RlbXBsYXRlLTAxMThcdTAwMDAifQ
  I0902 07:57:45.736378 16 chunking.go:98] Retrieved 17/17 results with rv 21715 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MTUsInN0YXJ0IjoiL3RlbXBsYXRlLTAxMzVcdTAwMDAifQ
  I0902 07:57:45.787917 16 chunking.go:98] Retrieved 17/17 results with rv 21715 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MTUsInN0YXJ0IjoiL3RlbXBsYXRlLTAxNTJcdTAwMDAifQ
  I0902 07:57:45.835212 16 chunking.go:98] Retrieved 17/17 results with rv 21715 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MTUsInN0YXJ0IjoiL3RlbXBsYXRlLTAxNjlcdTAwMDAifQ
  I0902 07:57:45.884793 16 chunking.go:98] Retrieved 17/17 results with rv 21715 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MTUsInN0YXJ0IjoiL3RlbXBsYXRlLTAxODZcdTAwMDAifQ
  I0902 07:57:45.937701 16 chunking.go:98] Retrieved 17/17 results with rv 21715 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MTUsInN0YXJ0IjoiL3RlbXBsYXRlLTAyMDNcdTAwMDAifQ
  I0902 07:57:45.984468 16 chunking.go:98] Retrieved 17/17 results with rv 21715 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MTUsInN0YXJ0IjoiL3RlbXBsYXRlLTAyMjBcdTAwMDAifQ
  I0902 07:57:46.033926 16 chunking.go:98] Retrieved 17/17 results with rv 21715 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MTUsInN0YXJ0IjoiL3RlbXBsYXRlLTAyMzdcdTAwMDAifQ
  I0902 07:57:46.086007 16 chunking.go:98] Retrieved 17/17 results with rv 21715 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MTUsInN0YXJ0IjoiL3RlbXBsYXRlLTAyNTRcdTAwMDAifQ
  I0902 07:57:46.136926 16 chunking.go:98] Retrieved 17/17 results with rv 21715 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MTUsInN0YXJ0IjoiL3RlbXBsYXRlLTAyNzFcdTAwMDAifQ
  I0902 07:57:46.185962 16 chunking.go:98] Retrieved 17/17 results with rv 21715 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MTUsInN0YXJ0IjoiL3RlbXBsYXRlLTAyODhcdTAwMDAifQ
  I0902 07:57:46.233425 16 chunking.go:98] Retrieved 17/17 results with rv 21715 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MTUsInN0YXJ0IjoiL3RlbXBsYXRlLTAzMDVcdTAwMDAifQ
  I0902 07:57:46.284667 16 chunking.go:98] Retrieved 17/17 results with rv 21715 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MTUsInN0YXJ0IjoiL3RlbXBsYXRlLTAzMjJcdTAwMDAifQ
  I0902 07:57:46.333993 16 chunking.go:98] Retrieved 17/17 results with rv 21715 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MTUsInN0YXJ0IjoiL3RlbXBsYXRlLTAzMzlcdTAwMDAifQ
  I0902 07:57:46.387213 16 chunking.go:98] Retrieved 17/17 results with rv 21715 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MTUsInN0YXJ0IjoiL3RlbXBsYXRlLTAzNTZcdTAwMDAifQ
  I0902 07:57:46.434285 16 chunking.go:98] Retrieved 17/17 results with rv 21715 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MTUsInN0YXJ0IjoiL3RlbXBsYXRlLTAzNzNcdTAwMDAifQ
  I0902 07:57:46.486794 16 chunking.go:98] Retrieved 17/17 results with rv 21715 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MTUsInN0YXJ0IjoiL3RlbXBsYXRlLTAzOTBcdTAwMDAifQ
  I0902 07:57:46.533464 16 chunking.go:98] Retrieved 9/17 results with rv 21715 and continue 
  I0902 07:57:46.597220 16 chunking.go:98] Retrieved 17/17 results with rv 21717 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MTcsInN0YXJ0IjoiL3RlbXBsYXRlLTAwMTZcdTAwMDAifQ
  I0902 07:57:46.635308 16 chunking.go:98] Retrieved 17/17 results with rv 21717 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MTcsInN0YXJ0IjoiL3RlbXBsYXRlLTAwMzNcdTAwMDAifQ
  I0902 07:57:46.684753 16 chunking.go:98] Retrieved 17/17 results with rv 21717 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MTcsInN0YXJ0IjoiL3RlbXBsYXRlLTAwNTBcdTAwMDAifQ
  I0902 07:57:46.735054 16 chunking.go:98] Retrieved 17/17 results with rv 21717 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MTcsInN0YXJ0IjoiL3RlbXBsYXRlLTAwNjdcdTAwMDAifQ
  I0902 07:57:46.784635 16 chunking.go:98] Retrieved 17/17 results with rv 21717 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MTcsInN0YXJ0IjoiL3RlbXBsYXRlLTAwODRcdTAwMDAifQ
  I0902 07:57:46.834235 16 chunking.go:98] Retrieved 17/17 results with rv 21717 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MTcsInN0YXJ0IjoiL3RlbXBsYXRlLTAxMDFcdTAwMDAifQ
  I0902 07:57:46.886185 16 chunking.go:98] Retrieved 17/17 results with rv 21717 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MTcsInN0YXJ0IjoiL3RlbXBsYXRlLTAxMThcdTAwMDAifQ
  I0902 07:57:46.933648 16 chunking.go:98] Retrieved 17/17 results with rv 21717 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MTcsInN0YXJ0IjoiL3RlbXBsYXRlLTAxMzVcdTAwMDAifQ
  I0902 07:57:46.985862 16 chunking.go:98] Retrieved 17/17 results with rv 21717 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MTcsInN0YXJ0IjoiL3RlbXBsYXRlLTAxNTJcdTAwMDAifQ
  I0902 07:57:47.034427 16 chunking.go:98] Retrieved 17/17 results with rv 21717 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MTcsInN0YXJ0IjoiL3RlbXBsYXRlLTAxNjlcdTAwMDAifQ
  I0902 07:57:47.086358 16 chunking.go:98] Retrieved 17/17 results with rv 21717 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MTcsInN0YXJ0IjoiL3RlbXBsYXRlLTAxODZcdTAwMDAifQ
  I0902 07:57:47.134114 16 chunking.go:98] Retrieved 17/17 results with rv 21717 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MTcsInN0YXJ0IjoiL3RlbXBsYXRlLTAyMDNcdTAwMDAifQ
  I0902 07:57:47.183621 16 chunking.go:98] Retrieved 17/17 results with rv 21717 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MTcsInN0YXJ0IjoiL3RlbXBsYXRlLTAyMjBcdTAwMDAifQ
  I0902 07:57:47.233912 16 chunking.go:98] Retrieved 17/17 results with rv 21717 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MTcsInN0YXJ0IjoiL3RlbXBsYXRlLTAyMzdcdTAwMDAifQ
  I0902 07:57:47.283588 16 chunking.go:98] Retrieved 17/17 results with rv 21717 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MTcsInN0YXJ0IjoiL3RlbXBsYXRlLTAyNTRcdTAwMDAifQ
  I0902 07:57:47.339922 16 chunking.go:98] Retrieved 17/17 results with rv 21717 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MTcsInN0YXJ0IjoiL3RlbXBsYXRlLTAyNzFcdTAwMDAifQ
  I0902 07:57:47.384391 16 chunking.go:98] Retrieved 17/17 results with rv 21717 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MTcsInN0YXJ0IjoiL3RlbXBsYXRlLTAyODhcdTAwMDAifQ
  I0902 07:57:47.441016 16 chunking.go:98] Retrieved 17/17 results with rv 21717 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MTcsInN0YXJ0IjoiL3RlbXBsYXRlLTAzMDVcdTAwMDAifQ
  I0902 07:57:47.496052 16 chunking.go:98] Retrieved 17/17 results with rv 21717 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MTcsInN0YXJ0IjoiL3RlbXBsYXRlLTAzMjJcdTAwMDAifQ
  I0902 07:57:47.533664 16 chunking.go:98] Retrieved 17/17 results with rv 21717 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MTcsInN0YXJ0IjoiL3RlbXBsYXRlLTAzMzlcdTAwMDAifQ
  I0902 07:57:47.583862 16 chunking.go:98] Retrieved 17/17 results with rv 21717 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MTcsInN0YXJ0IjoiL3RlbXBsYXRlLTAzNTZcdTAwMDAifQ
  I0902 07:57:47.635247 16 chunking.go:98] Retrieved 17/17 results with rv 21717 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MTcsInN0YXJ0IjoiL3RlbXBsYXRlLTAzNzNcdTAwMDAifQ
  I0902 07:57:47.683511 16 chunking.go:98] Retrieved 17/17 results with rv 21717 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MTcsInN0YXJ0IjoiL3RlbXBsYXRlLTAzOTBcdTAwMDAifQ
  I0902 07:57:47.733223 16 chunking.go:98] Retrieved 9/17 results with rv 21717 and continue 
  I0902 07:57:47.789601 16 chunking.go:98] Retrieved 17/17 results with rv 21721 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MjEsInN0YXJ0IjoiL3RlbXBsYXRlLTAwMTZcdTAwMDAifQ
  I0902 07:57:47.833538 16 chunking.go:98] Retrieved 17/17 results with rv 21721 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MjEsInN0YXJ0IjoiL3RlbXBsYXRlLTAwMzNcdTAwMDAifQ
  I0902 07:57:47.884259 16 chunking.go:98] Retrieved 17/17 results with rv 21721 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MjEsInN0YXJ0IjoiL3RlbXBsYXRlLTAwNTBcdTAwMDAifQ
  I0902 07:57:47.936858 16 chunking.go:98] Retrieved 17/17 results with rv 21721 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MjEsInN0YXJ0IjoiL3RlbXBsYXRlLTAwNjdcdTAwMDAifQ
  I0902 07:57:47.985675 16 chunking.go:98] Retrieved 17/17 results with rv 21721 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MjEsInN0YXJ0IjoiL3RlbXBsYXRlLTAwODRcdTAwMDAifQ
  I0902 07:57:48.033126 16 chunking.go:98] Retrieved 17/17 results with rv 21721 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MjEsInN0YXJ0IjoiL3RlbXBsYXRlLTAxMDFcdTAwMDAifQ
  I0902 07:57:48.084636 16 chunking.go:98] Retrieved 17/17 results with rv 21721 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MjEsInN0YXJ0IjoiL3RlbXBsYXRlLTAxMThcdTAwMDAifQ
  I0902 07:57:48.133818 16 chunking.go:98] Retrieved 17/17 results with rv 21721 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MjEsInN0YXJ0IjoiL3RlbXBsYXRlLTAxMzVcdTAwMDAifQ
  I0902 07:57:48.183383 16 chunking.go:98] Retrieved 17/17 results with rv 21721 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MjEsInN0YXJ0IjoiL3RlbXBsYXRlLTAxNTJcdTAwMDAifQ
  I0902 07:57:48.233252 16 chunking.go:98] Retrieved 17/17 results with rv 21721 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MjEsInN0YXJ0IjoiL3RlbXBsYXRlLTAxNjlcdTAwMDAifQ
  I0902 07:57:48.283584 16 chunking.go:98] Retrieved 17/17 results with rv 21721 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MjEsInN0YXJ0IjoiL3RlbXBsYXRlLTAxODZcdTAwMDAifQ
  I0902 07:57:48.334688 16 chunking.go:98] Retrieved 17/17 results with rv 21721 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MjEsInN0YXJ0IjoiL3RlbXBsYXRlLTAyMDNcdTAwMDAifQ
  I0902 07:57:48.383415 16 chunking.go:98] Retrieved 17/17 results with rv 21721 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MjEsInN0YXJ0IjoiL3RlbXBsYXRlLTAyMjBcdTAwMDAifQ
  I0902 07:57:48.433804 16 chunking.go:98] Retrieved 17/17 results with rv 21721 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MjEsInN0YXJ0IjoiL3RlbXBsYXRlLTAyMzdcdTAwMDAifQ
  I0902 07:57:48.483527 16 chunking.go:98] Retrieved 17/17 results with rv 21721 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MjEsInN0YXJ0IjoiL3RlbXBsYXRlLTAyNTRcdTAwMDAifQ
  I0902 07:57:48.533845 16 chunking.go:98] Retrieved 17/17 results with rv 21721 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MjEsInN0YXJ0IjoiL3RlbXBsYXRlLTAyNzFcdTAwMDAifQ
  I0902 07:57:48.584325 16 chunking.go:98] Retrieved 17/17 results with rv 21721 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MjEsInN0YXJ0IjoiL3RlbXBsYXRlLTAyODhcdTAwMDAifQ
  I0902 07:57:48.634138 16 chunking.go:98] Retrieved 17/17 results with rv 21721 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MjEsInN0YXJ0IjoiL3RlbXBsYXRlLTAzMDVcdTAwMDAifQ
  I0902 07:57:48.683905 16 chunking.go:98] Retrieved 17/17 results with rv 21721 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MjEsInN0YXJ0IjoiL3RlbXBsYXRlLTAzMjJcdTAwMDAifQ
  I0902 07:57:48.733655 16 chunking.go:98] Retrieved 17/17 results with rv 21721 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MjEsInN0YXJ0IjoiL3RlbXBsYXRlLTAzMzlcdTAwMDAifQ
  I0902 07:57:48.783713 16 chunking.go:98] Retrieved 17/17 results with rv 21721 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MjEsInN0YXJ0IjoiL3RlbXBsYXRlLTAzNTZcdTAwMDAifQ
  I0902 07:57:48.833618 16 chunking.go:98] Retrieved 17/17 results with rv 21721 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MjEsInN0YXJ0IjoiL3RlbXBsYXRlLTAzNzNcdTAwMDAifQ
  I0902 07:57:48.883528 16 chunking.go:98] Retrieved 17/17 results with rv 21721 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjE3MjEsInN0YXJ0IjoiL3RlbXBsYXRlLTAzOTBcdTAwMDAifQ
  I0902 07:57:48.933345 16 chunking.go:98] Retrieved 9/17 results with rv 21721 and continue 
  STEP: retrieving those results all at once @ 09/02/25 07:57:48.933
  I0902 07:57:48.999441 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "chunking-794" for this suite. @ 09/02/25 07:57:49.044
• [21.506 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1400
  STEP: Creating a kubernetes client @ 09/02/25 07:57:49.1
  I0902 07:57:49.100818 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename kubectl @ 09/02/25 07:57:49.103
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:57:49.141
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:57:49.147
  STEP: validating cluster-info @ 09/02/25 07:57:49.153
  I0902 07:57:49.154286 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-2470 cluster-info'
  I0902 07:57:49.375894 16 builder.go:156] stderr: ""
  I0902 07:57:49.376039 16 builder.go:157] stdout: "Kubernetes control plane is running at https://10.233.0.1:443\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
  I0902 07:57:49.377268 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-2470" for this suite. @ 09/02/25 07:57:49.392
• [0.310 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:851
  STEP: Creating a kubernetes client @ 09/02/25 07:57:49.41
  I0902 07:57:49.410684 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename daemonsets @ 09/02/25 07:57:49.418
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:57:49.451
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:57:49.464
  STEP: Creating simple DaemonSet "daemon-set" @ 09/02/25 07:57:49.553
  STEP: Check that daemon pods launch on every node of the cluster. @ 09/02/25 07:57:49.57
  I0902 07:57:49.664913 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0902 07:57:49.665011 16 fixtures.go:131] Node ietha7evai9i-1 is running 0 daemon pod, expected 1
  I0902 07:57:50.608079 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0902 07:57:50.608150 16 fixtures.go:131] Node ietha7evai9i-1 is running 0 daemon pod, expected 1
  I0902 07:57:51.603822 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0902 07:57:51.603891 16 fixtures.go:131] Node ietha7evai9i-1 is running 0 daemon pod, expected 1
  I0902 07:57:52.591112 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I0902 07:57:52.591240 16 fixtures.go:136] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: listing all DaemonSets @ 09/02/25 07:57:52.596
  STEP: DeleteCollection of the DaemonSets @ 09/02/25 07:57:52.603
  STEP: Verify that ReplicaSets have been deleted @ 09/02/25 07:57:52.621
  I0902 07:57:52.708769 16 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"21782"},"items":null}

  I0902 07:57:52.725510 16 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"21782"},"items":[{"metadata":{"name":"daemon-set-27g5v","generateName":"daemon-set-","namespace":"daemonsets-8760","uid":"4955b18a-8173-4061-8efe-1d53c06c26b8","resourceVersion":"21780","generation":2,"creationTimestamp":"2025-09-02T07:57:49Z","deletionTimestamp":"2025-09-02T07:58:22Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7777b7654c","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"fb5f4157-19de-4481-a6b2-cc2a343f7527","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2025-09-02T07:57:49Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fb5f4157-19de-4481-a6b2-cc2a343f7527\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2025-09-02T07:57:51Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:observedGeneration":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:observedGeneration":{},"f:status":{},"f:type":{}},"k:{\"type\":\"PodReadyToStartContainers\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:observedGeneration":{},"f:status":{},"f:type":{}},"k:{\"type\":\"PodScheduled\"}":{"f:observedGeneration":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:observedGeneration":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:hostIPs":{},"f:observedGeneration":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.66.222\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-n8fsj","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-n8fsj","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ietha7evai9i-2","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ietha7evai9i-2"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"observedGeneration":1,"phase":"Running","conditions":[{"type":"PodReadyToStartContainers","observedGeneration":1,"status":"True","lastProbeTime":null,"lastTransitionTime":"2025-09-02T07:57:51Z"},{"type":"Initialized","observedGeneration":1,"status":"True","lastProbeTime":null,"lastTransitionTime":"2025-09-02T07:57:49Z"},{"type":"Ready","observedGeneration":1,"status":"True","lastProbeTime":null,"lastTransitionTime":"2025-09-02T07:57:51Z"},{"type":"ContainersReady","observedGeneration":1,"status":"True","lastProbeTime":null,"lastTransitionTime":"2025-09-02T07:57:51Z"},{"type":"PodScheduled","observedGeneration":1,"status":"True","lastProbeTime":null,"lastTransitionTime":"2025-09-02T07:57:49Z"}],"hostIP":"192.168.121.46","hostIPs":[{"ip":"192.168.121.46"}],"podIP":"10.233.66.222","podIPs":[{"ip":"10.233.66.222"}],"startTime":"2025-09-02T07:57:49Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2025-09-02T07:57:50Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"cri-o://8ec106a8a844e24f127465bb30b3dd01380515c310833c264589f223134ebeca","started":true,"resources":{},"volumeMounts":[{"name":"kube-api-access-n8fsj","mountPath":"/var/run/secrets/kubernetes.io/serviceaccount","readOnly":true,"recursiveReadOnly":"Disabled"}],"user":{"linux":{"uid":0,"gid":0,"supplementalGroups":[0,1,2,3,4,6,10,11,20,26,27]}}}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-mb846","generateName":"daemon-set-","namespace":"daemonsets-8760","uid":"dd6912a8-9362-4855-870c-9ba11ce5d072","resourceVersion":"21779","generation":2,"creationTimestamp":"2025-09-02T07:57:49Z","deletionTimestamp":"2025-09-02T07:58:22Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7777b7654c","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"fb5f4157-19de-4481-a6b2-cc2a343f7527","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2025-09-02T07:57:49Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fb5f4157-19de-4481-a6b2-cc2a343f7527\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2025-09-02T07:57:51Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:observedGeneration":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:observedGeneration":{},"f:status":{},"f:type":{}},"k:{\"type\":\"PodReadyToStartContainers\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:observedGeneration":{},"f:status":{},"f:type":{}},"k:{\"type\":\"PodScheduled\"}":{"f:observedGeneration":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:observedGeneration":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:hostIPs":{},"f:observedGeneration":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.65.133\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-hdkpl","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-hdkpl","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ietha7evai9i-3","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ietha7evai9i-3"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"observedGeneration":1,"phase":"Running","conditions":[{"type":"PodReadyToStartContainers","observedGeneration":1,"status":"True","lastProbeTime":null,"lastTransitionTime":"2025-09-02T07:57:51Z"},{"type":"Initialized","observedGeneration":1,"status":"True","lastProbeTime":null,"lastTransitionTime":"2025-09-02T07:57:49Z"},{"type":"Ready","observedGeneration":1,"status":"True","lastProbeTime":null,"lastTransitionTime":"2025-09-02T07:57:51Z"},{"type":"ContainersReady","observedGeneration":1,"status":"True","lastProbeTime":null,"lastTransitionTime":"2025-09-02T07:57:51Z"},{"type":"PodScheduled","observedGeneration":1,"status":"True","lastProbeTime":null,"lastTransitionTime":"2025-09-02T07:57:49Z"}],"hostIP":"192.168.121.52","hostIPs":[{"ip":"192.168.121.52"}],"podIP":"10.233.65.133","podIPs":[{"ip":"10.233.65.133"}],"startTime":"2025-09-02T07:57:49Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2025-09-02T07:57:50Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"cri-o://67d6a8e8f6a06041ccab08408ffe3dc29444a6f756f0282b5197c9e70dd61f12","started":true,"resources":{},"volumeMounts":[{"name":"kube-api-access-hdkpl","mountPath":"/var/run/secrets/kubernetes.io/serviceaccount","readOnly":true,"recursiveReadOnly":"Disabled"}],"user":{"linux":{"uid":0,"gid":0,"supplementalGroups":[0,1,2,3,4,6,10,11,20,26,27]}}}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-nwzdm","generateName":"daemon-set-","namespace":"daemonsets-8760","uid":"a9996dbf-7403-4816-894d-f75cc64d70cf","resourceVersion":"21781","generation":2,"creationTimestamp":"2025-09-02T07:57:49Z","deletionTimestamp":"2025-09-02T07:58:22Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7777b7654c","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"fb5f4157-19de-4481-a6b2-cc2a343f7527","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2025-09-02T07:57:49Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fb5f4157-19de-4481-a6b2-cc2a343f7527\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2025-09-02T07:57:51Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:observedGeneration":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:observedGeneration":{},"f:status":{},"f:type":{}},"k:{\"type\":\"PodReadyToStartContainers\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:observedGeneration":{},"f:status":{},"f:type":{}},"k:{\"type\":\"PodScheduled\"}":{"f:observedGeneration":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:observedGeneration":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:hostIPs":{},"f:observedGeneration":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.64.68\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-pxg7p","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-pxg7p","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ietha7evai9i-1","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ietha7evai9i-1"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"observedGeneration":1,"phase":"Running","conditions":[{"type":"PodReadyToStartContainers","observedGeneration":1,"status":"True","lastProbeTime":null,"lastTransitionTime":"2025-09-02T07:57:51Z"},{"type":"Initialized","observedGeneration":1,"status":"True","lastProbeTime":null,"lastTransitionTime":"2025-09-02T07:57:49Z"},{"type":"Ready","observedGeneration":1,"status":"True","lastProbeTime":null,"lastTransitionTime":"2025-09-02T07:57:51Z"},{"type":"ContainersReady","observedGeneration":1,"status":"True","lastProbeTime":null,"lastTransitionTime":"2025-09-02T07:57:51Z"},{"type":"PodScheduled","observedGeneration":1,"status":"True","lastProbeTime":null,"lastTransitionTime":"2025-09-02T07:57:49Z"}],"hostIP":"192.168.121.25","hostIPs":[{"ip":"192.168.121.25"}],"podIP":"10.233.64.68","podIPs":[{"ip":"10.233.64.68"}],"startTime":"2025-09-02T07:57:49Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2025-09-02T07:57:51Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"cri-o://f4d9a2eec28fa1e2aa9eb838d7cd6f7349b23930909fdc3ea94a77287d14922e","started":true,"resources":{},"volumeMounts":[{"name":"kube-api-access-pxg7p","mountPath":"/var/run/secrets/kubernetes.io/serviceaccount","readOnly":true,"recursiveReadOnly":"Disabled"}],"user":{"linux":{"uid":0,"gid":0,"supplementalGroups":[0,1,2,3,4,6,10,11,20,26,27]}}}],"qosClass":"BestEffort"}}]}

  I0902 07:57:52.820889 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-8760" for this suite. @ 09/02/25 07:57:52.836
• [3.451 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should manage the lifecycle of a job [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:1158
  STEP: Creating a kubernetes client @ 09/02/25 07:57:52.862
  I0902 07:57:52.862279 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename job @ 09/02/25 07:57:52.865
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:57:52.889
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:57:52.898
  STEP: Creating a suspended job @ 09/02/25 07:57:52.917
  STEP: Patching the Job @ 09/02/25 07:57:52.932
  STEP: Watching for Job to be patched @ 09/02/25 07:57:52.979
  I0902 07:57:52.983460 16 job.go:1410] Event ADDED observed for Job e2e-pmlnh in namespace job-3744 with labels: map[e2e-job-label:e2e-pmlnh] and annotations: map[]
  I0902 07:57:52.983637 16 job.go:1410] Event MODIFIED observed for Job e2e-pmlnh in namespace job-3744 with labels: map[e2e-job-label:e2e-pmlnh] and annotations: map[]
  I0902 07:57:52.983701 16 job.go:1413] Event MODIFIED found for Job e2e-pmlnh in namespace job-3744 with labels: map[e2e-job-label:e2e-pmlnh e2e-pmlnh:patched] and annotations: map[]
  STEP: Updating the job @ 09/02/25 07:57:52.983
  STEP: Watching for Job to be updated @ 09/02/25 07:57:53.016
  I0902 07:57:53.025050 16 job.go:1413] Event MODIFIED found for Job e2e-pmlnh in namespace job-3744 with labels: map[e2e-job-label:e2e-pmlnh e2e-pmlnh:patched] and annotations: map[updated:true]
  I0902 07:57:53.025242 16 job.go:1236] Found Job annotations: map[string]string{"updated":"true"}
  STEP: Listing all Jobs with LabelSelector @ 09/02/25 07:57:53.025
  I0902 07:57:53.037970 16 job.go:1243] Job: e2e-pmlnh as labels: map[e2e-job-label:e2e-pmlnh e2e-pmlnh:patched]
  STEP: Waiting for job to complete @ 09/02/25 07:57:53.038
  STEP: Delete a job collection with a labelselector @ 09/02/25 07:58:01.12
  STEP: Watching for Job to be deleted @ 09/02/25 07:58:01.141
  I0902 07:58:01.145720 16 job.go:1410] Event MODIFIED observed for Job e2e-pmlnh in namespace job-3744 with labels: map[e2e-job-label:e2e-pmlnh e2e-pmlnh:patched] and annotations: map[updated:true]
  I0902 07:58:01.146878 16 job.go:1410] Event MODIFIED observed for Job e2e-pmlnh in namespace job-3744 with labels: map[e2e-job-label:e2e-pmlnh e2e-pmlnh:patched] and annotations: map[updated:true]
  I0902 07:58:01.146983 16 job.go:1410] Event MODIFIED observed for Job e2e-pmlnh in namespace job-3744 with labels: map[e2e-job-label:e2e-pmlnh e2e-pmlnh:patched] and annotations: map[updated:true]
  I0902 07:58:01.147261 16 job.go:1410] Event MODIFIED observed for Job e2e-pmlnh in namespace job-3744 with labels: map[e2e-job-label:e2e-pmlnh e2e-pmlnh:patched] and annotations: map[updated:true]
  I0902 07:58:01.147302 16 job.go:1410] Event MODIFIED observed for Job e2e-pmlnh in namespace job-3744 with labels: map[e2e-job-label:e2e-pmlnh e2e-pmlnh:patched] and annotations: map[updated:true]
  I0902 07:58:01.147453 16 job.go:1413] Event DELETED found for Job e2e-pmlnh in namespace job-3744 with labels: map[e2e-job-label:e2e-pmlnh e2e-pmlnh:patched] and annotations: map[updated:true]
  STEP: Relist jobs to confirm deletion @ 09/02/25 07:58:01.147
  I0902 07:58:01.154132 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-3744" for this suite. @ 09/02/25 07:58:01.169
• [8.357 seconds]
------------------------------
S
------------------------------
[sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:97
  STEP: Creating a kubernetes client @ 09/02/25 07:58:01.226
  I0902 07:58:01.226434 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename cronjob @ 09/02/25 07:58:01.233
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 07:58:01.269
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 07:58:01.276
  STEP: Creating a suspended cronjob @ 09/02/25 07:58:01.283
  STEP: Ensuring no jobs are scheduled @ 09/02/25 07:58:01.3
  STEP: Ensuring no job exists by listing jobs explicitly @ 09/02/25 08:03:01.301
  STEP: Removing cronjob @ 09/02/25 08:03:01.312
  I0902 08:03:01.336209 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-600" for this suite. @ 09/02/25 08:03:01.353
• [300.151 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace should update a single-container pod's image [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1826
  STEP: Creating a kubernetes client @ 09/02/25 08:03:01.391
  I0902 08:03:01.391819 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename kubectl @ 09/02/25 08:03:01.397
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:03:01.428
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:03:01.436
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 09/02/25 08:03:01.443
  I0902 08:03:01.443639 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-6584 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
  I0902 08:03:01.673888 16 builder.go:156] stderr: ""
  I0902 08:03:01.673984 16 builder.go:157] stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: verifying the pod e2e-test-httpd-pod is running @ 09/02/25 08:03:01.674
  STEP: verifying the pod e2e-test-httpd-pod was created @ 09/02/25 08:03:06.725
  I0902 08:03:06.726256 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-6584 get pod e2e-test-httpd-pod -o json'
  I0902 08:03:06.924096 16 builder.go:156] stderr: ""
  I0902 08:03:06.924502 16 builder.go:157] stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2025-09-02T08:03:01Z\",\n        \"generation\": 1,\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-6584\",\n        \"resourceVersion\": \"23030\",\n        \"uid\": \"60c9e1bc-18bf-47c7-9481-6c5b922aaf85\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-4\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-jwbqs\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"ietha7evai9i-2\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-jwbqs\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2025-09-02T08:03:03Z\",\n                \"observedGeneration\": 1,\n                \"status\": \"True\",\n                \"type\": \"PodReadyToStartContainers\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2025-09-02T08:03:01Z\",\n                \"observedGeneration\": 1,\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2025-09-02T08:03:03Z\",\n                \"observedGeneration\": 1,\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2025-09-02T08:03:03Z\",\n                \"observedGeneration\": 1,\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2025-09-02T08:03:01Z\",\n                \"observedGeneration\": 1,\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"cri-o://99dc9d4d4d83abe1b12f7ac914e3b7de0a2994bd21d0d88350b363de977f3ae3\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-4\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"resources\": {},\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2025-09-02T08:03:02Z\"\n                    }\n                },\n                \"user\": {\n                    \"linux\": {\n                        \"gid\": 0,\n                        \"supplementalGroups\": [\n                            0,\n                            1,\n                            2,\n                            3,\n                            4,\n                            6,\n                            10,\n                            11,\n                            20,\n                            26,\n                            27\n                        ],\n                        \"uid\": 0\n                    }\n                },\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-jwbqs\",\n                        \"readOnly\": true,\n                        \"recursiveReadOnly\": \"Disabled\"\n                    }\n                ]\n            }\n        ],\n        \"hostIP\": \"192.168.121.46\",\n        \"hostIPs\": [\n            {\n                \"ip\": \"192.168.121.46\"\n            }\n        ],\n        \"observedGeneration\": 1,\n        \"phase\": \"Running\",\n        \"podIP\": \"10.233.66.164\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.233.66.164\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2025-09-02T08:03:01Z\"\n    }\n}\n"
  STEP: replace the image in the pod @ 09/02/25 08:03:06.924
  I0902 08:03:06.924992 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-6584 replace -f -'
  I0902 08:03:07.273442 16 builder.go:156] stderr: ""
  I0902 08:03:07.273521 16 builder.go:157] stdout: "pod/e2e-test-httpd-pod replaced\n"
  STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.37.0-1 @ 09/02/25 08:03:07.273
  I0902 08:03:07.287141 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-6584 delete pods e2e-test-httpd-pod'
  I0902 08:03:09.419439 16 builder.go:156] stderr: ""
  I0902 08:03:09.419577 16 builder.go:157] stdout: "pod \"e2e-test-httpd-pod\" deleted from kubectl-6584 namespace\n"
  I0902 08:03:09.420080 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-6584" for this suite. @ 09/02/25 08:03:09.43
• [8.055 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet should serve a basic image on each replica with a public image [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:112
  STEP: Creating a kubernetes client @ 09/02/25 08:03:09.447
  I0902 08:03:09.448038 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename replicaset @ 09/02/25 08:03:09.45
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:03:09.475
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:03:09.48
  I0902 08:03:09.527007 16 replica_set.go:192] Creating ReplicaSet my-hostname-basic-cf122260-fd13-41f1-8fb0-15be779be2dc
  I0902 08:03:09.562370 16 resource.go:64] Pod name my-hostname-basic-cf122260-fd13-41f1-8fb0-15be779be2dc: Found 0 pods out of 1
  I0902 08:03:14.571894 16 resource.go:64] Pod name my-hostname-basic-cf122260-fd13-41f1-8fb0-15be779be2dc: Found 1 pods out of 1
  I0902 08:03:14.571978 16 replica_set.go:205] Ensuring a pod for ReplicaSet "my-hostname-basic-cf122260-fd13-41f1-8fb0-15be779be2dc" is running
  I0902 08:03:14.585377 16 replica_set.go:221] Pod "my-hostname-basic-cf122260-fd13-41f1-8fb0-15be779be2dc-vsq59" is running (conditions: [{Type:PodReadyToStartContainers ObservedGeneration:1 Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2025-09-02 08:03:11 +0000 UTC Reason: Message:} {Type:Initialized ObservedGeneration:1 Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2025-09-02 08:03:09 +0000 UTC Reason: Message:} {Type:Ready ObservedGeneration:1 Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2025-09-02 08:03:11 +0000 UTC Reason: Message:} {Type:ContainersReady ObservedGeneration:1 Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2025-09-02 08:03:11 +0000 UTC Reason: Message:} {Type:PodScheduled ObservedGeneration:1 Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2025-09-02 08:03:09 +0000 UTC Reason: Message:}])
  I0902 08:03:14.585460 16 replica_set.go:229] Trying to dial the pod
  STEP: trying to dial each unique pod @ 09/02/25 08:03:14.585
  I0902 08:03:14.692811 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-5583" for this suite. @ 09/02/25 08:03:14.71
• [5.285 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:297
  STEP: Creating a kubernetes client @ 09/02/25 08:03:14.736
  I0902 08:03:14.736336 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename webhook @ 09/02/25 08:03:14.74
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:03:14.764
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:03:14.775
  STEP: Setting up server cert @ 09/02/25 08:03:14.818
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 09/02/25 08:03:16.324
  STEP: Deploying the webhook pod @ 09/02/25 08:03:16.343
  STEP: Wait for the deployment to be ready @ 09/02/25 08:03:16.378
  I0902 08:03:16.399657 16 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 09/02/25 08:03:18.433
  STEP: Verifying the service has paired with the endpoint @ 09/02/25 08:03:18.472
  I0902 08:03:19.472863 16 util.go:419] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the crd webhook via the AdmissionRegistration API @ 09/02/25 08:03:19.491
  I0902 08:03:19.569943 16 webhook.go:2701] Waiting for webhook configuration to be ready...
  STEP: Creating a custom resource definition that should be denied by the webhook @ 09/02/25 08:03:19.707
  I0902 08:03:19.707179 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  I0902 08:03:19.958178 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-5449" for this suite. @ 09/02/25 08:03:20.004
  STEP: Destroying namespace "webhook-markers-2331" for this suite. @ 09/02/25 08:03:20.086
• [5.394 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:241
  STEP: Creating a kubernetes client @ 09/02/25 08:03:20.128
  I0902 08:03:20.128912 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename resourcequota @ 09/02/25 08:03:20.131
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:03:20.189
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:03:20.199
  STEP: Counting existing ResourceQuota @ 09/02/25 08:03:20.204
  STEP: Creating a ResourceQuota @ 09/02/25 08:03:25.215
  STEP: Ensuring resource quota status is calculated @ 09/02/25 08:03:25.229
  I0902 08:03:27.267267 16 resource_quota.go:2495] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc001d9c500>: 
          metadata:
            creationTimestamp: "2025-09-02T08:03:25Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: e2e.test
              operation: Update
              time: "2025-09-02T08:03:25Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
                  f:used:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: kube-controller-manager
              operation: Update
              subresource: status
              time: "2025-09-02T08:03:25Z"
            name: test-quota
            namespace: resourcequota-178
            resourceVersion: "23197"
            uid: bd8adbab-d53a-40b5-8779-02ac887ac09b
          spec:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
          status:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
            used:
              configmaps: "1"
              count/replicasets.apps: "0"
              cpu: "0"
              ephemeral-storage: "0"
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "0"
              gold.storageclass.storage.k8s.io/requests.storage: "0"
              memory: "0"
              persistentvolumeclaims: "0"
              pods: "0"
              replicationcontrollers: "0"
              requests.example.com/dongle: "0"
              requests.storage: "0"
              resourcequotas: "1"
              secrets: "0"
              services: "0"
              services.loadbalancers: "0"
              services.nodeports: "0"
  STEP: Creating a Pod that fits quota @ 09/02/25 08:03:27.268
  STEP: Ensuring ResourceQuota status captures the pod usage @ 09/02/25 08:03:27.3
  I0902 08:03:27.313395 16 resource_quota.go:2495] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc001d9cc80>: 
          metadata:
            creationTimestamp: "2025-09-02T08:03:25Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: e2e.test
              operation: Update
              time: "2025-09-02T08:03:25Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
                  f:used:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:persistentvolumeclaims: {}
                    f:replicationcontrollers: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: kube-controller-manager
              operation: Update
              subresource: status
              time: "2025-09-02T08:03:25Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:used:
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:memory: {}
                    f:pods: {}
                    f:requests.example.com/dongle: {}
              manager: kube-apiserver
              operation: Update
              subresource: status
              time: "2025-09-02T08:03:27Z"
            name: test-quota
            namespace: resourcequota-178
            resourceVersion: "23216"
            uid: bd8adbab-d53a-40b5-8779-02ac887ac09b
          spec:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
          status:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
            used:
              configmaps: "1"
              count/replicasets.apps: "0"
              cpu: 500m
              ephemeral-storage: 30Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "0"
              gold.storageclass.storage.k8s.io/requests.storage: "0"
              memory: 252Mi
              persistentvolumeclaims: "0"
              pods: "1"
              replicationcontrollers: "0"
              requests.example.com/dongle: "2"
              requests.storage: "0"
              resourcequotas: "1"
              secrets: "0"
              services: "0"
              services.loadbalancers: "0"
              services.nodeports: "0"
  STEP: Not allowing a pod to be created that exceeds remaining quota @ 09/02/25 08:03:27.316
  STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) @ 09/02/25 08:03:27.337
  STEP: Ensuring a pod cannot update its resource requirements @ 09/02/25 08:03:27.345
  STEP: Ensuring attempts to update pod resource requirements did not change quota usage @ 09/02/25 08:03:27.358
  I0902 08:03:27.369079 16 resource_quota.go:2495] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc001d9d900>: 
          metadata:
            creationTimestamp: "2025-09-02T08:03:25Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: e2e.test
              operation: Update
              time: "2025-09-02T08:03:25Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
                  f:used:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:persistentvolumeclaims: {}
                    f:replicationcontrollers: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: kube-controller-manager
              operation: Update
              subresource: status
              time: "2025-09-02T08:03:25Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:used:
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:memory: {}
                    f:pods: {}
                    f:requests.example.com/dongle: {}
              manager: kube-apiserver
              operation: Update
              subresource: status
              time: "2025-09-02T08:03:27Z"
            name: test-quota
            namespace: resourcequota-178
            resourceVersion: "23216"
            uid: bd8adbab-d53a-40b5-8779-02ac887ac09b
          spec:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
          status:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
            used:
              configmaps: "1"
              count/replicasets.apps: "0"
              cpu: 500m
              ephemeral-storage: 30Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "0"
              gold.storageclass.storage.k8s.io/requests.storage: "0"
              memory: 252Mi
              persistentvolumeclaims: "0"
              pods: "1"
              replicationcontrollers: "0"
              requests.example.com/dongle: "2"
              requests.storage: "0"
              resourcequotas: "1"
              secrets: "0"
              services: "0"
              services.loadbalancers: "0"
              services.nodeports: "0"
  STEP: Deleting the pod @ 09/02/25 08:03:27.37
  STEP: Ensuring resource quota status released the pod usage @ 09/02/25 08:03:27.394
  I0902 08:03:29.416296 16 resource_quota.go:2495] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc0020a0140>: 
          metadata:
            creationTimestamp: "2025-09-02T08:03:25Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: e2e.test
              operation: Update
              time: "2025-09-02T08:03:25Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
                  f:used:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: kube-controller-manager
              operation: Update
              subresource: status
              time: "2025-09-02T08:03:27Z"
            name: test-quota
            namespace: resourcequota-178
            resourceVersion: "23222"
            uid: bd8adbab-d53a-40b5-8779-02ac887ac09b
          spec:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
          status:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
            used:
              configmaps: "1"
              count/replicasets.apps: "0"
              cpu: "0"
              ephemeral-storage: "0"
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "0"
              gold.storageclass.storage.k8s.io/requests.storage: "0"
              memory: "0"
              persistentvolumeclaims: "0"
              pods: "0"
              replicationcontrollers: "0"
              requests.example.com/dongle: "0"
              requests.storage: "0"
              resourcequotas: "1"
              secrets: "0"
              services: "0"
              services.loadbalancers: "0"
              services.nodeports: "0"
  I0902 08:03:29.417941 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-178" for this suite. @ 09/02/25 08:03:29.426
• [9.313 seconds]
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:149
  STEP: Creating a kubernetes client @ 09/02/25 08:03:29.442
  I0902 08:03:29.442396 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename emptydir @ 09/02/25 08:03:29.444
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:03:29.476
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:03:29.48
  STEP: Creating a pod to test emptydir 0777 on tmpfs @ 09/02/25 08:03:29.49
  STEP: Saw pod success @ 09/02/25 08:03:33.561
  I0902 08:03:33.571453 16 output.go:207] Trying to get logs from node ietha7evai9i-2 pod pod-25552534-4181-452a-aba9-7ed970ee2248 container test-container: <nil>
  STEP: delete the pod @ 09/02/25 08:03:33.622
  I0902 08:03:33.659260 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-3251" for this suite. @ 09/02/25 08:03:33.674
• [4.252 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:269
  STEP: Creating a kubernetes client @ 09/02/25 08:03:33.697
  I0902 08:03:33.697902 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename webhook @ 09/02/25 08:03:33.701
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:03:33.739
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:03:33.748
  STEP: Setting up server cert @ 09/02/25 08:03:33.817
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 09/02/25 08:03:35.586
  STEP: Deploying the webhook pod @ 09/02/25 08:03:35.599
  STEP: Wait for the deployment to be ready @ 09/02/25 08:03:35.621
  I0902 08:03:35.638983 16 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  I0902 08:03:37.670223 16 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.September, 2, 8, 3, 35, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 8, 3, 35, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.September, 2, 8, 3, 35, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 8, 3, 35, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7d44fffc8\" is progressing."}}, CollisionCount:(*int32)(nil)}
  STEP: Deploying the webhook service @ 09/02/25 08:03:39.679
  STEP: Verifying the service has paired with the endpoint @ 09/02/25 08:03:39.706
  I0902 08:03:40.707712 16 util.go:419] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API @ 09/02/25 08:03:40.77
  I0902 08:03:40.831877 16 webhook.go:2701] Waiting for webhook configuration to be ready...
  STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API @ 09/02/25 08:03:40.966
  STEP: Creating a dummy validating-webhook-configuration object @ 09/02/25 08:03:41.005
  STEP: Deleting the validating-webhook-configuration, which should be possible to remove @ 09/02/25 08:03:41.039
  STEP: Creating a dummy mutating-webhook-configuration object @ 09/02/25 08:03:41.058
  STEP: Deleting the mutating-webhook-configuration, which should be possible to remove @ 09/02/25 08:03:41.079
  I0902 08:03:41.245844 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-3580" for this suite. @ 09/02/25 08:03:41.279
  STEP: Destroying namespace "webhook-markers-1265" for this suite. @ 09/02/25 08:03:41.326
• [7.650 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets should fail to create secret due to empty secret key [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:141
  STEP: Creating a kubernetes client @ 09/02/25 08:03:41.352
  I0902 08:03:41.353018 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename secrets @ 09/02/25 08:03:41.356
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:03:41.397
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:03:41.404
  STEP: Creating projection with secret that has name secret-emptykey-test-e3820f86-ed05-469f-9b54-5bf7e276f3c9 @ 09/02/25 08:03:41.412
  I0902 08:03:41.419954 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-4221" for this suite. @ 09/02/25 08:03:41.433
• [0.093 seconds]
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:246
  STEP: Creating a kubernetes client @ 09/02/25 08:03:41.446
  I0902 08:03:41.446749 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename webhook @ 09/02/25 08:03:41.449
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:03:41.485
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:03:41.498
  STEP: Setting up server cert @ 09/02/25 08:03:41.545
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 09/02/25 08:03:42.548
  STEP: Deploying the webhook pod @ 09/02/25 08:03:42.558
  STEP: Wait for the deployment to be ready @ 09/02/25 08:03:42.581
  I0902 08:03:42.600068 16 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  I0902 08:03:44.625080 16 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.September, 2, 8, 3, 42, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 8, 3, 42, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.September, 2, 8, 3, 42, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 8, 3, 42, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7d44fffc8\" is progressing."}}, CollisionCount:(*int32)(nil)}
  STEP: Deploying the webhook service @ 09/02/25 08:03:46.637
  STEP: Verifying the service has paired with the endpoint @ 09/02/25 08:03:46.666
  I0902 08:03:47.667870 16 util.go:419] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the mutating configmap webhook via the AdmissionRegistration API @ 09/02/25 08:03:47.681
  I0902 08:03:47.740988 16 webhook.go:2701] Waiting for webhook configuration to be ready...
  I0902 08:03:47.870635 16 webhook.go:2701] Waiting for webhook configuration to be ready...
  I0902 08:03:57.972725 16 webhook.go:2701] Waiting for webhook configuration to be ready...
  STEP: create a configmap that should be updated by the webhook @ 09/02/25 08:03:58.069
  I0902 08:03:58.260590 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-5147" for this suite. @ 09/02/25 08:03:58.274
  STEP: Destroying namespace "webhook-markers-7393" for this suite. @ 09/02/25 08:03:58.296
• [16.868 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:47
  STEP: Creating a kubernetes client @ 09/02/25 08:03:58.314
  I0902 08:03:58.314133 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename projected @ 09/02/25 08:03:58.321
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:03:58.364
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:03:58.371
  STEP: Creating configMap with name projected-configmap-test-volume-3eb6216b-e286-4b85-ba54-f7bca8bd8d38 @ 09/02/25 08:03:58.38
  STEP: Creating a pod to test consume configMaps @ 09/02/25 08:03:58.39
  STEP: Saw pod success @ 09/02/25 08:04:02.46
  I0902 08:04:02.475534 16 output.go:207] Trying to get logs from node ietha7evai9i-2 pod pod-projected-configmaps-5de1947a-ca4b-41a9-9bd1-0d8624872cb9 container agnhost-container: <nil>
  STEP: delete the pod @ 09/02/25 08:04:02.501
  I0902 08:04:02.552276 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8" for this suite. @ 09/02/25 08:04:02.563
• [4.269 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] VolumeAttachment Conformance should apply changes to a volumeattachment status [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/volume_attachment.go:180
  STEP: Creating a kubernetes client @ 09/02/25 08:04:02.583
  I0902 08:04:02.583599 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename volumeattachment @ 09/02/25 08:04:02.586
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:04:02.613
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:04:02.619
  STEP: Create VolumeAttachment "va-e2e-nxncx" on node "ietha7evai9i-1" @ 09/02/25 08:04:02.663
  STEP: Patch VolumeAttachment "va-e2e-nxncx" on node "ietha7evai9i-1" @ 09/02/25 08:04:02.676
  STEP: Reading "va-e2e-nxncx" Status @ 09/02/25 08:04:02.687
  STEP: Patching "va-e2e-nxncx" Status @ 09/02/25 08:04:02.695
  I0902 08:04:02.706613 16 volume_attachment.go:224] "va-e2e-nxncx" Status.Attached: true
  STEP: Updating "va-e2e-nxncx" Status @ 09/02/25 08:04:02.706
  I0902 08:04:02.720727 16 volume_attachment.go:240] "va-e2e-nxncx" Status.Attached: false
  STEP: Delete VolumeAttachment "va-e2e-nxncx" on node "ietha7evai9i-1" @ 09/02/25 08:04:02.72
  STEP: Confirm deletion of VolumeAttachment "va-e2e-nxncx" on node "ietha7evai9i-1" @ 09/02/25 08:04:02.734
  I0902 08:04:02.740623 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "volumeattachment-8608" for this suite. @ 09/02/25 08:04:02.764
• [0.196 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Node Lifecycle should run through the lifecycle of a node [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/node_lifecycle.go:51
  STEP: Creating a kubernetes client @ 09/02/25 08:04:02.78
  I0902 08:04:02.780338 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename fake-node @ 09/02/25 08:04:02.785
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:04:02.862
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:04:02.868
  STEP: Create "e2e-fake-node-nvblh" @ 09/02/25 08:04:02.872
  STEP: Getting "e2e-fake-node-nvblh" @ 09/02/25 08:04:02.883
  STEP: Patching "e2e-fake-node-nvblh" @ 09/02/25 08:04:02.899
  STEP: Listing nodes with LabelSelector "e2e-fake-node-nvblh=patched" @ 09/02/25 08:04:02.917
  STEP: Updating "e2e-fake-node-nvblh" @ 09/02/25 08:04:02.933
  STEP: Delete "e2e-fake-node-nvblh" @ 09/02/25 08:04:03.035
  STEP: Confirm deletion of "e2e-fake-node-nvblh" @ 09/02/25 08:04:03.055
  I0902 08:04:03.064022 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "fake-node-180" for this suite. @ 09/02/25 08:04:03.074
• [0.320 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:270
  STEP: Creating a kubernetes client @ 09/02/25 08:04:03.101
  I0902 08:04:03.101179 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename custom-resource-definition @ 09/02/25 08:04:03.103
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:04:03.139
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:04:03.168
  I0902 08:04:03.174909 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  I0902 08:04:06.709633 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-7977" for this suite. @ 09/02/25 08:04:06.72
• [3.634 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:218
  STEP: Creating a kubernetes client @ 09/02/25 08:04:06.735
  I0902 08:04:06.735766 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 09/02/25 08:04:06.738
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:04:06.763
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:04:06.768
  STEP: create the container to handle the HTTPGet hook request. @ 09/02/25 08:04:06.819
  STEP: create the pod with lifecycle hook @ 09/02/25 08:04:10.883
  STEP: delete the pod with lifecycle hook @ 09/02/25 08:04:12.926
  STEP: check prestop hook @ 09/02/25 08:04:16.978
  I0902 08:04:17.005171 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-7328" for this suite. @ 09/02/25 08:04:17.016
• [10.297 seconds]
------------------------------
[sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance] [sig-node, Serial, Disruptive, Conformance]
k8s.io/kubernetes/test/e2e/node/taints.go:444
  STEP: Creating a kubernetes client @ 09/02/25 08:04:17.032
  I0902 08:04:17.033035 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename taint-multiple-pods @ 09/02/25 08:04:17.037
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:04:17.073
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:04:17.08
  I0902 08:04:17.086146 16 wait.go:51] Waiting up to 1m0s for all nodes to be ready
  I0902 08:05:17.087576 16 util.go:390] Waiting for terminating namespaces to be deleted...
  I0902 08:05:17.097400 16 taints.go:144] Starting informer...
  STEP: Starting pods... @ 09/02/25 08:05:17.097
  I0902 08:05:17.343775 16 taints.go:463] Pod1 is running on ietha7evai9i-2. Tainting Node
  I0902 08:05:19.589453 16 taints.go:471] Pod2 is running on ietha7evai9i-2. Tainting Node
  STEP: Trying to apply a taint on the Node @ 09/02/25 08:05:19.589
  STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 09/02/25 08:05:19.616
  STEP: Waiting for Pod1 and Pod2 to be deleted @ 09/02/25 08:05:19.629
  I0902 08:05:25.381622 16 taints.go:492] Noticed Pod "taint-eviction-b1" gets evicted.
  I0902 08:05:45.504088 16 taints.go:492] Noticed Pod "taint-eviction-b2" gets evicted.
  STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 09/02/25 08:05:45.543
  I0902 08:05:45.553510 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "taint-multiple-pods-9264" for this suite. @ 09/02/25 08:05:45.563
• [88.546 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:809
  STEP: Creating a kubernetes client @ 09/02/25 08:05:45.579
  I0902 08:05:45.579199 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename statefulset @ 09/02/25 08:05:45.581
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:05:45.62
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:05:45.626
  STEP: Creating service test in namespace statefulset-3459 @ 09/02/25 08:05:45.633
  I0902 08:05:45.664649      16 warnings.go:110] "Warning: spec.SessionAffinity is ignored for headless services"
  STEP: Looking for a node to schedule stateful set and pod @ 09/02/25 08:05:45.664
  STEP: Creating pod with conflicting port in namespace statefulset-3459 @ 09/02/25 08:05:45.695
  STEP: Waiting until pod test-pod will start running in namespace statefulset-3459 @ 09/02/25 08:05:45.727
  STEP: Creating statefulset with conflicting port in namespace statefulset-3459 @ 09/02/25 08:05:47.757
  STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-3459 @ 09/02/25 08:05:47.771
  I0902 08:05:47.808580 16 statefulset.go:882] Observed stateful pod in namespace: statefulset-3459, name: ss-0, uid: 40e08ccd-a9bb-41bd-b4a4-56898964ded7, status phase: Pending. Waiting for statefulset controller to delete.
  I0902 08:05:47.863094 16 statefulset.go:882] Observed stateful pod in namespace: statefulset-3459, name: ss-0, uid: 40e08ccd-a9bb-41bd-b4a4-56898964ded7, status phase: Failed. Waiting for statefulset controller to delete.
  I0902 08:05:47.886759 16 statefulset.go:882] Observed stateful pod in namespace: statefulset-3459, name: ss-0, uid: 40e08ccd-a9bb-41bd-b4a4-56898964ded7, status phase: Failed. Waiting for statefulset controller to delete.
  I0902 08:05:47.890926 16 statefulset.go:876] Observed delete event for stateful pod ss-0 in namespace statefulset-3459
  STEP: Removing pod with conflicting port in namespace statefulset-3459 @ 09/02/25 08:05:47.891
  STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-3459 and will be in running state @ 09/02/25 08:05:47.983
  I0902 08:05:50.007303 16 statefulset.go:136] Deleting all statefulset in ns statefulset-3459
  I0902 08:05:50.014633 16 rest.go:153] Scaling statefulset ss to 0
  I0902 08:06:00.050398 16 wait.go:159] Waiting for statefulset status.replicas updated to 0
  I0902 08:06:00.057670 16 rest.go:91] Deleting statefulset ss
  I0902 08:06:00.093708 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-3459" for this suite. @ 09/02/25 08:06:00.104
• [14.541 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl logs logs should be able to retrieve and filter logs [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/logs.go:167
  STEP: Creating a kubernetes client @ 09/02/25 08:06:00.125
  I0902 08:06:00.125806 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename kubectl-logs @ 09/02/25 08:06:00.129
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:06:00.16
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:06:00.169
  STEP: creating a pod @ 09/02/25 08:06:00.177
  I0902 08:06:00.179000 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-logs-9315 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.56 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
  I0902 08:06:00.390713 16 builder.go:156] stderr: ""
  I0902 08:06:00.390787 16 builder.go:157] stdout: "pod/logs-generator created\n"
  STEP: Waiting for log generator to start. @ 09/02/25 08:06:00.39
  I0902 08:06:00.390993 16 resource.go:396] Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
  I0902 08:06:02.413286 16 resource.go:418] Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
  STEP: checking for a matching strings @ 09/02/25 08:06:02.413
  I0902 08:06:02.413973 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-logs-9315 logs logs-generator logs-generator'
  I0902 08:06:02.629085 16 builder.go:156] stderr: ""
  I0902 08:06:02.629836 16 builder.go:157] stdout: "I0902 08:06:01.388314       1 logs_generator.go:76] 0 POST /api/v1/namespaces/default/pods/6ck 424\nI0902 08:06:01.589329       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/default/pods/kmlb 470\nI0902 08:06:01.788940       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/kube-system/pods/498 248\nI0902 08:06:01.989329       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/ns/pods/ssk 436\nI0902 08:06:02.188817       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/default/pods/mvd 359\nI0902 08:06:02.389278       1 logs_generator.go:76] 5 POST /api/v1/namespaces/ns/pods/vhp 574\nI0902 08:06:02.588736       1 logs_generator.go:76] 6 POST /api/v1/namespaces/ns/pods/g5pj 562\n"
  STEP: limiting log lines @ 09/02/25 08:06:02.629
  I0902 08:06:02.630376 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-logs-9315 logs logs-generator logs-generator --tail=1'
  I0902 08:06:02.803344 16 builder.go:156] stderr: ""
  I0902 08:06:02.803676 16 builder.go:157] stdout: "I0902 08:06:02.588736       1 logs_generator.go:76] 6 POST /api/v1/namespaces/ns/pods/g5pj 562\n"
  I0902 08:06:02.803709 16 logs.go:180] got output "I0902 08:06:02.588736       1 logs_generator.go:76] 6 POST /api/v1/namespaces/ns/pods/g5pj 562\n"
  STEP: limiting log bytes @ 09/02/25 08:06:02.803
  I0902 08:06:02.804072 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-logs-9315 logs logs-generator logs-generator --limit-bytes=1'
  I0902 08:06:02.999440 16 builder.go:156] stderr: ""
  I0902 08:06:02.999867 16 builder.go:157] stdout: "I"
  I0902 08:06:02.999896 16 logs.go:186] got output "I"
  STEP: exposing timestamps @ 09/02/25 08:06:02.999
  I0902 08:06:03.000330 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-logs-9315 logs logs-generator logs-generator --tail=1 --timestamps'
  I0902 08:06:03.180036 16 builder.go:156] stderr: ""
  I0902 08:06:03.180253 16 builder.go:157] stdout: "2025-09-02T08:06:02.989315925Z I0902 08:06:02.989205       1 logs_generator.go:76] 8 GET /api/v1/namespaces/default/pods/srr 458\n"
  I0902 08:06:03.180324 16 logs.go:192] got output "2025-09-02T08:06:02.989315925Z I0902 08:06:02.989205       1 logs_generator.go:76] 8 GET /api/v1/namespaces/default/pods/srr 458\n"
  STEP: restricting to a time range @ 09/02/25 08:06:03.18
  I0902 08:06:05.681394 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-logs-9315 logs logs-generator logs-generator --since=1s'
  I0902 08:06:05.907810 16 builder.go:156] stderr: ""
  I0902 08:06:05.908101 16 builder.go:157] stdout: "I0902 08:06:04.988694       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/default/pods/29d 404\nI0902 08:06:05.189348       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/kube-system/pods/4rk 271\nI0902 08:06:05.389058       1 logs_generator.go:76] 20 GET /api/v1/namespaces/kube-system/pods/hz8 218\nI0902 08:06:05.588419       1 logs_generator.go:76] 21 PUT /api/v1/namespaces/kube-system/pods/qgb 584\nI0902 08:06:05.788951       1 logs_generator.go:76] 22 PUT /api/v1/namespaces/ns/pods/v5lt 430\n"
  I0902 08:06:05.908412 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-logs-9315 logs logs-generator logs-generator --since=24h'
  I0902 08:06:06.119028 16 builder.go:156] stderr: ""
  I0902 08:06:06.119248 16 builder.go:157] stdout: "I0902 08:06:01.388314       1 logs_generator.go:76] 0 POST /api/v1/namespaces/default/pods/6ck 424\nI0902 08:06:01.589329       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/default/pods/kmlb 470\nI0902 08:06:01.788940       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/kube-system/pods/498 248\nI0902 08:06:01.989329       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/ns/pods/ssk 436\nI0902 08:06:02.188817       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/default/pods/mvd 359\nI0902 08:06:02.389278       1 logs_generator.go:76] 5 POST /api/v1/namespaces/ns/pods/vhp 574\nI0902 08:06:02.588736       1 logs_generator.go:76] 6 POST /api/v1/namespaces/ns/pods/g5pj 562\nI0902 08:06:02.789159       1 logs_generator.go:76] 7 POST /api/v1/namespaces/default/pods/ck6 493\nI0902 08:06:02.989205       1 logs_generator.go:76] 8 GET /api/v1/namespaces/default/pods/srr 458\nI0902 08:06:03.188593       1 logs_generator.go:76] 9 GET /api/v1/namespaces/kube-system/pods/mfqb 455\nI0902 08:06:03.389346       1 logs_generator.go:76] 10 POST /api/v1/namespaces/ns/pods/gxj 342\nI0902 08:06:03.588911       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/kube-system/pods/v2vh 439\nI0902 08:06:03.789360       1 logs_generator.go:76] 12 PUT /api/v1/namespaces/ns/pods/2rbd 200\nI0902 08:06:03.989235       1 logs_generator.go:76] 13 GET /api/v1/namespaces/kube-system/pods/rqrb 273\nI0902 08:06:04.188535       1 logs_generator.go:76] 14 POST /api/v1/namespaces/ns/pods/gbsw 498\nI0902 08:06:04.389202       1 logs_generator.go:76] 15 PUT /api/v1/namespaces/kube-system/pods/t8qn 433\nI0902 08:06:04.588600       1 logs_generator.go:76] 16 GET /api/v1/namespaces/ns/pods/2kp 409\nI0902 08:06:04.789203       1 logs_generator.go:76] 17 POST /api/v1/namespaces/default/pods/zzk 597\nI0902 08:06:04.988694       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/default/pods/29d 404\nI0902 08:06:05.189348       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/kube-system/pods/4rk 271\nI0902 08:06:05.389058       1 logs_generator.go:76] 20 GET /api/v1/namespaces/kube-system/pods/hz8 218\nI0902 08:06:05.588419       1 logs_generator.go:76] 21 PUT /api/v1/namespaces/kube-system/pods/qgb 584\nI0902 08:06:05.788951       1 logs_generator.go:76] 22 PUT /api/v1/namespaces/ns/pods/v5lt 430\nI0902 08:06:05.988877       1 logs_generator.go:76] 23 GET /api/v1/namespaces/kube-system/pods/r9f 500\n"
  I0902 08:06:06.120226 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-logs-9315 delete pod logs-generator'
  I0902 08:06:07.682393 16 builder.go:156] stderr: ""
  I0902 08:06:07.683311 16 builder.go:157] stdout: "pod \"logs-generator\" deleted from kubectl-logs-9315 namespace\n"
  I0902 08:06:07.685688 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-logs-9315" for this suite. @ 09/02/25 08:06:07.704
• [7.594 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet_etc_hosts.go:65
  STEP: Creating a kubernetes client @ 09/02/25 08:06:07.722
  I0902 08:06:07.722274 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts @ 09/02/25 08:06:07.726
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:06:07.749
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:06:07.756
  STEP: Setting up the test @ 09/02/25 08:06:07.762
  STEP: Creating hostNetwork=false pod @ 09/02/25 08:06:07.763
  STEP: Creating hostNetwork=true pod @ 09/02/25 08:06:09.812
  STEP: Running the test @ 09/02/25 08:06:11.855
  STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false @ 09/02/25 08:06:11.855
  I0902 08:06:11.855687 16 exec_util.go:63] ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6354 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0902 08:06:11.855784 16 exec_util.go:68] ExecWithOptions: Clientset creation
  I0902 08:06:11.855914 16 exec_util.go:84] ExecWithOptions: execute(https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-6354/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&stderr=true&stdout=true)
  I0902 08:06:11.978192 16 exec_util.go:112] Exec stderr: ""
  I0902 08:06:11.978286 16 exec_util.go:63] ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6354 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0902 08:06:11.978837 16 exec_util.go:68] ExecWithOptions: Clientset creation
  I0902 08:06:11.980251 16 exec_util.go:84] ExecWithOptions: execute(https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-6354/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&stderr=true&stdout=true)
  I0902 08:06:12.079252 16 exec_util.go:112] Exec stderr: ""
  I0902 08:06:12.079363 16 exec_util.go:63] ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6354 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0902 08:06:12.079389 16 exec_util.go:68] ExecWithOptions: Clientset creation
  I0902 08:06:12.079479 16 exec_util.go:84] ExecWithOptions: execute(https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-6354/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&stderr=true&stdout=true)
  I0902 08:06:12.182210 16 exec_util.go:112] Exec stderr: ""
  I0902 08:06:12.182303 16 exec_util.go:63] ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6354 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0902 08:06:12.182324 16 exec_util.go:68] ExecWithOptions: Clientset creation
  I0902 08:06:12.183057 16 exec_util.go:84] ExecWithOptions: execute(https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-6354/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&stderr=true&stdout=true)
  I0902 08:06:12.276311 16 exec_util.go:112] Exec stderr: ""
  STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount @ 09/02/25 08:06:12.276
  I0902 08:06:12.276987 16 exec_util.go:63] ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6354 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0902 08:06:12.277272 16 exec_util.go:68] ExecWithOptions: Clientset creation
  I0902 08:06:12.277604 16 exec_util.go:84] ExecWithOptions: execute(https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-6354/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&stderr=true&stdout=true)
  I0902 08:06:12.412232 16 exec_util.go:112] Exec stderr: ""
  I0902 08:06:12.412359 16 exec_util.go:63] ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6354 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0902 08:06:12.412400 16 exec_util.go:68] ExecWithOptions: Clientset creation
  I0902 08:06:12.413197 16 exec_util.go:84] ExecWithOptions: execute(https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-6354/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&stderr=true&stdout=true)
  I0902 08:06:12.519735 16 exec_util.go:112] Exec stderr: ""
  STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true @ 09/02/25 08:06:12.519
  I0902 08:06:12.520530 16 exec_util.go:63] ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6354 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0902 08:06:12.520953 16 exec_util.go:68] ExecWithOptions: Clientset creation
  I0902 08:06:12.521456 16 exec_util.go:84] ExecWithOptions: execute(https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-6354/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&stderr=true&stdout=true)
  I0902 08:06:12.639126 16 exec_util.go:112] Exec stderr: ""
  I0902 08:06:12.639273 16 exec_util.go:63] ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6354 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0902 08:06:12.639582 16 exec_util.go:68] ExecWithOptions: Clientset creation
  I0902 08:06:12.639977 16 exec_util.go:84] ExecWithOptions: execute(https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-6354/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&stderr=true&stdout=true)
  I0902 08:06:12.760066 16 exec_util.go:112] Exec stderr: ""
  I0902 08:06:12.760252 16 exec_util.go:63] ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6354 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0902 08:06:12.760694 16 exec_util.go:68] ExecWithOptions: Clientset creation
  I0902 08:06:12.761021 16 exec_util.go:84] ExecWithOptions: execute(https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-6354/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&stderr=true&stdout=true)
  I0902 08:06:12.872453 16 exec_util.go:112] Exec stderr: ""
  I0902 08:06:12.872537 16 exec_util.go:63] ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6354 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0902 08:06:12.873237 16 exec_util.go:68] ExecWithOptions: Clientset creation
  I0902 08:06:12.874690 16 exec_util.go:84] ExecWithOptions: execute(https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-6354/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&stderr=true&stdout=true)
  I0902 08:06:12.969904 16 exec_util.go:112] Exec stderr: ""
  I0902 08:06:12.970205 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "e2e-kubelet-etc-hosts-6354" for this suite. @ 09/02/25 08:06:12.981
• [5.275 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/controller_revision.go:126
  STEP: Creating a kubernetes client @ 09/02/25 08:06:12.997
  I0902 08:06:12.997994 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename controllerrevisions @ 09/02/25 08:06:13.002
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:06:13.042
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:06:13.051
  STEP: Creating DaemonSet "e2e-7qftg-daemon-set" @ 09/02/25 08:06:13.117
  STEP: Check that daemon pods launch on every node of the cluster. @ 09/02/25 08:06:13.136
  I0902 08:06:13.245285 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset e2e-7qftg-daemon-set: 0
  I0902 08:06:13.245393 16 fixtures.go:131] Node ietha7evai9i-1 is running 0 daemon pod, expected 1
  I0902 08:06:14.172976 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset e2e-7qftg-daemon-set: 0
  I0902 08:06:14.174747 16 fixtures.go:131] Node ietha7evai9i-1 is running 0 daemon pod, expected 1
  I0902 08:06:15.157840 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset e2e-7qftg-daemon-set: 3
  I0902 08:06:15.157923 16 fixtures.go:136] Number of running nodes: 3, number of available pods: 3 in daemonset e2e-7qftg-daemon-set
  STEP: Confirm DaemonSet "e2e-7qftg-daemon-set" successfully created with "daemonset-name=e2e-7qftg-daemon-set" label @ 09/02/25 08:06:15.162
  STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-7qftg-daemon-set" @ 09/02/25 08:06:15.179
  I0902 08:06:15.189061 16 controller_revision.go:162] Located ControllerRevision: "e2e-7qftg-daemon-set-5fc97ff6b4"
  STEP: Patching ControllerRevision "e2e-7qftg-daemon-set-5fc97ff6b4" @ 09/02/25 08:06:15.197
  I0902 08:06:15.211076 16 controller_revision.go:173] e2e-7qftg-daemon-set-5fc97ff6b4 has been patched
  STEP: Create a new ControllerRevision @ 09/02/25 08:06:15.211
  I0902 08:06:15.228115 16 controller_revision.go:191] Created ControllerRevision: e2e-7qftg-daemon-set-68b5f96f78
  STEP: Confirm that there are two ControllerRevisions @ 09/02/25 08:06:15.228
  I0902 08:06:15.228355 16 controller_revision.go:254] Requesting list of ControllerRevisions to confirm quantity
  I0902 08:06:15.235763 16 controller_revision.go:265] Found 2 ControllerRevisions
  STEP: Deleting ControllerRevision "e2e-7qftg-daemon-set-5fc97ff6b4" @ 09/02/25 08:06:15.235
  STEP: Confirm that there is only one ControllerRevision @ 09/02/25 08:06:15.247
  I0902 08:06:15.247672 16 controller_revision.go:254] Requesting list of ControllerRevisions to confirm quantity
  I0902 08:06:15.255316 16 controller_revision.go:265] Found 1 ControllerRevisions
  STEP: Updating ControllerRevision "e2e-7qftg-daemon-set-68b5f96f78" @ 09/02/25 08:06:15.262
  I0902 08:06:15.280603 16 controller_revision.go:220] e2e-7qftg-daemon-set-68b5f96f78 has been updated
  STEP: Generate another ControllerRevision by patching the Daemonset @ 09/02/25 08:06:15.28
  I0902 08:06:15.297835      16 warnings.go:110] "Warning: unknown field \"updateStrategy\""
  STEP: Confirm that there are two ControllerRevisions @ 09/02/25 08:06:15.298
  I0902 08:06:15.298117 16 controller_revision.go:254] Requesting list of ControllerRevisions to confirm quantity
  I0902 08:06:16.298293 16 controller_revision.go:254] Requesting list of ControllerRevisions to confirm quantity
  I0902 08:06:16.342915 16 controller_revision.go:265] Found 2 ControllerRevisions
  STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-7qftg-daemon-set-68b5f96f78=updated" @ 09/02/25 08:06:16.343
  STEP: Confirm that there is only one ControllerRevision @ 09/02/25 08:06:16.445
  I0902 08:06:16.446560 16 controller_revision.go:254] Requesting list of ControllerRevisions to confirm quantity
  I0902 08:06:16.455645 16 controller_revision.go:265] Found 1 ControllerRevisions
  I0902 08:06:16.465651 16 controller_revision.go:246] ControllerRevision "e2e-7qftg-daemon-set-5b7fb5667" has revision 3
  STEP: Deleting DaemonSet "e2e-7qftg-daemon-set" @ 09/02/25 08:06:16.477
  STEP: deleting DaemonSet.extensions e2e-7qftg-daemon-set in namespace controllerrevisions-6368, will wait for the garbage collector to delete the pods @ 09/02/25 08:06:16.477
  I0902 08:06:16.555655 16 resources.go:139] Deleting DaemonSet.extensions e2e-7qftg-daemon-set took: 18.56733ms
  I0902 08:06:16.657208 16 resources.go:163] Terminating DaemonSet.extensions e2e-7qftg-daemon-set pods took: 101.543485ms
  I0902 08:06:18.965973 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset e2e-7qftg-daemon-set: 0
  I0902 08:06:18.966050 16 fixtures.go:136] Number of running nodes: 0, number of available pods: 0 in daemonset e2e-7qftg-daemon-set
  I0902 08:06:18.972240 16 controller_revision.go:73] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"24234"},"items":null}

  I0902 08:06:18.978376 16 controller_revision.go:78] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"24234"},"items":null}

  I0902 08:06:19.014708 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "controllerrevisions-6368" for this suite. @ 09/02/25 08:06:19.023
• [6.042 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes should not conflict [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/empty_dir_wrapper.go:69
  STEP: Creating a kubernetes client @ 09/02/25 08:06:19.04
  I0902 08:06:19.040580 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename emptydir-wrapper @ 09/02/25 08:06:19.044
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:06:19.071
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:06:19.077
  STEP: Cleaning up the secret @ 09/02/25 08:06:21.151
  STEP: Cleaning up the configmap @ 09/02/25 08:06:21.167
  STEP: Cleaning up the pod @ 09/02/25 08:06:21.186
  I0902 08:06:21.213924 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-wrapper-3464" for this suite. @ 09/02/25 08:06:21.23
• [2.216 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 should proxy through a service and a pod [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/proxy.go:100
  STEP: Creating a kubernetes client @ 09/02/25 08:06:21.257
  I0902 08:06:21.257675 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename proxy @ 09/02/25 08:06:21.262
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:06:21.327
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:06:21.341
  STEP: starting an echo server on multiple ports @ 09/02/25 08:06:21.403
  I0902 08:06:21.499707 16 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:0, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:0, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition(nil), CollisionCount:(*int32)(nil)}
  I0902 08:06:23.519470 16 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.September, 2, 8, 6, 21, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 8, 6, 21, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.September, 2, 8, 6, 21, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 8, 6, 21, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"proxy-service-2nkf9-64bd8d4d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
  I0902 08:06:25.529914 16 wait.go:65] Waiting for amount of service proxy-325/proxy-service-2nkf9 endpoints to be 1
  I0902 08:06:25.551306 16 proxy.go:610] (0) /api/v1/namespaces/proxy-325/services/proxy-service-2nkf9:portname1/proxy/: foo (200; 13.28482ms)
  I0902 08:06:25.551508 16 proxy.go:282] setup took 4.192441918s, starting test cases
  STEP: running 16 cases, 20 attempts per case, 320 total attempts @ 09/02/25 08:06:25.551
  I0902 08:06:25.571972 16 proxy.go:610] (0) /api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/re... (200; 20.104642ms)
  I0902 08:06:25.587060 16 proxy.go:610] (0) /api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:160/proxy/: foo (200; 33.685626ms)
  I0902 08:06:25.590918 16 proxy.go:610] (0) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q/proxy/rewriteme">t... (200; 37.905618ms)
  I0902 08:06:25.591465 16 proxy.go:610] (0) /api/v1/namespaces/proxy-325/services/proxy-service-2nkf9:portname2/proxy/: bar (200; 39.342381ms)
  I0902 08:06:25.591488 16 proxy.go:610] (0) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:162/proxy/: bar (200; 39.134431ms)
  I0902 08:06:25.591622 16 proxy.go:610] (0) /api/v1/namespaces/proxy-325/services/http:proxy-service-2nkf9:portname1/proxy/: foo (200; 39.553912ms)
  I0902 08:06:25.591715 16 proxy.go:610] (0) /api/v1/namespaces/proxy-325/services/proxy-service-2nkf9:portname1/proxy/: foo (200; 39.772203ms)
  I0902 08:06:25.592020 16 proxy.go:610] (0) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:160/proxy/: foo (200; 38.920184ms)
  I0902 08:06:25.592079 16 proxy.go:610] (0) /api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:162/proxy/: bar (200; 38.608264ms)
  I0902 08:06:25.593677 16 proxy.go:610] (0) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/rewrite... (200; 39.972275ms)
  I0902 08:06:25.595967 16 proxy.go:610] (0) /api/v1/namespaces/proxy-325/services/https:proxy-service-2nkf9:tlsportname1/proxy/: tls baz (200; 43.299057ms)
  I0902 08:06:25.596146 16 proxy.go:610] (0) /api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:460/proxy/: tls baz (200; 44.387722ms)
  I0902 08:06:25.596162 16 proxy.go:610] (0) /api/v1/namespaces/proxy-325/services/https:proxy-service-2nkf9:tlsportname2/proxy/: tls qux (200; 42.576393ms)
  I0902 08:06:25.596219 16 proxy.go:610] (0) /api/v1/namespaces/proxy-325/services/http:proxy-service-2nkf9:portname2/proxy/: bar (200; 43.372252ms)
  I0902 08:06:25.596266 16 proxy.go:610] (0) /api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:462/proxy/: tls qux (200; 42.964515ms)
  I0902 08:06:25.596260 16 proxy.go:610] (0) /api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:443/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:443/proxy/tl... (200; 43.07204ms)
  I0902 08:06:25.614906 16 proxy.go:610] (1) /api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:443/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:443/proxy/tl... (200; 18.04049ms)
  I0902 08:06:25.617605 16 proxy.go:610] (1) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q/proxy/rewriteme">t... (200; 20.030874ms)
  I0902 08:06:25.617722 16 proxy.go:610] (1) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:160/proxy/: foo (200; 20.943003ms)
  I0902 08:06:25.618432 16 proxy.go:610] (1) /api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/re... (200; 21.483031ms)
  I0902 08:06:25.620007 16 proxy.go:610] (1) /api/v1/namespaces/proxy-325/services/proxy-service-2nkf9:portname1/proxy/: foo (200; 22.794743ms)
  I0902 08:06:25.621325 16 proxy.go:610] (1) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/rewrite... (200; 24.632295ms)
  I0902 08:06:25.622224 16 proxy.go:610] (1) /api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:460/proxy/: tls baz (200; 25.125569ms)
  I0902 08:06:25.622314 16 proxy.go:610] (1) /api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:462/proxy/: tls qux (200; 24.535287ms)
  I0902 08:06:25.623219 16 proxy.go:610] (1) /api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:160/proxy/: foo (200; 25.489614ms)
  I0902 08:06:25.623493 16 proxy.go:610] (1) /api/v1/namespaces/proxy-325/services/https:proxy-service-2nkf9:tlsportname2/proxy/: tls qux (200; 27.111547ms)
  I0902 08:06:25.624800 16 proxy.go:610] (1) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:162/proxy/: bar (200; 27.80008ms)
  I0902 08:06:25.624858 16 proxy.go:610] (1) /api/v1/namespaces/proxy-325/services/http:proxy-service-2nkf9:portname1/proxy/: foo (200; 27.571432ms)
  I0902 08:06:25.624889 16 proxy.go:610] (1) /api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:162/proxy/: bar (200; 27.282839ms)
  I0902 08:06:25.624933 16 proxy.go:610] (1) /api/v1/namespaces/proxy-325/services/https:proxy-service-2nkf9:tlsportname1/proxy/: tls baz (200; 27.481871ms)
  I0902 08:06:25.627319 16 proxy.go:610] (1) /api/v1/namespaces/proxy-325/services/proxy-service-2nkf9:portname2/proxy/: bar (200; 29.947234ms)
  I0902 08:06:25.628960 16 proxy.go:610] (1) /api/v1/namespaces/proxy-325/services/http:proxy-service-2nkf9:portname2/proxy/: bar (200; 31.910952ms)
  I0902 08:06:25.640789 16 proxy.go:610] (2) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q/proxy/rewriteme">t... (200; 11.461993ms)
  I0902 08:06:25.643880 16 proxy.go:610] (2) /api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:162/proxy/: bar (200; 12.958405ms)
  I0902 08:06:25.643933 16 proxy.go:610] (2) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:160/proxy/: foo (200; 14.415802ms)
  I0902 08:06:25.644059 16 proxy.go:610] (2) /api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:460/proxy/: tls baz (200; 13.998846ms)
  I0902 08:06:25.650642 16 proxy.go:610] (2) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:162/proxy/: bar (200; 20.277893ms)
  I0902 08:06:25.653327 16 proxy.go:610] (2) /api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/re... (200; 22.857842ms)
  I0902 08:06:25.654271 16 proxy.go:610] (2) /api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:443/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:443/proxy/tl... (200; 23.862405ms)
  I0902 08:06:25.655039 16 proxy.go:610] (2) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/rewrite... (200; 25.058356ms)
  I0902 08:06:25.656748 16 proxy.go:610] (2) /api/v1/namespaces/proxy-325/services/http:proxy-service-2nkf9:portname2/proxy/: bar (200; 25.90139ms)
  I0902 08:06:25.657094 16 proxy.go:610] (2) /api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:462/proxy/: tls qux (200; 27.37717ms)
  I0902 08:06:25.657389 16 proxy.go:610] (2) /api/v1/namespaces/proxy-325/services/https:proxy-service-2nkf9:tlsportname2/proxy/: tls qux (200; 27.644384ms)
  I0902 08:06:25.657747 16 proxy.go:610] (2) /api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:160/proxy/: foo (200; 26.994027ms)
  I0902 08:06:25.659698 16 proxy.go:610] (2) /api/v1/namespaces/proxy-325/services/proxy-service-2nkf9:portname1/proxy/: foo (200; 29.553831ms)
  I0902 08:06:25.659889 16 proxy.go:610] (2) /api/v1/namespaces/proxy-325/services/https:proxy-service-2nkf9:tlsportname1/proxy/: tls baz (200; 30.857866ms)
  I0902 08:06:25.660005 16 proxy.go:610] (2) /api/v1/namespaces/proxy-325/services/http:proxy-service-2nkf9:portname1/proxy/: foo (200; 29.825722ms)
  I0902 08:06:25.660670 16 proxy.go:610] (2) /api/v1/namespaces/proxy-325/services/proxy-service-2nkf9:portname2/proxy/: bar (200; 30.392708ms)
  I0902 08:06:25.673224 16 proxy.go:610] (3) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q/proxy/rewriteme">t... (200; 12.320121ms)
  I0902 08:06:25.679602 16 proxy.go:610] (3) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:160/proxy/: foo (200; 17.741952ms)
  I0902 08:06:25.679600 16 proxy.go:610] (3) /api/v1/namespaces/proxy-325/services/proxy-service-2nkf9:portname1/proxy/: foo (200; 18.30939ms)
  I0902 08:06:25.681198 16 proxy.go:610] (3) /api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:460/proxy/: tls baz (200; 19.479435ms)
  I0902 08:06:25.683780 16 proxy.go:610] (3) /api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/re... (200; 21.522619ms)
  I0902 08:06:25.685992 16 proxy.go:610] (3) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:162/proxy/: bar (200; 23.678233ms)
  I0902 08:06:25.687370 16 proxy.go:610] (3) /api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:443/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:443/proxy/tl... (200; 25.17169ms)
  I0902 08:06:25.694882 16 proxy.go:610] (3) /api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:462/proxy/: tls qux (200; 29.797092ms)
  I0902 08:06:25.695050 16 proxy.go:610] (3) /api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:160/proxy/: foo (200; 32.641937ms)
  I0902 08:06:25.695267 16 proxy.go:610] (3) /api/v1/namespaces/proxy-325/services/http:proxy-service-2nkf9:portname2/proxy/: bar (200; 32.91153ms)
  I0902 08:06:25.695338 16 proxy.go:610] (3) /api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:162/proxy/: bar (200; 30.340654ms)
  I0902 08:06:25.695907 16 proxy.go:610] (3) /api/v1/namespaces/proxy-325/services/proxy-service-2nkf9:portname2/proxy/: bar (200; 32.895646ms)
  I0902 08:06:25.696202 16 proxy.go:610] (3) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/rewrite... (200; 30.961042ms)
  I0902 08:06:25.698272 16 proxy.go:610] (3) /api/v1/namespaces/proxy-325/services/http:proxy-service-2nkf9:portname1/proxy/: foo (200; 35.360623ms)
  I0902 08:06:25.699001 16 proxy.go:610] (3) /api/v1/namespaces/proxy-325/services/https:proxy-service-2nkf9:tlsportname1/proxy/: tls baz (200; 35.922662ms)
  I0902 08:06:25.700343 16 proxy.go:610] (3) /api/v1/namespaces/proxy-325/services/https:proxy-service-2nkf9:tlsportname2/proxy/: tls qux (200; 35.162065ms)
  I0902 08:06:25.719338 16 proxy.go:610] (4) /api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:443/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:443/proxy/tl... (200; 16.874895ms)
  I0902 08:06:25.723470 16 proxy.go:610] (4) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q/proxy/rewriteme">t... (200; 21.745508ms)
  I0902 08:06:25.723495 16 proxy.go:610] (4) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:162/proxy/: bar (200; 20.78529ms)
  I0902 08:06:25.725447 16 proxy.go:610] (4) /api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:460/proxy/: tls baz (200; 24.927327ms)
  I0902 08:06:25.730612 16 proxy.go:610] (4) /api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/re... (200; 27.98214ms)
  I0902 08:06:25.730628 16 proxy.go:610] (4) /api/v1/namespaces/proxy-325/services/proxy-service-2nkf9:portname2/proxy/: bar (200; 29.400742ms)
  I0902 08:06:25.730771 16 proxy.go:610] (4) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/rewrite... (200; 28.420451ms)
  I0902 08:06:25.730760 16 proxy.go:610] (4) /api/v1/namespaces/proxy-325/services/proxy-service-2nkf9:portname1/proxy/: foo (200; 29.967141ms)
  I0902 08:06:25.731313 16 proxy.go:610] (4) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:160/proxy/: foo (200; 28.838298ms)
  I0902 08:06:25.732359 16 proxy.go:610] (4) /api/v1/namespaces/proxy-325/services/https:proxy-service-2nkf9:tlsportname1/proxy/: tls baz (200; 30.905945ms)
  I0902 08:06:25.734958 16 proxy.go:610] (4) /api/v1/namespaces/proxy-325/services/http:proxy-service-2nkf9:portname1/proxy/: foo (200; 33.942228ms)
  I0902 08:06:25.736834 16 proxy.go:610] (4) /api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:162/proxy/: bar (200; 34.726433ms)
  I0902 08:06:25.736966 16 proxy.go:610] (4) /api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:160/proxy/: foo (200; 34.945744ms)
  I0902 08:06:25.738075 16 proxy.go:610] (4) /api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:462/proxy/: tls qux (200; 35.869658ms)
  I0902 08:06:25.738865 16 proxy.go:610] (4) /api/v1/namespaces/proxy-325/services/http:proxy-service-2nkf9:portname2/proxy/: bar (200; 36.972582ms)
  I0902 08:06:25.743495 16 proxy.go:610] (4) /api/v1/namespaces/proxy-325/services/https:proxy-service-2nkf9:tlsportname2/proxy/: tls qux (200; 41.196814ms)
  I0902 08:06:25.770209 16 proxy.go:610] (5) /api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:160/proxy/: foo (200; 25.942616ms)
  I0902 08:06:25.770714 16 proxy.go:610] (5) /api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:162/proxy/: bar (200; 26.267475ms)
  I0902 08:06:25.770913 16 proxy.go:610] (5) /api/v1/namespaces/proxy-325/services/proxy-service-2nkf9:portname1/proxy/: foo (200; 27.12325ms)
  I0902 08:06:25.770970 16 proxy.go:610] (5) /api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:462/proxy/: tls qux (200; 26.335729ms)
  I0902 08:06:25.772172 16 proxy.go:610] (5) /api/v1/namespaces/proxy-325/services/http:proxy-service-2nkf9:portname2/proxy/: bar (200; 28.141649ms)
  I0902 08:06:25.772242 16 proxy.go:610] (5) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/rewrite... (200; 27.190048ms)
  I0902 08:06:25.774259 16 proxy.go:610] (5) /api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/re... (200; 28.014691ms)
  I0902 08:06:25.776333 16 proxy.go:610] (5) /api/v1/namespaces/proxy-325/services/https:proxy-service-2nkf9:tlsportname2/proxy/: tls qux (200; 31.222961ms)
  I0902 08:06:25.776811 16 proxy.go:610] (5) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:162/proxy/: bar (200; 33.181517ms)
  I0902 08:06:25.779425 16 proxy.go:610] (5) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:160/proxy/: foo (200; 33.698668ms)
  I0902 08:06:25.780410 16 proxy.go:610] (5) /api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:460/proxy/: tls baz (200; 35.167993ms)
  I0902 08:06:25.790995 16 proxy.go:610] (5) /api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:443/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:443/proxy/tl... (200; 45.019203ms)
  I0902 08:06:25.794690 16 proxy.go:610] (5) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q/proxy/rewriteme">t... (200; 49.250158ms)
  I0902 08:06:25.800423 16 proxy.go:610] (5) /api/v1/namespaces/proxy-325/services/proxy-service-2nkf9:portname2/proxy/: bar (200; 53.993368ms)
  I0902 08:06:25.803431 16 proxy.go:610] (5) /api/v1/namespaces/proxy-325/services/http:proxy-service-2nkf9:portname1/proxy/: foo (200; 56.673113ms)
  I0902 08:06:25.803426 16 proxy.go:610] (5) /api/v1/namespaces/proxy-325/services/https:proxy-service-2nkf9:tlsportname1/proxy/: tls baz (200; 56.026748ms)
  I0902 08:06:25.824302 16 proxy.go:610] (6) /api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:162/proxy/: bar (200; 19.225027ms)
  I0902 08:06:25.827166 16 proxy.go:610] (6) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/rewrite... (200; 21.906643ms)
  I0902 08:06:25.831186 16 proxy.go:610] (6) /api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:462/proxy/: tls qux (200; 26.068754ms)
  I0902 08:06:25.834888 16 proxy.go:610] (6) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:160/proxy/: foo (200; 30.108929ms)
  I0902 08:06:25.852092 16 proxy.go:610] (6) /api/v1/namespaces/proxy-325/services/proxy-service-2nkf9:portname2/proxy/: bar (200; 47.893931ms)
  I0902 08:06:25.852295 16 proxy.go:610] (6) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q/proxy/rewriteme">t... (200; 47.663178ms)
  I0902 08:06:25.853112 16 proxy.go:610] (6) /api/v1/namespaces/proxy-325/services/proxy-service-2nkf9:portname1/proxy/: foo (200; 47.739089ms)
  I0902 08:06:25.853199 16 proxy.go:610] (6) /api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:160/proxy/: foo (200; 48.570041ms)
  I0902 08:06:25.853286 16 proxy.go:610] (6) /api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/re... (200; 48.41432ms)
  I0902 08:06:25.853091 16 proxy.go:610] (6) /api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:443/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:443/proxy/tl... (200; 48.295657ms)
  I0902 08:06:25.853877 16 proxy.go:610] (6) /api/v1/namespaces/proxy-325/services/https:proxy-service-2nkf9:tlsportname1/proxy/: tls baz (200; 49.452581ms)
  I0902 08:06:25.853935 16 proxy.go:610] (6) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:162/proxy/: bar (200; 48.997477ms)
  I0902 08:06:25.853943 16 proxy.go:610] (6) /api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:460/proxy/: tls baz (200; 48.705985ms)
  I0902 08:06:25.855968 16 proxy.go:610] (6) /api/v1/namespaces/proxy-325/services/http:proxy-service-2nkf9:portname1/proxy/: foo (200; 52.033983ms)
  I0902 08:06:25.856854 16 proxy.go:610] (6) /api/v1/namespaces/proxy-325/services/https:proxy-service-2nkf9:tlsportname2/proxy/: tls qux (200; 51.822057ms)
  I0902 08:06:25.857061 16 proxy.go:610] (6) /api/v1/namespaces/proxy-325/services/http:proxy-service-2nkf9:portname2/proxy/: bar (200; 52.072958ms)
  I0902 08:06:25.888050 16 proxy.go:610] (7) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:162/proxy/: bar (200; 30.886049ms)
  I0902 08:06:25.900008 16 proxy.go:610] (7) /api/v1/namespaces/proxy-325/services/http:proxy-service-2nkf9:portname2/proxy/: bar (200; 42.627923ms)
  I0902 08:06:25.900079 16 proxy.go:610] (7) /api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:162/proxy/: bar (200; 42.530964ms)
  I0902 08:06:25.903193 16 proxy.go:610] (7) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/rewrite... (200; 45.400202ms)
  I0902 08:06:25.903286 16 proxy.go:610] (7) /api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:462/proxy/: tls qux (200; 45.632181ms)
  I0902 08:06:25.910150 16 proxy.go:610] (7) /api/v1/namespaces/proxy-325/services/https:proxy-service-2nkf9:tlsportname2/proxy/: tls qux (200; 52.424393ms)
  I0902 08:06:25.913536 16 proxy.go:610] (7) /api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:160/proxy/: foo (200; 56.0894ms)
  I0902 08:06:25.915974 16 proxy.go:610] (7) /api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:443/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:443/proxy/tl... (200; 57.69525ms)
  I0902 08:06:25.919591 16 proxy.go:610] (7) /api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/re... (200; 61.088283ms)
  I0902 08:06:25.919691 16 proxy.go:610] (7) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q/proxy/rewriteme">t... (200; 61.750947ms)
  I0902 08:06:25.919758 16 proxy.go:610] (7) /api/v1/namespaces/proxy-325/services/proxy-service-2nkf9:portname1/proxy/: foo (200; 62.501609ms)
  I0902 08:06:25.920413 16 proxy.go:610] (7) /api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:460/proxy/: tls baz (200; 62.543789ms)
  I0902 08:06:25.921593 16 proxy.go:610] (7) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:160/proxy/: foo (200; 63.219491ms)
  I0902 08:06:25.921743 16 proxy.go:610] (7) /api/v1/namespaces/proxy-325/services/http:proxy-service-2nkf9:portname1/proxy/: foo (200; 63.730466ms)
  I0902 08:06:25.922505 16 proxy.go:610] (7) /api/v1/namespaces/proxy-325/services/proxy-service-2nkf9:portname2/proxy/: bar (200; 64.42732ms)
  I0902 08:06:25.923345 16 proxy.go:610] (7) /api/v1/namespaces/proxy-325/services/https:proxy-service-2nkf9:tlsportname1/proxy/: tls baz (200; 65.221469ms)
  I0902 08:06:25.955619 16 proxy.go:610] (8) /api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:160/proxy/: foo (200; 30.770096ms)
  I0902 08:06:25.955732 16 proxy.go:610] (8) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/rewrite... (200; 30.604537ms)
  I0902 08:06:25.956420 16 proxy.go:610] (8) /api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:162/proxy/: bar (200; 31.445756ms)
  I0902 08:06:25.956855 16 proxy.go:610] (8) /api/v1/namespaces/proxy-325/services/proxy-service-2nkf9:portname2/proxy/: bar (200; 32.608681ms)
  I0902 08:06:25.957446 16 proxy.go:610] (8) /api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:460/proxy/: tls baz (200; 32.236931ms)
  I0902 08:06:25.960810 16 proxy.go:610] (8) /api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:462/proxy/: tls qux (200; 35.771753ms)
  I0902 08:06:25.961057 16 proxy.go:610] (8) /api/v1/namespaces/proxy-325/services/http:proxy-service-2nkf9:portname2/proxy/: bar (200; 36.288861ms)
  I0902 08:06:25.962433 16 proxy.go:610] (8) /api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/re... (200; 36.963638ms)
  I0902 08:06:25.962502 16 proxy.go:610] (8) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:162/proxy/: bar (200; 38.746783ms)
  I0902 08:06:25.962667 16 proxy.go:610] (8) /api/v1/namespaces/proxy-325/services/http:proxy-service-2nkf9:portname1/proxy/: foo (200; 38.640665ms)
  I0902 08:06:25.962713 16 proxy.go:610] (8) /api/v1/namespaces/proxy-325/services/proxy-service-2nkf9:portname1/proxy/: foo (200; 39.308133ms)
  I0902 08:06:25.962723 16 proxy.go:610] (8) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q/proxy/rewriteme">t... (200; 37.386681ms)
  I0902 08:06:25.962755 16 proxy.go:610] (8) /api/v1/namespaces/proxy-325/services/https:proxy-service-2nkf9:tlsportname2/proxy/: tls qux (200; 37.678657ms)
  I0902 08:06:25.963345 16 proxy.go:610] (8) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:160/proxy/: foo (200; 38.087676ms)
  I0902 08:06:25.967824 16 proxy.go:610] (8) /api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:443/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:443/proxy/tl... (200; 42.416771ms)
  I0902 08:06:25.989245 16 proxy.go:610] (8) /api/v1/namespaces/proxy-325/services/https:proxy-service-2nkf9:tlsportname1/proxy/: tls baz (200; 64.803249ms)
  I0902 08:06:26.005635 16 proxy.go:610] (9) /api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:462/proxy/: tls qux (200; 16.229318ms)
  I0902 08:06:26.005625 16 proxy.go:610] (9) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q/proxy/rewriteme">t... (200; 15.983962ms)
  I0902 08:06:26.006037 16 proxy.go:610] (9) /api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:443/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:443/proxy/tl... (200; 15.748473ms)
  I0902 08:06:26.007869 16 proxy.go:610] (9) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:162/proxy/: bar (200; 17.645201ms)
  I0902 08:06:26.014100 16 proxy.go:610] (9) /api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:460/proxy/: tls baz (200; 24.15011ms)
  I0902 08:06:26.016007 16 proxy.go:610] (9) /api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/re... (200; 25.665886ms)
  I0902 08:06:26.017312 16 proxy.go:610] (9) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:160/proxy/: foo (200; 27.18222ms)
  I0902 08:06:26.017323 16 proxy.go:610] (9) /api/v1/namespaces/proxy-325/services/proxy-service-2nkf9:portname1/proxy/: foo (200; 27.279549ms)
  I0902 08:06:26.019696 16 proxy.go:610] (9) /api/v1/namespaces/proxy-325/services/http:proxy-service-2nkf9:portname1/proxy/: foo (200; 29.64786ms)
  I0902 08:06:26.019692 16 proxy.go:610] (9) /api/v1/namespaces/proxy-325/services/http:proxy-service-2nkf9:portname2/proxy/: bar (200; 29.329391ms)
  I0902 08:06:26.022451 16 proxy.go:610] (9) /api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:162/proxy/: bar (200; 31.503464ms)
  I0902 08:06:26.022499 16 proxy.go:610] (9) /api/v1/namespaces/proxy-325/services/https:proxy-service-2nkf9:tlsportname1/proxy/: tls baz (200; 32.31806ms)
  I0902 08:06:26.023057 16 proxy.go:610] (9) /api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:160/proxy/: foo (200; 32.377608ms)
  I0902 08:06:26.028045 16 proxy.go:610] (9) /api/v1/namespaces/proxy-325/services/proxy-service-2nkf9:portname2/proxy/: bar (200; 37.948927ms)
  I0902 08:06:26.029101 16 proxy.go:610] (9) /api/v1/namespaces/proxy-325/services/https:proxy-service-2nkf9:tlsportname2/proxy/: tls qux (200; 39.359503ms)
  I0902 08:06:26.032482 16 proxy.go:610] (9) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/rewrite... (200; 42.622687ms)
  I0902 08:06:26.065686 16 proxy.go:610] (10) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q/proxy/rewriteme">t... (200; 32.475719ms)
  I0902 08:06:26.066074 16 proxy.go:610] (10) /api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:160/proxy/: foo (200; 32.762227ms)
  I0902 08:06:26.067905 16 proxy.go:610] (10) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:162/proxy/: bar (200; 34.467898ms)
  I0902 08:06:26.068798 16 proxy.go:610] (10) /api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:162/proxy/: bar (200; 34.911913ms)
  I0902 08:06:26.071039 16 proxy.go:610] (10) /api/v1/namespaces/proxy-325/services/http:proxy-service-2nkf9:portname1/proxy/: foo (200; 38.060849ms)
  I0902 08:06:26.078122 16 proxy.go:610] (10) /api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/re... (200; 44.738693ms)
  I0902 08:06:26.078400 16 proxy.go:610] (10) /api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:462/proxy/: tls qux (200; 44.406081ms)
  I0902 08:06:26.078674 16 proxy.go:610] (10) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:160/proxy/: foo (200; 45.408355ms)
  I0902 08:06:26.080358 16 proxy.go:610] (10) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/rewrite... (200; 47.737276ms)
  I0902 08:06:26.081917 16 proxy.go:610] (10) /api/v1/namespaces/proxy-325/services/http:proxy-service-2nkf9:portname2/proxy/: bar (200; 48.418906ms)
  I0902 08:06:26.082077 16 proxy.go:610] (10) /api/v1/namespaces/proxy-325/services/proxy-service-2nkf9:portname2/proxy/: bar (200; 49.031418ms)
  I0902 08:06:26.083118 16 proxy.go:610] (10) /api/v1/namespaces/proxy-325/services/proxy-service-2nkf9:portname1/proxy/: foo (200; 50.189856ms)
  I0902 08:06:26.083075 16 proxy.go:610] (10) /api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:443/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:443/proxy/tl... (200; 50.374804ms)
  I0902 08:06:26.083887 16 proxy.go:610] (10) /api/v1/namespaces/proxy-325/services/https:proxy-service-2nkf9:tlsportname2/proxy/: tls qux (200; 49.836215ms)
  I0902 08:06:26.087629 16 proxy.go:610] (10) /api/v1/namespaces/proxy-325/services/https:proxy-service-2nkf9:tlsportname1/proxy/: tls baz (200; 54.519033ms)
  I0902 08:06:26.088965 16 proxy.go:610] (10) /api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:460/proxy/: tls baz (200; 56.131493ms)
  I0902 08:06:26.119770 16 proxy.go:610] (11) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:162/proxy/: bar (200; 30.697143ms)
  I0902 08:06:26.130399 16 proxy.go:610] (11) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/rewrite... (200; 40.350965ms)
  I0902 08:06:26.130664 16 proxy.go:610] (11) /api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:460/proxy/: tls baz (200; 40.395506ms)
  I0902 08:06:26.139664 16 proxy.go:610] (11) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q/proxy/rewriteme">t... (200; 50.15947ms)
  I0902 08:06:26.139657 16 proxy.go:610] (11) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:160/proxy/: foo (200; 50.10658ms)
  I0902 08:06:26.140396 16 proxy.go:610] (11) /api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:462/proxy/: tls qux (200; 50.586241ms)
  I0902 08:06:26.141046 16 proxy.go:610] (11) /api/v1/namespaces/proxy-325/services/http:proxy-service-2nkf9:portname2/proxy/: bar (200; 51.182047ms)
  I0902 08:06:26.141125 16 proxy.go:610] (11) /api/v1/namespaces/proxy-325/services/http:proxy-service-2nkf9:portname1/proxy/: foo (200; 51.814726ms)
  I0902 08:06:26.140788 16 proxy.go:610] (11) /api/v1/namespaces/proxy-325/services/proxy-service-2nkf9:portname2/proxy/: bar (200; 51.386366ms)
  I0902 08:06:26.141701 16 proxy.go:610] (11) /api/v1/namespaces/proxy-325/services/proxy-service-2nkf9:portname1/proxy/: foo (200; 52.473124ms)
  I0902 08:06:26.145271 16 proxy.go:610] (11) /api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:162/proxy/: bar (200; 55.313169ms)
  I0902 08:06:26.145338 16 proxy.go:610] (11) /api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/re... (200; 55.579349ms)
  I0902 08:06:26.145809 16 proxy.go:610] (11) /api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:443/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:443/proxy/tl... (200; 56.09705ms)
  I0902 08:06:26.145929 16 proxy.go:610] (11) /api/v1/namespaces/proxy-325/services/https:proxy-service-2nkf9:tlsportname2/proxy/: tls qux (200; 55.76942ms)
  I0902 08:06:26.146078 16 proxy.go:610] (11) /api/v1/namespaces/proxy-325/services/https:proxy-service-2nkf9:tlsportname1/proxy/: tls baz (200; 56.623256ms)
  I0902 08:06:26.146313 16 proxy.go:610] (11) /api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:160/proxy/: foo (200; 56.400276ms)
  I0902 08:06:26.169496 16 proxy.go:610] (12) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:162/proxy/: bar (200; 23.090378ms)
  I0902 08:06:26.187402 16 proxy.go:610] (12) /api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:162/proxy/: bar (200; 39.663049ms)
  I0902 08:06:26.190807 16 proxy.go:610] (12) /api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:160/proxy/: foo (200; 43.698997ms)
  I0902 08:06:26.191205 16 proxy.go:610] (12) /api/v1/namespaces/proxy-325/services/http:proxy-service-2nkf9:portname1/proxy/: foo (200; 44.46879ms)
  I0902 08:06:26.192282 16 proxy.go:610] (12) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q/proxy/rewriteme">t... (200; 44.888698ms)
  I0902 08:06:26.192414 16 proxy.go:610] (12) /api/v1/namespaces/proxy-325/services/https:proxy-service-2nkf9:tlsportname2/proxy/: tls qux (200; 44.767232ms)
  I0902 08:06:26.193262 16 proxy.go:610] (12) /api/v1/namespaces/proxy-325/services/proxy-service-2nkf9:portname1/proxy/: foo (200; 46.616957ms)
  I0902 08:06:26.194451 16 proxy.go:610] (12) /api/v1/namespaces/proxy-325/services/http:proxy-service-2nkf9:portname2/proxy/: bar (200; 47.638293ms)
  I0902 08:06:26.205300 16 proxy.go:610] (12) /api/v1/namespaces/proxy-325/services/https:proxy-service-2nkf9:tlsportname1/proxy/: tls baz (200; 57.842084ms)
  I0902 08:06:26.211150 16 proxy.go:610] (12) /api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/re... (200; 63.530264ms)
  I0902 08:06:26.211430 16 proxy.go:610] (12) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/rewrite... (200; 63.551603ms)
  I0902 08:06:26.211484 16 proxy.go:610] (12) /api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:460/proxy/: tls baz (200; 63.65648ms)
  I0902 08:06:26.212698 16 proxy.go:610] (12) /api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:443/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:443/proxy/tl... (200; 65.175849ms)
  I0902 08:06:26.212905 16 proxy.go:610] (12) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:160/proxy/: foo (200; 65.43466ms)
  I0902 08:06:26.226287 16 proxy.go:610] (12) /api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:462/proxy/: tls qux (200; 78.491135ms)
  I0902 08:06:26.229777 16 proxy.go:610] (12) /api/v1/namespaces/proxy-325/services/proxy-service-2nkf9:portname2/proxy/: bar (200; 82.879259ms)
  I0902 08:06:26.270899 16 proxy.go:610] (13) /api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/re... (200; 41.018483ms)
  I0902 08:06:26.289192 16 proxy.go:610] (13) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:160/proxy/: foo (200; 56.992324ms)
  I0902 08:06:26.289341 16 proxy.go:610] (13) /api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:460/proxy/: tls baz (200; 57.498268ms)
  I0902 08:06:26.289196 16 proxy.go:610] (13) /api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:462/proxy/: tls qux (200; 58.171177ms)
  I0902 08:06:26.296528 16 proxy.go:610] (13) /api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:160/proxy/: foo (200; 65.911702ms)
  I0902 08:06:26.296961 16 proxy.go:610] (13) /api/v1/namespaces/proxy-325/services/proxy-service-2nkf9:portname2/proxy/: bar (200; 64.933089ms)
  I0902 08:06:26.297200 16 proxy.go:610] (13) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/rewrite... (200; 65.329108ms)
  I0902 08:06:26.297238 16 proxy.go:610] (13) /api/v1/namespaces/proxy-325/services/http:proxy-service-2nkf9:portname2/proxy/: bar (200; 66.868611ms)
  I0902 08:06:26.297779 16 proxy.go:610] (13) /api/v1/namespaces/proxy-325/services/http:proxy-service-2nkf9:portname1/proxy/: foo (200; 66.284544ms)
  I0902 08:06:26.297743 16 proxy.go:610] (13) /api/v1/namespaces/proxy-325/services/https:proxy-service-2nkf9:tlsportname2/proxy/: tls qux (200; 65.934061ms)
  I0902 08:06:26.297836 16 proxy.go:610] (13) /api/v1/namespaces/proxy-325/services/https:proxy-service-2nkf9:tlsportname1/proxy/: tls baz (200; 65.766147ms)
  I0902 08:06:26.297890 16 proxy.go:610] (13) /api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:443/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:443/proxy/tl... (200; 65.4517ms)
  I0902 08:06:26.298203 16 proxy.go:610] (13) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:162/proxy/: bar (200; 68.042854ms)
  I0902 08:06:26.298872 16 proxy.go:610] (13) /api/v1/namespaces/proxy-325/services/proxy-service-2nkf9:portname1/proxy/: foo (200; 66.986932ms)
  I0902 08:06:26.298876 16 proxy.go:610] (13) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q/proxy/rewriteme">t... (200; 66.940203ms)
  I0902 08:06:26.302002 16 proxy.go:610] (13) /api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:162/proxy/: bar (200; 71.186251ms)
  I0902 08:06:26.329242 16 proxy.go:610] (14) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/rewrite... (200; 26.596645ms)
  I0902 08:06:26.342466 16 proxy.go:610] (14) /api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:160/proxy/: foo (200; 40.325979ms)
  I0902 08:06:26.349514 16 proxy.go:610] (14) /api/v1/namespaces/proxy-325/services/https:proxy-service-2nkf9:tlsportname1/proxy/: tls baz (200; 46.277747ms)
  I0902 08:06:26.349782 16 proxy.go:610] (14) /api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:460/proxy/: tls baz (200; 47.027922ms)
  I0902 08:06:26.354451 16 proxy.go:610] (14) /api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:462/proxy/: tls qux (200; 51.984109ms)
  I0902 08:06:26.354896 16 proxy.go:610] (14) /api/v1/namespaces/proxy-325/services/https:proxy-service-2nkf9:tlsportname2/proxy/: tls qux (200; 52.381275ms)
  I0902 08:06:26.362677 16 proxy.go:610] (14) /api/v1/namespaces/proxy-325/services/proxy-service-2nkf9:portname1/proxy/: foo (200; 59.759928ms)
  I0902 08:06:26.362628 16 proxy.go:610] (14) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:160/proxy/: foo (200; 59.201453ms)
  I0902 08:06:26.362628 16 proxy.go:610] (14) /api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:162/proxy/: bar (200; 60.221062ms)
  I0902 08:06:26.368866 16 proxy.go:610] (14) /api/v1/namespaces/proxy-325/services/proxy-service-2nkf9:portname2/proxy/: bar (200; 66.773702ms)
  I0902 08:06:26.369179 16 proxy.go:610] (14) /api/v1/namespaces/proxy-325/services/http:proxy-service-2nkf9:portname1/proxy/: foo (200; 66.121946ms)
  I0902 08:06:26.369235 16 proxy.go:610] (14) /api/v1/namespaces/proxy-325/services/http:proxy-service-2nkf9:portname2/proxy/: bar (200; 65.211822ms)
  I0902 08:06:26.373396 16 proxy.go:610] (14) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:162/proxy/: bar (200; 69.892677ms)
  I0902 08:06:26.373662 16 proxy.go:610] (14) /api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:443/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:443/proxy/tl... (200; 70.49025ms)
  I0902 08:06:26.376799 16 proxy.go:610] (14) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q/proxy/rewriteme">t... (200; 73.42288ms)
  I0902 08:06:26.377309 16 proxy.go:610] (14) /api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/re... (200; 73.783299ms)
  I0902 08:06:26.407725 16 proxy.go:610] (15) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q/proxy/rewriteme">t... (200; 28.899358ms)
  I0902 08:06:26.415100 16 proxy.go:610] (15) /api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:443/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:443/proxy/tl... (200; 37.704313ms)
  I0902 08:06:26.416467 16 proxy.go:610] (15) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:160/proxy/: foo (200; 37.427124ms)
  I0902 08:06:26.416665 16 proxy.go:610] (15) /api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:162/proxy/: bar (200; 37.453799ms)
  I0902 08:06:26.420021 16 proxy.go:610] (15) /api/v1/namespaces/proxy-325/services/http:proxy-service-2nkf9:portname1/proxy/: foo (200; 41.519201ms)
  I0902 08:06:26.421638 16 proxy.go:610] (15) /api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:460/proxy/: tls baz (200; 43.438939ms)
  I0902 08:06:26.424800 16 proxy.go:610] (15) /api/v1/namespaces/proxy-325/services/proxy-service-2nkf9:portname1/proxy/: foo (200; 46.464988ms)
  I0902 08:06:26.424950 16 proxy.go:610] (15) /api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:160/proxy/: foo (200; 46.276407ms)
  I0902 08:06:26.425014 16 proxy.go:610] (15) /api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/re... (200; 47.361205ms)
  I0902 08:06:26.425214 16 proxy.go:610] (15) /api/v1/namespaces/proxy-325/services/proxy-service-2nkf9:portname2/proxy/: bar (200; 46.619196ms)
  I0902 08:06:26.425270 16 proxy.go:610] (15) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:162/proxy/: bar (200; 47.361088ms)
  I0902 08:06:26.425470 16 proxy.go:610] (15) /api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:462/proxy/: tls qux (200; 46.055176ms)
  I0902 08:06:26.428742 16 proxy.go:610] (15) /api/v1/namespaces/proxy-325/services/http:proxy-service-2nkf9:portname2/proxy/: bar (200; 50.678976ms)
  I0902 08:06:26.431245 16 proxy.go:610] (15) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/rewrite... (200; 51.624978ms)
  I0902 08:06:26.431349 16 proxy.go:610] (15) /api/v1/namespaces/proxy-325/services/https:proxy-service-2nkf9:tlsportname1/proxy/: tls baz (200; 52.692129ms)
  I0902 08:06:26.432450 16 proxy.go:610] (15) /api/v1/namespaces/proxy-325/services/https:proxy-service-2nkf9:tlsportname2/proxy/: tls qux (200; 52.801413ms)
  I0902 08:06:26.456642 16 proxy.go:610] (16) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/rewrite... (200; 23.505988ms)
  I0902 08:06:26.457450 16 proxy.go:610] (16) /api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:443/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:443/proxy/tl... (200; 24.690359ms)
  I0902 08:06:26.459734 16 proxy.go:610] (16) /api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:162/proxy/: bar (200; 26.750394ms)
  I0902 08:06:26.459981 16 proxy.go:610] (16) /api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:160/proxy/: foo (200; 26.846119ms)
  I0902 08:06:26.466184 16 proxy.go:610] (16) /api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:462/proxy/: tls qux (200; 33.17019ms)
  I0902 08:06:26.466252 16 proxy.go:610] (16) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:162/proxy/: bar (200; 33.338222ms)
  I0902 08:06:26.467718 16 proxy.go:610] (16) /api/v1/namespaces/proxy-325/services/http:proxy-service-2nkf9:portname2/proxy/: bar (200; 34.751636ms)
  I0902 08:06:26.468088 16 proxy.go:610] (16) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:160/proxy/: foo (200; 34.919173ms)
  I0902 08:06:26.469296 16 proxy.go:610] (16) /api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/re... (200; 36.390558ms)
  I0902 08:06:26.470426 16 proxy.go:610] (16) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q/proxy/rewriteme">t... (200; 37.281345ms)
  I0902 08:06:26.471263 16 proxy.go:610] (16) /api/v1/namespaces/proxy-325/services/http:proxy-service-2nkf9:portname1/proxy/: foo (200; 38.037154ms)
  I0902 08:06:26.471735 16 proxy.go:610] (16) /api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:460/proxy/: tls baz (200; 38.67403ms)
  I0902 08:06:26.472657 16 proxy.go:610] (16) /api/v1/namespaces/proxy-325/services/https:proxy-service-2nkf9:tlsportname1/proxy/: tls baz (200; 39.774336ms)
  I0902 08:06:26.473024 16 proxy.go:610] (16) /api/v1/namespaces/proxy-325/services/https:proxy-service-2nkf9:tlsportname2/proxy/: tls qux (200; 40.003002ms)
  I0902 08:06:26.473066 16 proxy.go:610] (16) /api/v1/namespaces/proxy-325/services/proxy-service-2nkf9:portname2/proxy/: bar (200; 39.963081ms)
  I0902 08:06:26.473167 16 proxy.go:610] (16) /api/v1/namespaces/proxy-325/services/proxy-service-2nkf9:portname1/proxy/: foo (200; 40.114133ms)
  I0902 08:06:26.498766 16 proxy.go:610] (17) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/rewrite... (200; 22.434367ms)
  I0902 08:06:26.500394 16 proxy.go:610] (17) /api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/re... (200; 24.895103ms)
  I0902 08:06:26.502610 16 proxy.go:610] (17) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q/proxy/rewriteme">t... (200; 28.093464ms)
  I0902 08:06:26.507428 16 proxy.go:610] (17) /api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:443/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:443/proxy/tl... (200; 31.976726ms)
  I0902 08:06:26.511271 16 proxy.go:610] (17) /api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:160/proxy/: foo (200; 33.390193ms)
  I0902 08:06:26.516207 16 proxy.go:610] (17) /api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:462/proxy/: tls qux (200; 41.714683ms)
  I0902 08:06:26.516481 16 proxy.go:610] (17) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:160/proxy/: foo (200; 41.112872ms)
  I0902 08:06:26.516539 16 proxy.go:610] (17) /api/v1/namespaces/proxy-325/services/proxy-service-2nkf9:portname1/proxy/: foo (200; 39.616874ms)
  I0902 08:06:26.517335 16 proxy.go:610] (17) /api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:460/proxy/: tls baz (200; 40.816855ms)
  I0902 08:06:26.517489 16 proxy.go:610] (17) /api/v1/namespaces/proxy-325/services/https:proxy-service-2nkf9:tlsportname2/proxy/: tls qux (200; 42.689924ms)
  I0902 08:06:26.517867 16 proxy.go:610] (17) /api/v1/namespaces/proxy-325/services/http:proxy-service-2nkf9:portname2/proxy/: bar (200; 39.92647ms)
  I0902 08:06:26.518819 16 proxy.go:610] (17) /api/v1/namespaces/proxy-325/services/http:proxy-service-2nkf9:portname1/proxy/: foo (200; 41.411707ms)
  I0902 08:06:26.520050 16 proxy.go:610] (17) /api/v1/namespaces/proxy-325/services/https:proxy-service-2nkf9:tlsportname1/proxy/: tls baz (200; 42.334641ms)
  I0902 08:06:26.522337 16 proxy.go:610] (17) /api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:162/proxy/: bar (200; 44.268012ms)
  I0902 08:06:26.522343 16 proxy.go:610] (17) /api/v1/namespaces/proxy-325/services/proxy-service-2nkf9:portname2/proxy/: bar (200; 44.812468ms)
  I0902 08:06:26.522528 16 proxy.go:610] (17) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:162/proxy/: bar (200; 46.98972ms)
  I0902 08:06:26.541804 16 proxy.go:610] (18) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:160/proxy/: foo (200; 18.97217ms)
  I0902 08:06:26.546464 16 proxy.go:610] (18) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/rewrite... (200; 22.917872ms)
  I0902 08:06:26.546540 16 proxy.go:610] (18) /api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:443/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:443/proxy/tl... (200; 23.555328ms)
  I0902 08:06:26.555077 16 proxy.go:610] (18) /api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:462/proxy/: tls qux (200; 32.441829ms)
  I0902 08:06:26.555174 16 proxy.go:610] (18) /api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:460/proxy/: tls baz (200; 31.310689ms)
  I0902 08:06:26.555219 16 proxy.go:610] (18) /api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:160/proxy/: foo (200; 30.792374ms)
  I0902 08:06:26.555876 16 proxy.go:610] (18) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q/proxy/rewriteme">t... (200; 33.168547ms)
  I0902 08:06:26.558507 16 proxy.go:610] (18) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:162/proxy/: bar (200; 34.131352ms)
  I0902 08:06:26.562792 16 proxy.go:610] (18) /api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:162/proxy/: bar (200; 38.262367ms)
  I0902 08:06:26.562885 16 proxy.go:610] (18) /api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/re... (200; 39.53688ms)
  I0902 08:06:26.564642 16 proxy.go:610] (18) /api/v1/namespaces/proxy-325/services/http:proxy-service-2nkf9:portname2/proxy/: bar (200; 40.375293ms)
  I0902 08:06:26.565617 16 proxy.go:610] (18) /api/v1/namespaces/proxy-325/services/http:proxy-service-2nkf9:portname1/proxy/: foo (200; 41.576938ms)
  I0902 08:06:26.565889 16 proxy.go:610] (18) /api/v1/namespaces/proxy-325/services/proxy-service-2nkf9:portname2/proxy/: bar (200; 41.264577ms)
  I0902 08:06:26.570658 16 proxy.go:610] (18) /api/v1/namespaces/proxy-325/services/https:proxy-service-2nkf9:tlsportname2/proxy/: tls qux (200; 47.455355ms)
  I0902 08:06:26.570965 16 proxy.go:610] (18) /api/v1/namespaces/proxy-325/services/https:proxy-service-2nkf9:tlsportname1/proxy/: tls baz (200; 46.746412ms)
  I0902 08:06:26.571051 16 proxy.go:610] (18) /api/v1/namespaces/proxy-325/services/proxy-service-2nkf9:portname1/proxy/: foo (200; 47.06507ms)
  I0902 08:06:26.589018 16 proxy.go:610] (19) /api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:162/proxy/: bar (200; 17.373252ms)
  I0902 08:06:26.591061 16 proxy.go:610] (19) /api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:160/proxy/: foo (200; 19.64307ms)
  I0902 08:06:26.602531 16 proxy.go:610] (19) /api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:462/proxy/: tls qux (200; 30.679047ms)
  I0902 08:06:26.609484 16 proxy.go:610] (19) /api/v1/namespaces/proxy-325/services/https:proxy-service-2nkf9:tlsportname2/proxy/: tls qux (200; 37.453099ms)
  I0902 08:06:26.613005 16 proxy.go:610] (19) /api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:460/proxy/: tls baz (200; 40.415076ms)
  I0902 08:06:26.621014 16 proxy.go:610] (19) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:160/proxy/: foo (200; 48.274518ms)
  I0902 08:06:26.621205 16 proxy.go:610] (19) /api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:443/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/https:proxy-service-2nkf9-64bd8d4d9-jm98q:443/proxy/tl... (200; 48.377817ms)
  I0902 08:06:26.621236 16 proxy.go:610] (19) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:162/proxy/: bar (200; 48.329296ms)
  I0902 08:06:26.621257 16 proxy.go:610] (19) /api/v1/namespaces/proxy-325/services/http:proxy-service-2nkf9:portname2/proxy/: bar (200; 50.133215ms)
  I0902 08:06:26.625624 16 proxy.go:610] (19) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/rewrite... (200; 53.395874ms)
  I0902 08:06:26.626176 16 proxy.go:610] (19) /api/v1/namespaces/proxy-325/services/https:proxy-service-2nkf9:tlsportname1/proxy/: tls baz (200; 53.69328ms)
  I0902 08:06:26.626265 16 proxy.go:610] (19) /api/v1/namespaces/proxy-325/services/proxy-service-2nkf9:portname2/proxy/: bar (200; 53.48801ms)
  I0902 08:06:26.626314 16 proxy.go:610] (19) /api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/http:proxy-service-2nkf9-64bd8d4d9-jm98q:1080/proxy/re... (200; 53.471058ms)
  I0902 08:06:26.625690 16 proxy.go:610] (19) /api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q/proxy/: <a href="/api/v1/namespaces/proxy-325/pods/proxy-service-2nkf9-64bd8d4d9-jm98q/proxy/rewriteme">t... (200; 53.067539ms)
  I0902 08:06:26.628878 16 proxy.go:610] (19) /api/v1/namespaces/proxy-325/services/http:proxy-service-2nkf9:portname1/proxy/: foo (200; 56.173711ms)
  I0902 08:06:26.630404 16 proxy.go:610] (19) /api/v1/namespaces/proxy-325/services/proxy-service-2nkf9:portname1/proxy/: foo (200; 57.766742ms)
  I0902 08:06:26.651322 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-325" for this suite. @ 09/02/25 08:06:26.668
• [5.432 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:359
  STEP: Creating a kubernetes client @ 09/02/25 08:06:26.692
  I0902 08:06:26.693499 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename crd-publish-openapi @ 09/02/25 08:06:26.699
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:06:26.738
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:06:26.749
  STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation @ 09/02/25 08:06:26.766
  I0902 08:06:26.767689 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  I0902 08:06:29.512347 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  I0902 08:06:39.079642 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-5117" for this suite. @ 09/02/25 08:06:39.099
• [12.428 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:367
  STEP: Creating a kubernetes client @ 09/02/25 08:06:39.122
  I0902 08:06:39.122498 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename webhook @ 09/02/25 08:06:39.125
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:06:39.154
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:06:39.159
  STEP: Setting up server cert @ 09/02/25 08:06:39.202
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 09/02/25 08:06:41.09
  STEP: Deploying the webhook pod @ 09/02/25 08:06:41.104
  STEP: Wait for the deployment to be ready @ 09/02/25 08:06:41.132
  I0902 08:06:41.153994 16 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 09/02/25 08:06:43.181
  STEP: Verifying the service has paired with the endpoint @ 09/02/25 08:06:43.201
  I0902 08:06:44.204623 16 util.go:419] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Setting timeout (1s) shorter than webhook latency (5s) @ 09/02/25 08:06:44.214
  STEP: Registering slow webhook via the AdmissionRegistration API @ 09/02/25 08:06:44.214
  I0902 08:06:44.253153 16 webhook.go:2701] Waiting for webhook configuration to be ready...
  STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) @ 09/02/25 08:06:44.383
  STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore @ 09/02/25 08:06:45.406
  STEP: Registering slow webhook via the AdmissionRegistration API @ 09/02/25 08:06:45.406
  STEP: Having no error when timeout is longer than webhook latency @ 09/02/25 08:06:46.495
  STEP: Registering slow webhook via the AdmissionRegistration API @ 09/02/25 08:06:46.495
  STEP: Having no error when timeout is empty (defaulted to 10s in v1) @ 09/02/25 08:06:51.584
  STEP: Registering slow webhook via the AdmissionRegistration API @ 09/02/25 08:06:51.584
  I0902 08:06:56.826483 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-5505" for this suite. @ 09/02/25 08:06:56.84
  STEP: Destroying namespace "webhook-markers-2529" for this suite. @ 09/02/25 08:06:56.86
• [17.764 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1507
  STEP: Creating a kubernetes client @ 09/02/25 08:06:56.886
  I0902 08:06:56.886498 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename services @ 09/02/25 08:06:56.892
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:06:56.923
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:06:56.938
  STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-8446 @ 09/02/25 08:06:56.948
  STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service @ 09/02/25 08:06:56.969
  STEP: creating service externalsvc in namespace services-8446 @ 09/02/25 08:06:56.969
  I0902 08:06:57.067061 16 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:0, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:0, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition(nil), CollisionCount:(*int32)(nil)}
  I0902 08:06:59.077835 16 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:2, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.September, 2, 8, 6, 57, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 8, 6, 57, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.September, 2, 8, 6, 59, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 8, 6, 57, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"externalsvc-8664db8f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
  STEP: changing the ClusterIP service to type=ExternalName @ 09/02/25 08:07:01.104
  I0902 08:07:01.139228 16 resource.go:344] Creating new exec pod
  I0902 08:07:03.182963 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=services-8446 exec execpodx72fl -- /bin/sh -x -c nslookup clusterip-service.services-8446.svc.cluster.local'
  I0902 08:07:03.578602 16 builder.go:156] stderr: "+ nslookup clusterip-service.services-8446.svc.cluster.local\n"
  I0902 08:07:03.578840 16 builder.go:157] stdout: ";; Got recursion not available from 10.233.0.10\n;; Got recursion not available from 10.233.0.10\n;; Got recursion not available from 10.233.0.10\n;; Got recursion not available from 10.233.0.10\nServer:\t\t10.233.0.10\nAddress:\t10.233.0.10#53\n\nclusterip-service.services-8446.svc.cluster.local\tcanonical name = externalsvc.services-8446.svc.cluster.local.\nName:\texternalsvc.services-8446.svc.cluster.local\nAddress: 10.233.28.101\n;; Got recursion not available from 10.233.0.10\n\n"
  I0902 08:07:03.637283 16 service.go:1516] Cleaning up the ClusterIP to ExternalName test service
  I0902 08:07:03.668458 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-8446" for this suite. @ 09/02/25 08:07:03.683
• [6.819 seconds]
------------------------------
[sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1547
  STEP: Creating a kubernetes client @ 09/02/25 08:07:03.708
  I0902 08:07:03.709107 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename services @ 09/02/25 08:07:03.712
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:07:03.764
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:07:03.772
  STEP: creating a service nodeport-service with the type=NodePort in namespace services-795 @ 09/02/25 08:07:03.813
  STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service @ 09/02/25 08:07:03.847
  STEP: creating service externalsvc in namespace services-795 @ 09/02/25 08:07:03.848
  I0902 08:07:03.897301 16 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:0, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:0, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition(nil), CollisionCount:(*int32)(nil)}
  I0902 08:07:05.909045 16 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:2, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.September, 2, 8, 7, 3, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 8, 7, 3, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.September, 2, 8, 7, 5, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 8, 7, 3, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"externalsvc-8664db8f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
  STEP: changing the NodePort service to type=ExternalName @ 09/02/25 08:07:07.936
  I0902 08:07:07.989223 16 resource.go:344] Creating new exec pod
  I0902 08:07:10.040341 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=services-795 exec execpodzc7jt -- /bin/sh -x -c nslookup nodeport-service.services-795.svc.cluster.local'
  I0902 08:07:10.459514 16 builder.go:156] stderr: "+ nslookup nodeport-service.services-795.svc.cluster.local\n"
  I0902 08:07:10.459635 16 builder.go:157] stdout: ";; Got recursion not available from 10.233.0.10\n;; Got recursion not available from 10.233.0.10\n;; Got recursion not available from 10.233.0.10\n;; Got recursion not available from 10.233.0.10\nServer:\t\t10.233.0.10\nAddress:\t10.233.0.10#53\n\nnodeport-service.services-795.svc.cluster.local\tcanonical name = externalsvc.services-795.svc.cluster.local.\nName:\texternalsvc.services-795.svc.cluster.local\nAddress: 10.233.60.129\n;; Got recursion not available from 10.233.0.10\n\n"
  I0902 08:07:10.521475 16 service.go:1558] Cleaning up the NodePort to ExternalName test service
  I0902 08:07:10.562321 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-795" for this suite. @ 09/02/25 08:07:10.615
• [6.926 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:163
  STEP: Creating a kubernetes client @ 09/02/25 08:07:10.635
  I0902 08:07:10.635940 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename projected @ 09/02/25 08:07:10.64
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:07:10.673
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:07:10.68
  STEP: Creating the pod @ 09/02/25 08:07:10.686
  I0902 08:07:13.350478 16 pod_client.go:186] Successfully updated pod "annotationupdate13b9c519-9071-4f2c-95ca-fb20e7f4d270"
  I0902 08:07:15.386908 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9033" for this suite. @ 09/02/25 08:07:15.4
• [4.776 seconds]
------------------------------
SS
------------------------------
[sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:87
  STEP: Creating a kubernetes client @ 09/02/25 08:07:15.413
  I0902 08:07:15.413148 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename replication-controller @ 09/02/25 08:07:15.416
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:07:15.456
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:07:15.462
  I0902 08:07:15.467577 16 rc.go:546] Creating quota "condition-test" that allows only two pods to run in the current namespace
  STEP: Creating rc "condition-test" that asks for more than the allowed pod quota @ 09/02/25 08:07:16.49
  STEP: Checking rc "condition-test" has the desired failure condition set @ 09/02/25 08:07:16.503
  STEP: Scaling down rc "condition-test" to satisfy pod quota @ 09/02/25 08:07:17.522
  I0902 08:07:17.553194 16 rc.go:733] Updating replication controller "condition-test"
  STEP: Checking rc "condition-test" has no failure condition set @ 09/02/25 08:07:17.553
  I0902 08:07:17.569105 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-5668" for this suite. @ 09/02/25 08:07:17.581
• [2.183 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should find a service from listing all namespaces [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3222
  STEP: Creating a kubernetes client @ 09/02/25 08:07:17.597
  I0902 08:07:17.597413 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename services @ 09/02/25 08:07:17.599
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:07:17.631
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:07:17.64
  STEP: fetching services @ 09/02/25 08:07:17.648
  I0902 08:07:17.659285 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-9988" for this suite. @ 09/02/25 08:07:17.681
• [0.099 seconds]
------------------------------
SS
------------------------------
[sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1430
  STEP: Creating a kubernetes client @ 09/02/25 08:07:17.696
  I0902 08:07:17.696888 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename services @ 09/02/25 08:07:17.7
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:07:17.724
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:07:17.731
  STEP: creating a service externalname-service with the type=ExternalName in namespace services-8169 @ 09/02/25 08:07:17.737
  STEP: changing the ExternalName service to type=ClusterIP @ 09/02/25 08:07:17.75
  I0902 08:07:17.810695 16 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:0, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:0, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition(nil), CollisionCount:(*int32)(nil)}
  I0902 08:07:19.820677 16 resource.go:344] Creating new exec pod
  I0902 08:07:21.879376 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=services-8169 exec execpodz2gk2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  I0902 08:07:22.237816 16 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service (10.233.36.153) 80 port [tcp/http] succeeded!\n"
  I0902 08:07:22.237980 16 builder.go:157] stdout: ""
  I0902 08:07:22.880388 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=services-8169 exec execpodz2gk2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  I0902 08:07:23.438758 16 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service (10.233.36.153) 80 port [tcp/http] succeeded!\n"
  I0902 08:07:23.438839 16 builder.go:157] stdout: "externalname-service-7dbbc8949-hgzx7"
  I0902 08:07:23.439367 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=services-8169 exec execpodz2gk2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.36.153 80'
  I0902 08:07:23.955883 16 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.36.153 80\nConnection to 10.233.36.153 80 port [tcp/http] succeeded!\n"
  I0902 08:07:23.956022 16 builder.go:157] stdout: "externalname-service-7dbbc8949-sgxpv"
  I0902 08:07:23.956200 16 service.go:1439] Cleaning up the ExternalName to ClusterIP test service
  I0902 08:07:24.021141 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-8169" for this suite. @ 09/02/25 08:07:24.037
• [6.358 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:135
  STEP: Creating a kubernetes client @ 09/02/25 08:07:24.058
  I0902 08:07:24.058213 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename container-probe @ 09/02/25 08:07:24.06
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:07:24.087
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:07:24.095
  STEP: Creating pod busybox-5a8ba860-24d2-407f-95d8-e6e21d824fcf in namespace container-probe-4266 @ 09/02/25 08:07:24.102
  STEP: checking the pod's current state and verifying that restartCount is present @ 09/02/25 08:07:26.14
  I0902 08:07:26.148050 16 container_probe.go:1749] Initial restart count of pod busybox-5a8ba860-24d2-407f-95d8-e6e21d824fcf is 0
  I0902 08:07:26.154487 16 container_probe.go:1759] Get pod busybox-5a8ba860-24d2-407f-95d8-e6e21d824fcf in namespace container-probe-4266
  I0902 08:07:28.167845 16 container_probe.go:1759] Get pod busybox-5a8ba860-24d2-407f-95d8-e6e21d824fcf in namespace container-probe-4266
  I0902 08:07:30.177083 16 container_probe.go:1759] Get pod busybox-5a8ba860-24d2-407f-95d8-e6e21d824fcf in namespace container-probe-4266
  I0902 08:07:32.186162 16 container_probe.go:1759] Get pod busybox-5a8ba860-24d2-407f-95d8-e6e21d824fcf in namespace container-probe-4266
  I0902 08:07:34.203493 16 container_probe.go:1759] Get pod busybox-5a8ba860-24d2-407f-95d8-e6e21d824fcf in namespace container-probe-4266
  I0902 08:07:36.216657 16 container_probe.go:1759] Get pod busybox-5a8ba860-24d2-407f-95d8-e6e21d824fcf in namespace container-probe-4266
  I0902 08:07:38.229755 16 container_probe.go:1759] Get pod busybox-5a8ba860-24d2-407f-95d8-e6e21d824fcf in namespace container-probe-4266
  I0902 08:07:40.243542 16 container_probe.go:1759] Get pod busybox-5a8ba860-24d2-407f-95d8-e6e21d824fcf in namespace container-probe-4266
  I0902 08:07:42.256865 16 container_probe.go:1759] Get pod busybox-5a8ba860-24d2-407f-95d8-e6e21d824fcf in namespace container-probe-4266
  I0902 08:07:44.271138 16 container_probe.go:1759] Get pod busybox-5a8ba860-24d2-407f-95d8-e6e21d824fcf in namespace container-probe-4266
  I0902 08:07:46.279944 16 container_probe.go:1759] Get pod busybox-5a8ba860-24d2-407f-95d8-e6e21d824fcf in namespace container-probe-4266
  I0902 08:07:48.290660 16 container_probe.go:1759] Get pod busybox-5a8ba860-24d2-407f-95d8-e6e21d824fcf in namespace container-probe-4266
  I0902 08:07:50.302293 16 container_probe.go:1759] Get pod busybox-5a8ba860-24d2-407f-95d8-e6e21d824fcf in namespace container-probe-4266
  I0902 08:07:52.310605 16 container_probe.go:1759] Get pod busybox-5a8ba860-24d2-407f-95d8-e6e21d824fcf in namespace container-probe-4266
  I0902 08:07:54.321151 16 container_probe.go:1759] Get pod busybox-5a8ba860-24d2-407f-95d8-e6e21d824fcf in namespace container-probe-4266
  I0902 08:07:56.334923 16 container_probe.go:1759] Get pod busybox-5a8ba860-24d2-407f-95d8-e6e21d824fcf in namespace container-probe-4266
  I0902 08:07:58.347684 16 container_probe.go:1759] Get pod busybox-5a8ba860-24d2-407f-95d8-e6e21d824fcf in namespace container-probe-4266
  I0902 08:08:00.363529 16 container_probe.go:1759] Get pod busybox-5a8ba860-24d2-407f-95d8-e6e21d824fcf in namespace container-probe-4266
  I0902 08:08:02.385656 16 container_probe.go:1759] Get pod busybox-5a8ba860-24d2-407f-95d8-e6e21d824fcf in namespace container-probe-4266
  I0902 08:08:04.407118 16 container_probe.go:1759] Get pod busybox-5a8ba860-24d2-407f-95d8-e6e21d824fcf in namespace container-probe-4266
  I0902 08:08:06.415178 16 container_probe.go:1759] Get pod busybox-5a8ba860-24d2-407f-95d8-e6e21d824fcf in namespace container-probe-4266
  I0902 08:08:08.431823 16 container_probe.go:1759] Get pod busybox-5a8ba860-24d2-407f-95d8-e6e21d824fcf in namespace container-probe-4266
  I0902 08:08:10.448303 16 container_probe.go:1759] Get pod busybox-5a8ba860-24d2-407f-95d8-e6e21d824fcf in namespace container-probe-4266
  I0902 08:08:12.455467 16 container_probe.go:1759] Get pod busybox-5a8ba860-24d2-407f-95d8-e6e21d824fcf in namespace container-probe-4266
  I0902 08:08:14.469200 16 container_probe.go:1759] Get pod busybox-5a8ba860-24d2-407f-95d8-e6e21d824fcf in namespace container-probe-4266
  I0902 08:08:16.478827 16 container_probe.go:1759] Get pod busybox-5a8ba860-24d2-407f-95d8-e6e21d824fcf in namespace container-probe-4266
  I0902 08:08:16.478983 16 container_probe.go:1763] Restart count of pod container-probe-4266/busybox-5a8ba860-24d2-407f-95d8-e6e21d824fcf is now 1 (50.33083288s elapsed)
  STEP: deleting the pod @ 09/02/25 08:08:16.479
  I0902 08:08:16.523321 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-4266" for this suite. @ 09/02/25 08:08:16.538
• [52.500 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment Deployment should have a working scale subresource [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:150
  STEP: Creating a kubernetes client @ 09/02/25 08:08:16.561
  I0902 08:08:16.561253 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename deployment @ 09/02/25 08:08:16.57
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:08:16.595
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:08:16.602
  I0902 08:08:16.608199 16 deployment.go:1664] Creating simple deployment test-new-deployment
  I0902 08:08:16.639376 16 deployment.go:223] deployment "test-new-deployment" doesn't have the required revision set
  I0902 08:08:18.674938 16 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.September, 2, 8, 8, 16, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 8, 8, 16, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.September, 2, 8, 8, 16, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 8, 8, 16, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-new-deployment-6bc58496c7\" is progressing."}}, CollisionCount:(*int32)(nil)}
  STEP: getting scale subresource @ 09/02/25 08:08:20.712
  STEP: updating a scale subresource @ 09/02/25 08:08:20.735
  STEP: verifying the deployment Spec.Replicas was modified @ 09/02/25 08:08:20.766
  STEP: Patch a scale subresource @ 09/02/25 08:08:20.785
  I0902 08:08:20.850392 16 deployment.go:632] Deployment "test-new-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=19) "test-new-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2312",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "69af60da-26f9-497b-b96a-c8ff2596bab1",
      ResourceVersion: (string) (len=5) "25195",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63892397296,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)(<nil>),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=28) {
              00000000  7b 22 66 3a 73 70 65 63  22 3a 7b 22 66 3a 72 65  |{"f:spec":{"f:re|
              00000010  70 6c 69 63 61 73 22 3a  7b 7d 7d 7d              |plicas":{}}}|
            }
          }),
          Subresource: (string) (len=5) "scale"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892397296,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=619) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |onds":{},"f:revi|
              00000060  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000070  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              00000090  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000a0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000b0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000c0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000d0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000e0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              000000f0  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000100  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000110  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000120  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000130  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000140  6d 65 5c 22 3a 5c 22 68  74 74 70 64 5c 22 7d 22  |me\":\"httpd\"}"|
              00000150  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000160  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000170  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000180  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              00000190  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              000001a0  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              000001b0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001c0  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000001d0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000001e0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              000001f0  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              00000200  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              00000210  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              00000220  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000230  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000240  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000250  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000260  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892397299,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(4),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          HostnameOverride: (*string)(<nil>)
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      TerminatingReplicas: (*int32)(<nil>),
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892397299,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892397299,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892397299,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892397296,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=72) "ReplicaSet \"test-new-deployment-6bc58496c7\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0902 08:08:20.877739 16 deployment.go:40] New ReplicaSet "test-new-deployment-6bc58496c7" of Deployment "test-new-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-new-deployment-6bc58496c7",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2312",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "2e195234-2439-4c33-bf17-d101c071affb",
      ResourceVersion: (string) (len=5) "25200",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63892397296,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "6bc58496c7"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "2",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "3",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=19) "test-new-deployment",
          UID: (types.UID) (len=36) "69af60da-26f9-497b-b96a-c8ff2596bab1",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892397300,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 36 39 61 66 36 30  64 61 2d 32 36 66 39 2d  |\"69af60da-26f9-|
              00000120  34 39 37 62 2d 62 39 36  61 2d 63 38 66 66 32 35  |497b-b96a-c8ff25|
              00000130  39 36 62 61 62 31 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |96bab1\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892397300,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(2),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=10) "6bc58496c7"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=10) "6bc58496c7"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          HostnameOverride: (*string)(<nil>)
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 2,
      FullyLabeledReplicas: (int32) 2,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      TerminatingReplicas: (*int32)(<nil>),
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0902 08:08:20.897252 16 deployment.go:68] Pod "test-new-deployment-6bc58496c7-6qsjn" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "test-new-deployment-6bc58496c7-6qsjn",
      GenerateName: (string) (len=31) "test-new-deployment-6bc58496c7-",
      Namespace: (string) (len=15) "deployment-2312",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "414714c1-e4ad-46d3-af51-515ed794a63f",
      ResourceVersion: (string) (len=5) "25188",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63892397296,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "6bc58496c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "test-new-deployment-6bc58496c7",
          UID: (types.UID) (len=36) "2e195234-2439-4c33-bf17-d101c071affb",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892397296,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 32 65  31 39 35 32 33 34 2d 32  |d\":\"2e195234-2|
              00000090  34 33 39 2d 34 63 33 33  2d 62 66 31 37 2d 64 31  |439-4c33-bf17-d1|
              000000a0  30 31 63 30 37 31 61 66  66 62 5c 22 7d 22 3a 7b  |01c071affb\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892397299,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=852) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6f 62 73 65 72 76  |me":{},"f:observ|
              00000080  65 64 47 65 6e 65 72 61  74 69 6f 6e 22 3a 7b 7d  |edGeneration":{}|
              00000090  2c 22 66 3a 73 74 61 74  75 73 22 3a 7b 7d 2c 22  |,"f:status":{},"|
              000000a0  66 3a 74 79 70 65 22 3a  7b 7d 7d 2c 22 6b 3a 7b  |f:type":{}},"k:{|
              000000b0  5c 22 74 79 70 65 5c 22  3a 5c 22 49 6e 69 74 69  |\"type\":\"Initi|
              000000c0  61 6c 69 7a 65 64 5c 22  7d 22 3a 7b 22 2e 22 3a  |alized\"}":{".":|
              000000d0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000000f0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              00000100  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000110  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |eration":{},"f:s|
              00000120  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000130  65 22 3a 7b 7d 7d 2c 22  6b 3a 7b 5c 22 74 79 70  |e":{}},"k:{\"typ|
              00000140  65 5c 22 3a 5c 22 50 6f  64 52 65 61 64 79 54 6f  |e\":\"PodReadyTo|
              00000150  53 74 61 72 74 43 6f 6e  74 61 69 6e 65 72 73 5c  |StartContainers\|
              00000160  22 7d 22 3a 7b 22 2e 22  3a 7b 7d 2c 22 66 3a 6c  |"}":{".":{},"f:l|
              00000170  61 73 74 50 72 6f 62 65  54 69 6d 65 22 3a 7b 7d  |astProbeTime":{}|
              00000180  2c 22 66 3a 6c 61 73 74  54 72 61 6e 73 69 74 69  |,"f:lastTransiti|
              00000190  6f 6e 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6f 62  |onTime":{},"f:ob|
              000001a0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001b0  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              000001c0  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              000001d0  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              000001e0  6f 64 53 63 68 65 64 75  6c 65 64 5c 22 7d 22 3a  |odScheduled\"}":|
              000001f0  7b 22 66 3a 6f 62 73 65  72 76 65 64 47 65 6e 65  |{"f:observedGene|
              00000200  72 61 74 69 6f 6e 22 3a  7b 7d 7d 2c 22 6b 3a 7b  |ration":{}},"k:{|
              00000210  5c 22 74 79 70 65 5c 22  3a 5c 22 52 65 61 64 79  |\"type\":\"Ready|
              00000220  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000230  6c 61 73 74 50 72 6f 62  65 54 69 6d 65 22 3a 7b  |lastProbeTime":{|
              00000240  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000250  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6f  |ionTime":{},"f:o|
              00000260  62 73 65 72 76 65 64 47  65 6e 65 72 61 74 69 6f  |bservedGeneratio|
              00000270  6e 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |n":{},"f:status"|
              00000280  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000290  7d 2c 22 66 3a 63 6f 6e  74 61 69 6e 65 72 53 74  |},"f:containerSt|
              000002a0  61 74 75 73 65 73 22 3a  7b 7d 2c 22 66 3a 68 6f  |atuses":{},"f:ho|
              000002b0  73 74 49 50 22 3a 7b 7d  2c 22 66 3a 68 6f 73 74  |stIP":{},"f:host|
              000002c0  49 50 73 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |IPs":{},"f:obser|
              000002d0  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000002e0  7d 2c 22 66 3a 70 68 61  73 65 22 3a 7b 7d 2c 22  |},"f:phase":{},"|
              000002f0  66 3a 70 6f 64 49 50 22  3a 7b 7d 2c 22 66 3a 70  |f:podIP":{},"f:p|
              00000300  6f 64 49 50 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |odIPs":{".":{},"|
              00000310  6b 3a 7b 5c 22 69 70 5c  22 3a 5c 22 31 30 2e 32  |k:{\"ip\":\"10.2|
              00000320  33 33 2e 36 36 2e 31 36  31 5c 22 7d 22 3a 7b 22  |33.66.161\"}":{"|
              00000330  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              00000340  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              00000350  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-bgfzv",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-bgfzv",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "ietha7evai9i-2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 1,
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892397299,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892397296,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892397299,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892397299,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892397296,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.46",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.121.46"
        }
      },
      PodIP: (string) (len=13) "10.233.66.161",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "10.233.66.161"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63892397296,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63892397298,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=72) "cri-o://7d1e715405b691e522ad39af231a03b0419b17cff8c030340225ad01e3f7121f",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)({
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          }),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-bgfzv",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)({
            Linux: (*v1.LinuxContainerUser)({
              UID: (int64) 0,
              GID: (int64) 0,
              SupplementalGroups: ([]int64) (len=11) {
                (int64) 0,
                (int64) 1,
                (int64) 2,
                (int64) 3,
                (int64) 4,
                (int64) 6,
                (int64) 10,
                (int64) 11,
                (int64) 20,
                (int64) 26,
                (int64) 27
              }
            })
          }),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>)
    }
  }

  I0902 08:08:20.905473 16 deployment.go:68] Pod "test-new-deployment-6bc58496c7-svskv" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "test-new-deployment-6bc58496c7-svskv",
      GenerateName: (string) (len=31) "test-new-deployment-6bc58496c7-",
      Namespace: (string) (len=15) "deployment-2312",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "3bb6d319-51a7-4df8-b45c-e75022fb08a9",
      ResourceVersion: (string) (len=5) "25202",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63892397300,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "6bc58496c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "test-new-deployment-6bc58496c7",
          UID: (types.UID) (len=36) "2e195234-2439-4c33-bf17-d101c071affb",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892397300,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 32 65  31 39 35 32 33 34 2d 32  |d\":\"2e195234-2|
              00000090  34 33 39 2d 34 63 33 33  2d 62 66 31 37 2d 64 31  |439-4c33-bf17-d1|
              000000a0  30 31 63 30 37 31 61 66  66 62 5c 22 7d 22 3a 7b  |01c071affb\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892397300,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=814) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 6f 62 73 65 72 76 65  |e":{},"f:observe|
              00000090  64 47 65 6e 65 72 61 74  69 6f 6e 22 3a 7b 7d 2c  |dGeneration":{},|
              000000a0  22 66 3a 72 65 61 73 6f  6e 22 3a 7b 7d 2c 22 66  |"f:reason":{},"f|
              000000b0  3a 73 74 61 74 75 73 22  3a 7b 7d 2c 22 66 3a 74  |:status":{},"f:t|
              000000c0  79 70 65 22 3a 7b 7d 7d  2c 22 6b 3a 7b 5c 22 74  |ype":{}},"k:{\"t|
              000000d0  79 70 65 5c 22 3a 5c 22  49 6e 69 74 69 61 6c 69  |ype\":\"Initiali|
              000000e0  7a 65 64 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |zed\"}":{".":{},|
              000000f0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              00000110  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              00000120  66 3a 6f 62 73 65 72 76  65 64 47 65 6e 65 72 61  |f:observedGenera|
              00000130  74 69 6f 6e 22 3a 7b 7d  2c 22 66 3a 73 74 61 74  |tion":{},"f:stat|
              00000140  75 73 22 3a 7b 7d 2c 22  66 3a 74 79 70 65 22 3a  |us":{},"f:type":|
              00000150  7b 7d 7d 2c 22 6b 3a 7b  5c 22 74 79 70 65 5c 22  |{}},"k:{\"type\"|
              00000160  3a 5c 22 50 6f 64 52 65  61 64 79 54 6f 53 74 61  |:\"PodReadyToSta|
              00000170  72 74 43 6f 6e 74 61 69  6e 65 72 73 5c 22 7d 22  |rtContainers\"}"|
              00000180  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              00000190  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000001a0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |ime":{},"f:obser|
              000001c0  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 2c 22 6b 3a  |"f:type":{}},"k:|
              000001f0  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 50 6f 64 53  |{\"type\":\"PodS|
              00000200  63 68 65 64 75 6c 65 64  5c 22 7d 22 3a 7b 22 66  |cheduled\"}":{"f|
              00000210  3a 6f 62 73 65 72 76 65  64 47 65 6e 65 72 61 74  |:observedGenerat|
              00000220  69 6f 6e 22 3a 7b 7d 7d  2c 22 6b 3a 7b 5c 22 74  |ion":{}},"k:{\"t|
              00000230  79 70 65 5c 22 3a 5c 22  52 65 61 64 79 5c 22 7d  |ype\":\"Ready\"}|
              00000240  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |":{".":{},"f:las|
              00000250  74 50 72 6f 62 65 54 69  6d 65 22 3a 7b 7d 2c 22  |tProbeTime":{},"|
              00000260  66 3a 6c 61 73 74 54 72  61 6e 73 69 74 69 6f 6e  |f:lastTransition|
              00000270  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6d 65 73 73  |Time":{},"f:mess|
              00000280  61 67 65 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |age":{},"f:obser|
              00000290  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000002a0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              000002b0  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              000002c0  3a 74 79 70 65 22 3a 7b  7d 7d 7d 2c 22 66 3a 63  |:type":{}}},"f:c|
              000002d0  6f 6e 74 61 69 6e 65 72  53 74 61 74 75 73 65 73  |ontainerStatuses|
              000002e0  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 22 3a  |":{},"f:hostIP":|
              000002f0  7b 7d 2c 22 66 3a 68 6f  73 74 49 50 73 22 3a 7b  |{},"f:hostIPs":{|
              00000300  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000310  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |eration":{},"f:s|
              00000320  74 61 72 74 54 69 6d 65  22 3a 7b 7d 7d 7d        |tartTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-xm4vf",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-xm4vf",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "ietha7evai9i-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 1,
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892397300,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892397300,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892397300,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892397300,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892397300,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.52",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.121.52"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63892397300,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-xm4vf",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>)
    }
  }

  I0902 08:08:20.909200 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-2312" for this suite. @ 09/02/25 08:08:20.924
• [4.378 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:47
  STEP: Creating a kubernetes client @ 09/02/25 08:08:20.94
  I0902 08:08:20.940825 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename configmap @ 09/02/25 08:08:20.949
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:08:20.979
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:08:20.986
  STEP: Creating configMap with name configmap-test-volume-5b3570c1-6a7f-4557-a132-624857603779 @ 09/02/25 08:08:20.992
  STEP: Creating a pod to test consume configMaps @ 09/02/25 08:08:21.013
  STEP: Saw pod success @ 09/02/25 08:08:25.078
  I0902 08:08:25.093649 16 output.go:207] Trying to get logs from node ietha7evai9i-1 pod pod-configmaps-d019e944-8d52-4d51-b24b-625480e0639b container agnhost-container: <nil>
  STEP: delete the pod @ 09/02/25 08:08:25.159
  I0902 08:08:25.211821 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-9009" for this suite. @ 09/02/25 08:08:25.223
• [4.323 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:199
  STEP: Creating a kubernetes client @ 09/02/25 08:08:25.267
  I0902 08:08:25.267382 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename container-probe @ 09/02/25 08:08:25.27
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:08:25.326
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:08:25.333
  STEP: Creating pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307 @ 09/02/25 08:08:25.339
  STEP: checking the pod's current state and verifying that restartCount is present @ 09/02/25 08:08:27.392
  I0902 08:08:27.407266 16 container_probe.go:1749] Initial restart count of pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 is 0
  I0902 08:08:27.417671 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:08:29.435175 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:08:31.445808 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:08:33.455305 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:08:35.466585 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:08:37.476431 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:08:39.490992 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:08:41.506845 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:08:43.522102 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:08:45.532053 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:08:47.542048 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:08:47.542261 16 container_probe.go:1763] Restart count of pod container-probe-8307/liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 is now 1 (20.134721697s elapsed)
  I0902 08:08:49.556906 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:08:51.566967 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:08:53.576321 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:08:55.585975 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:08:57.601797 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:08:59.612475 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:09:01.623082 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:09:03.631411 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:09:05.639715 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:09:07.652524 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:09:07.652713 16 container_probe.go:1763] Restart count of pod container-probe-8307/liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 is now 2 (40.245264693s elapsed)
  I0902 08:09:09.662327 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:09:11.669580 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:09:13.690318 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:09:15.701254 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:09:17.712112 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:09:19.720144 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:09:21.729613 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:09:23.738541 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:09:25.750903 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:09:27.759461 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:09:27.759727 16 container_probe.go:1763] Restart count of pod container-probe-8307/liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 is now 3 (1m0.352268403s elapsed)
  I0902 08:09:29.767840 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:09:31.775838 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:09:33.783386 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:09:35.792821 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:09:37.801714 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:09:39.820463 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:09:41.829230 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:09:43.838702 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:09:45.850705 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:09:47.862806 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:09:47.862896 16 container_probe.go:1763] Restart count of pod container-probe-8307/liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 is now 4 (1m20.45545069s elapsed)
  I0902 08:09:49.869728 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:09:51.880424 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:09:53.889921 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:09:55.900607 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:09:57.908165 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:09:59.917941 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:10:01.926981 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:10:03.935745 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:10:05.945619 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:10:07.954799 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:10:09.963860 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:10:11.973763 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:10:13.984251 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:10:15.998990 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:10:18.015813 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:10:20.024129 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:10:22.032798 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:10:24.047289 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:10:26.066463 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:10:28.078607 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:10:30.089429 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:10:32.098362 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:10:34.118773 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:10:36.133722 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:10:38.150454 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:10:40.175093 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:10:42.185466 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:10:44.194637 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:10:46.213046 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:10:48.222452 16 container_probe.go:1759] Get pod liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 in namespace container-probe-8307
  I0902 08:10:48.222596 16 container_probe.go:1763] Restart count of pod container-probe-8307/liveness-5ec21a90-512c-49e5-995c-055fb5c6f016 is now 5 (2m20.815093638s elapsed)
  STEP: deleting the pod @ 09/02/25 08:10:48.222
  I0902 08:10:48.258888 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-8307" for this suite. @ 09/02/25 08:10:48.274
• [143.029 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:192
  STEP: Creating a kubernetes client @ 09/02/25 08:10:48.295
  I0902 08:10:48.295786 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename container-runtime @ 09/02/25 08:10:48.303
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:10:48.34
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:10:48.356
  STEP: create the container @ 09/02/25 08:10:48.368
  I0902 08:10:48.394180      16 warnings.go:110] "Warning: metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]"
  STEP: wait for the container to reach Succeeded @ 09/02/25 08:10:48.396
  STEP: get the container status @ 09/02/25 08:10:51.436
  STEP: the container should be terminated @ 09/02/25 08:10:51.445
  STEP: the termination message should be set @ 09/02/25 08:10:51.445
  I0902 08:10:51.445287 16 runtime.go:164] Expected: &{DONE} to match Container's Termination Message: DONE --
  STEP: delete the container @ 09/02/25 08:10:51.445
  I0902 08:10:51.488085 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-1506" for this suite. @ 09/02/25 08:10:51.501
• [3.224 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect duplicates in a CR when preserving unknown fields [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:620
  STEP: Creating a kubernetes client @ 09/02/25 08:10:51.52
  I0902 08:10:51.520491 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename field-validation @ 09/02/25 08:10:51.524
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:10:51.556
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:10:51.569
  I0902 08:10:51.575268 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  I0902 08:10:51.599339      16 warnings.go:110] "Warning: unrecognized format \"int32\""
  I0902 08:10:54.317528      16 warnings.go:110] "Warning: unknown field \"alpha\""
  I0902 08:10:54.318324      16 warnings.go:110] "Warning: unknown field \"beta\""
  I0902 08:10:54.318359      16 warnings.go:110] "Warning: unknown field \"delta\""
  I0902 08:10:54.318387      16 warnings.go:110] "Warning: unknown field \"epsilon\""
  I0902 08:10:54.318423      16 warnings.go:110] "Warning: unknown field \"gamma\""
  I0902 08:10:54.931436 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-7683" for this suite. @ 09/02/25 08:10:54.943
• [3.438 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:245
  STEP: Creating a kubernetes client @ 09/02/25 08:10:54.96
  I0902 08:10:54.960063 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename container-runtime @ 09/02/25 08:10:54.962
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:10:54.989
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:10:54.994
  STEP: create the container @ 09/02/25 08:10:55.001
  I0902 08:10:55.022732      16 warnings.go:110] "Warning: metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]"
  STEP: wait for the container to reach Succeeded @ 09/02/25 08:10:55.022
  STEP: get the container status @ 09/02/25 08:10:58.068
  STEP: the container should be terminated @ 09/02/25 08:10:58.075
  STEP: the termination message should be set @ 09/02/25 08:10:58.075
  I0902 08:10:58.076010 16 runtime.go:164] Expected: &{OK} to match Container's Termination Message: OK --
  STEP: delete the container @ 09/02/25 08:10:58.076
  I0902 08:10:58.110720 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-7626" for this suite. @ 09/02/25 08:10:58.12
• [3.174 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets should patch a secret [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:155
  STEP: Creating a kubernetes client @ 09/02/25 08:10:58.137
  I0902 08:10:58.137491 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename secrets @ 09/02/25 08:10:58.141
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:10:58.168
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:10:58.178
  STEP: creating a secret @ 09/02/25 08:10:58.183
  STEP: listing secrets in all namespaces to ensure that there are more than zero @ 09/02/25 08:10:58.193
  STEP: patching the secret @ 09/02/25 08:10:58.199
  STEP: deleting the secret using a LabelSelector @ 09/02/25 08:10:58.219
  STEP: listing secrets in all namespaces, searching for label name and value in patch @ 09/02/25 08:10:58.236
  I0902 08:10:58.243757 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-989" for this suite. @ 09/02/25 08:10:58.252
• [0.128 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:206
  STEP: Creating a kubernetes client @ 09/02/25 08:10:58.264
  I0902 08:10:58.264977 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename webhook @ 09/02/25 08:10:58.267
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:10:58.3
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:10:58.307
  STEP: Setting up server cert @ 09/02/25 08:10:58.356
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 09/02/25 08:10:59.238
  STEP: Deploying the webhook pod @ 09/02/25 08:10:59.251
  STEP: Wait for the deployment to be ready @ 09/02/25 08:10:59.278
  I0902 08:10:59.295364 16 deployment.go:223] new replicaset for deployment "sample-webhook-deployment" is yet to be created
  STEP: Deploying the webhook service @ 09/02/25 08:11:01.327
  STEP: Verifying the service has paired with the endpoint @ 09/02/25 08:11:01.362
  I0902 08:11:02.362480 16 util.go:419] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the webhook via the AdmissionRegistration API @ 09/02/25 08:11:02.379
  I0902 08:11:02.441441 16 webhook.go:2701] Waiting for webhook configuration to be ready...
  STEP: create a pod @ 09/02/25 08:11:02.571
  STEP: 'kubectl attach' the pod, should be denied by the webhook @ 09/02/25 08:11:04.627
  I0902 08:11:04.627700 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=webhook-1423 attach --namespace=webhook-1423 to-be-attached-pod -i -c=container1'
  I0902 08:11:04.909123 16 builder.go:145] rc: 1
  I0902 08:11:05.028433 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-1423" for this suite. @ 09/02/25 08:11:05.068
  STEP: Destroying namespace "webhook-markers-1057" for this suite. @ 09/02/25 08:11:05.089
• [6.840 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:399
  STEP: Creating a kubernetes client @ 09/02/25 08:11:05.109
  I0902 08:11:05.109684 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename webhook @ 09/02/25 08:11:05.113
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:11:05.136
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:11:05.143
  STEP: Setting up server cert @ 09/02/25 08:11:05.199
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 09/02/25 08:11:06.133
  STEP: Deploying the webhook pod @ 09/02/25 08:11:06.143
  STEP: Wait for the deployment to be ready @ 09/02/25 08:11:06.171
  I0902 08:11:06.191361 16 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 09/02/25 08:11:08.217
  STEP: Verifying the service has paired with the endpoint @ 09/02/25 08:11:08.239
  I0902 08:11:09.244342 16 util.go:419] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Creating a validating webhook configuration @ 09/02/25 08:11:09.253
  I0902 08:11:09.326589 16 webhook.go:2701] Waiting for webhook configuration to be ready...
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 09/02/25 08:11:09.447
  STEP: Updating a validating webhook configuration's rules to not include the create operation @ 09/02/25 08:11:09.471
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 09/02/25 08:11:09.494
  STEP: Patching a validating webhook configuration's rules to include the create operation @ 09/02/25 08:11:09.518
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 09/02/25 08:11:09.535
  I0902 08:11:09.652867 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-6760" for this suite. @ 09/02/25 08:11:09.663
  STEP: Destroying namespace "webhook-markers-3222" for this suite. @ 09/02/25 08:11:09.678
• [4.605 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should create pods for an Indexed job with completion indexes and specified hostname [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:406
  STEP: Creating a kubernetes client @ 09/02/25 08:11:09.717
  I0902 08:11:09.717747 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename job @ 09/02/25 08:11:09.72
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:11:09.754
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:11:09.762
  STEP: Creating Indexed job @ 09/02/25 08:11:09.769
  STEP: Ensuring job reaches completions @ 09/02/25 08:11:09.796
  STEP: Ensuring pods with index for job exist @ 09/02/25 08:11:19.855
  I0902 08:11:19.865260 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-6578" for this suite. @ 09/02/25 08:11:19.874
• [10.172 seconds]
------------------------------
S
------------------------------
[sig-scheduling] LimitRange should list, patch and delete a LimitRange by collection [Conformance] [sig-scheduling, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/limit_range.go:253
  STEP: Creating a kubernetes client @ 09/02/25 08:11:19.889
  I0902 08:11:19.889390 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename limitrange @ 09/02/25 08:11:19.892
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:11:19.927
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:11:19.936
  STEP: Creating LimitRange "e2e-limitrange-6ww4c" in namespace "limitrange-1546" @ 09/02/25 08:11:19.941
  STEP: Creating another limitRange in another namespace @ 09/02/25 08:11:19.968
  I0902 08:11:20.006322 16 limit_range.go:299] Namespace "e2e-limitrange-6ww4c-4208" created
  I0902 08:11:20.006381 16 limit_range.go:300] Creating LimitRange "e2e-limitrange-6ww4c" in namespace "e2e-limitrange-6ww4c-4208"
  STEP: Listing all LimitRanges with label "e2e-test=e2e-limitrange-6ww4c" @ 09/02/25 08:11:20.02
  I0902 08:11:20.027127 16 limit_range.go:309] Found 2 limitRanges
  STEP: Patching LimitRange "e2e-limitrange-6ww4c" in "limitrange-1546" namespace @ 09/02/25 08:11:20.028
  I0902 08:11:20.044352 16 limit_range.go:335] LimitRange "e2e-limitrange-6ww4c" has been patched
  STEP: Delete LimitRange "e2e-limitrange-6ww4c" by Collection with labelSelector: "e2e-limitrange-6ww4c=patched" @ 09/02/25 08:11:20.044
  STEP: Confirm that the limitRange "e2e-limitrange-6ww4c" has been deleted @ 09/02/25 08:11:20.062
  I0902 08:11:20.063298 16 limit_range.go:443] Requesting list of LimitRange to confirm quantity
  I0902 08:11:20.071023 16 limit_range.go:453] Found 0 LimitRange with label "e2e-limitrange-6ww4c=patched"
  I0902 08:11:20.071095 16 limit_range.go:344] LimitRange "e2e-limitrange-6ww4c" has been deleted.
  STEP: Confirm that a single LimitRange still exists with label "e2e-test=e2e-limitrange-6ww4c" @ 09/02/25 08:11:20.071
  I0902 08:11:20.077464 16 limit_range.go:350] Found 1 limitRange
  I0902 08:11:20.077956 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "limitrange-1546" for this suite. @ 09/02/25 08:11:20.087
  STEP: Destroying namespace "e2e-limitrange-6ww4c-4208" for this suite. @ 09/02/25 08:11:20.102
• [0.225 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should allow expressions to refer variables. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/validatingadmissionpolicy.go:221
  STEP: Creating a kubernetes client @ 09/02/25 08:11:20.116
  I0902 08:11:20.116412 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename validating-admission-policy @ 09/02/25 08:11:20.12
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:11:20.146
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:11:20.153
  STEP: creating a policy with variables @ 09/02/25 08:11:20.174
  STEP: waiting until the marker is denied @ 09/02/25 08:11:20.256
  STEP: testing a replicated Deployment to be allowed @ 09/02/25 08:11:20.547
  STEP: testing a non-replicated ReplicaSet not to be denied @ 09/02/25 08:11:20.584
  I0902 08:11:20.652344 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "validating-admission-policy-1152" for this suite. @ 09/02/25 08:11:20.663
• [0.568 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:86
  STEP: Creating a kubernetes client @ 09/02/25 08:11:20.688
  I0902 08:11:20.688204 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename custom-resource-definition @ 09/02/25 08:11:20.692
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:11:20.808
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:11:20.824
  I0902 08:11:20.830733 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  I0902 08:11:27.237784 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-9545" for this suite. @ 09/02/25 08:11:27.247
• [6.575 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:139
  STEP: Creating a kubernetes client @ 09/02/25 08:11:27.263
  I0902 08:11:27.263794 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename crd-webhook @ 09/02/25 08:11:27.268
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:11:27.361
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:11:27.369
  STEP: Setting up server cert @ 09/02/25 08:11:27.376
  STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication @ 09/02/25 08:11:27.846
  STEP: Deploying the custom resource conversion webhook pod @ 09/02/25 08:11:27.857
  STEP: Wait for the deployment to be ready @ 09/02/25 08:11:27.884
  I0902 08:11:27.902641 16 deployment.go:223] deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
  I0902 08:11:29.930166 16 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.September, 2, 8, 11, 27, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 8, 11, 27, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.September, 2, 8, 11, 27, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 8, 11, 27, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-788cb954bd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  STEP: Deploying the webhook service @ 09/02/25 08:11:31.943
  STEP: Verifying the service has paired with the endpoint @ 09/02/25 08:11:31.977
  I0902 08:11:32.979307 16 util.go:419] Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
  I0902 08:11:32.989904 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Creating a v1 custom resource @ 09/02/25 08:11:35.79
  STEP: v2 custom resource should be converted @ 09/02/25 08:11:35.806
  I0902 08:11:36.460652 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-webhook-5083" for this suite. @ 09/02/25 08:11:36.474
• [9.252 seconds]
------------------------------
SS
------------------------------
[sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:166
  STEP: Creating a kubernetes client @ 09/02/25 08:11:36.516
  I0902 08:11:36.516376 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename replicaset @ 09/02/25 08:11:36.519
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:11:36.549
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:11:36.555
  STEP: Create a ReplicaSet @ 09/02/25 08:11:36.562
  STEP: Verify that the required pods have come up @ 09/02/25 08:11:36.575
  I0902 08:11:36.583404 16 resource.go:64] Pod name sample-pod: Found 0 pods out of 3
  I0902 08:11:41.601160 16 resource.go:64] Pod name sample-pod: Found 3 pods out of 3
  STEP: ensuring each pod is running @ 09/02/25 08:11:41.601
  I0902 08:11:41.611442 16 replica_set.go:588] Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 TerminatingReplicas:<nil> ObservedGeneration:1 Conditions:[]}
  STEP: Listing all ReplicaSets @ 09/02/25 08:11:41.611
  STEP: DeleteCollection of the ReplicaSets @ 09/02/25 08:11:41.622
  STEP: After DeleteCollection verify that ReplicaSets have been deleted @ 09/02/25 08:11:41.661
  I0902 08:11:41.732032 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-3018" for this suite. @ 09/02/25 08:11:41.768
• [5.273 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:338
  STEP: Creating a kubernetes client @ 09/02/25 08:11:41.792
  I0902 08:11:41.792283 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename statefulset @ 09/02/25 08:11:41.794
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:11:41.835
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:11:41.855
  STEP: Creating service test in namespace statefulset-2383 @ 09/02/25 08:11:41.867
  I0902 08:11:41.885341      16 warnings.go:110] "Warning: spec.SessionAffinity is ignored for headless services"
  STEP: Creating a new StatefulSet @ 09/02/25 08:11:41.886
  I0902 08:11:41.930767 16 wait.go:44] Found 0 stateful pods, waiting for 3
  I0902 08:11:51.926841 16 wait.go:54] Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  I0902 08:11:51.926993 16 wait.go:54] Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  I0902 08:11:51.927079 16 wait.go:54] Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-4 to registry.k8s.io/e2e-test-images/httpd:2.4.39-4 @ 09/02/25 08:11:51.98
  I0902 08:11:52.000984 16 statefulset.go:2504] Updating stateful set ss2
  STEP: Creating a new revision @ 09/02/25 08:11:52.001
  STEP: Not applying an update when the partition is greater than the number of replicas @ 09/02/25 08:12:02.02
  STEP: Performing a canary update @ 09/02/25 08:12:02.02
  I0902 08:12:02.050435 16 statefulset.go:2504] Updating stateful set ss2
  I0902 08:12:02.067828 16 wait.go:74] Waiting for Pod statefulset-2383/ss2-2 to have revision ss2-67f5b944c4 update revision ss2-59cb84cf99
  STEP: Restoring Pods to the correct revision when they are deleted @ 09/02/25 08:12:12.068
  I0902 08:12:12.197446 16 wait.go:44] Found 1 stateful pods, waiting for 3
  I0902 08:12:22.203235 16 wait.go:54] Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  I0902 08:12:22.203340 16 wait.go:54] Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  I0902 08:12:22.203506 16 wait.go:54] Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Performing a phased rolling update @ 09/02/25 08:12:22.218
  I0902 08:12:22.241809 16 statefulset.go:2504] Updating stateful set ss2
  I0902 08:12:22.265314 16 wait.go:74] Waiting for Pod statefulset-2383/ss2-1 to have revision ss2-67f5b944c4 update revision ss2-59cb84cf99
  I0902 08:12:32.283105 16 statefulset.go:2504] Updating stateful set ss2
  I0902 08:12:32.364365 16 wait.go:56] Waiting for StatefulSet statefulset-2383/ss2 to complete update
  I0902 08:12:32.364668 16 wait.go:63] Waiting for Pod statefulset-2383/ss2-0 to have revision ss2-67f5b944c4 update revision ss2-59cb84cf99
  I0902 08:12:42.305022 16 wait.go:56] Waiting for StatefulSet statefulset-2383/ss2 to complete update
  I0902 08:12:52.320507 16 wait.go:56] Waiting for StatefulSet statefulset-2383/ss2 to complete update
  I0902 08:13:02.314206 16 statefulset.go:136] Deleting all statefulset in ns statefulset-2383
  I0902 08:13:02.340719 16 rest.go:153] Scaling statefulset ss2 to 0
  I0902 08:13:12.386093 16 wait.go:159] Waiting for statefulset status.replicas updated to 0
  I0902 08:13:12.394391 16 rest.go:91] Deleting statefulset ss2
  I0902 08:13:12.427155 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-2383" for this suite. @ 09/02/25 08:13:12.439
• [90.668 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:754
  STEP: Creating a kubernetes client @ 09/02/25 08:13:12.462
  I0902 08:13:12.462974 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename sched-preemption @ 09/02/25 08:13:12.467
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:13:12.496
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:13:12.505
  I0902 08:13:12.545970 16 wait.go:51] Waiting up to 1m0s for all nodes to be ready
  I0902 08:14:12.556882 16 util.go:390] Waiting for terminating namespaces to be deleted...
  STEP: Creating a kubernetes client @ 09/02/25 08:14:12.564
  I0902 08:14:12.565123 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename sched-preemption-path @ 09/02/25 08:14:12.57
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:14:12.596
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:14:12.603
  STEP: Finding an available node @ 09/02/25 08:14:12.61
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 09/02/25 08:14:12.611
  STEP: Explicitly delete pod here to free the resource it takes. @ 09/02/25 08:14:14.665
  I0902 08:14:14.695339 16 preemption.go:717] found a healthy node: ietha7evai9i-2
  STEP: Adding a custom resource @ 09/02/25 08:14:14.705
  I0902 08:14:20.840112 16 preemption.go:836] pods created so far: [1 1 1]
  I0902 08:14:20.840437 16 preemption.go:837] length of pods created so far: 3
  I0902 08:14:22.860101 16 preemption.go:854] pods created so far: [2 2 1]
  STEP: Removing a custom resource @ 09/02/25 08:14:29.864
  STEP: Removing a custom resource @ 09/02/25 08:14:29.982
  STEP: Removing a custom resource @ 09/02/25 08:14:30.003
  STEP: Removing a custom resource @ 09/02/25 08:14:30.025
  I0902 08:14:30.066872 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-path-6811" for this suite. @ 09/02/25 08:14:30.08
  I0902 08:14:30.096435 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-2897" for this suite. @ 09/02/25 08:14:30.18
• [77.733 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:131
  STEP: Creating a kubernetes client @ 09/02/25 08:14:30.197
  I0902 08:14:30.197482 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename downward-api @ 09/02/25 08:14:30.199
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:14:30.225
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:14:30.233
  STEP: Creating the pod @ 09/02/25 08:14:30.241
  I0902 08:14:32.871428 16 pod_client.go:186] Successfully updated pod "labelsupdatefe3db979-f2a2-4795-9883-14df39ef99b2"
  I0902 08:14:34.908515 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-6928" for this suite. @ 09/02/25 08:14:34.918
• [4.736 seconds]
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:173
  STEP: Creating a kubernetes client @ 09/02/25 08:14:34.934
  I0902 08:14:34.934270 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 09/02/25 08:14:34.938
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:14:34.964
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:14:34.976
  STEP: create the container to handle the HTTPGet hook request. @ 09/02/25 08:14:35.018
  STEP: create the pod with lifecycle hook @ 09/02/25 08:14:37.074
  STEP: check poststart hook @ 09/02/25 08:14:39.123
  STEP: delete the pod with lifecycle hook @ 09/02/25 08:14:39.139
  I0902 08:14:41.173003 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-1387" for this suite. @ 09/02/25 08:14:41.183
• [6.264 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:177
  STEP: Creating a kubernetes client @ 09/02/25 08:14:41.198
  I0902 08:14:41.198539 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename replicaset @ 09/02/25 08:14:41.201
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:14:41.229
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:14:41.237
  STEP: Create a Replicaset @ 09/02/25 08:14:41.249
  STEP: Verify that the required pods have come up. @ 09/02/25 08:14:41.268
  I0902 08:14:41.285870 16 resource.go:64] Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 09/02/25 08:14:41.285
  STEP: Getting /status @ 09/02/25 08:14:43.346
  I0902 08:14:43.364000 16 replica_set.go:649] Replicaset test-rs has Conditions: []
  STEP: updating the Replicaset Status @ 09/02/25 08:14:43.364
  I0902 08:14:43.392954 16 replica_set.go:669] updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the ReplicaSet status to be updated @ 09/02/25 08:14:43.393
  I0902 08:14:43.398274 16 replica_set.go:695] Observed &ReplicaSet event: ADDED
  I0902 08:14:43.398513 16 replica_set.go:695] Observed &ReplicaSet event: MODIFIED
  I0902 08:14:43.398715 16 replica_set.go:695] Observed &ReplicaSet event: MODIFIED
  I0902 08:14:43.399411 16 replica_set.go:695] Observed &ReplicaSet event: MODIFIED
  I0902 08:14:43.399520 16 replica_set.go:688] Found replicaset test-rs in namespace replicaset-3062 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  I0902 08:14:43.399587 16 replica_set.go:699] Replicaset test-rs has an updated status
  STEP: patching the Replicaset Status @ 09/02/25 08:14:43.399
  I0902 08:14:43.399642 16 replica_set.go:703] Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  I0902 08:14:43.421356 16 replica_set.go:707] Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Replicaset status to be patched @ 09/02/25 08:14:43.421
  I0902 08:14:43.431132 16 replica_set.go:731] Observed &ReplicaSet event: ADDED
  I0902 08:14:43.431403 16 replica_set.go:731] Observed &ReplicaSet event: MODIFIED
  I0902 08:14:43.432368 16 replica_set.go:731] Observed &ReplicaSet event: MODIFIED
  I0902 08:14:43.433417 16 replica_set.go:731] Observed &ReplicaSet event: MODIFIED
  I0902 08:14:43.433623 16 replica_set.go:727] Observed replicaset test-rs in namespace replicaset-3062 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I0902 08:14:43.434070 16 replica_set.go:731] Observed &ReplicaSet event: MODIFIED
  I0902 08:14:43.434372 16 replica_set.go:724] Found replicaset test-rs in namespace replicaset-3062 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
  I0902 08:14:43.435241 16 replica_set.go:735] Replicaset test-rs has a patched status
  I0902 08:14:43.435505 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-3062" for this suite. @ 09/02/25 08:14:43.455
• [2.279 seconds]
------------------------------
SSS
------------------------------
[sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:645
  STEP: Creating a kubernetes client @ 09/02/25 08:14:43.479
  I0902 08:14:43.479312 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename security-context-test @ 09/02/25 08:14:43.485
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:14:43.514
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:14:43.521
  I0902 08:14:47.663776 16 security_context.go:652] Got logs for pod "busybox-privileged-false-e13926c5-21dd-478d-b262-ac41e1a84481": "ip: RTNETLINK answers: Operation not permitted\n"
  I0902 08:14:47.664025 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-7500" for this suite. @ 09/02/25 08:14:47.674
• [4.209 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:375
  STEP: Creating a kubernetes client @ 09/02/25 08:14:47.69
  I0902 08:14:47.690530 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename projected @ 09/02/25 08:14:47.693
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:14:47.716
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:14:47.722
  STEP: Creating configMap with name projected-configmap-test-volume-369991c7-68f5-4fb1-ab5b-240619a37998 @ 09/02/25 08:14:47.728
  STEP: Creating a pod to test consume configMaps @ 09/02/25 08:14:47.738
  STEP: Saw pod success @ 09/02/25 08:14:51.781
  I0902 08:14:51.788009 16 output.go:207] Trying to get logs from node ietha7evai9i-3 pod pod-projected-configmaps-4c9ce2d5-5972-4708-8bfd-e3a91693a178 container projected-configmap-volume-test: <nil>
  STEP: delete the pod @ 09/02/25 08:14:51.804
  I0902 08:14:51.840963 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1980" for this suite. @ 09/02/25 08:14:51.853
• [4.188 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:236
  STEP: Creating a kubernetes client @ 09/02/25 08:14:51.881
  I0902 08:14:51.881839 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename downward-api @ 09/02/25 08:14:51.886
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:14:51.921
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:14:51.926
  STEP: Creating a pod to test downward API volume plugin @ 09/02/25 08:14:51.932
  STEP: Saw pod success @ 09/02/25 08:14:56.04
  I0902 08:14:56.050736 16 output.go:207] Trying to get logs from node ietha7evai9i-3 pod downwardapi-volume-82a86146-6fad-43bb-86b8-90fcb2db74f5 container client-container: <nil>
  STEP: delete the pod @ 09/02/25 08:14:56.073
  I0902 08:14:56.121630 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-1258" for this suite. @ 09/02/25 08:14:56.14
• [4.278 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:109
  STEP: Creating a kubernetes client @ 09/02/25 08:14:56.16
  I0902 08:14:56.160475 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename emptydir @ 09/02/25 08:14:56.165
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:14:56.195
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:14:56.2
  STEP: Creating a pod to test emptydir 0666 on tmpfs @ 09/02/25 08:14:56.204
  STEP: Saw pod success @ 09/02/25 08:15:00.26
  I0902 08:15:00.271227 16 output.go:207] Trying to get logs from node ietha7evai9i-2 pod pod-fcd6e730-d229-4525-ac66-3f53e23fc7af container test-container: <nil>
  STEP: delete the pod @ 09/02/25 08:15:00.323
  I0902 08:15:00.356394 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-358" for this suite. @ 09/02/25 08:15:00.371
• [4.226 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:89
  STEP: Creating a kubernetes client @ 09/02/25 08:15:00.389
  I0902 08:15:00.389655 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename secrets @ 09/02/25 08:15:00.396
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:15:00.419
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:15:00.425
  STEP: Creating secret with name secret-test-map-2c7e353f-b12e-4f83-b382-0121cf2c4fb2 @ 09/02/25 08:15:00.433
  STEP: Creating a pod to test consume secrets @ 09/02/25 08:15:00.444
  STEP: Saw pod success @ 09/02/25 08:15:04.5
  I0902 08:15:04.511703 16 output.go:207] Trying to get logs from node ietha7evai9i-2 pod pod-secrets-73d04f81-4016-40b0-8773-b07d946fe01a container secret-volume-test: <nil>
  STEP: delete the pod @ 09/02/25 08:15:04.535
  I0902 08:15:04.597472 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-9916" for this suite. @ 09/02/25 08:15:04.613
• [4.247 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:74
  STEP: Creating a kubernetes client @ 09/02/25 08:15:04.639
  I0902 08:15:04.639179 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename projected @ 09/02/25 08:15:04.643
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:15:04.697
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:15:04.704
  STEP: Creating configMap with name projected-configmap-test-volume-8881b08d-f65f-44bc-9986-ae5bbcfcaad1 @ 09/02/25 08:15:04.713
  STEP: Creating a pod to test consume configMaps @ 09/02/25 08:15:04.749
  STEP: Saw pod success @ 09/02/25 08:15:08.801
  I0902 08:15:08.810902 16 output.go:207] Trying to get logs from node ietha7evai9i-2 pod pod-projected-configmaps-e857a2e2-336d-4a72-8e80-e001dd4ed9e4 container agnhost-container: <nil>
  STEP: delete the pod @ 09/02/25 08:15:08.827
  I0902 08:15:08.861484 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6381" for this suite. @ 09/02/25 08:15:08.87
• [4.255 seconds]
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:159
  STEP: Creating a kubernetes client @ 09/02/25 08:15:08.893
  I0902 08:15:08.893909 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename emptydir @ 09/02/25 08:15:08.898
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:15:08.918
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:15:08.923
  STEP: Creating a pod to test emptydir volume type on node default medium @ 09/02/25 08:15:08.929
  STEP: Saw pod success @ 09/02/25 08:15:12.971
  I0902 08:15:12.979456 16 output.go:207] Trying to get logs from node ietha7evai9i-2 pod pod-14d3de0d-9032-4bd7-90d4-3c77d086ce2e container test-container: <nil>
  STEP: delete the pod @ 09/02/25 08:15:12.995
  I0902 08:15:13.026801 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-9545" for this suite. @ 09/02/25 08:15:13.036
• [4.156 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should reject validating webhook configurations with invalid match conditions [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:816
  STEP: Creating a kubernetes client @ 09/02/25 08:15:13.049
  I0902 08:15:13.049902 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename webhook @ 09/02/25 08:15:13.052
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:15:13.074
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:15:13.079
  STEP: Setting up server cert @ 09/02/25 08:15:13.122
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 09/02/25 08:15:13.671
  STEP: Deploying the webhook pod @ 09/02/25 08:15:13.683
  STEP: Wait for the deployment to be ready @ 09/02/25 08:15:13.725
  I0902 08:15:13.756796 16 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  I0902 08:15:15.800639 16 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.September, 2, 8, 15, 13, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 8, 15, 13, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.September, 2, 8, 15, 13, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 8, 15, 13, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7d44fffc8\" is progressing."}}, CollisionCount:(*int32)(nil)}
  STEP: Deploying the webhook service @ 09/02/25 08:15:17.81
  STEP: Verifying the service has paired with the endpoint @ 09/02/25 08:15:17.838
  I0902 08:15:18.838694 16 util.go:419] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: creating a validating webhook with match conditions @ 09/02/25 08:15:18.849
  I0902 08:15:18.953423 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-9121" for this suite. @ 09/02/25 08:15:18.962
  STEP: Destroying namespace "webhook-markers-1966" for this suite. @ 09/02/25 08:15:18.978
• [5.953 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1725
  STEP: Creating a kubernetes client @ 09/02/25 08:15:19.005
  I0902 08:15:19.005814 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename kubectl @ 09/02/25 08:15:19.009
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:15:19.059
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:15:19.067
  STEP: creating Agnhost RC @ 09/02/25 08:15:19.073
  I0902 08:15:19.073765 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-408 create -f -'
  I0902 08:15:19.434657 16 builder.go:156] stderr: ""
  I0902 08:15:19.434732 16 builder.go:157] stdout: "replicationcontroller/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 09/02/25 08:15:19.434
  I0902 08:15:20.445933 16 framework.go:697] Selector matched 1 pods for map[app:agnhost]
  I0902 08:15:20.445997 16 framework.go:738] Found 0 / 1
  I0902 08:15:21.450868 16 framework.go:697] Selector matched 1 pods for map[app:agnhost]
  I0902 08:15:21.451021 16 framework.go:738] Found 1 / 1
  I0902 08:15:21.451104 16 framework.go:747] WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  STEP: patching all pods @ 09/02/25 08:15:21.451
  I0902 08:15:21.462931 16 framework.go:697] Selector matched 1 pods for map[app:agnhost]
  I0902 08:15:21.463048 16 framework.go:770] ForEach: Found 1 pods from the filter.  Now looping through them.
  I0902 08:15:21.463578 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-408 patch pod agnhost-primary-hlp8m -p {"metadata":{"annotations":{"x":"y"}}}'
  I0902 08:15:21.691484 16 builder.go:156] stderr: ""
  I0902 08:15:21.691969 16 builder.go:157] stdout: "pod/agnhost-primary-hlp8m patched\n"
  STEP: checking annotations @ 09/02/25 08:15:21.692
  I0902 08:15:21.701821 16 framework.go:697] Selector matched 1 pods for map[app:agnhost]
  I0902 08:15:21.701889 16 framework.go:770] ForEach: Found 1 pods from the filter.  Now looping through them.
  I0902 08:15:21.702155 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-408" for this suite. @ 09/02/25 08:15:21.72
• [2.741 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AggregatedDiscovery should support aggregated discovery interface [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/aggregated_discovery.go:259
  STEP: Creating a kubernetes client @ 09/02/25 08:15:21.748
  I0902 08:15:21.748397 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename aggregateddiscovery @ 09/02/25 08:15:21.753
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:15:21.786
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:15:21.793
  I0902 08:15:21.817116 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregateddiscovery-527" for this suite. @ 09/02/25 08:15:21.839
• [0.116 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:88
  STEP: Creating a kubernetes client @ 09/02/25 08:15:21.878
  I0902 08:15:21.878315 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename projected @ 09/02/25 08:15:21.884
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:15:21.915
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:15:21.924
  STEP: Creating projection with secret that has name projected-secret-test-map-5852b5d6-ac36-463e-826d-6b408c72f9cf @ 09/02/25 08:15:21.933
  STEP: Creating a pod to test consume secrets @ 09/02/25 08:15:21.946
  STEP: Saw pod success @ 09/02/25 08:15:26.01
  I0902 08:15:26.017460 16 output.go:207] Trying to get logs from node ietha7evai9i-3 pod pod-projected-secrets-bb38a935-da2c-4f6c-82ff-125af7518842 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 09/02/25 08:15:26.03
  I0902 08:15:26.065434 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8124" for this suite. @ 09/02/25 08:15:26.076
• [4.212 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:56
  STEP: Creating a kubernetes client @ 09/02/25 08:15:26.09
  I0902 08:15:26.090333 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename projected @ 09/02/25 08:15:26.094
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:15:26.115
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:15:26.12
  STEP: Creating projection with secret that has name projected-secret-test-eb48cc5a-67c0-4cd8-a1b2-1601721f5e1a @ 09/02/25 08:15:26.125
  STEP: Creating a pod to test consume secrets @ 09/02/25 08:15:26.137
  STEP: Saw pod success @ 09/02/25 08:15:30.186
  I0902 08:15:30.194978 16 output.go:207] Trying to get logs from node ietha7evai9i-3 pod pod-projected-secrets-0909a55e-8eaa-4927-90b5-b667bae52a17 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 09/02/25 08:15:30.209
  I0902 08:15:30.243119 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-615" for this suite. @ 09/02/25 08:15:30.252
• [4.175 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Pods should be submitted and removed [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:227
  STEP: Creating a kubernetes client @ 09/02/25 08:15:30.266
  I0902 08:15:30.266235 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename pods @ 09/02/25 08:15:30.269
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:15:30.295
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:15:30.303
  STEP: creating the pod @ 09/02/25 08:15:30.308
  STEP: setting up watch @ 09/02/25 08:15:30.309
  STEP: submitting the pod to kubernetes @ 09/02/25 08:15:30.417
  STEP: verifying the pod is in kubernetes @ 09/02/25 08:15:30.455
  STEP: verifying pod creation was observed @ 09/02/25 08:15:30.465
  STEP: deleting the pod gracefully @ 09/02/25 08:15:32.491
  STEP: verifying pod deletion was observed @ 09/02/25 08:15:32.507
  I0902 08:15:34.065531 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-8892" for this suite. @ 09/02/25 08:15:34.076
• [3.828 seconds]
------------------------------
S
------------------------------
[sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:677
  STEP: Creating a kubernetes client @ 09/02/25 08:15:34.095
  I0902 08:15:34.095425 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename svcaccounts @ 09/02/25 08:15:34.098
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:15:34.129
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:15:34.136
  STEP: creating a ServiceAccount @ 09/02/25 08:15:34.143
  STEP: watching for the ServiceAccount to be added @ 09/02/25 08:15:34.161
  STEP: patching the ServiceAccount @ 09/02/25 08:15:34.17
  STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) @ 09/02/25 08:15:34.184
  STEP: deleting the ServiceAccount @ 09/02/25 08:15:34.194
  I0902 08:15:34.229402 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-1779" for this suite. @ 09/02/25 08:15:34.241
• [0.161 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:169
  STEP: Creating a kubernetes client @ 09/02/25 08:15:34.257
  I0902 08:15:34.257149 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename emptydir @ 09/02/25 08:15:34.26
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:15:34.281
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:15:34.287
  STEP: Creating a pod to test emptydir 0644 on node default medium @ 09/02/25 08:15:34.293
  STEP: Saw pod success @ 09/02/25 08:15:38.339
  I0902 08:15:38.347082 16 output.go:207] Trying to get logs from node ietha7evai9i-2 pod pod-1a68ba55-bd6f-4ca5-b289-4176db73de95 container test-container: <nil>
  STEP: delete the pod @ 09/02/25 08:15:38.362
  I0902 08:15:38.399165 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-6760" for this suite. @ 09/02/25 08:15:38.409
• [4.165 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:142
  STEP: Creating a kubernetes client @ 09/02/25 08:15:38.431
  I0902 08:15:38.431767 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename watch @ 09/02/25 08:15:38.435
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:15:38.459
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:15:38.464
  STEP: creating a new configmap @ 09/02/25 08:15:38.469
  STEP: modifying the configmap once @ 09/02/25 08:15:38.479
  STEP: modifying the configmap a second time @ 09/02/25 08:15:38.495
  STEP: deleting the configmap @ 09/02/25 08:15:38.509
  STEP: creating a watch on configmaps from the resource version returned by the first update @ 09/02/25 08:15:38.518
  STEP: Expecting to observe notifications for all changes to the configmap after the first update @ 09/02/25 08:15:38.522
  I0902 08:15:38.523327 16 watch.go:426] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-9373  86305165-c7f4-4f6d-8185-41b5d203319c 28037 0 2025-09-02 08:15:38 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2025-09-02 08:15:38 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0902 08:15:38.524194 16 watch.go:426] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-9373  86305165-c7f4-4f6d-8185-41b5d203319c 28038 0 2025-09-02 08:15:38 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2025-09-02 08:15:38 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0902 08:15:38.524720 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-9373" for this suite. @ 09/02/25 08:15:38.533
• [0.116 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:444
  STEP: Creating a kubernetes client @ 09/02/25 08:15:38.548
  I0902 08:15:38.548842 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename crd-publish-openapi @ 09/02/25 08:15:38.552
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:15:38.576
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:15:38.582
  STEP: set up a multi version CRD @ 09/02/25 08:15:38.589
  I0902 08:15:38.590431 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: mark a version not serverd @ 09/02/25 08:15:44.439
  STEP: check the unserved version gets removed @ 09/02/25 08:15:44.505
  STEP: check the other version is not changed @ 09/02/25 08:15:46.333
  I0902 08:15:51.026424 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-1268" for this suite. @ 09/02/25 08:15:51.059
• [12.537 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:256
  STEP: Creating a kubernetes client @ 09/02/25 08:15:51.087
  I0902 08:15:51.087798 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename init-container @ 09/02/25 08:15:51.092
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:15:51.135
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:15:51.144
  STEP: creating the pod @ 09/02/25 08:15:51.151
  I0902 08:15:51.152109 16 init_container.go:294] PodSpec: initContainers in spec.initContainers
  I0902 08:15:54.499020 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-1165" for this suite. @ 09/02/25 08:15:54.514
• [3.452 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-apps] ReplicationController should get and update a ReplicationController scale [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:426
  STEP: Creating a kubernetes client @ 09/02/25 08:15:54.539
  I0902 08:15:54.539484 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename replication-controller @ 09/02/25 08:15:54.544
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:15:54.574
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:15:54.582
  STEP: Creating ReplicationController "e2e-rc-blqln" @ 09/02/25 08:15:54.595
  I0902 08:15:54.608788 16 rc.go:795] Get Replication Controller "e2e-rc-blqln" to confirm replicas
  I0902 08:15:55.608956 16 rc.go:795] Get Replication Controller "e2e-rc-blqln" to confirm replicas
  I0902 08:15:55.617015 16 rc.go:804] Found 1 replicas for "e2e-rc-blqln" replication controller
  STEP: Getting scale subresource for ReplicationController "e2e-rc-blqln" @ 09/02/25 08:15:55.617
  STEP: Updating a scale subresource @ 09/02/25 08:15:55.625
  STEP: Verifying replicas where modified for replication controller "e2e-rc-blqln" @ 09/02/25 08:15:55.642
  I0902 08:15:55.643028 16 rc.go:795] Get Replication Controller "e2e-rc-blqln" to confirm replicas
  I0902 08:15:56.643851 16 rc.go:795] Get Replication Controller "e2e-rc-blqln" to confirm replicas
  I0902 08:15:56.651507 16 rc.go:804] Found 2 replicas for "e2e-rc-blqln" replication controller
  I0902 08:15:56.651889 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-8713" for this suite. @ 09/02/25 08:15:56.662
• [2.145 seconds]
------------------------------
SSSSSS
------------------------------
[sig-network] DNS should support configurable pod DNS nameservers [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:436
  STEP: Creating a kubernetes client @ 09/02/25 08:15:56.684
  I0902 08:15:56.684964 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename dns @ 09/02/25 08:15:56.692
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:15:56.717
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:15:56.724
  STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... @ 09/02/25 08:15:56.782
  I0902 08:15:56.813928 16 dns.go:448] Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-9339  3ae9692e-a8a4-45ed-b221-f322f92674bb 28173 1 2025-09-02 08:15:56 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2025-09-02 08:15:56 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-f5gmw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},ClusterTrustBundle:nil,PodCertificate:nil,},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,ClusterTrustBundle:nil,PodCertificate:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,ClusterTrustBundle:nil,PodCertificate:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,Image:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.56,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-f5gmw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,RecursiveReadOnly:nil,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,AppArmorProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},RestartPolicy:nil,RestartPolicyRules:[]ContainerRestartRule{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,AppArmorProfile:nil,SupplementalGroupsPolicy:nil,SELinuxChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},Resources:nil,HostnameOverride:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,ResourceClaimStatuses:[]PodResourceClaimStatus{},HostIPs:[]HostIP{},ObservedGeneration:0,ExtendedResourceClaimStatus:nil,},}
  STEP: Verifying customized DNS suffix list is configured on pod... @ 09/02/25 08:15:58.836
  I0902 08:15:58.836669 16 exec_util.go:63] ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-9339 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0902 08:15:58.836741 16 exec_util.go:68] ExecWithOptions: Clientset creation
  I0902 08:15:58.836851 16 exec_util.go:84] ExecWithOptions: execute(https://10.233.0.1:443/api/v1/namespaces/dns-9339/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&stderr=true&stdout=true)
  STEP: Verifying customized DNS server is configured on pod... @ 09/02/25 08:15:59.016
  I0902 08:15:59.017084 16 exec_util.go:63] ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-9339 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0902 08:15:59.017175 16 exec_util.go:68] ExecWithOptions: Clientset creation
  I0902 08:15:59.017390 16 exec_util.go:84] ExecWithOptions: execute(https://10.233.0.1:443/api/v1/namespaces/dns-9339/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&stderr=true&stdout=true)
  I0902 08:15:59.197103 16 dns.go:450] Deleting pod test-dns-nameservers...
  I0902 08:15:59.224472 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-9339" for this suite. @ 09/02/25 08:15:59.244
• [2.577 seconds]
------------------------------
SSS
------------------------------
[sig-node] Kubelet when scheduling an agnhost Pod with hostAliases should write entries to /etc/hosts [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:148
  STEP: Creating a kubernetes client @ 09/02/25 08:15:59.262
  I0902 08:15:59.262388 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename kubelet-test @ 09/02/25 08:15:59.265
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:15:59.29
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:15:59.296
  STEP: Waiting for pod completion @ 09/02/25 08:15:59.322
  I0902 08:16:03.368820 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-5046" for this suite. @ 09/02/25 08:16:03.379
• [4.133 seconds]
------------------------------
SS
------------------------------
[sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance] [sig-node, Serial, Disruptive, Conformance]
k8s.io/kubernetes/test/e2e/node/taints.go:284
  STEP: Creating a kubernetes client @ 09/02/25 08:16:03.395
  I0902 08:16:03.395407 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename taint-single-pod @ 09/02/25 08:16:03.397
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:16:03.422
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:16:03.43
  I0902 08:16:03.437453 16 wait.go:51] Waiting up to 1m0s for all nodes to be ready
  I0902 08:17:03.438702 16 util.go:390] Waiting for terminating namespaces to be deleted...
  I0902 08:17:03.447591 16 taints.go:144] Starting informer...
  STEP: Starting pod... @ 09/02/25 08:17:03.447
  I0902 08:17:03.675034 16 taints.go:294] Pod is running on ietha7evai9i-2. Tainting Node
  STEP: Trying to apply a taint on the Node @ 09/02/25 08:17:03.675
  STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 09/02/25 08:17:03.699
  STEP: Waiting short time to make sure Pod is queued for deletion @ 09/02/25 08:17:03.708
  I0902 08:17:03.708096 16 taints.go:313] Pod wasn't evicted. Proceeding
  I0902 08:17:03.708207 16 taints.go:320] Removing taint from Node
  STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 09/02/25 08:17:03.734
  STEP: Waiting some time to make sure that toleration time passed. @ 09/02/25 08:17:03.743
  I0902 08:18:18.744830 16 taints.go:329] Pod wasn't evicted. Test successful
  I0902 08:18:18.746518 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "taint-single-pod-3679" for this suite. @ 09/02/25 08:18:18.763
• [135.386 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply a CR with unknown fields for CRD with no validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:287
  STEP: Creating a kubernetes client @ 09/02/25 08:18:18.789
  I0902 08:18:18.789213 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename field-validation @ 09/02/25 08:18:18.794
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:18:18.849
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:18:18.856
  I0902 08:18:18.861912 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  I0902 08:18:22.202320 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-5332" for this suite. @ 09/02/25 08:18:22.219
• [3.448 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:404
  STEP: Creating a kubernetes client @ 09/02/25 08:18:22.238
  I0902 08:18:22.238442 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename resourcequota @ 09/02/25 08:18:22.242
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:18:22.272
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:18:22.277
  STEP: Counting existing ResourceQuota @ 09/02/25 08:18:22.285
  STEP: Creating a ResourceQuota @ 09/02/25 08:18:27.293
  STEP: Ensuring resource quota status is calculated @ 09/02/25 08:18:27.305
  I0902 08:18:29.325457 16 resource_quota.go:2495] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc001bf8000>: 
          metadata:
            creationTimestamp: "2025-09-02T08:18:27Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: e2e.test
              operation: Update
              time: "2025-09-02T08:18:27Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
                  f:used:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: kube-controller-manager
              operation: Update
              subresource: status
              time: "2025-09-02T08:18:27Z"
            name: test-quota
            namespace: resourcequota-1879
            resourceVersion: "28648"
            uid: 3d2f20dc-1c0f-4969-b0be-180376d54021
          spec:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
          status:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
            used:
              configmaps: "1"
              count/replicasets.apps: "0"
              cpu: "0"
              ephemeral-storage: "0"
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "0"
              gold.storageclass.storage.k8s.io/requests.storage: "0"
              memory: "0"
              persistentvolumeclaims: "0"
              pods: "0"
              replicationcontrollers: "0"
              requests.example.com/dongle: "0"
              requests.storage: "0"
              resourcequotas: "1"
              secrets: "0"
              services: "0"
              services.loadbalancers: "0"
              services.nodeports: "0"
  STEP: Creating a ReplicationController @ 09/02/25 08:18:29.326
  STEP: Ensuring resource quota status captures replication controller creation @ 09/02/25 08:18:29.356
  I0902 08:18:29.367007 16 resource_quota.go:2495] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc001bf8c80>: 
          metadata:
            creationTimestamp: "2025-09-02T08:18:27Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: e2e.test
              operation: Update
              time: "2025-09-02T08:18:27Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
                  f:used:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: kube-controller-manager
              operation: Update
              subresource: status
              time: "2025-09-02T08:18:27Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:used:
                    f:replicationcontrollers: {}
              manager: kube-apiserver
              operation: Update
              subresource: status
              time: "2025-09-02T08:18:29Z"
            name: test-quota
            namespace: resourcequota-1879
            resourceVersion: "28661"
            uid: 3d2f20dc-1c0f-4969-b0be-180376d54021
          spec:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
          status:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
            used:
              configmaps: "1"
              count/replicasets.apps: "0"
              cpu: "0"
              ephemeral-storage: "0"
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "0"
              gold.storageclass.storage.k8s.io/requests.storage: "0"
              memory: "0"
              persistentvolumeclaims: "0"
              pods: "0"
              replicationcontrollers: "1"
              requests.example.com/dongle: "0"
              requests.storage: "0"
              resourcequotas: "1"
              secrets: "0"
              services: "0"
              services.loadbalancers: "0"
              services.nodeports: "0"
  STEP: Deleting a ReplicationController @ 09/02/25 08:18:29.369
  STEP: Ensuring resource quota status released usage @ 09/02/25 08:18:29.386
  I0902 08:18:31.408740 16 resource_quota.go:2495] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc001d86000>: 
          metadata:
            creationTimestamp: "2025-09-02T08:18:27Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: e2e.test
              operation: Update
              time: "2025-09-02T08:18:27Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
                  f:used:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: kube-controller-manager
              operation: Update
              subresource: status
              time: "2025-09-02T08:18:29Z"
            name: test-quota
            namespace: resourcequota-1879
            resourceVersion: "28667"
            uid: 3d2f20dc-1c0f-4969-b0be-180376d54021
          spec:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
          status:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
            used:
              configmaps: "1"
              count/replicasets.apps: "0"
              cpu: "0"
              ephemeral-storage: "0"
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "0"
              gold.storageclass.storage.k8s.io/requests.storage: "0"
              memory: "0"
              persistentvolumeclaims: "0"
              pods: "0"
              replicationcontrollers: "0"
              requests.example.com/dongle: "0"
              requests.storage: "0"
              resourcequotas: "1"
              secrets: "0"
              services: "0"
              services.loadbalancers: "0"
              services.nodeports: "0"
  I0902 08:18:31.410040 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-1879" for this suite. @ 09/02/25 08:18:31.424
• [9.203 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance] [sig-storage, Serial, Conformance]
k8s.io/kubernetes/test/e2e/storage/empty_dir_wrapper.go:190
  STEP: Creating a kubernetes client @ 09/02/25 08:18:31.442
  I0902 08:18:31.442476 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename emptydir-wrapper @ 09/02/25 08:18:31.446
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:18:31.481
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:18:31.488
  STEP: Creating 50 configmaps @ 09/02/25 08:18:31.527
  STEP: Creating RC which spawns configmap-volume pods @ 09/02/25 08:18:32.021
  I0902 08:18:32.046842 16 resource.go:64] Pod name wrapped-volume-race-63c84b24-bbae-45e4-899b-520a117ae333: Found 0 pods out of 5
  I0902 08:18:37.071814 16 resource.go:64] Pod name wrapped-volume-race-63c84b24-bbae-45e4-899b-520a117ae333: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 09/02/25 08:18:37.071
  STEP: Creating RC which spawns configmap-volume pods @ 09/02/25 08:18:37.149
  I0902 08:18:37.183966 16 resource.go:64] Pod name wrapped-volume-race-8de0dfc9-2b61-4fda-ac64-06c007c4696b: Found 0 pods out of 5
  I0902 08:18:42.201181 16 resource.go:64] Pod name wrapped-volume-race-8de0dfc9-2b61-4fda-ac64-06c007c4696b: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 09/02/25 08:18:42.201
  STEP: Creating RC which spawns configmap-volume pods @ 09/02/25 08:18:44.289
  I0902 08:18:44.356140 16 resource.go:64] Pod name wrapped-volume-race-da7afae6-5265-4596-b8e1-1e61affb4bd9: Found 1 pods out of 5
  I0902 08:18:49.382957 16 resource.go:64] Pod name wrapped-volume-race-da7afae6-5265-4596-b8e1-1e61affb4bd9: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 09/02/25 08:18:49.383
  STEP: deleting ReplicationController wrapped-volume-race-da7afae6-5265-4596-b8e1-1e61affb4bd9 in namespace emptydir-wrapper-5502, will wait for the garbage collector to delete the pods @ 09/02/25 08:18:49.433
  I0902 08:18:49.512383 16 resources.go:139] Deleting ReplicationController wrapped-volume-race-da7afae6-5265-4596-b8e1-1e61affb4bd9 took: 19.446625ms
  I0902 08:18:49.713155 16 resources.go:163] Terminating ReplicationController wrapped-volume-race-da7afae6-5265-4596-b8e1-1e61affb4bd9 pods took: 200.756458ms
  STEP: deleting ReplicationController wrapped-volume-race-8de0dfc9-2b61-4fda-ac64-06c007c4696b in namespace emptydir-wrapper-5502, will wait for the garbage collector to delete the pods @ 09/02/25 08:18:52.214
  I0902 08:18:52.300174 16 resources.go:139] Deleting ReplicationController wrapped-volume-race-8de0dfc9-2b61-4fda-ac64-06c007c4696b took: 16.309623ms
  I0902 08:18:52.500644 16 resources.go:163] Terminating ReplicationController wrapped-volume-race-8de0dfc9-2b61-4fda-ac64-06c007c4696b pods took: 200.463709ms
  STEP: deleting ReplicationController wrapped-volume-race-63c84b24-bbae-45e4-899b-520a117ae333 in namespace emptydir-wrapper-5502, will wait for the garbage collector to delete the pods @ 09/02/25 08:18:55.302
  I0902 08:18:55.384802 16 resources.go:139] Deleting ReplicationController wrapped-volume-race-63c84b24-bbae-45e4-899b-520a117ae333 took: 19.657361ms
  I0902 08:18:55.585884 16 resources.go:163] Terminating ReplicationController wrapped-volume-race-63c84b24-bbae-45e4-899b-520a117ae333 pods took: 201.051548ms
  STEP: Cleaning up the configMaps @ 09/02/25 08:18:57.887
  I0902 08:18:58.544196 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-wrapper-5502" for this suite. @ 09/02/25 08:18:58.554
• [27.129 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:49
  STEP: Creating a kubernetes client @ 09/02/25 08:18:58.573
  I0902 08:18:58.573260 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename downward-api @ 09/02/25 08:18:58.575
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:18:58.603
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:18:58.609
  STEP: Creating a pod to test downward api env vars @ 09/02/25 08:18:58.615
  STEP: Saw pod success @ 09/02/25 08:19:02.663
  I0902 08:19:02.670731 16 output.go:207] Trying to get logs from node ietha7evai9i-3 pod downward-api-3849c494-004d-492d-83be-5e92f7789353 container dapi-container: <nil>
  STEP: delete the pod @ 09/02/25 08:19:02.713
  I0902 08:19:02.756591 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-3567" for this suite. @ 09/02/25 08:19:02.768
• [4.216 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:154
  STEP: Creating a kubernetes client @ 09/02/25 08:19:02.79
  I0902 08:19:02.790445 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename tables @ 09/02/25 08:19:02.794
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:19:02.819
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:19:02.824
  I0902 08:19:02.835374 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "tables-6917" for this suite. @ 09/02/25 08:19:02.87
• [0.095 seconds]
------------------------------
[sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:160
  STEP: Creating a kubernetes client @ 09/02/25 08:19:02.885
  I0902 08:19:02.885976 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename runtimeclass @ 09/02/25 08:19:02.888
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:19:02.921
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:19:02.926
  STEP: Deleting RuntimeClass runtimeclass-8521-delete-me @ 09/02/25 08:19:02.948
  STEP: Waiting for the RuntimeClass to disappear @ 09/02/25 08:19:02.966
  I0902 08:19:03.001287 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-8521" for this suite. @ 09/02/25 08:19:03.017
• [0.154 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:281
  STEP: Creating a kubernetes client @ 09/02/25 08:19:03.041
  I0902 08:19:03.041528 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename webhook @ 09/02/25 08:19:03.045
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:19:03.08
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:19:03.086
  STEP: Setting up server cert @ 09/02/25 08:19:03.141
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 09/02/25 08:19:05.133
  STEP: Deploying the webhook pod @ 09/02/25 08:19:05.146
  STEP: Wait for the deployment to be ready @ 09/02/25 08:19:05.174
  I0902 08:19:05.193271 16 deployment.go:223] new replicaset for deployment "sample-webhook-deployment" is yet to be created
  STEP: Deploying the webhook service @ 09/02/25 08:19:07.22
  STEP: Verifying the service has paired with the endpoint @ 09/02/25 08:19:07.24
  I0902 08:19:08.240804 16 util.go:419] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  I0902 08:19:08.253623 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-8682-1944-crds.webhook.example.com via the AdmissionRegistration API @ 09/02/25 08:19:08.779
  STEP: Creating a custom resource that should be mutated by the webhook @ 09/02/25 08:19:08.838
  I0902 08:19:11.689765 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-8682" for this suite. @ 09/02/25 08:19:11.701
  STEP: Destroying namespace "webhook-markers-7437" for this suite. @ 09/02/25 08:19:11.718
• [8.692 seconds]
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client Proxy server should support --unix-socket=/path [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1893
  STEP: Creating a kubernetes client @ 09/02/25 08:19:11.734
  I0902 08:19:11.734055 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename kubectl @ 09/02/25 08:19:11.736
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:19:11.764
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:19:11.77
  STEP: Starting the proxy @ 09/02/25 08:19:11.783
  I0902 08:19:11.785154 16 util.go:542] Asynchronously running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-6958 proxy --unix-socket=/tmp/kubectl-proxy-unix1719251865/test'
  STEP: retrieving proxy /api/ output @ 09/02/25 08:19:11.928
  I0902 08:19:11.932938 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-6958" for this suite. @ 09/02/25 08:19:11.953
• [0.261 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:217
  STEP: Creating a kubernetes client @ 09/02/25 08:19:11.994
  I0902 08:19:11.995028 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename webhook @ 09/02/25 08:19:11.998
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:19:12.026
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:19:12.035
  STEP: Setting up server cert @ 09/02/25 08:19:12.09
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 09/02/25 08:19:12.905
  STEP: Deploying the webhook pod @ 09/02/25 08:19:12.917
  STEP: Wait for the deployment to be ready @ 09/02/25 08:19:12.939
  I0902 08:19:12.952433 16 deployment.go:223] new replicaset for deployment "sample-webhook-deployment" is yet to be created
  STEP: Deploying the webhook service @ 09/02/25 08:19:14.978
  STEP: Verifying the service has paired with the endpoint @ 09/02/25 08:19:14.997
  I0902 08:19:15.997933 16 util.go:419] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  I0902 08:19:16.006991 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Registering the custom resource webhook via the AdmissionRegistration API @ 09/02/25 08:19:16.526
  STEP: Creating a custom resource that should be denied by the webhook @ 09/02/25 08:19:16.562
  STEP: Creating a custom resource whose deletion would be denied by the webhook @ 09/02/25 08:19:18.682
  STEP: Updating the custom resource with disallowed data should be denied @ 09/02/25 08:19:18.696
  STEP: Deleting the custom resource should be denied @ 09/02/25 08:19:18.716
  STEP: Remove the offending key and value from the custom resource data @ 09/02/25 08:19:18.735
  STEP: Deleting the updated custom resource should be successful @ 09/02/25 08:19:18.762
  I0902 08:19:19.440197 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-2146" for this suite. @ 09/02/25 08:19:19.45
  STEP: Destroying namespace "webhook-markers-3314" for this suite. @ 09/02/25 08:19:19.465
• [7.491 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:199
  STEP: Creating a kubernetes client @ 09/02/25 08:19:19.487
  I0902 08:19:19.487270 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename custom-resource-definition @ 09/02/25 08:19:19.49
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:19:19.517
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:19:19.526
  STEP: fetching the /apis discovery document @ 09/02/25 08:19:19.529
  STEP: finding the apiextensions.k8s.io API group in the /apis discovery document @ 09/02/25 08:19:19.535
  STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document @ 09/02/25 08:19:19.535
  STEP: fetching the /apis/apiextensions.k8s.io discovery document @ 09/02/25 08:19:19.535
  STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document @ 09/02/25 08:19:19.538
  STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document @ 09/02/25 08:19:19.538
  STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document @ 09/02/25 08:19:19.54
  I0902 08:19:19.540299 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-82" for this suite. @ 09/02/25 08:19:19.551
• [0.081 seconds]
------------------------------
[sig-auth] ServiceAccounts should update a ServiceAccount [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:838
  STEP: Creating a kubernetes client @ 09/02/25 08:19:19.569
  I0902 08:19:19.569584 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename svcaccounts @ 09/02/25 08:19:19.573
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:19:19.603
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:19:19.608
  STEP: Creating ServiceAccount "e2e-sa-2n6lj"  @ 09/02/25 08:19:19.614
  I0902 08:19:19.625250 16 service_accounts.go:853] AutomountServiceAccountToken: false
  STEP: Updating ServiceAccount "e2e-sa-2n6lj"  @ 09/02/25 08:19:19.625
  I0902 08:19:19.647439 16 service_accounts.go:867] AutomountServiceAccountToken: true
  I0902 08:19:19.647667 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-1458" for this suite. @ 09/02/25 08:19:19.659
• [0.116 seconds]
------------------------------
SSSSS
------------------------------
[sig-network] Services should delete a collection of services [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3657
  STEP: Creating a kubernetes client @ 09/02/25 08:19:19.686
  I0902 08:19:19.686157 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename services @ 09/02/25 08:19:19.689
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:19:19.722
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:19:19.73
  STEP: creating a collection of services @ 09/02/25 08:19:19.74
  I0902 08:19:19.740603 16 service.go:3693] Creating e2e-svc-a-blf6f
  I0902 08:19:19.762660 16 service.go:3693] Creating e2e-svc-b-q2h8h
  I0902 08:19:19.789159 16 service.go:3693] Creating e2e-svc-c-w5xtt
  STEP: deleting service collection @ 09/02/25 08:19:19.818
  I0902 08:19:19.905140 16 service.go:3728] Collection of services has been deleted
  I0902 08:19:19.905865 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-7338" for this suite. @ 09/02/25 08:19:19.918
• [0.248 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] ResourceQuota should apply changes to a resourcequota status [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:1074
  STEP: Creating a kubernetes client @ 09/02/25 08:19:19.936
  I0902 08:19:19.937238 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename resourcequota @ 09/02/25 08:19:19.94
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:19:20.012
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:19:20.019
  STEP: Creating resourceQuota "e2e-rq-status-v7l2q" @ 09/02/25 08:19:20.034
  I0902 08:19:20.054088 16 resource_quota.go:1110] Resource quota "e2e-rq-status-v7l2q" reports spec: hard cpu limit of 500m
  I0902 08:19:20.054207 16 resource_quota.go:1112] Resource quota "e2e-rq-status-v7l2q" reports spec: hard memory limit of 500Mi
  STEP: Updating resourceQuota "e2e-rq-status-v7l2q" /status @ 09/02/25 08:19:20.054
  STEP: Confirm /status for "e2e-rq-status-v7l2q" resourceQuota via watch @ 09/02/25 08:19:20.077
  I0902 08:19:20.081253 16 resource_quota.go:1139] observed resourceQuota "e2e-rq-status-v7l2q" in namespace "resourcequota-3378" with hard status: v1.ResourceList(nil)
  I0902 08:19:20.081417 16 resource_quota.go:1142] Found resourceQuota "e2e-rq-status-v7l2q" in namespace "resourcequota-3378" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
  I0902 08:19:20.081480 16 resource_quota.go:1149] ResourceQuota "e2e-rq-status-v7l2q" /status was updated
  STEP: Patching hard spec values for cpu & memory @ 09/02/25 08:19:20.087
  I0902 08:19:20.103218 16 resource_quota.go:1160] Resource quota "e2e-rq-status-v7l2q" reports spec: hard cpu limit of 1
  I0902 08:19:20.103284 16 resource_quota.go:1161] Resource quota "e2e-rq-status-v7l2q" reports spec: hard memory limit of 1Gi
  STEP: Patching "e2e-rq-status-v7l2q" /status @ 09/02/25 08:19:20.103
  STEP: Confirm /status for "e2e-rq-status-v7l2q" resourceQuota via watch @ 09/02/25 08:19:20.116
  I0902 08:19:20.119436 16 resource_quota.go:1183] observed resourceQuota "e2e-rq-status-v7l2q" in namespace "resourcequota-3378" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
  I0902 08:19:20.119546 16 resource_quota.go:1186] Found resourceQuota "e2e-rq-status-v7l2q" in namespace "resourcequota-3378" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}
  I0902 08:19:20.119667 16 resource_quota.go:1193] ResourceQuota "e2e-rq-status-v7l2q" /status was patched
  STEP: Get "e2e-rq-status-v7l2q" /status @ 09/02/25 08:19:20.119
  I0902 08:19:20.127254 16 resource_quota.go:1204] Resourcequota "e2e-rq-status-v7l2q" reports status: hard cpu of 1
  I0902 08:19:20.127347 16 resource_quota.go:1206] Resourcequota "e2e-rq-status-v7l2q" reports status: hard memory of 1Gi
  STEP: Repatching "e2e-rq-status-v7l2q" /status before checking Spec is unchanged @ 09/02/25 08:19:20.132
  I0902 08:19:20.143690 16 resource_quota.go:1226] Resourcequota "e2e-rq-status-v7l2q" reports status: hard cpu of 2
  I0902 08:19:20.143762 16 resource_quota.go:1228] Resourcequota "e2e-rq-status-v7l2q" reports status: hard memory of 2Gi
  I0902 08:19:20.146528 16 resource_quota.go:1240] Found resourceQuota "e2e-rq-status-v7l2q" in namespace "resourcequota-3378" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}
  I0902 08:19:20.151675 16 resource_quota.go:1271] ResourceQuota "e2e-rq-status-v7l2q" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-v7l2q", GenerateName:"", Namespace:"resourcequota-3378", SelfLink:"", UID:"c9f5ae2d-d386-4997-8546-88b195a8e619", ResourceVersion:"29493", Generation:0, CreationTimestamp:time.Date(2025, time.September, 2, 8, 19, 20, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-v7l2q"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.September, 2, 8, 19, 20, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003c4f038), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.September, 2, 8, 19, 20, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003c4f068), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.September, 2, 8, 19, 20, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003c4f098), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0902 08:19:25.160132 16 resource_quota.go:1271] ResourceQuota "e2e-rq-status-v7l2q" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-v7l2q", GenerateName:"", Namespace:"resourcequota-3378", SelfLink:"", UID:"c9f5ae2d-d386-4997-8546-88b195a8e619", ResourceVersion:"29493", Generation:0, CreationTimestamp:time.Date(2025, time.September, 2, 8, 19, 20, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-v7l2q"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.September, 2, 8, 19, 20, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003c4f158), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.September, 2, 8, 19, 20, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003c4f188), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.September, 2, 8, 19, 20, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003c4f1b8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0902 08:19:30.157690 16 resource_quota.go:1268] ResourceQuota "e2e-rq-status-v7l2q" Spec was unchanged and /status reset
  I0902 08:19:30.158090 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-3378" for this suite. @ 09/02/25 08:19:30.171
• [10.255 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should serve multiport endpoints from pods [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:810
  STEP: Creating a kubernetes client @ 09/02/25 08:19:30.192
  I0902 08:19:30.192963 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename services @ 09/02/25 08:19:30.196
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:19:30.221
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:19:30.229
  STEP: creating service multi-endpoint-test in namespace services-4677 @ 09/02/25 08:19:30.236
  I0902 08:19:30.258251 16 wait.go:65] Waiting for amount of service services-4677/multi-endpoint-test endpoints to be 0
  I0902 08:19:30.270640 16 wait.go:68] Waiting for at least 1 EndpointSlice to exist
  STEP: creating pod1 serving port1 @ 09/02/25 08:19:31.266
  STEP: Creating pod pod1 in namespace services-4677 @ 09/02/25 08:19:31.266
  I0902 08:19:33.311038 16 wait.go:139] Waiting for service services-4677/multi-endpoint-test to have endpoints for ports [{portname1  pod1 100}]
  STEP: creating pod2 serving port2 @ 09/02/25 08:19:33.323
  STEP: Creating pod pod2 in namespace services-4677 @ 09/02/25 08:19:33.323
  I0902 08:19:35.362849 16 wait.go:139] Waiting for service services-4677/multi-endpoint-test to have endpoints for ports [{portname1  pod1 100} {portname2  pod2 101}]
  STEP: Checking if the Service forwards traffic to pods @ 09/02/25 08:19:35.37
  I0902 08:19:35.370670 16 resource.go:344] Creating new exec pod
  I0902 08:19:37.417045 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=services-4677 exec execpodnsbch -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
  I0902 08:19:37.763169 16 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 80\nConnection to multi-endpoint-test (10.233.21.240) 80 port [tcp/http] succeeded!\n"
  I0902 08:19:37.763261 16 builder.go:157] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0902 08:19:37.763879 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=services-4677 exec execpodnsbch -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.21.240 80'
  I0902 08:19:38.026474 16 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.21.240 80\nConnection to 10.233.21.240 80 port [tcp/http] succeeded!\n"
  I0902 08:19:38.026650 16 builder.go:157] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0902 08:19:38.027083 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=services-4677 exec execpodnsbch -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
  I0902 08:19:38.313746 16 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 81\nConnection to multi-endpoint-test (10.233.21.240) 81 port [tcp/*] succeeded!\n"
  I0902 08:19:38.313954 16 builder.go:157] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0902 08:19:38.314975 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=services-4677 exec execpodnsbch -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.21.240 81'
  I0902 08:19:38.596679 16 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.21.240 81\nConnection to 10.233.21.240 81 port [tcp/*] succeeded!\n"
  I0902 08:19:38.596825 16 builder.go:157] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: deleting pod1 serving port1 @ 09/02/25 08:19:38.596
  STEP: Deleting pod pod1 in namespace services-4677 @ 09/02/25 08:19:38.597
  I0902 08:19:38.644898 16 wait.go:139] Waiting for service services-4677/multi-endpoint-test to have endpoints for ports [{portname2  pod2 101}]
  STEP: deleting pod2 serving port2 @ 09/02/25 08:19:38.67
  STEP: Deleting pod pod2 in namespace services-4677 @ 09/02/25 08:19:38.67
  I0902 08:19:38.719950 16 wait.go:65] Waiting for amount of service services-4677/multi-endpoint-test endpoints to be 0
  I0902 08:19:38.733853 16 wait.go:83] Unexpected number of Endpoints on Slices, got 1, expected 0
  I0902 08:19:39.779458 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-4677" for this suite. @ 09/02/25 08:19:39.793
• [9.619 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:460
  STEP: Creating a kubernetes client @ 09/02/25 08:19:39.813
  I0902 08:19:39.813295 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename resourcequota @ 09/02/25 08:19:39.815
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:19:39.86
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:19:39.866
  STEP: Counting existing ResourceQuota @ 09/02/25 08:19:39.872
  STEP: Creating a ResourceQuota @ 09/02/25 08:19:44.885
  STEP: Ensuring resource quota status is calculated @ 09/02/25 08:19:44.897
  I0902 08:19:46.929433 16 resource_quota.go:2495] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc0010c8f00>: 
          metadata:
            creationTimestamp: "2025-09-02T08:19:44Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: e2e.test
              operation: Update
              time: "2025-09-02T08:19:44Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
                  f:used:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: kube-controller-manager
              operation: Update
              subresource: status
              time: "2025-09-02T08:19:44Z"
            name: test-quota
            namespace: resourcequota-3426
            resourceVersion: "29650"
            uid: 69b481ca-6af3-4a0d-a973-bdf467569125
          spec:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
          status:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
            used:
              configmaps: "1"
              count/replicasets.apps: "0"
              cpu: "0"
              ephemeral-storage: "0"
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "0"
              gold.storageclass.storage.k8s.io/requests.storage: "0"
              memory: "0"
              persistentvolumeclaims: "0"
              pods: "0"
              replicationcontrollers: "0"
              requests.example.com/dongle: "0"
              requests.storage: "0"
              resourcequotas: "1"
              secrets: "0"
              services: "0"
              services.loadbalancers: "0"
              services.nodeports: "0"
  STEP: Creating a ReplicaSet @ 09/02/25 08:19:46.93
  STEP: Ensuring resource quota status captures replicaset creation @ 09/02/25 08:19:46.978
  I0902 08:19:46.997366 16 resource_quota.go:2495] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc0010c9540>: 
          metadata:
            creationTimestamp: "2025-09-02T08:19:44Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: e2e.test
              operation: Update
              time: "2025-09-02T08:19:44Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
                  f:used:
                    .: {}
                    f:configmaps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: kube-controller-manager
              operation: Update
              subresource: status
              time: "2025-09-02T08:19:44Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:used:
                    f:count/replicasets.apps: {}
              manager: kube-apiserver
              operation: Update
              subresource: status
              time: "2025-09-02T08:19:46Z"
            name: test-quota
            namespace: resourcequota-3426
            resourceVersion: "29676"
            uid: 69b481ca-6af3-4a0d-a973-bdf467569125
          spec:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
          status:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
            used:
              configmaps: "1"
              count/replicasets.apps: "1"
              cpu: "0"
              ephemeral-storage: "0"
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "0"
              gold.storageclass.storage.k8s.io/requests.storage: "0"
              memory: "0"
              persistentvolumeclaims: "0"
              pods: "0"
              replicationcontrollers: "0"
              requests.example.com/dongle: "0"
              requests.storage: "0"
              resourcequotas: "1"
              secrets: "0"
              services: "0"
              services.loadbalancers: "0"
              services.nodeports: "0"
  STEP: Deleting a ReplicaSet @ 09/02/25 08:19:46.999
  STEP: Ensuring resource quota status released usage @ 09/02/25 08:19:47.023
  I0902 08:19:49.043782 16 resource_quota.go:2495] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc0012ee280>: 
          metadata:
            creationTimestamp: "2025-09-02T08:19:44Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: e2e.test
              operation: Update
              time: "2025-09-02T08:19:44Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
                  f:used:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: kube-controller-manager
              operation: Update
              subresource: status
              time: "2025-09-02T08:19:47Z"
            name: test-quota
            namespace: resourcequota-3426
            resourceVersion: "29681"
            uid: 69b481ca-6af3-4a0d-a973-bdf467569125
          spec:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
          status:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
            used:
              configmaps: "1"
              count/replicasets.apps: "0"
              cpu: "0"
              ephemeral-storage: "0"
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "0"
              gold.storageclass.storage.k8s.io/requests.storage: "0"
              memory: "0"
              persistentvolumeclaims: "0"
              pods: "0"
              replicationcontrollers: "0"
              requests.example.com/dongle: "0"
              requests.storage: "0"
              resourcequotas: "1"
              secrets: "0"
              services: "0"
              services.loadbalancers: "0"
              services.nodeports: "0"
  I0902 08:19:49.045199 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-3426" for this suite. @ 09/02/25 08:19:49.054
• [9.257 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-network] ServiceCIDR and IPAddress API should support IPAddress API operations [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service_cidrs.go:209
  STEP: Creating a kubernetes client @ 09/02/25 08:19:49.072
  I0902 08:19:49.072048 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename servicecidr @ 09/02/25 08:19:49.075
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:19:49.102
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:19:49.108
  STEP: creating @ 09/02/25 08:19:49.114
  STEP: patching @ 09/02/25 08:19:49.136
  STEP: updating @ 09/02/25 08:19:49.148
  STEP: getting @ 09/02/25 08:19:49.165
  STEP: listing @ 09/02/25 08:19:49.172
  STEP: watching @ 09/02/25 08:19:49.179
  STEP: deleting @ 09/02/25 08:19:49.187
  STEP: deleting a collection @ 09/02/25 08:19:49.206
  I0902 08:19:49.238013 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "servicecidr-3492" for this suite. @ 09/02/25 08:19:49.245
• [0.195 seconds]
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:139
  STEP: Creating a kubernetes client @ 09/02/25 08:19:49.269
  I0902 08:19:49.269701 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename emptydir @ 09/02/25 08:19:49.273
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:19:49.312
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:19:49.319
  STEP: Creating a pod to test emptydir 0666 on tmpfs @ 09/02/25 08:19:49.324
  STEP: Saw pod success @ 09/02/25 08:19:53.39
  I0902 08:19:53.396493 16 output.go:207] Trying to get logs from node ietha7evai9i-2 pod pod-3d33a365-e09c-4ae6-9793-1392882c7ee5 container test-container: <nil>
  STEP: delete the pod @ 09/02/25 08:19:53.436
  I0902 08:19:53.473281 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-908" for this suite. @ 09/02/25 08:19:53.483
• [4.231 seconds]
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Update Demo should create and stop a replication controller [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:357
  STEP: Creating a kubernetes client @ 09/02/25 08:19:53.499
  I0902 08:19:53.499817 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename kubectl @ 09/02/25 08:19:53.502
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:19:53.528
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:19:53.533
  STEP: creating a replication controller @ 09/02/25 08:19:53.539
  I0902 08:19:53.539675 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-7104 create -f -'
  I0902 08:19:53.904994 16 builder.go:156] stderr: ""
  I0902 08:19:53.905403 16 builder.go:157] stdout: "replicationcontroller/update-demo-nautilus created\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 09/02/25 08:19:53.905
  I0902 08:19:53.906401 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-7104 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0902 08:19:54.143403 16 builder.go:156] stderr: ""
  I0902 08:19:54.144051 16 builder.go:157] stdout: "update-demo-nautilus-bhpq6 update-demo-nautilus-hwxgs "
  I0902 08:19:54.144361 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-7104 get pods update-demo-nautilus-bhpq6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0902 08:19:54.414194 16 builder.go:156] stderr: ""
  I0902 08:19:54.414265 16 builder.go:157] stdout: ""
  I0902 08:19:54.414302 16 kubectl.go:2537] update-demo-nautilus-bhpq6 is created but not running
  I0902 08:19:59.415383 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-7104 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0902 08:19:59.595650 16 builder.go:156] stderr: ""
  I0902 08:19:59.595750 16 builder.go:157] stdout: "update-demo-nautilus-bhpq6 update-demo-nautilus-hwxgs "
  I0902 08:19:59.596251 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-7104 get pods update-demo-nautilus-bhpq6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0902 08:19:59.780435 16 builder.go:156] stderr: ""
  I0902 08:19:59.780534 16 builder.go:157] stdout: "true"
  I0902 08:19:59.781330 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-7104 get pods update-demo-nautilus-bhpq6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I0902 08:19:59.958764 16 builder.go:156] stderr: ""
  I0902 08:19:59.958838 16 builder.go:157] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0902 08:19:59.958864 16 kubectl.go:2428] validating pod update-demo-nautilus-bhpq6
  I0902 08:20:00.001280 16 kubectl.go:2448] got data: {
    "image": "nautilus.jpg"
  }

  I0902 08:20:00.001391 16 kubectl.go:2453] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0902 08:20:00.001418 16 kubectl.go:2555] update-demo-nautilus-bhpq6 is verified up and running
  I0902 08:20:00.001687 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-7104 get pods update-demo-nautilus-hwxgs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0902 08:20:00.172427 16 builder.go:156] stderr: ""
  I0902 08:20:00.172994 16 builder.go:157] stdout: "true"
  I0902 08:20:00.173736 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-7104 get pods update-demo-nautilus-hwxgs -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I0902 08:20:00.353121 16 builder.go:156] stderr: ""
  I0902 08:20:00.353224 16 builder.go:157] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0902 08:20:00.353249 16 kubectl.go:2428] validating pod update-demo-nautilus-hwxgs
  I0902 08:20:00.371922 16 kubectl.go:2448] got data: {
    "image": "nautilus.jpg"
  }

  I0902 08:20:00.372188 16 kubectl.go:2453] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0902 08:20:00.372218 16 kubectl.go:2555] update-demo-nautilus-hwxgs is verified up and running
  STEP: using delete to clean up resources @ 09/02/25 08:20:00.372
  I0902 08:20:00.372673 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-7104 delete --grace-period=0 --force -f -'
  I0902 08:20:00.538634 16 builder.go:156] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0902 08:20:00.538826 16 builder.go:157] stdout: "replicationcontroller \"update-demo-nautilus\" force deleted from kubectl-7104 namespace\n"
  I0902 08:20:00.539184 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-7104 get rc,svc -l name=update-demo --no-headers'
  I0902 08:20:00.928404 16 builder.go:156] stderr: "No resources found in kubectl-7104 namespace.\n"
  I0902 08:20:00.929883 16 builder.go:157] stdout: ""
  I0902 08:20:00.931999 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-7104 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  I0902 08:20:01.137045 16 builder.go:156] stderr: ""
  I0902 08:20:01.137154 16 builder.go:157] stdout: ""
  I0902 08:20:01.137535 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-7104" for this suite. @ 09/02/25 08:20:01.147
• [7.664 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap should be consumable as environment variable names with various prefixes [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:253
  STEP: Creating a kubernetes client @ 09/02/25 08:20:01.163
  I0902 08:20:01.163937 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename configmap @ 09/02/25 08:20:01.168
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:20:01.198
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:20:01.205
  STEP: Creating configMap configmap-9846/configmap-test-fc735367-2792-4814-9f1e-154534f3ef94 @ 09/02/25 08:20:01.21
  STEP: Creating a pod to test consume configMaps @ 09/02/25 08:20:01.219
  STEP: Saw pod success @ 09/02/25 08:20:05.291
  I0902 08:20:05.330620 16 output.go:207] Trying to get logs from node ietha7evai9i-2 pod pod-configmaps-c4fb5239-6212-4aef-aee3-1240df238feb container env-test: <nil>
  STEP: delete the pod @ 09/02/25 08:20:05.357
  I0902 08:20:05.399326 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-9846" for this suite. @ 09/02/25 08:20:05.411
• [4.262 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2267
  STEP: Creating a kubernetes client @ 09/02/25 08:20:05.427
  I0902 08:20:05.427094 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename services @ 09/02/25 08:20:05.429
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:20:05.459
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:20:05.464
  STEP: creating service in namespace services-711 @ 09/02/25 08:20:05.469
  STEP: creating service affinity-nodeport in namespace services-711 @ 09/02/25 08:20:05.469
  I0902 08:20:05.525726 16 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:0, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:0, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition(nil), CollisionCount:(*int32)(nil)}
  I0902 08:20:07.534202 16 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:3, UpdatedReplicas:3, ReadyReplicas:2, AvailableReplicas:2, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.September, 2, 8, 20, 5, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 8, 20, 5, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.September, 2, 8, 20, 7, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 8, 20, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"affinity-nodeport-65758f6cfc\" is progressing."}}, CollisionCount:(*int32)(nil)}
  I0902 08:20:09.579414 16 resource.go:344] Creating new exec pod
  I0902 08:20:11.646737 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=services-711 exec execpod-affinityfqhxj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
  I0902 08:20:11.993270 16 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport (10.233.57.208) 80 port [tcp/http] succeeded!\n"
  I0902 08:20:11.993367 16 builder.go:157] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0902 08:20:11.994064 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=services-711 exec execpod-affinityfqhxj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.57.208 80'
  I0902 08:20:12.314085 16 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.57.208 80\nConnection to 10.233.57.208 80 port [tcp/http] succeeded!\n"
  I0902 08:20:12.314329 16 builder.go:157] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0902 08:20:12.314930 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=services-711 exec execpod-affinityfqhxj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.46 32741'
  I0902 08:20:12.615504 16 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.46 32741\nConnection to 192.168.121.46 32741 port [tcp/*] succeeded!\n"
  I0902 08:20:12.615871 16 builder.go:157] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0902 08:20:12.616824 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=services-711 exec execpod-affinityfqhxj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.25 32741'
  I0902 08:20:12.930042 16 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.25 32741\nConnection to 192.168.121.25 32741 port [tcp/*] succeeded!\n"
  I0902 08:20:12.930175 16 builder.go:157] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0902 08:20:12.931077 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=services-711 exec execpod-affinityfqhxj -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 --max-time 60 http://192.168.121.25:32741/ ; done'
  I0902 08:20:13.590029 16 builder.go:156] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.121.25:32741/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.121.25:32741/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.121.25:32741/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.121.25:32741/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.121.25:32741/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.121.25:32741/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.121.25:32741/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.121.25:32741/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.121.25:32741/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.121.25:32741/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.121.25:32741/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.121.25:32741/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.121.25:32741/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.121.25:32741/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.121.25:32741/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.121.25:32741/\n"
  I0902 08:20:13.590190 16 builder.go:157] stdout: "\naffinity-nodeport-65758f6cfc-h9lqd\naffinity-nodeport-65758f6cfc-h9lqd\naffinity-nodeport-65758f6cfc-h9lqd\naffinity-nodeport-65758f6cfc-h9lqd\naffinity-nodeport-65758f6cfc-h9lqd\naffinity-nodeport-65758f6cfc-h9lqd\naffinity-nodeport-65758f6cfc-h9lqd\naffinity-nodeport-65758f6cfc-h9lqd\naffinity-nodeport-65758f6cfc-h9lqd\naffinity-nodeport-65758f6cfc-h9lqd\naffinity-nodeport-65758f6cfc-h9lqd\naffinity-nodeport-65758f6cfc-h9lqd\naffinity-nodeport-65758f6cfc-h9lqd\naffinity-nodeport-65758f6cfc-h9lqd\naffinity-nodeport-65758f6cfc-h9lqd\naffinity-nodeport-65758f6cfc-h9lqd"
  I0902 08:20:13.590535 16 service.go:225] Received response from host: affinity-nodeport-65758f6cfc-h9lqd
  I0902 08:20:13.590864 16 service.go:225] Received response from host: affinity-nodeport-65758f6cfc-h9lqd
  I0902 08:20:13.591168 16 service.go:225] Received response from host: affinity-nodeport-65758f6cfc-h9lqd
  I0902 08:20:13.591410 16 service.go:225] Received response from host: affinity-nodeport-65758f6cfc-h9lqd
  I0902 08:20:13.591659 16 service.go:225] Received response from host: affinity-nodeport-65758f6cfc-h9lqd
  I0902 08:20:13.591957 16 service.go:225] Received response from host: affinity-nodeport-65758f6cfc-h9lqd
  I0902 08:20:13.592162 16 service.go:225] Received response from host: affinity-nodeport-65758f6cfc-h9lqd
  I0902 08:20:13.592207 16 service.go:225] Received response from host: affinity-nodeport-65758f6cfc-h9lqd
  I0902 08:20:13.592425 16 service.go:225] Received response from host: affinity-nodeport-65758f6cfc-h9lqd
  I0902 08:20:13.592468 16 service.go:225] Received response from host: affinity-nodeport-65758f6cfc-h9lqd
  I0902 08:20:13.592516 16 service.go:225] Received response from host: affinity-nodeport-65758f6cfc-h9lqd
  I0902 08:20:13.592786 16 service.go:225] Received response from host: affinity-nodeport-65758f6cfc-h9lqd
  I0902 08:20:13.593185 16 service.go:225] Received response from host: affinity-nodeport-65758f6cfc-h9lqd
  I0902 08:20:13.593908 16 service.go:225] Received response from host: affinity-nodeport-65758f6cfc-h9lqd
  I0902 08:20:13.594145 16 service.go:225] Received response from host: affinity-nodeport-65758f6cfc-h9lqd
  I0902 08:20:13.594402 16 service.go:225] Received response from host: affinity-nodeport-65758f6cfc-h9lqd
  I0902 08:20:13.595486 16 service.go:4469] Cleaning up the exec pod
  I0902 08:20:13.717419 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-711" for this suite. @ 09/02/25 08:20:13.732
• [8.397 seconds]
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1426
  STEP: Creating a kubernetes client @ 09/02/25 08:20:13.826
  I0902 08:20:13.826788 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename kubectl @ 09/02/25 08:20:13.836
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:20:13.877
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:20:13.888
  I0902 08:20:13.897061 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-5959 create -f -'
  I0902 08:20:14.262008 16 builder.go:156] stderr: ""
  I0902 08:20:14.262107 16 builder.go:157] stdout: "replicationcontroller/agnhost-primary created\n"
  I0902 08:20:14.262482 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-5959 create -f -'
  I0902 08:20:14.623199 16 builder.go:156] stderr: ""
  I0902 08:20:14.624127 16 builder.go:157] stdout: "service/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 09/02/25 08:20:14.624
  I0902 08:20:15.635652 16 framework.go:697] Selector matched 1 pods for map[app:agnhost]
  I0902 08:20:15.635737 16 framework.go:738] Found 0 / 1
  I0902 08:20:16.637605 16 framework.go:697] Selector matched 1 pods for map[app:agnhost]
  I0902 08:20:16.637887 16 framework.go:738] Found 1 / 1
  I0902 08:20:16.637990 16 framework.go:747] WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  I0902 08:20:16.647920 16 framework.go:697] Selector matched 1 pods for map[app:agnhost]
  I0902 08:20:16.648366 16 framework.go:770] ForEach: Found 1 pods from the filter.  Now looping through them.
  I0902 08:20:16.649925 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-5959 describe pod agnhost-primary-ggjc8'
  I0902 08:20:16.874140 16 builder.go:156] stderr: ""
  I0902 08:20:16.874853 16 builder.go:157] stdout: "Name:             agnhost-primary-ggjc8\nNamespace:        kubectl-5959\nPriority:         0\nService Account:  default\nNode:             ietha7evai9i-2/192.168.121.46\nStart Time:       Tue, 02 Sep 2025 08:20:14 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      <none>\nStatus:           Running\nIP:               10.233.66.114\nIPs:\n  IP:           10.233.66.114\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   cri-o://f1298d6c2094ea5ed7e8681ea9e9ae961353878ecdbf7f1d9c14d0897f1a365f\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.56\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:30ffacb713aad721881f1c11a768df228bfad3dc366d268e82b02fc43511dfa4\n    Port:           6379/TCP (agnhost-server)\n    Host Port:      0/TCP (agnhost-server)\n    State:          Running\n      Started:      Tue, 02 Sep 2025 08:20:15 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-h24gk (ro)\nConditions:\n  Type                        Status\n  PodReadyToStartContainers   True \n  Initialized                 True \n  Ready                       True \n  ContainersReady             True \n  PodScheduled                True \nVolumes:\n  kube-api-access-h24gk:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    Optional:                false\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  2s    default-scheduler  Successfully assigned kubectl-5959/agnhost-primary-ggjc8 to ietha7evai9i-2\n  Normal  Pulled     1s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.56\" already present on machine\n  Normal  Created    1s    kubelet            Created container: agnhost-primary\n  Normal  Started    1s    kubelet            Started container agnhost-primary\n"
  I0902 08:20:16.875457 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-5959 describe rc agnhost-primary'
  I0902 08:20:17.121995 16 builder.go:156] stderr: ""
  I0902 08:20:17.122190 16 builder.go:157] stdout: "Name:         agnhost-primary\nNamespace:    kubectl-5959\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:         registry.k8s.io/e2e-test-images/agnhost:2.56\n    Port:          6379/TCP (agnhost-server)\n    Host Port:     0/TCP (agnhost-server)\n    Environment:   <none>\n    Mounts:        <none>\n  Volumes:         <none>\n  Node-Selectors:  <none>\n  Tolerations:     <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: agnhost-primary-ggjc8\n"
  I0902 08:20:17.122614 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-5959 describe service agnhost-primary'
  I0902 08:20:17.341723 16 builder.go:156] stderr: ""
  I0902 08:20:17.341847 16 builder.go:157] stdout: "Name:                     agnhost-primary\nNamespace:                kubectl-5959\nLabels:                   app=agnhost\n                          role=primary\nAnnotations:              <none>\nSelector:                 app=agnhost,role=primary\nType:                     ClusterIP\nIP Family Policy:         SingleStack\nIP Families:              IPv4\nIP:                       10.233.31.206\nIPs:                      10.233.31.206\nPort:                     <unset>  6379/TCP\nTargetPort:               agnhost-server/TCP\nEndpoints:                10.233.66.114:6379\nSession Affinity:         None\nInternal Traffic Policy:  Cluster\nEvents:                   <none>\n"
  I0902 08:20:17.351132 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-5959 describe node ietha7evai9i-1'
  I0902 08:20:17.592290 16 builder.go:156] stderr: ""
  I0902 08:20:17.592486 16 builder.go:157] stdout: "Name:               ietha7evai9i-1\nRoles:              control-plane\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=ietha7evai9i-1\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/control-plane=\n                    node.kubernetes.io/exclude-from-external-load-balancers=\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Tue, 02 Sep 2025 06:11:14 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  ietha7evai9i-1\n  AcquireTime:     <unset>\n  RenewTime:       Tue, 02 Sep 2025 08:20:15 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Tue, 02 Sep 2025 06:13:51 +0000   Tue, 02 Sep 2025 06:13:51 +0000   CiliumIsUp                   Cilium is running on this node\n  MemoryPressure       False   Tue, 02 Sep 2025 08:16:56 +0000   Tue, 02 Sep 2025 06:17:54 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Tue, 02 Sep 2025 08:16:56 +0000   Tue, 02 Sep 2025 06:17:54 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Tue, 02 Sep 2025 08:16:56 +0000   Tue, 02 Sep 2025 06:17:54 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Tue, 02 Sep 2025 08:16:56 +0000   Tue, 02 Sep 2025 06:17:54 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  192.168.121.25\n  Hostname:    ietha7evai9i-1\nCapacity:\n  cpu:                2\n  ephemeral-storage:  115008636Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             8133132Ki\n  pods:               256\nAllocatable:\n  cpu:                1600m\n  ephemeral-storage:  111880401014\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             3283468Ki\n  pods:               256\nSystem Info:\n  Machine ID:                 2977c6c638924a289a57c657a77e8b80\n  System UUID:                2977c6c6-3892-4a28-9a57-c657a77e8b80\n  Boot ID:                    a97274d3-02fe-47df-abf8-9259972a3c6b\n  Kernel Version:             6.14.0-29-generic\n  OS Image:                   Ubuntu 24.04.3 LTS\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  cri-o://1.34.0\n  Kubelet Version:            v1.34.0\n  Kube-Proxy Version:         \nPodCIDR:                      10.233.64.0/24\nPodCIDRs:                     10.233.64.0/24\nNon-terminated Pods:          (8 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                 cilium-bn6l7                                               100m (6%)     0 (0%)      10Mi (0%)        0 (0%)         127m\n  kube-system                 cilium-node-init-qt8dx                                     100m (6%)     0 (0%)      100Mi (3%)       0 (0%)         127m\n  kube-system                 coredns-66bc5c9577-zh8kv                                   100m (6%)     0 (0%)      70Mi (2%)        170Mi (5%)     128m\n  kube-system                 kube-apiserver-ietha7evai9i-1                              250m (15%)    0 (0%)      0 (0%)           0 (0%)         128m\n  kube-system                 kube-controller-manager-ietha7evai9i-1                     200m (12%)    0 (0%)      0 (0%)           0 (0%)         128m\n  kube-system                 kube-proxy-9czjg                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         128m\n  kube-system                 kube-scheduler-ietha7evai9i-1                              100m (6%)     0 (0%)      0 (0%)           0 (0%)         128m\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-707d3c8598644e6c-hzzpm    0 (0%)        0 (0%)      0 (0%)           0 (0%)         50m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                850m (53%)  0 (0%)\n  memory             180Mi (5%)  170Mi (5%)\n  ephemeral-storage  0 (0%)      0 (0%)\n  hugepages-1Gi      0 (0%)      0 (0%)\n  hugepages-2Mi      0 (0%)      0 (0%)\nEvents:              <none>\n"
  I0902 08:20:17.592998 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-5959 describe namespace kubectl-5959'
  I0902 08:20:17.772075 16 builder.go:156] stderr: ""
  I0902 08:20:17.772186 16 builder.go:157] stdout: "Name:         kubectl-5959\nLabels:       e2e-framework=kubectl\n              e2e-run=aeecdebe-316c-45be-9858-11f08143cc7b\n              kubernetes.io/metadata.name=kubectl-5959\n              pod-security.kubernetes.io/audit=baseline\n              pod-security.kubernetes.io/enforce=baseline\n              pod-security.kubernetes.io/warn=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
  I0902 08:20:17.772839 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-5959" for this suite. @ 09/02/25 08:20:17.781
• [3.973 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:298
  STEP: Creating a kubernetes client @ 09/02/25 08:20:17.799
  I0902 08:20:17.799436 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename downward-api @ 09/02/25 08:20:17.803
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:20:17.84
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:20:17.846
  STEP: Creating a pod to test downward api env vars @ 09/02/25 08:20:17.851
  STEP: Saw pod success @ 09/02/25 08:20:21.907
  I0902 08:20:21.915002 16 output.go:207] Trying to get logs from node ietha7evai9i-3 pod downward-api-1761f711-d5e1-463c-b2f7-31845cdd5d4d container dapi-container: <nil>
  STEP: delete the pod @ 09/02/25 08:20:21.938
  I0902 08:20:21.974968 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-945" for this suite. @ 09/02/25 08:20:21.984
• [4.200 seconds]
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:74
  STEP: Creating a kubernetes client @ 09/02/25 08:20:21.999
  I0902 08:20:21.999635 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename configmap @ 09/02/25 08:20:22.003
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:20:22.035
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:20:22.044
  STEP: Creating configMap with name configmap-test-volume-3f490b04-f0c0-4b88-adbb-10d741398c48 @ 09/02/25 08:20:22.058
  STEP: Creating a pod to test consume configMaps @ 09/02/25 08:20:22.07
  STEP: Saw pod success @ 09/02/25 08:20:26.117
  I0902 08:20:26.125773 16 output.go:207] Trying to get logs from node ietha7evai9i-3 pod pod-configmaps-32129d68-fa15-447d-8b6f-22e599c16779 container agnhost-container: <nil>
  STEP: delete the pod @ 09/02/25 08:20:26.139
  I0902 08:20:26.179403 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-5506" for this suite. @ 09/02/25 08:20:26.197
• [4.217 seconds]
------------------------------
[sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Serial] [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:722
  STEP: Creating a kubernetes client @ 09/02/25 08:20:26.221
  I0902 08:20:26.221439 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename gc @ 09/02/25 08:20:26.227
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:20:26.257
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:20:26.266
  STEP: create the rc1 @ 09/02/25 08:20:26.294
  STEP: create the rc2 @ 09/02/25 08:20:26.304
  STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well @ 09/02/25 08:20:38.35
  STEP: delete the rc simpletest-rc-to-be-deleted @ 09/02/25 08:20:42.258
  STEP: wait for the rc to be deleted @ 09/02/25 08:20:42.277
  I0902 08:20:47.639322 16 garbage_collector.go:770] 92 pods remaining
  I0902 08:20:47.639418 16 garbage_collector.go:777] 69 pods has nil DeletionTimestamp
  I0902 08:20:47.639441 16 garbage_collector.go:778] 
  I0902 08:20:52.311096 16 garbage_collector.go:770] 68 pods remaining
  I0902 08:20:52.311167 16 garbage_collector.go:777] 50 pods has nil DeletionTimestamp
  I0902 08:20:52.311186 16 garbage_collector.go:778] 
  STEP: Gathering metrics @ 09/02/25 08:20:57.314
  I0902 08:20:57.539305 16 garbage_collector.go:273] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I0902 08:20:57.539738 16 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-22rqc" in namespace "gc-9071"
  I0902 08:20:57.578334 16 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-28jnn" in namespace "gc-9071"
  I0902 08:20:57.605876 16 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-2fvs6" in namespace "gc-9071"
  I0902 08:20:57.652112 16 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-2njqv" in namespace "gc-9071"
  I0902 08:20:57.695745 16 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-2wt4b" in namespace "gc-9071"
  I0902 08:20:57.739260 16 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-4mk4s" in namespace "gc-9071"
  I0902 08:20:57.822052 16 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-4pqq5" in namespace "gc-9071"
  I0902 08:20:57.903206 16 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-5jwrx" in namespace "gc-9071"
  I0902 08:20:57.945763 16 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-5khfk" in namespace "gc-9071"
  I0902 08:20:58.008100 16 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-6j825" in namespace "gc-9071"
  I0902 08:20:58.078734 16 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-6nqfm" in namespace "gc-9071"
  I0902 08:20:58.158982 16 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-6txb6" in namespace "gc-9071"
  I0902 08:20:58.260781 16 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-6vqdl" in namespace "gc-9071"
  I0902 08:20:58.345923 16 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-7flf7" in namespace "gc-9071"
  I0902 08:20:58.421088 16 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-7ljwz" in namespace "gc-9071"
  I0902 08:20:58.513236 16 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-7np5t" in namespace "gc-9071"
  I0902 08:20:58.579327 16 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-7z5b6" in namespace "gc-9071"
  I0902 08:20:58.662742 16 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-87vvd" in namespace "gc-9071"
  I0902 08:20:58.717316 16 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-89qk6" in namespace "gc-9071"
  I0902 08:20:58.795665 16 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-8qn28" in namespace "gc-9071"
  I0902 08:20:58.865746 16 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-8z5ph" in namespace "gc-9071"
  I0902 08:20:58.908704 16 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-95chg" in namespace "gc-9071"
  I0902 08:20:59.039946 16 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-9hslb" in namespace "gc-9071"
  I0902 08:20:59.101060 16 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-9mj8h" in namespace "gc-9071"
  I0902 08:20:59.167215 16 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-9wlkg" in namespace "gc-9071"
  I0902 08:20:59.377407 16 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-9ztmx" in namespace "gc-9071"
  I0902 08:20:59.485116 16 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-bljwm" in namespace "gc-9071"
  I0902 08:20:59.608213 16 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-bngvq" in namespace "gc-9071"
  I0902 08:20:59.674120 16 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-bqh9g" in namespace "gc-9071"
  I0902 08:20:59.752230 16 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-cf44m" in namespace "gc-9071"
  I0902 08:20:59.784904 16 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-cg6wr" in namespace "gc-9071"
  I0902 08:20:59.844150 16 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-cnh8z" in namespace "gc-9071"
  I0902 08:20:59.949204 16 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-csghz" in namespace "gc-9071"
  I0902 08:20:59.984819 16 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-d6mrk" in namespace "gc-9071"
  I0902 08:21:00.058813 16 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-dczvd" in namespace "gc-9071"
  I0902 08:21:00.143452 16 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-dj848" in namespace "gc-9071"
  I0902 08:21:00.199128 16 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-f5lkj" in namespace "gc-9071"
  I0902 08:21:00.244569 16 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-fhkz2" in namespace "gc-9071"
  I0902 08:21:00.313184 16 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-fqjsc" in namespace "gc-9071"
  I0902 08:21:00.520797 16 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-ftj65" in namespace "gc-9071"
  I0902 08:21:00.625172 16 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-gz9xz" in namespace "gc-9071"
  I0902 08:21:00.780374 16 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-h6hrg" in namespace "gc-9071"
  I0902 08:21:00.893403 16 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-h9jd8" in namespace "gc-9071"
  I0902 08:21:00.921737 16 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-j6wfx" in namespace "gc-9071"
  I0902 08:21:01.019224 16 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-jj26z" in namespace "gc-9071"
  I0902 08:21:01.094376 16 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-jkdc2" in namespace "gc-9071"
  I0902 08:21:01.151657 16 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-jkpvc" in namespace "gc-9071"
  I0902 08:21:01.242798 16 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-jwbdk" in namespace "gc-9071"
  I0902 08:21:01.491122 16 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-k8knj" in namespace "gc-9071"
  I0902 08:21:01.569534 16 delete.go:111] Deleting pod "simpletest-rc-to-be-deleted-km29j" in namespace "gc-9071"
  I0902 08:21:01.595018 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-9071" for this suite. @ 09/02/25 08:21:01.61
• [35.418 seconds]
------------------------------
SSS
------------------------------
[sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:114
  STEP: Creating a kubernetes client @ 09/02/25 08:21:01.643
  I0902 08:21:01.643487 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename replication-controller @ 09/02/25 08:21:01.649
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:21:01.677
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:21:01.689
  STEP: creating a ReplicationController @ 09/02/25 08:21:01.71
  STEP: waiting for RC to be added @ 09/02/25 08:21:01.731
  STEP: waiting for available Replicas @ 09/02/25 08:21:01.732
  STEP: patching ReplicationController @ 09/02/25 08:21:18.111
  STEP: waiting for RC to be modified @ 09/02/25 08:21:18.138
  STEP: patching ReplicationController status @ 09/02/25 08:21:18.143
  STEP: waiting for RC to be modified @ 09/02/25 08:21:18.16
  STEP: waiting for available Replicas @ 09/02/25 08:21:18.16
  STEP: fetching ReplicationController status @ 09/02/25 08:21:18.18
  STEP: patching ReplicationController scale @ 09/02/25 08:21:18.19
  STEP: waiting for RC to be modified @ 09/02/25 08:21:18.206
  STEP: waiting for ReplicationController's scale to be the max amount @ 09/02/25 08:21:18.207
  STEP: fetching ReplicationController; ensuring that it's patched @ 09/02/25 08:21:19.854
  STEP: updating ReplicationController status @ 09/02/25 08:21:19.861
  STEP: waiting for RC to be modified @ 09/02/25 08:21:19.876
  STEP: listing all ReplicationControllers @ 09/02/25 08:21:19.876
  STEP: checking that ReplicationController has expected values @ 09/02/25 08:21:19.887
  STEP: deleting ReplicationControllers by collection @ 09/02/25 08:21:19.887
  STEP: waiting for ReplicationController to have a DELETED watchEvent @ 09/02/25 08:21:19.923
  I0902 08:21:20.016897 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  E0902 08:21:20.017853      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Destroying namespace "replication-controller-4652" for this suite. @ 09/02/25 08:21:20.033
• [18.404 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:547
  STEP: Creating a kubernetes client @ 09/02/25 08:21:20.048
  I0902 08:21:20.048148 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename gc @ 09/02/25 08:21:20.051
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:21:20.086
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:21:20.097
  STEP: create the deployment @ 09/02/25 08:21:20.104
  I0902 08:21:20.118650      16 warnings.go:110] "Warning: metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]"
  STEP: Wait for the Deployment to create new ReplicaSet @ 09/02/25 08:21:20.118
  STEP: delete the deployment @ 09/02/25 08:21:20.649
  STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs @ 09/02/25 08:21:20.665
  E0902 08:21:21.018802      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 09/02/25 08:21:21.226
  I0902 08:21:21.534010 16 garbage_collector.go:273] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I0902 08:21:21.535264 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-741" for this suite. @ 09/02/25 08:21:21.545
• [1.518 seconds]
------------------------------
S
------------------------------
[sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:76
  STEP: Creating a kubernetes client @ 09/02/25 08:21:21.567
  I0902 08:21:21.567212 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename var-expansion @ 09/02/25 08:21:21.57
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:21:21.597
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:21:21.602
  STEP: Creating a pod to test substitution in container's command @ 09/02/25 08:21:21.61
  E0902 08:21:22.018764      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:21:23.019286      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:21:24.020654      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:21:25.021011      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/02/25 08:21:25.663
  I0902 08:21:25.676991 16 output.go:207] Trying to get logs from node ietha7evai9i-3 pod var-expansion-2ba82001-b3eb-46e4-adf8-1869be5de118 container dapi-container: <nil>
  STEP: delete the pod @ 09/02/25 08:21:25.697
  I0902 08:21:25.735128 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-5305" for this suite. @ 09/02/25 08:21:25.751
• [4.202 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:85
  STEP: Creating a kubernetes client @ 09/02/25 08:21:25.772
  I0902 08:21:25.772248 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename resourcequota @ 09/02/25 08:21:25.774
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:21:25.803
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:21:25.812
  STEP: Counting existing ResourceQuota @ 09/02/25 08:21:25.819
  E0902 08:21:26.021851      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:21:27.022050      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:21:28.022688      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:21:29.022872      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:21:30.023657      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 09/02/25 08:21:30.829
  STEP: Ensuring resource quota status is calculated @ 09/02/25 08:21:30.841
  E0902 08:21:31.024447      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:21:32.024748      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:21:32.867908 16 resource_quota.go:2495] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc00162f180>: 
          metadata:
            creationTimestamp: "2025-09-02T08:21:30Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: e2e.test
              operation: Update
              time: "2025-09-02T08:21:30Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
                  f:used:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: kube-controller-manager
              operation: Update
              subresource: status
              time: "2025-09-02T08:21:30Z"
            name: test-quota
            namespace: resourcequota-8394
            resourceVersion: "32084"
            uid: 36d11cf8-9325-4c60-832c-e9fc71436907
          spec:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
          status:
            hard:
              configmaps: "10"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
            used:
              configmaps: "1"
              count/replicasets.apps: "0"
              cpu: "0"
              ephemeral-storage: "0"
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "0"
              gold.storageclass.storage.k8s.io/requests.storage: "0"
              memory: "0"
              persistentvolumeclaims: "0"
              pods: "0"
              replicationcontrollers: "0"
              requests.example.com/dongle: "0"
              requests.storage: "0"
              resourcequotas: "1"
              secrets: "0"
              services: "0"
              services.loadbalancers: "0"
              services.nodeports: "0"
  I0902 08:21:32.869692 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-8394" for this suite. @ 09/02/25 08:21:32.882
• [7.128 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:57
  STEP: Creating a kubernetes client @ 09/02/25 08:21:32.904
  I0902 08:21:32.904133 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename projected @ 09/02/25 08:21:32.907
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:21:32.944
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:21:32.954
  STEP: Creating configMap with name projected-configmap-test-volume-e6297098-210c-4f6f-91ba-6396e1cb9ec3 @ 09/02/25 08:21:32.96
  STEP: Creating a pod to test consume configMaps @ 09/02/25 08:21:32.972
  E0902 08:21:33.025366      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:21:34.026021      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:21:35.026652      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:21:36.027045      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:21:37.027801      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/02/25 08:21:37.038
  I0902 08:21:37.048347 16 output.go:207] Trying to get logs from node ietha7evai9i-2 pod pod-projected-configmaps-2c8ff4ef-77c6-43e2-8e1f-302bcedd89b9 container agnhost-container: <nil>
  STEP: delete the pod @ 09/02/25 08:21:37.071
  I0902 08:21:37.114349 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1989" for this suite. @ 09/02/25 08:21:37.124
• [4.240 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:85
  STEP: Creating a kubernetes client @ 09/02/25 08:21:37.144
  I0902 08:21:37.144746 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename projected @ 09/02/25 08:21:37.147
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:21:37.179
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:21:37.186
  STEP: Creating a pod to test downward API volume plugin @ 09/02/25 08:21:37.192
  E0902 08:21:38.027959      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:21:39.028264      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:21:40.028205      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:21:41.028365      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:21:42.029015      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:21:43.029481      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/02/25 08:21:43.265
  I0902 08:21:43.287215 16 output.go:207] Trying to get logs from node ietha7evai9i-2 pod downwardapi-volume-c7a00909-c619-4635-8c01-57e2f12fce11 container client-container: <nil>
  STEP: delete the pod @ 09/02/25 08:21:43.318
  I0902 08:21:43.371465 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7538" for this suite. @ 09/02/25 08:21:43.384
• [6.258 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:89
  STEP: Creating a kubernetes client @ 09/02/25 08:21:43.403
  I0902 08:21:43.403251 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename projected @ 09/02/25 08:21:43.407
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:21:43.435
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:21:43.441
  STEP: Creating configMap with name projected-configmap-test-volume-map-1eab6164-d8b1-420a-b537-42478897d995 @ 09/02/25 08:21:43.448
  STEP: Creating a pod to test consume configMaps @ 09/02/25 08:21:43.46
  E0902 08:21:44.029723      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:21:45.030165      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:21:46.031148      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:21:47.032963      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/02/25 08:21:47.511
  I0902 08:21:47.520168 16 output.go:207] Trying to get logs from node ietha7evai9i-2 pod pod-projected-configmaps-5f4d4792-5af9-447a-8985-538ba4521c94 container agnhost-container: <nil>
  STEP: delete the pod @ 09/02/25 08:21:47.535
  I0902 08:21:47.579808 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1481" for this suite. @ 09/02/25 08:21:47.591
• [4.204 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:657
  STEP: Creating a kubernetes client @ 09/02/25 08:21:47.609
  I0902 08:21:47.609442 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename statefulset @ 09/02/25 08:21:47.612
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:21:47.642
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:21:47.649
  STEP: Creating service test in namespace statefulset-885 @ 09/02/25 08:21:47.655
  I0902 08:21:47.665084      16 warnings.go:110] "Warning: spec.SessionAffinity is ignored for headless services"
  STEP: Initializing watcher for selector baz=blah,foo=bar @ 09/02/25 08:21:47.666
  STEP: Creating stateful set ss in namespace statefulset-885 @ 09/02/25 08:21:47.675
  STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-885 @ 09/02/25 08:21:47.688
  I0902 08:21:47.778974 16 wait.go:54] Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
  E0902 08:21:48.033275      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:21:49.034021      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:21:50.034616      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:21:51.034470      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:21:52.034976      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:21:53.035280      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:21:54.036952      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:21:55.036521      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:21:56.036685      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:21:57.037000      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:21:57.705731 16 wait.go:54] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod @ 09/02/25 08:21:57.705
  I0902 08:21:57.714201 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=statefulset-885 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  E0902 08:21:58.037190      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:21:58.039774 16 builder.go:156] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0902 08:21:58.039874 16 builder.go:157] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0902 08:21:58.039954 16 rest.go:280] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0902 08:21:58.048124 16 wait.go:54] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
  E0902 08:21:59.038097      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:22:00.038275      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:22:01.039033      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:22:02.039852      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:22:03.040463      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:22:04.040903      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:22:05.041232      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:22:06.041372      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:22:07.042608      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:22:08.042074      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:22:08.054857 16 wait.go:54] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  I0902 08:22:08.054982 16 wait.go:109] Waiting for statefulset status.readyReplicas updated to 0
  I0902 08:22:08.157791 16 statefulset.go:2415] Verifying statefulset ss doesn't scale past 1 for another 9.999999326s
  E0902 08:22:09.042741      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:22:09.178497 16 statefulset.go:2415] Verifying statefulset ss doesn't scale past 1 for another 8.933163019s
  E0902 08:22:10.042884      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:22:10.189360 16 statefulset.go:2415] Verifying statefulset ss doesn't scale past 1 for another 7.911990804s
  E0902 08:22:11.043269      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:22:11.205905 16 statefulset.go:2415] Verifying statefulset ss doesn't scale past 1 for another 6.901949351s
  E0902 08:22:12.044397      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:22:12.225200 16 statefulset.go:2415] Verifying statefulset ss doesn't scale past 1 for another 5.885533121s
  E0902 08:22:13.044536      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:22:13.240316 16 statefulset.go:2415] Verifying statefulset ss doesn't scale past 1 for another 4.866916406s
  E0902 08:22:14.044642      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:22:14.251069 16 statefulset.go:2415] Verifying statefulset ss doesn't scale past 1 for another 3.851479566s
  E0902 08:22:15.045031      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:22:15.262275 16 statefulset.go:2415] Verifying statefulset ss doesn't scale past 1 for another 2.840124589s
  E0902 08:22:16.045324      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:22:16.273260 16 statefulset.go:2415] Verifying statefulset ss doesn't scale past 1 for another 1.8290534s
  E0902 08:22:17.046684      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:22:17.300935 16 statefulset.go:2415] Verifying statefulset ss doesn't scale past 1 for another 817.734558ms
  E0902 08:22:18.048175      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-885 @ 09/02/25 08:22:18.302
  I0902 08:22:18.319621 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=statefulset-885 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0902 08:22:18.663475 16 builder.go:156] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I0902 08:22:18.663825 16 builder.go:157] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0902 08:22:18.663866 16 rest.go:280] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I0902 08:22:18.679265 16 wait.go:44] Found 1 stateful pods, waiting for 3
  E0902 08:22:19.048018      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:22:20.048023      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:22:21.048409      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:22:22.051034      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:22:23.049517      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:22:24.049295      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:22:25.049955      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:22:26.049870      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:22:27.050229      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:22:28.050654      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:22:28.686030 16 wait.go:54] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  I0902 08:22:28.686216 16 wait.go:54] Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
  I0902 08:22:28.686255 16 wait.go:54] Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Verifying that stateful set ss was scaled up in order @ 09/02/25 08:22:28.686
  STEP: Scale down will halt with unhealthy stateful pod @ 09/02/25 08:22:28.687
  I0902 08:22:28.714615 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=statefulset-885 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0902 08:22:29.008957 16 builder.go:156] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0902 08:22:29.009117 16 builder.go:157] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0902 08:22:29.009167 16 rest.go:280] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0902 08:22:29.009665 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=statefulset-885 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  E0902 08:22:29.050827      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:22:29.323273 16 builder.go:156] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0902 08:22:29.323386 16 builder.go:157] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0902 08:22:29.323808 16 rest.go:280] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0902 08:22:29.324868 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=statefulset-885 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0902 08:22:29.683192 16 builder.go:156] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0902 08:22:29.683747 16 builder.go:157] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0902 08:22:29.683984 16 rest.go:280] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0902 08:22:29.684056 16 wait.go:109] Waiting for statefulset status.readyReplicas updated to 0
  I0902 08:22:29.692645 16 wait.go:122] Waiting for statefulset status.readyReplicas to become 0, currently 2
  E0902 08:22:30.052290      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:22:31.052689      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:22:32.052875      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:22:33.053299      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:22:34.053850      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:22:35.054487      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:22:36.055171      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:22:37.055864      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:22:38.056344      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:22:39.057055      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:22:39.709803 16 wait.go:54] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  I0902 08:22:39.710698 16 wait.go:54] Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
  I0902 08:22:39.710847 16 wait.go:54] Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
  I0902 08:22:39.812379 16 statefulset.go:2415] Verifying statefulset ss doesn't scale past 3 for another 9.999999326s
  E0902 08:22:40.057533      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:22:40.828177 16 statefulset.go:2415] Verifying statefulset ss doesn't scale past 3 for another 8.925635602s
  E0902 08:22:41.057952      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:22:41.842957 16 statefulset.go:2415] Verifying statefulset ss doesn't scale past 3 for another 7.911116737s
  E0902 08:22:42.059165      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:22:42.859375 16 statefulset.go:2415] Verifying statefulset ss doesn't scale past 3 for another 6.896125703s
  E0902 08:22:43.059895      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:22:43.874291 16 statefulset.go:2415] Verifying statefulset ss doesn't scale past 3 for another 5.879892169s
  E0902 08:22:44.060448      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:22:44.886183 16 statefulset.go:2415] Verifying statefulset ss doesn't scale past 3 for another 4.864325005s
  E0902 08:22:45.060906      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:22:45.897048 16 statefulset.go:2415] Verifying statefulset ss doesn't scale past 3 for another 3.852546634s
  E0902 08:22:46.062024      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:22:46.913298 16 statefulset.go:2415] Verifying statefulset ss doesn't scale past 3 for another 2.84172085s
  E0902 08:22:47.063013      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:22:47.921854 16 statefulset.go:2415] Verifying statefulset ss doesn't scale past 3 for another 1.825723379s
  E0902 08:22:48.063663      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:22:48.934088 16 statefulset.go:2415] Verifying statefulset ss doesn't scale past 3 for another 817.141487ms
  E0902 08:22:49.063881      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-885 @ 09/02/25 08:22:49.934
  I0902 08:22:49.956187 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=statefulset-885 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  E0902 08:22:50.064341      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:22:50.228733 16 builder.go:156] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I0902 08:22:50.229840 16 builder.go:157] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0902 08:22:50.229888 16 rest.go:280] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I0902 08:22:50.230826 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=statefulset-885 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0902 08:22:50.562067 16 builder.go:156] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I0902 08:22:50.562325 16 builder.go:157] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0902 08:22:50.562356 16 rest.go:280] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I0902 08:22:50.562800 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=statefulset-885 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0902 08:22:50.826093 16 builder.go:156] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I0902 08:22:50.826171 16 builder.go:157] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0902 08:22:50.826216 16 rest.go:280] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I0902 08:22:50.826266 16 rest.go:153] Scaling statefulset ss to 0
  E0902 08:22:51.065375      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:22:52.066057      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:22:53.067034      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:22:54.068675      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:22:55.068709      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:22:56.068779      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:22:57.069679      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:22:58.070950      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:22:59.071296      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:23:00.072255      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Verifying that stateful set ss was scaled down in reverse order @ 09/02/25 08:23:00.847
  I0902 08:23:00.848394 16 statefulset.go:136] Deleting all statefulset in ns statefulset-885
  I0902 08:23:00.859855 16 rest.go:153] Scaling statefulset ss to 0
  I0902 08:23:00.877121 16 wait.go:159] Waiting for statefulset status.replicas updated to 0
  I0902 08:23:00.885813 16 rest.go:91] Deleting statefulset ss
  I0902 08:23:00.915500 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-885" for this suite. @ 09/02/25 08:23:00.928
• [73.338 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/discovery.go:126
  STEP: Creating a kubernetes client @ 09/02/25 08:23:00.948
  I0902 08:23:00.948691 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename discovery @ 09/02/25 08:23:00.953
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:23:00.992
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:23:00.999
  STEP: Setting up server cert @ 09/02/25 08:23:01.01
  E0902 08:23:01.072646      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:23:02.072935      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:23:02.311646 16 discovery.go:139] Checking APIGroup: apiregistration.k8s.io
  I0902 08:23:02.314895 16 discovery.go:147] PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
  I0902 08:23:02.314962 16 discovery.go:148] Versions found [{apiregistration.k8s.io/v1 v1}]
  I0902 08:23:02.314984 16 discovery.go:154] apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
  I0902 08:23:02.314999 16 discovery.go:139] Checking APIGroup: apps
  I0902 08:23:02.317186 16 discovery.go:147] PreferredVersion.GroupVersion: apps/v1
  I0902 08:23:02.317774 16 discovery.go:148] Versions found [{apps/v1 v1}]
  I0902 08:23:02.317830 16 discovery.go:154] apps/v1 matches apps/v1
  I0902 08:23:02.317849 16 discovery.go:139] Checking APIGroup: events.k8s.io
  I0902 08:23:02.319530 16 discovery.go:147] PreferredVersion.GroupVersion: events.k8s.io/v1
  I0902 08:23:02.320069 16 discovery.go:148] Versions found [{events.k8s.io/v1 v1}]
  I0902 08:23:02.320097 16 discovery.go:154] events.k8s.io/v1 matches events.k8s.io/v1
  I0902 08:23:02.320139 16 discovery.go:139] Checking APIGroup: authentication.k8s.io
  I0902 08:23:02.322023 16 discovery.go:147] PreferredVersion.GroupVersion: authentication.k8s.io/v1
  I0902 08:23:02.322398 16 discovery.go:148] Versions found [{authentication.k8s.io/v1 v1}]
  I0902 08:23:02.322423 16 discovery.go:154] authentication.k8s.io/v1 matches authentication.k8s.io/v1
  I0902 08:23:02.322439 16 discovery.go:139] Checking APIGroup: authorization.k8s.io
  I0902 08:23:02.324321 16 discovery.go:147] PreferredVersion.GroupVersion: authorization.k8s.io/v1
  I0902 08:23:02.324798 16 discovery.go:148] Versions found [{authorization.k8s.io/v1 v1}]
  I0902 08:23:02.324823 16 discovery.go:154] authorization.k8s.io/v1 matches authorization.k8s.io/v1
  I0902 08:23:02.324861 16 discovery.go:139] Checking APIGroup: autoscaling
  I0902 08:23:02.326623 16 discovery.go:147] PreferredVersion.GroupVersion: autoscaling/v2
  I0902 08:23:02.326967 16 discovery.go:148] Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1}]
  I0902 08:23:02.326992 16 discovery.go:154] autoscaling/v2 matches autoscaling/v2
  I0902 08:23:02.327431 16 discovery.go:139] Checking APIGroup: batch
  I0902 08:23:02.330954 16 discovery.go:147] PreferredVersion.GroupVersion: batch/v1
  I0902 08:23:02.331032 16 discovery.go:148] Versions found [{batch/v1 v1}]
  I0902 08:23:02.331050 16 discovery.go:154] batch/v1 matches batch/v1
  I0902 08:23:02.331078 16 discovery.go:139] Checking APIGroup: certificates.k8s.io
  I0902 08:23:02.336483 16 discovery.go:147] PreferredVersion.GroupVersion: certificates.k8s.io/v1
  I0902 08:23:02.336538 16 discovery.go:148] Versions found [{certificates.k8s.io/v1 v1}]
  I0902 08:23:02.336586 16 discovery.go:154] certificates.k8s.io/v1 matches certificates.k8s.io/v1
  I0902 08:23:02.336604 16 discovery.go:139] Checking APIGroup: networking.k8s.io
  I0902 08:23:02.346580 16 discovery.go:147] PreferredVersion.GroupVersion: networking.k8s.io/v1
  I0902 08:23:02.346646 16 discovery.go:148] Versions found [{networking.k8s.io/v1 v1}]
  I0902 08:23:02.346676 16 discovery.go:154] networking.k8s.io/v1 matches networking.k8s.io/v1
  I0902 08:23:02.346702 16 discovery.go:139] Checking APIGroup: policy
  I0902 08:23:02.348903 16 discovery.go:147] PreferredVersion.GroupVersion: policy/v1
  I0902 08:23:02.348964 16 discovery.go:148] Versions found [{policy/v1 v1}]
  I0902 08:23:02.348981 16 discovery.go:154] policy/v1 matches policy/v1
  I0902 08:23:02.349015 16 discovery.go:139] Checking APIGroup: rbac.authorization.k8s.io
  I0902 08:23:02.350754 16 discovery.go:147] PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
  I0902 08:23:02.351224 16 discovery.go:148] Versions found [{rbac.authorization.k8s.io/v1 v1}]
  I0902 08:23:02.351269 16 discovery.go:154] rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
  I0902 08:23:02.351291 16 discovery.go:139] Checking APIGroup: storage.k8s.io
  I0902 08:23:02.353288 16 discovery.go:147] PreferredVersion.GroupVersion: storage.k8s.io/v1
  I0902 08:23:02.353389 16 discovery.go:148] Versions found [{storage.k8s.io/v1 v1}]
  I0902 08:23:02.353434 16 discovery.go:154] storage.k8s.io/v1 matches storage.k8s.io/v1
  I0902 08:23:02.353473 16 discovery.go:139] Checking APIGroup: admissionregistration.k8s.io
  I0902 08:23:02.355646 16 discovery.go:147] PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
  I0902 08:23:02.355698 16 discovery.go:148] Versions found [{admissionregistration.k8s.io/v1 v1}]
  I0902 08:23:02.355879 16 discovery.go:154] admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
  I0902 08:23:02.356137 16 discovery.go:139] Checking APIGroup: apiextensions.k8s.io
  I0902 08:23:02.358910 16 discovery.go:147] PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
  I0902 08:23:02.358985 16 discovery.go:148] Versions found [{apiextensions.k8s.io/v1 v1}]
  I0902 08:23:02.359020 16 discovery.go:154] apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
  I0902 08:23:02.359051 16 discovery.go:139] Checking APIGroup: scheduling.k8s.io
  I0902 08:23:02.362215 16 discovery.go:147] PreferredVersion.GroupVersion: scheduling.k8s.io/v1
  I0902 08:23:02.362298 16 discovery.go:148] Versions found [{scheduling.k8s.io/v1 v1}]
  I0902 08:23:02.362318 16 discovery.go:154] scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
  I0902 08:23:02.362647 16 discovery.go:139] Checking APIGroup: coordination.k8s.io
  I0902 08:23:02.365701 16 discovery.go:147] PreferredVersion.GroupVersion: coordination.k8s.io/v1
  I0902 08:23:02.366218 16 discovery.go:148] Versions found [{coordination.k8s.io/v1 v1}]
  I0902 08:23:02.366540 16 discovery.go:154] coordination.k8s.io/v1 matches coordination.k8s.io/v1
  I0902 08:23:02.366584 16 discovery.go:139] Checking APIGroup: node.k8s.io
  I0902 08:23:02.368337 16 discovery.go:147] PreferredVersion.GroupVersion: node.k8s.io/v1
  I0902 08:23:02.368459 16 discovery.go:148] Versions found [{node.k8s.io/v1 v1}]
  I0902 08:23:02.368493 16 discovery.go:154] node.k8s.io/v1 matches node.k8s.io/v1
  I0902 08:23:02.368521 16 discovery.go:139] Checking APIGroup: discovery.k8s.io
  I0902 08:23:02.371390 16 discovery.go:147] PreferredVersion.GroupVersion: discovery.k8s.io/v1
  I0902 08:23:02.371443 16 discovery.go:148] Versions found [{discovery.k8s.io/v1 v1}]
  I0902 08:23:02.371461 16 discovery.go:154] discovery.k8s.io/v1 matches discovery.k8s.io/v1
  I0902 08:23:02.371476 16 discovery.go:139] Checking APIGroup: resource.k8s.io
  I0902 08:23:02.374822 16 discovery.go:147] PreferredVersion.GroupVersion: resource.k8s.io/v1
  I0902 08:23:02.374888 16 discovery.go:148] Versions found [{resource.k8s.io/v1 v1}]
  I0902 08:23:02.374910 16 discovery.go:154] resource.k8s.io/v1 matches resource.k8s.io/v1
  I0902 08:23:02.374926 16 discovery.go:139] Checking APIGroup: flowcontrol.apiserver.k8s.io
  I0902 08:23:02.377920 16 discovery.go:147] PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1
  I0902 08:23:02.377970 16 discovery.go:148] Versions found [{flowcontrol.apiserver.k8s.io/v1 v1}]
  I0902 08:23:02.377989 16 discovery.go:154] flowcontrol.apiserver.k8s.io/v1 matches flowcontrol.apiserver.k8s.io/v1
  I0902 08:23:02.378003 16 discovery.go:139] Checking APIGroup: cilium.io
  I0902 08:23:02.382360 16 discovery.go:147] PreferredVersion.GroupVersion: cilium.io/v2
  I0902 08:23:02.382537 16 discovery.go:148] Versions found [{cilium.io/v2 v2} {cilium.io/v2alpha1 v2alpha1}]
  I0902 08:23:02.382636 16 discovery.go:154] cilium.io/v2 matches cilium.io/v2
  I0902 08:23:02.382929 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "discovery-4353" for this suite. @ 09/02/25 08:23:02.396
• [1.460 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:196
  STEP: Creating a kubernetes client @ 09/02/25 08:23:02.411
  I0902 08:23:02.411719 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename crd-publish-openapi @ 09/02/25 08:23:02.414
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:23:02.443
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:23:02.448
  I0902 08:23:02.455581 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  E0902 08:23:03.073656      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:23:04.074637      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 09/02/25 08:23:04.82
  I0902 08:23:04.821259 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=crd-publish-openapi-8904 --namespace=crd-publish-openapi-8904 create -f -'
  E0902 08:23:05.074802      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:23:05.210854 16 builder.go:156] stderr: ""
  I0902 08:23:05.210962 16 builder.go:157] stdout: "e2e-test-crd-publish-openapi-8904-3585-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
  I0902 08:23:05.212268 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=crd-publish-openapi-8904 --namespace=crd-publish-openapi-8904 delete e2e-test-crd-publish-openapi-8904-3585-crds test-cr'
  I0902 08:23:05.594836 16 builder.go:156] stderr: ""
  I0902 08:23:05.594968 16 builder.go:157] stdout: "e2e-test-crd-publish-openapi-8904-3585-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted from crd-publish-openapi-8904 namespace\n"
  I0902 08:23:05.595171 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=crd-publish-openapi-8904 --namespace=crd-publish-openapi-8904 apply -f -'
  I0902 08:23:05.791581 16 builder.go:156] stderr: ""
  I0902 08:23:05.791739 16 builder.go:157] stdout: "e2e-test-crd-publish-openapi-8904-3585-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
  I0902 08:23:05.792451 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=crd-publish-openapi-8904 --namespace=crd-publish-openapi-8904 delete e2e-test-crd-publish-openapi-8904-3585-crds test-cr'
  I0902 08:23:06.004430 16 builder.go:156] stderr: ""
  I0902 08:23:06.004524 16 builder.go:157] stdout: "e2e-test-crd-publish-openapi-8904-3585-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted from crd-publish-openapi-8904 namespace\n"
  STEP: kubectl explain works to explain CR @ 09/02/25 08:23:06.004
  I0902 08:23:06.004899 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=crd-publish-openapi-8904 explain e2e-test-crd-publish-openapi-8904-3585-crds'
  E0902 08:23:06.075040      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:23:06.220591 16 builder.go:156] stderr: ""
  I0902 08:23:06.220717 16 builder.go:157] stdout: "GROUP:      crd-publish-openapi-test-unknown-at-root.example.com\nKIND:       e2e-test-crd-publish-openapi-8904-3585-crd\nVERSION:    v1\n\nDESCRIPTION:\n    preserve-unknown-properties at root for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Waldo\n\n  status\t<Object>\n    Status of Waldo\n\n\n"
  E0902 08:23:07.075640      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:23:08.076219      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:23:09.076513      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:23:09.361293 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-8904" for this suite. @ 09/02/25 08:23:09.383
• [6.991 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:69
  STEP: Creating a kubernetes client @ 09/02/25 08:23:09.404
  I0902 08:23:09.404279 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename subpath @ 09/02/25 08:23:09.407
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:23:09.437
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:23:09.447
  STEP: Setting up data @ 09/02/25 08:23:09.454
  STEP: Creating pod pod-subpath-test-configmap-bt92 @ 09/02/25 08:23:09.481
  STEP: Creating a pod to test atomic-volume-subpath @ 09/02/25 08:23:09.481
  E0902 08:23:10.076782      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:23:11.076975      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:23:12.077531      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:23:13.077983      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:23:14.079095      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:23:15.080089      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:23:16.079886      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:23:17.080650      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:23:18.082084      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:23:19.082822      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:23:20.083093      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:23:21.083827      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:23:22.084371      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:23:23.084974      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:23:24.085523      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:23:25.086018      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:23:26.087017      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:23:27.087489      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:23:28.088435      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:23:29.088778      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:23:30.089268      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:23:31.089494      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:23:32.090789      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:23:33.091454      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/02/25 08:23:33.651
  I0902 08:23:33.660129 16 output.go:207] Trying to get logs from node ietha7evai9i-2 pod pod-subpath-test-configmap-bt92 container test-container-subpath-configmap-bt92: <nil>
  STEP: delete the pod @ 09/02/25 08:23:33.727
  STEP: Deleting pod pod-subpath-test-configmap-bt92 @ 09/02/25 08:23:33.775
  I0902 08:23:33.775172 16 delete.go:78] Deleting pod "pod-subpath-test-configmap-bt92" in namespace "subpath-7659"
  I0902 08:23:33.782918 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-7659" for this suite. @ 09/02/25 08:23:33.795
• [24.410 seconds]
------------------------------
[sig-api-machinery] OrderedNamespaceDeletion namespace deletion should delete pod first [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:488
  STEP: Creating a kubernetes client @ 09/02/25 08:23:33.814
  I0902 08:23:33.814162 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename namespacedeletion @ 09/02/25 08:23:33.822
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:23:33.88
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:23:33.887
  STEP: Creating a test namespace @ 09/02/25 08:23:33.892
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:23:33.944
  STEP: Creating a pod with finalizer in the namespace @ 09/02/25 08:23:33.954
  STEP: Waiting for the pod to have running status @ 09/02/25 08:23:33.982
  E0902 08:23:34.091935      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:23:35.092022      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Creating a configmap "test-configmap" in namespace "nsdeletetest-8966" @ 09/02/25 08:23:36.01
  STEP: Deleting the namespace @ 09/02/25 08:23:36.021
  STEP: wait until namespace controller had time to process @ 09/02/25 08:23:36.034
  I0902 08:23:36.043698 16 namespace.go:568] Namespace "nsdeletetest-8966" does not yet have a NamespaceDeletionContentFailure condition, retrying...
  E0902 08:23:36.092445      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:23:37.092926      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:23:38.043726 16 namespace.go:568] Namespace "nsdeletetest-8966" does not yet have a NamespaceDeletionContentFailure condition, retrying...
  E0902 08:23:38.092952      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:23:39.095092      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:23:40.043955 16 namespace.go:568] Namespace "nsdeletetest-8966" does not yet have a NamespaceDeletionContentFailure condition, retrying...
  E0902 08:23:40.094267      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:23:41.094958      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: the pod should be deleted before processing deletion for other resources @ 09/02/25 08:23:42.044
  STEP: Removing finalizer from pod "test-pod" in namespace "nsdeletetest-8966" @ 09/02/25 08:23:42.062
  E0902 08:23:42.095508      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Waiting for the pod to not be present in the namespace @ 09/02/25 08:23:42.114
  E0902 08:23:43.095996      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:23:44.097080      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Waiting for the namespace to be removed. @ 09/02/25 08:23:44.136
  E0902 08:23:45.097444      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:23:46.097695      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:23:47.097816      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:23:47.147454 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespacedeletion-9813" for this suite. @ 09/02/25 08:23:47.159
  STEP: Destroying namespace "nsdeletetest-8966" for this suite. @ 09/02/25 08:23:47.177
  I0902 08:23:47.189169 16 framework.go:370] Namespace nsdeletetest-8966 was already deleted
• [13.376 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance] [sig-scheduling, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/limit_range.go:62
  STEP: Creating a kubernetes client @ 09/02/25 08:23:47.193
  I0902 08:23:47.193318 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename limitrange @ 09/02/25 08:23:47.196
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:23:47.219
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:23:47.226
  STEP: Creating a LimitRange @ 09/02/25 08:23:47.232
  STEP: Setting up watch @ 09/02/25 08:23:47.233
  STEP: Submitting a LimitRange @ 09/02/25 08:23:47.341
  STEP: Verifying LimitRange creation was observed @ 09/02/25 08:23:47.355
  STEP: Fetching the LimitRange to ensure it has proper values @ 09/02/25 08:23:47.355
  I0902 08:23:47.363462 16 limit_range.go:355] Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
  I0902 08:23:47.363643 16 limit_range.go:360] Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Creating a Pod with no resource requirements @ 09/02/25 08:23:47.363
  STEP: Ensuring Pod has resource requirements applied from LimitRange @ 09/02/25 08:23:47.375
  I0902 08:23:47.386322 16 limit_range.go:355] Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
  I0902 08:23:47.386430 16 limit_range.go:360] Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Creating a Pod with partial resource requirements @ 09/02/25 08:23:47.386
  STEP: Ensuring Pod has merged resource requirements applied from LimitRange @ 09/02/25 08:23:47.399
  I0902 08:23:47.406246 16 limit_range.go:355] Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
  I0902 08:23:47.406519 16 limit_range.go:360] Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Failing to create a Pod with less than min resources @ 09/02/25 08:23:47.406
  STEP: Failing to create a Pod with more than max resources @ 09/02/25 08:23:47.412
  STEP: Updating a LimitRange @ 09/02/25 08:23:47.418
  STEP: Verifying LimitRange updating is effective @ 09/02/25 08:23:47.44
  E0902 08:23:48.097933      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:23:49.098230      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Creating a Pod with less than former min resources @ 09/02/25 08:23:49.448
  STEP: Failing to create a Pod with more than max resources @ 09/02/25 08:23:49.461
  STEP: Deleting a LimitRange @ 09/02/25 08:23:49.468
  STEP: Verifying the LimitRange was deleted @ 09/02/25 08:23:49.508
  E0902 08:23:50.098419      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:23:51.098806      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:23:52.100641      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:23:53.099987      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:23:54.100362      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:23:54.518474 16 limit_range.go:211] limitRange is already deleted
  STEP: Creating a Pod with more than former max resources @ 09/02/25 08:23:54.518
  I0902 08:23:54.537620 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "limitrange-3244" for this suite. @ 09/02/25 08:23:54.554
• [7.383 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:115
  STEP: Creating a kubernetes client @ 09/02/25 08:23:54.576
  I0902 08:23:54.576606 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename var-expansion @ 09/02/25 08:23:54.578
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:23:54.608
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:23:54.619
  STEP: Creating a pod to test substitution in volume subpath @ 09/02/25 08:23:54.623
  E0902 08:23:55.100672      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:23:56.100915      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:23:57.101353      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:23:58.102522      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/02/25 08:23:58.683
  I0902 08:23:58.697731 16 output.go:207] Trying to get logs from node ietha7evai9i-2 pod var-expansion-14dcbc59-d923-41c6-a39d-a20be1a80915 container dapi-container: <nil>
  STEP: delete the pod @ 09/02/25 08:23:58.721
  I0902 08:23:58.768924 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-6152" for this suite. @ 09/02/25 08:23:58.782
• [4.226 seconds]
------------------------------
[sig-network] Ingress API should support creating Ingress API operations [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/ingress.go:55
  STEP: Creating a kubernetes client @ 09/02/25 08:23:58.803
  I0902 08:23:58.803279 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename ingress @ 09/02/25 08:23:58.807
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:23:58.84
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:23:58.848
  STEP: getting /apis @ 09/02/25 08:23:58.856
  STEP: getting /apis/networking.k8s.io @ 09/02/25 08:23:58.865
  STEP: getting /apis/networking.k8s.iov1 @ 09/02/25 08:23:58.869
  STEP: creating @ 09/02/25 08:23:58.872
  STEP: getting @ 09/02/25 08:23:58.907
  STEP: listing @ 09/02/25 08:23:58.914
  STEP: watching @ 09/02/25 08:23:58.923
  I0902 08:23:58.923727 16 ingress.go:186] starting watch
  STEP: cluster-wide listing @ 09/02/25 08:23:58.925
  STEP: cluster-wide watching @ 09/02/25 08:23:58.931
  I0902 08:23:58.932588 16 ingress.go:198] starting watch
  STEP: patching @ 09/02/25 08:23:58.935
  STEP: updating @ 09/02/25 08:23:58.946
  I0902 08:23:58.964694 16 ingress.go:221] waiting for watch events with expected annotations
  I0902 08:23:58.964788 16 ingress.go:234] saw patched and updated annotations
  STEP: patching /status @ 09/02/25 08:23:58.964
  STEP: updating /status @ 09/02/25 08:23:58.975
  STEP: get /status @ 09/02/25 08:23:58.992
  STEP: deleting @ 09/02/25 08:23:59.001
  STEP: deleting a collection @ 09/02/25 08:23:59.026
  I0902 08:23:59.060180 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ingress-9441" for this suite. @ 09/02/25 08:23:59.07
• [0.283 seconds]
------------------------------
[sig-apps] ReplicationController should adopt matching pods on creation [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:96
  STEP: Creating a kubernetes client @ 09/02/25 08:23:59.087
  I0902 08:23:59.087645 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename replication-controller @ 09/02/25 08:23:59.09
  E0902 08:23:59.103514      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:23:59.12
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:23:59.125
  STEP: Given a Pod with a 'name' label pod-adoption is created @ 09/02/25 08:23:59.132
  E0902 08:24:00.104467      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:24:01.104065      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: When a replication controller with a matching selector is created @ 09/02/25 08:24:01.187
  STEP: Then the orphan pod is adopted @ 09/02/25 08:24:01.211
  E0902 08:24:02.104828      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:24:02.237928 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-8806" for this suite. @ 09/02/25 08:24:02.249
• [3.182 seconds]
------------------------------
S
------------------------------
[sig-network] Service endpoints latency should not be very high [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service_latency.go:60
  STEP: Creating a kubernetes client @ 09/02/25 08:24:02.269
  I0902 08:24:02.270038 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename svc-latency @ 09/02/25 08:24:02.272
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:24:02.302
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:24:02.313
  I0902 08:24:02.321106 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  I0902 08:24:02.347100 16 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:0, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:0, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition(nil), CollisionCount:(*int32)(nil)}
  E0902 08:24:03.105128      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:24:04.105198      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:24:04.500210 16 service_latency.go:356] Created: latency-svc-wnthl
  I0902 08:24:04.528594 16 service_latency.go:363] Got endpoints: latency-svc-wnthl [66.686936ms]
  I0902 08:24:04.556507 16 service_latency.go:356] Created: latency-svc-tjbbh
  I0902 08:24:04.573242 16 service_latency.go:363] Got endpoints: latency-svc-tjbbh [43.870806ms]
  I0902 08:24:04.580053 16 service_latency.go:356] Created: latency-svc-rpjsw
  I0902 08:24:04.596605 16 service_latency.go:356] Created: latency-svc-br6h7
  I0902 08:24:04.606141 16 service_latency.go:363] Got endpoints: latency-svc-rpjsw [74.985991ms]
  I0902 08:24:04.629899 16 service_latency.go:356] Created: latency-svc-92jjq
  I0902 08:24:04.630032 16 service_latency.go:363] Got endpoints: latency-svc-br6h7 [100.401871ms]
  I0902 08:24:04.641458 16 service_latency.go:363] Got endpoints: latency-svc-92jjq [111.994553ms]
  I0902 08:24:04.659928 16 service_latency.go:356] Created: latency-svc-r25vl
  I0902 08:24:04.676449 16 service_latency.go:356] Created: latency-svc-h6dbq
  I0902 08:24:04.682636 16 service_latency.go:363] Got endpoints: latency-svc-r25vl [152.870951ms]
  I0902 08:24:04.701792 16 service_latency.go:363] Got endpoints: latency-svc-h6dbq [172.602834ms]
  I0902 08:24:04.707424 16 service_latency.go:356] Created: latency-svc-59tt8
  I0902 08:24:04.743201 16 service_latency.go:356] Created: latency-svc-d7tnw
  I0902 08:24:04.752873 16 service_latency.go:363] Got endpoints: latency-svc-59tt8 [222.998592ms]
  I0902 08:24:04.805719 16 service_latency.go:356] Created: latency-svc-8859s
  I0902 08:24:04.809131 16 service_latency.go:363] Got endpoints: latency-svc-d7tnw [279.166126ms]
  I0902 08:24:04.841982 16 service_latency.go:356] Created: latency-svc-rwfwl
  I0902 08:24:04.847985 16 service_latency.go:363] Got endpoints: latency-svc-8859s [317.753814ms]
  I0902 08:24:04.859080 16 service_latency.go:356] Created: latency-svc-hkw2r
  I0902 08:24:04.881647 16 service_latency.go:356] Created: latency-svc-j9w56
  I0902 08:24:04.885896 16 service_latency.go:363] Got endpoints: latency-svc-rwfwl [355.848551ms]
  I0902 08:24:04.921320 16 service_latency.go:363] Got endpoints: latency-svc-hkw2r [390.985298ms]
  I0902 08:24:04.937424 16 service_latency.go:363] Got endpoints: latency-svc-j9w56 [407.288142ms]
  I0902 08:24:04.952109 16 service_latency.go:356] Created: latency-svc-7mg9c
  I0902 08:24:04.975736 16 service_latency.go:363] Got endpoints: latency-svc-7mg9c [445.3247ms]
  I0902 08:24:04.988868 16 service_latency.go:356] Created: latency-svc-jfb4n
  I0902 08:24:05.034388 16 service_latency.go:356] Created: latency-svc-jnf4w
  I0902 08:24:05.040910 16 service_latency.go:363] Got endpoints: latency-svc-jfb4n [509.707793ms]
  I0902 08:24:05.066984 16 service_latency.go:363] Got endpoints: latency-svc-jnf4w [537.776179ms]
  I0902 08:24:05.099970 16 service_latency.go:356] Created: latency-svc-47742
  E0902 08:24:05.106289      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:24:05.150641 16 service_latency.go:356] Created: latency-svc-kqvsb
  I0902 08:24:05.151641 16 service_latency.go:363] Got endpoints: latency-svc-47742 [578.2879ms]
  I0902 08:24:05.183978 16 service_latency.go:356] Created: latency-svc-2cldd
  I0902 08:24:05.196059 16 service_latency.go:363] Got endpoints: latency-svc-kqvsb [589.840501ms]
  I0902 08:24:05.255213 16 service_latency.go:363] Got endpoints: latency-svc-2cldd [625.126486ms]
  I0902 08:24:05.263271 16 service_latency.go:356] Created: latency-svc-r6j6r
  I0902 08:24:05.296022 16 service_latency.go:363] Got endpoints: latency-svc-r6j6r [654.491667ms]
  I0902 08:24:05.340033 16 service_latency.go:356] Created: latency-svc-zvxnx
  I0902 08:24:05.347472 16 service_latency.go:356] Created: latency-svc-hhl85
  I0902 08:24:05.351940 16 service_latency.go:363] Got endpoints: latency-svc-zvxnx [668.850778ms]
  I0902 08:24:05.390753 16 service_latency.go:363] Got endpoints: latency-svc-hhl85 [688.846925ms]
  I0902 08:24:05.401929 16 service_latency.go:356] Created: latency-svc-pxx2q
  I0902 08:24:05.447444 16 service_latency.go:356] Created: latency-svc-ndpgq
  I0902 08:24:05.451433 16 service_latency.go:363] Got endpoints: latency-svc-pxx2q [698.433071ms]
  I0902 08:24:05.471330 16 service_latency.go:363] Got endpoints: latency-svc-ndpgq [662.074329ms]
  I0902 08:24:05.517433 16 service_latency.go:356] Created: latency-svc-m4mnl
  I0902 08:24:05.536476 16 service_latency.go:356] Created: latency-svc-gflh6
  I0902 08:24:05.539693 16 service_latency.go:363] Got endpoints: latency-svc-m4mnl [691.624273ms]
  I0902 08:24:05.574185 16 service_latency.go:363] Got endpoints: latency-svc-gflh6 [688.167625ms]
  I0902 08:24:05.580396 16 service_latency.go:356] Created: latency-svc-6t97l
  I0902 08:24:05.599108 16 service_latency.go:363] Got endpoints: latency-svc-6t97l [677.673042ms]
  I0902 08:24:05.614106 16 service_latency.go:356] Created: latency-svc-p6rcc
  I0902 08:24:05.626784 16 service_latency.go:356] Created: latency-svc-sjdj4
  I0902 08:24:05.632519 16 service_latency.go:363] Got endpoints: latency-svc-p6rcc [695.001615ms]
  I0902 08:24:05.652589 16 service_latency.go:356] Created: latency-svc-458z4
  I0902 08:24:05.663846 16 service_latency.go:363] Got endpoints: latency-svc-sjdj4 [688.016887ms]
  I0902 08:24:05.680763 16 service_latency.go:363] Got endpoints: latency-svc-458z4 [639.762612ms]
  I0902 08:24:05.684575 16 service_latency.go:356] Created: latency-svc-tmtd4
  I0902 08:24:05.699840 16 service_latency.go:356] Created: latency-svc-74gns
  I0902 08:24:05.703756 16 service_latency.go:363] Got endpoints: latency-svc-tmtd4 [636.67924ms]
  I0902 08:24:05.718453 16 service_latency.go:363] Got endpoints: latency-svc-74gns [566.732442ms]
  I0902 08:24:05.733240 16 service_latency.go:356] Created: latency-svc-7d6vw
  I0902 08:24:05.740508 16 service_latency.go:356] Created: latency-svc-zxpvf
  I0902 08:24:05.759362 16 service_latency.go:356] Created: latency-svc-wfhjf
  I0902 08:24:05.777994 16 service_latency.go:363] Got endpoints: latency-svc-zxpvf [522.670455ms]
  I0902 08:24:05.779151 16 service_latency.go:363] Got endpoints: latency-svc-7d6vw [582.978832ms]
  I0902 08:24:05.781649 16 service_latency.go:363] Got endpoints: latency-svc-wfhjf [485.483833ms]
  I0902 08:24:05.799955 16 service_latency.go:356] Created: latency-svc-blpfd
  I0902 08:24:05.808420 16 service_latency.go:363] Got endpoints: latency-svc-blpfd [456.105667ms]
  I0902 08:24:05.822778 16 service_latency.go:356] Created: latency-svc-tstrb
  I0902 08:24:05.836941 16 service_latency.go:356] Created: latency-svc-szpcq
  I0902 08:24:05.861394 16 service_latency.go:363] Got endpoints: latency-svc-tstrb [470.292728ms]
  I0902 08:24:05.881435 16 service_latency.go:363] Got endpoints: latency-svc-szpcq [429.896479ms]
  I0902 08:24:05.887513 16 service_latency.go:356] Created: latency-svc-kr2c5
  I0902 08:24:05.908243 16 service_latency.go:363] Got endpoints: latency-svc-kr2c5 [436.820254ms]
  I0902 08:24:05.920349 16 service_latency.go:356] Created: latency-svc-ccbcx
  I0902 08:24:05.935003 16 service_latency.go:356] Created: latency-svc-bc7td
  I0902 08:24:05.941205 16 service_latency.go:363] Got endpoints: latency-svc-ccbcx [401.439ms]
  I0902 08:24:05.959785 16 service_latency.go:363] Got endpoints: latency-svc-bc7td [385.490998ms]
  I0902 08:24:05.964519 16 service_latency.go:356] Created: latency-svc-z5k6l
  I0902 08:24:05.990029 16 service_latency.go:363] Got endpoints: latency-svc-z5k6l [390.831833ms]
  I0902 08:24:05.990045 16 service_latency.go:356] Created: latency-svc-lp252
  I0902 08:24:06.013853 16 service_latency.go:356] Created: latency-svc-2ln4w
  I0902 08:24:06.015011 16 service_latency.go:363] Got endpoints: latency-svc-lp252 [382.338871ms]
  I0902 08:24:06.041503 16 service_latency.go:356] Created: latency-svc-4q6dp
  I0902 08:24:06.046626 16 service_latency.go:363] Got endpoints: latency-svc-2ln4w [382.68682ms]
  I0902 08:24:06.073061 16 service_latency.go:356] Created: latency-svc-d2z28
  I0902 08:24:06.077725 16 service_latency.go:363] Got endpoints: latency-svc-4q6dp [396.856169ms]
  I0902 08:24:06.097325 16 service_latency.go:356] Created: latency-svc-h9hx9
  E0902 08:24:06.107064      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:24:06.117883 16 service_latency.go:363] Got endpoints: latency-svc-d2z28 [413.922917ms]
  I0902 08:24:06.134708 16 service_latency.go:363] Got endpoints: latency-svc-h9hx9 [416.173873ms]
  I0902 08:24:06.136912 16 service_latency.go:356] Created: latency-svc-8wpbs
  I0902 08:24:06.157716 16 service_latency.go:356] Created: latency-svc-wzrcv
  I0902 08:24:06.170979 16 service_latency.go:356] Created: latency-svc-46ml9
  I0902 08:24:06.187168 16 service_latency.go:363] Got endpoints: latency-svc-wzrcv [407.505098ms]
  I0902 08:24:06.189609 16 service_latency.go:363] Got endpoints: latency-svc-8wpbs [411.524972ms]
  I0902 08:24:06.209327 16 service_latency.go:363] Got endpoints: latency-svc-46ml9 [426.50635ms]
  I0902 08:24:06.228102 16 service_latency.go:356] Created: latency-svc-2gjg6
  I0902 08:24:06.242891 16 service_latency.go:356] Created: latency-svc-c5fb5
  I0902 08:24:06.248771 16 service_latency.go:363] Got endpoints: latency-svc-2gjg6 [440.251643ms]
  I0902 08:24:06.267142 16 service_latency.go:356] Created: latency-svc-s68jz
  I0902 08:24:06.270613 16 service_latency.go:363] Got endpoints: latency-svc-c5fb5 [409.108316ms]
  I0902 08:24:06.290305 16 service_latency.go:363] Got endpoints: latency-svc-s68jz [408.773324ms]
  I0902 08:24:06.294535 16 service_latency.go:356] Created: latency-svc-zlskr
  I0902 08:24:06.312775 16 service_latency.go:356] Created: latency-svc-7dthn
  I0902 08:24:06.320427 16 service_latency.go:363] Got endpoints: latency-svc-zlskr [412.035539ms]
  I0902 08:24:06.347862 16 service_latency.go:356] Created: latency-svc-d5j4w
  I0902 08:24:06.353501 16 service_latency.go:363] Got endpoints: latency-svc-7dthn [412.176879ms]
  I0902 08:24:06.365185 16 service_latency.go:363] Got endpoints: latency-svc-d5j4w [405.287035ms]
  I0902 08:24:06.381038 16 service_latency.go:356] Created: latency-svc-h6zjh
  I0902 08:24:06.395035 16 service_latency.go:356] Created: latency-svc-sj5zb
  I0902 08:24:06.396463 16 service_latency.go:363] Got endpoints: latency-svc-h6zjh [406.317941ms]
  I0902 08:24:06.429996 16 service_latency.go:356] Created: latency-svc-zcg5x
  I0902 08:24:06.434328 16 service_latency.go:363] Got endpoints: latency-svc-sj5zb [419.249605ms]
  I0902 08:24:06.457445 16 service_latency.go:363] Got endpoints: latency-svc-zcg5x [410.742769ms]
  I0902 08:24:06.464876 16 service_latency.go:356] Created: latency-svc-f4tmq
  I0902 08:24:06.495744 16 service_latency.go:363] Got endpoints: latency-svc-f4tmq [417.622155ms]
  I0902 08:24:06.495865 16 service_latency.go:356] Created: latency-svc-nkrqx
  I0902 08:24:06.531841 16 service_latency.go:356] Created: latency-svc-6zw5q
  I0902 08:24:06.551274 16 service_latency.go:363] Got endpoints: latency-svc-6zw5q [416.462924ms]
  I0902 08:24:06.551619 16 service_latency.go:363] Got endpoints: latency-svc-nkrqx [433.65586ms]
  I0902 08:24:06.582423 16 service_latency.go:356] Created: latency-svc-8rspd
  I0902 08:24:06.606612 16 service_latency.go:356] Created: latency-svc-wfgcr
  I0902 08:24:06.615110 16 service_latency.go:363] Got endpoints: latency-svc-8rspd [427.831351ms]
  I0902 08:24:06.642123 16 service_latency.go:363] Got endpoints: latency-svc-wfgcr [452.44367ms]
  I0902 08:24:06.671116 16 service_latency.go:356] Created: latency-svc-ln4bm
  I0902 08:24:06.683442 16 service_latency.go:356] Created: latency-svc-kmdq7
  I0902 08:24:06.704334 16 service_latency.go:363] Got endpoints: latency-svc-ln4bm [494.886591ms]
  I0902 08:24:06.722862 16 service_latency.go:356] Created: latency-svc-gdxlb
  I0902 08:24:06.748143 16 service_latency.go:363] Got endpoints: latency-svc-kmdq7 [499.296828ms]
  I0902 08:24:06.758605 16 service_latency.go:363] Got endpoints: latency-svc-gdxlb [487.921177ms]
  I0902 08:24:06.761702 16 service_latency.go:356] Created: latency-svc-jkhkk
  I0902 08:24:06.800261 16 service_latency.go:356] Created: latency-svc-7dxdn
  I0902 08:24:06.817468 16 service_latency.go:363] Got endpoints: latency-svc-jkhkk [527.033607ms]
  I0902 08:24:06.821581 16 service_latency.go:363] Got endpoints: latency-svc-7dxdn [501.041049ms]
  I0902 08:24:06.860081 16 service_latency.go:356] Created: latency-svc-pxccq
  I0902 08:24:06.899906 16 service_latency.go:356] Created: latency-svc-cnp9m
  I0902 08:24:06.938079 16 service_latency.go:356] Created: latency-svc-d5fwn
  I0902 08:24:06.939821 16 service_latency.go:363] Got endpoints: latency-svc-cnp9m [574.501884ms]
  I0902 08:24:06.940181 16 service_latency.go:363] Got endpoints: latency-svc-pxccq [586.593435ms]
  I0902 08:24:06.976366 16 service_latency.go:356] Created: latency-svc-dhcdn
  I0902 08:24:06.981804 16 service_latency.go:363] Got endpoints: latency-svc-d5fwn [585.269361ms]
  I0902 08:24:07.000301 16 service_latency.go:356] Created: latency-svc-4p4h4
  I0902 08:24:07.019216 16 service_latency.go:356] Created: latency-svc-th4nc
  I0902 08:24:07.046083 16 service_latency.go:363] Got endpoints: latency-svc-th4nc [550.248231ms]
  I0902 08:24:07.046483 16 service_latency.go:363] Got endpoints: latency-svc-dhcdn [610.448386ms]
  I0902 08:24:07.046625 16 service_latency.go:363] Got endpoints: latency-svc-4p4h4 [588.915518ms]
  I0902 08:24:07.104471 16 service_latency.go:356] Created: latency-svc-dk64k
  E0902 08:24:07.108964      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:24:07.128906 16 service_latency.go:356] Created: latency-svc-5cpfs
  I0902 08:24:07.149178 16 service_latency.go:363] Got endpoints: latency-svc-5cpfs [597.824073ms]
  I0902 08:24:07.149279 16 service_latency.go:363] Got endpoints: latency-svc-dk64k [597.547327ms]
  I0902 08:24:07.192088 16 service_latency.go:356] Created: latency-svc-gkg9g
  I0902 08:24:07.222804 16 service_latency.go:356] Created: latency-svc-m9fk4
  I0902 08:24:07.224616 16 service_latency.go:363] Got endpoints: latency-svc-gkg9g [609.410757ms]
  I0902 08:24:07.256988 16 service_latency.go:363] Got endpoints: latency-svc-m9fk4 [614.743056ms]
  I0902 08:24:07.266275 16 service_latency.go:356] Created: latency-svc-szpm4
  I0902 08:24:07.298325 16 service_latency.go:356] Created: latency-svc-zzh4h
  I0902 08:24:07.304083 16 service_latency.go:363] Got endpoints: latency-svc-szpm4 [599.662604ms]
  I0902 08:24:07.355514 16 service_latency.go:363] Got endpoints: latency-svc-zzh4h [607.181229ms]
  I0902 08:24:07.358059 16 service_latency.go:356] Created: latency-svc-g8hrc
  I0902 08:24:07.382175 16 service_latency.go:356] Created: latency-svc-vtqdm
  I0902 08:24:07.394165 16 service_latency.go:356] Created: latency-svc-p9gqt
  I0902 08:24:07.416077 16 service_latency.go:363] Got endpoints: latency-svc-vtqdm [597.029658ms]
  I0902 08:24:07.420241 16 service_latency.go:363] Got endpoints: latency-svc-g8hrc [661.457511ms]
  I0902 08:24:07.437875 16 service_latency.go:363] Got endpoints: latency-svc-p9gqt [616.227191ms]
  I0902 08:24:07.446301 16 service_latency.go:356] Created: latency-svc-n9kg6
  I0902 08:24:07.478598 16 service_latency.go:363] Got endpoints: latency-svc-n9kg6 [538.304942ms]
  I0902 08:24:07.481216 16 service_latency.go:356] Created: latency-svc-fllcw
  I0902 08:24:07.518275 16 service_latency.go:363] Got endpoints: latency-svc-fllcw [578.348451ms]
  I0902 08:24:07.545457 16 service_latency.go:356] Created: latency-svc-qncfn
  I0902 08:24:07.568994 16 service_latency.go:363] Got endpoints: latency-svc-qncfn [587.025393ms]
  I0902 08:24:07.580185 16 service_latency.go:356] Created: latency-svc-phxcx
  I0902 08:24:07.603722 16 service_latency.go:356] Created: latency-svc-5lqfl
  I0902 08:24:07.603499 16 service_latency.go:363] Got endpoints: latency-svc-phxcx [557.282272ms]
  I0902 08:24:07.621176 16 service_latency.go:356] Created: latency-svc-lxmst
  I0902 08:24:07.675627 16 service_latency.go:363] Got endpoints: latency-svc-lxmst [629.08716ms]
  I0902 08:24:07.676372 16 service_latency.go:363] Got endpoints: latency-svc-5lqfl [629.67342ms]
  I0902 08:24:07.694106 16 service_latency.go:356] Created: latency-svc-rppcm
  I0902 08:24:07.716017 16 service_latency.go:363] Got endpoints: latency-svc-rppcm [566.674446ms]
  I0902 08:24:07.720516 16 service_latency.go:356] Created: latency-svc-bskrj
  I0902 08:24:07.737889 16 service_latency.go:356] Created: latency-svc-ml7ww
  I0902 08:24:07.740191 16 service_latency.go:363] Got endpoints: latency-svc-bskrj [590.902133ms]
  I0902 08:24:07.767940 16 service_latency.go:363] Got endpoints: latency-svc-ml7ww [543.264648ms]
  I0902 08:24:07.774939 16 service_latency.go:356] Created: latency-svc-js5mp
  I0902 08:24:07.800705 16 service_latency.go:356] Created: latency-svc-bq8t4
  I0902 08:24:07.828635 16 service_latency.go:363] Got endpoints: latency-svc-bq8t4 [524.318579ms]
  I0902 08:24:07.828774 16 service_latency.go:363] Got endpoints: latency-svc-js5mp [570.742749ms]
  I0902 08:24:07.845117 16 service_latency.go:356] Created: latency-svc-546jg
  I0902 08:24:07.875457 16 service_latency.go:356] Created: latency-svc-6q2vg
  I0902 08:24:07.884157 16 service_latency.go:363] Got endpoints: latency-svc-546jg [528.426349ms]
  I0902 08:24:07.893395 16 service_latency.go:356] Created: latency-svc-bx59h
  I0902 08:24:07.894161 16 service_latency.go:363] Got endpoints: latency-svc-6q2vg [473.793282ms]
  I0902 08:24:07.913276 16 service_latency.go:356] Created: latency-svc-g9htq
  I0902 08:24:07.956318 16 service_latency.go:356] Created: latency-svc-xdt6b
  I0902 08:24:07.975533 16 service_latency.go:356] Created: latency-svc-q22kb
  I0902 08:24:07.992980 16 service_latency.go:363] Got endpoints: latency-svc-g9htq [554.976614ms]
  I0902 08:24:07.992988 16 service_latency.go:363] Got endpoints: latency-svc-bx59h [575.837186ms]
  I0902 08:24:08.023750 16 service_latency.go:356] Created: latency-svc-c7bjd
  I0902 08:24:08.028933 16 service_latency.go:356] Created: latency-svc-qtlgd
  I0902 08:24:08.036333 16 service_latency.go:363] Got endpoints: latency-svc-xdt6b [557.610622ms]
  I0902 08:24:08.050164 16 service_latency.go:356] Created: latency-svc-9nnz9
  I0902 08:24:08.062030 16 service_latency.go:356] Created: latency-svc-xqhx5
  I0902 08:24:08.073531 16 service_latency.go:363] Got endpoints: latency-svc-q22kb [555.162797ms]
  I0902 08:24:08.090626 16 service_latency.go:356] Created: latency-svc-24xzj
  I0902 08:24:08.098387 16 service_latency.go:356] Created: latency-svc-gvg46
  E0902 08:24:08.108897      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:24:08.114188 16 service_latency.go:356] Created: latency-svc-ch9n8
  I0902 08:24:08.122504 16 service_latency.go:363] Got endpoints: latency-svc-c7bjd [552.881637ms]
  I0902 08:24:08.131841 16 service_latency.go:356] Created: latency-svc-ztbbl
  I0902 08:24:08.145197 16 service_latency.go:356] Created: latency-svc-4gdxh
  I0902 08:24:08.159392 16 service_latency.go:356] Created: latency-svc-l7kz6
  I0902 08:24:08.171373 16 service_latency.go:356] Created: latency-svc-mn2gf
  I0902 08:24:08.184980 16 service_latency.go:356] Created: latency-svc-xwsrb
  I0902 08:24:08.193957 16 service_latency.go:363] Got endpoints: latency-svc-qtlgd [588.814476ms]
  I0902 08:24:08.223159 16 service_latency.go:356] Created: latency-svc-2xr2f
  I0902 08:24:08.231645 16 service_latency.go:363] Got endpoints: latency-svc-9nnz9 [555.895144ms]
  I0902 08:24:08.253974 16 service_latency.go:356] Created: latency-svc-dnsjn
  I0902 08:24:08.273428 16 service_latency.go:356] Created: latency-svc-2gjrw
  I0902 08:24:08.294116 16 service_latency.go:363] Got endpoints: latency-svc-xqhx5 [617.653341ms]
  I0902 08:24:08.308137 16 service_latency.go:356] Created: latency-svc-7bchr
  I0902 08:24:08.330762 16 service_latency.go:356] Created: latency-svc-s2mbw
  I0902 08:24:08.333628 16 service_latency.go:363] Got endpoints: latency-svc-24xzj [616.183912ms]
  I0902 08:24:08.391050 16 service_latency.go:356] Created: latency-svc-t5d87
  I0902 08:24:08.404223 16 service_latency.go:363] Got endpoints: latency-svc-gvg46 [663.923076ms]
  I0902 08:24:08.410948 16 service_latency.go:356] Created: latency-svc-sg7pq
  I0902 08:24:08.453135 16 service_latency.go:363] Got endpoints: latency-svc-ch9n8 [685.031722ms]
  I0902 08:24:08.467534 16 service_latency.go:356] Created: latency-svc-h5hvs
  I0902 08:24:08.489909 16 service_latency.go:363] Got endpoints: latency-svc-ztbbl [661.150519ms]
  I0902 08:24:08.503396 16 service_latency.go:356] Created: latency-svc-lcmb6
  I0902 08:24:08.537850 16 service_latency.go:356] Created: latency-svc-4jptx
  I0902 08:24:08.539788 16 service_latency.go:363] Got endpoints: latency-svc-4gdxh [710.926438ms]
  I0902 08:24:08.587231 16 service_latency.go:356] Created: latency-svc-pbvvv
  I0902 08:24:08.598662 16 service_latency.go:363] Got endpoints: latency-svc-l7kz6 [712.985941ms]
  I0902 08:24:08.643732 16 service_latency.go:363] Got endpoints: latency-svc-mn2gf [749.482377ms]
  I0902 08:24:08.661049 16 service_latency.go:356] Created: latency-svc-clqnm
  I0902 08:24:08.700936 16 service_latency.go:356] Created: latency-svc-6zh92
  I0902 08:24:08.712858 16 service_latency.go:363] Got endpoints: latency-svc-xwsrb [719.505111ms]
  I0902 08:24:08.789088 16 service_latency.go:356] Created: latency-svc-bsvrq
  I0902 08:24:08.791816 16 service_latency.go:363] Got endpoints: latency-svc-2xr2f [798.439376ms]
  I0902 08:24:08.821067 16 service_latency.go:363] Got endpoints: latency-svc-dnsjn [784.625232ms]
  I0902 08:24:08.847354 16 service_latency.go:356] Created: latency-svc-6qqzh
  I0902 08:24:08.881239 16 service_latency.go:363] Got endpoints: latency-svc-2gjrw [807.530009ms]
  I0902 08:24:08.941134 16 service_latency.go:356] Created: latency-svc-kb89n
  I0902 08:24:08.977530 16 service_latency.go:363] Got endpoints: latency-svc-s2mbw [783.456625ms]
  I0902 08:24:08.977687 16 service_latency.go:363] Got endpoints: latency-svc-7bchr [854.525402ms]
  I0902 08:24:09.010499 16 service_latency.go:363] Got endpoints: latency-svc-t5d87 [778.656764ms]
  I0902 08:24:09.022169 16 service_latency.go:356] Created: latency-svc-vnx59
  I0902 08:24:09.037943 16 service_latency.go:363] Got endpoints: latency-svc-sg7pq [743.729977ms]
  I0902 08:24:09.080159 16 service_latency.go:356] Created: latency-svc-v4gq9
  E0902 08:24:09.112949      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:24:09.122821 16 service_latency.go:363] Got endpoints: latency-svc-h5hvs [789.126499ms]
  I0902 08:24:09.128915 16 service_latency.go:356] Created: latency-svc-sxhzs
  I0902 08:24:09.172396 16 service_latency.go:356] Created: latency-svc-rppg2
  I0902 08:24:09.209477 16 service_latency.go:363] Got endpoints: latency-svc-lcmb6 [805.126842ms]
  I0902 08:24:09.224514 16 service_latency.go:363] Got endpoints: latency-svc-4jptx [771.083837ms]
  I0902 08:24:09.258501 16 service_latency.go:356] Created: latency-svc-ntbd6
  I0902 08:24:09.285073 16 service_latency.go:356] Created: latency-svc-vnlw5
  I0902 08:24:09.301049 16 service_latency.go:356] Created: latency-svc-t6rj8
  I0902 08:24:09.308070 16 service_latency.go:363] Got endpoints: latency-svc-pbvvv [817.823439ms]
  I0902 08:24:09.308298 16 service_latency.go:363] Got endpoints: latency-svc-clqnm [768.439069ms]
  I0902 08:24:09.357319 16 service_latency.go:356] Created: latency-svc-2b7v4
  I0902 08:24:09.364905 16 service_latency.go:363] Got endpoints: latency-svc-6zh92 [766.152703ms]
  I0902 08:24:09.395678 16 service_latency.go:363] Got endpoints: latency-svc-bsvrq [751.815355ms]
  I0902 08:24:09.407039 16 service_latency.go:356] Created: latency-svc-zdndr
  I0902 08:24:09.413617 16 service_latency.go:356] Created: latency-svc-2x97j
  I0902 08:24:09.437326 16 service_latency.go:363] Got endpoints: latency-svc-6qqzh [724.336548ms]
  I0902 08:24:09.438944 16 service_latency.go:356] Created: latency-svc-4jf46
  I0902 08:24:09.453320 16 service_latency.go:356] Created: latency-svc-kfzjf
  I0902 08:24:09.468476 16 service_latency.go:363] Got endpoints: latency-svc-kb89n [675.432223ms]
  I0902 08:24:09.494404 16 service_latency.go:356] Created: latency-svc-lqszp
  I0902 08:24:09.509743 16 service_latency.go:356] Created: latency-svc-t9kvh
  I0902 08:24:09.522912 16 service_latency.go:363] Got endpoints: latency-svc-vnx59 [701.751709ms]
  I0902 08:24:09.529912 16 service_latency.go:356] Created: latency-svc-shwgz
  I0902 08:24:09.547688 16 service_latency.go:356] Created: latency-svc-4gksj
  I0902 08:24:09.571630 16 service_latency.go:363] Got endpoints: latency-svc-v4gq9 [689.676572ms]
  I0902 08:24:09.597374 16 service_latency.go:356] Created: latency-svc-95td7
  I0902 08:24:09.626436 16 service_latency.go:363] Got endpoints: latency-svc-sxhzs [648.529816ms]
  I0902 08:24:09.650179 16 service_latency.go:356] Created: latency-svc-qrzrf
  I0902 08:24:09.668496 16 service_latency.go:363] Got endpoints: latency-svc-rppg2 [690.635165ms]
  I0902 08:24:09.695064 16 service_latency.go:356] Created: latency-svc-cjqmg
  I0902 08:24:09.724452 16 service_latency.go:363] Got endpoints: latency-svc-vnlw5 [713.716662ms]
  I0902 08:24:09.745748 16 service_latency.go:356] Created: latency-svc-6d5f7
  I0902 08:24:09.770997 16 service_latency.go:363] Got endpoints: latency-svc-ntbd6 [732.86528ms]
  I0902 08:24:09.798877 16 service_latency.go:356] Created: latency-svc-wz4bh
  I0902 08:24:09.822973 16 service_latency.go:363] Got endpoints: latency-svc-t6rj8 [700.064127ms]
  I0902 08:24:09.844050 16 service_latency.go:356] Created: latency-svc-mdz5x
  I0902 08:24:09.873908 16 service_latency.go:363] Got endpoints: latency-svc-2b7v4 [664.260058ms]
  I0902 08:24:09.900887 16 service_latency.go:356] Created: latency-svc-t7psd
  I0902 08:24:09.924782 16 service_latency.go:363] Got endpoints: latency-svc-zdndr [699.132802ms]
  I0902 08:24:09.955106 16 service_latency.go:356] Created: latency-svc-9jbfx
  I0902 08:24:09.972864 16 service_latency.go:363] Got endpoints: latency-svc-2x97j [664.721526ms]
  I0902 08:24:09.992895 16 service_latency.go:356] Created: latency-svc-vlhwj
  I0902 08:24:10.025317 16 service_latency.go:363] Got endpoints: latency-svc-4jf46 [716.331515ms]
  I0902 08:24:10.057832 16 service_latency.go:356] Created: latency-svc-j57pz
  I0902 08:24:10.073538 16 service_latency.go:363] Got endpoints: latency-svc-kfzjf [708.554027ms]
  I0902 08:24:10.094637 16 service_latency.go:356] Created: latency-svc-xjhfn
  E0902 08:24:10.113162      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:24:10.125084 16 service_latency.go:363] Got endpoints: latency-svc-lqszp [729.063973ms]
  I0902 08:24:10.150965 16 service_latency.go:356] Created: latency-svc-lljj9
  I0902 08:24:10.181901 16 service_latency.go:363] Got endpoints: latency-svc-t9kvh [744.394772ms]
  I0902 08:24:10.202812 16 service_latency.go:356] Created: latency-svc-2gwh9
  I0902 08:24:10.231496 16 service_latency.go:363] Got endpoints: latency-svc-shwgz [762.877135ms]
  I0902 08:24:10.256002 16 service_latency.go:356] Created: latency-svc-2ztwz
  I0902 08:24:10.278346 16 service_latency.go:363] Got endpoints: latency-svc-4gksj [755.113047ms]
  I0902 08:24:10.321833 16 service_latency.go:356] Created: latency-svc-zd9kj
  I0902 08:24:10.362729 16 service_latency.go:363] Got endpoints: latency-svc-95td7 [790.960552ms]
  I0902 08:24:10.382936 16 service_latency.go:363] Got endpoints: latency-svc-qrzrf [756.257523ms]
  I0902 08:24:10.410986 16 service_latency.go:356] Created: latency-svc-vscvp
  I0902 08:24:10.445392 16 service_latency.go:363] Got endpoints: latency-svc-cjqmg [776.543012ms]
  I0902 08:24:10.452227 16 service_latency.go:356] Created: latency-svc-zzqfg
  I0902 08:24:10.473884 16 service_latency.go:363] Got endpoints: latency-svc-6d5f7 [749.26643ms]
  I0902 08:24:10.503357 16 service_latency.go:356] Created: latency-svc-pbf9p
  I0902 08:24:10.527535 16 service_latency.go:356] Created: latency-svc-bvg6d
  I0902 08:24:10.530881 16 service_latency.go:363] Got endpoints: latency-svc-wz4bh [759.777781ms]
  I0902 08:24:10.553814 16 service_latency.go:356] Created: latency-svc-6txkr
  I0902 08:24:10.573620 16 service_latency.go:363] Got endpoints: latency-svc-mdz5x [750.190877ms]
  I0902 08:24:10.608907 16 service_latency.go:356] Created: latency-svc-fpqf9
  I0902 08:24:10.631842 16 service_latency.go:363] Got endpoints: latency-svc-t7psd [757.848936ms]
  I0902 08:24:10.658036 16 service_latency.go:356] Created: latency-svc-7vllh
  I0902 08:24:10.678966 16 service_latency.go:363] Got endpoints: latency-svc-9jbfx [752.901778ms]
  I0902 08:24:10.736813 16 service_latency.go:356] Created: latency-svc-mp4k2
  I0902 08:24:10.748629 16 service_latency.go:363] Got endpoints: latency-svc-vlhwj [775.668615ms]
  I0902 08:24:10.779189 16 service_latency.go:363] Got endpoints: latency-svc-j57pz [753.705261ms]
  I0902 08:24:10.786285 16 service_latency.go:356] Created: latency-svc-6q2t5
  I0902 08:24:10.802966 16 service_latency.go:356] Created: latency-svc-dbj9b
  I0902 08:24:10.827929 16 service_latency.go:363] Got endpoints: latency-svc-xjhfn [754.219138ms]
  I0902 08:24:10.850775 16 service_latency.go:356] Created: latency-svc-h9q2s
  I0902 08:24:10.873880 16 service_latency.go:363] Got endpoints: latency-svc-lljj9 [748.709464ms]
  I0902 08:24:10.897365 16 service_latency.go:356] Created: latency-svc-2pw5v
  I0902 08:24:10.923471 16 service_latency.go:363] Got endpoints: latency-svc-2gwh9 [741.47239ms]
  I0902 08:24:10.947960 16 service_latency.go:356] Created: latency-svc-zp4f6
  I0902 08:24:10.975100 16 service_latency.go:363] Got endpoints: latency-svc-2ztwz [743.282071ms]
  I0902 08:24:11.000967 16 service_latency.go:356] Created: latency-svc-5n9wz
  I0902 08:24:11.020455 16 service_latency.go:363] Got endpoints: latency-svc-zd9kj [741.973363ms]
  I0902 08:24:11.043752 16 service_latency.go:356] Created: latency-svc-l5v68
  I0902 08:24:11.075227 16 service_latency.go:363] Got endpoints: latency-svc-vscvp [712.378925ms]
  I0902 08:24:11.097959 16 service_latency.go:356] Created: latency-svc-cgdsq
  E0902 08:24:11.113436      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:24:11.122767 16 service_latency.go:363] Got endpoints: latency-svc-zzqfg [739.742579ms]
  I0902 08:24:11.145447 16 service_latency.go:356] Created: latency-svc-4bn98
  I0902 08:24:11.174861 16 service_latency.go:363] Got endpoints: latency-svc-pbf9p [729.123528ms]
  I0902 08:24:11.214665 16 service_latency.go:356] Created: latency-svc-q29fm
  I0902 08:24:11.227103 16 service_latency.go:363] Got endpoints: latency-svc-bvg6d [753.119766ms]
  I0902 08:24:11.254898 16 service_latency.go:356] Created: latency-svc-pfv7m
  I0902 08:24:11.275158 16 service_latency.go:363] Got endpoints: latency-svc-6txkr [744.198648ms]
  I0902 08:24:11.300353 16 service_latency.go:356] Created: latency-svc-xlt5q
  I0902 08:24:11.323519 16 service_latency.go:363] Got endpoints: latency-svc-fpqf9 [749.154379ms]
  I0902 08:24:11.350191 16 service_latency.go:356] Created: latency-svc-jgqn7
  I0902 08:24:11.384109 16 service_latency.go:363] Got endpoints: latency-svc-7vllh [752.177018ms]
  I0902 08:24:11.411162 16 service_latency.go:356] Created: latency-svc-6t7d8
  I0902 08:24:11.422851 16 service_latency.go:363] Got endpoints: latency-svc-mp4k2 [743.77733ms]
  I0902 08:24:11.456421 16 service_latency.go:356] Created: latency-svc-2jbz8
  I0902 08:24:11.475794 16 service_latency.go:363] Got endpoints: latency-svc-6q2t5 [727.079823ms]
  I0902 08:24:11.498461 16 service_latency.go:356] Created: latency-svc-xjfg7
  I0902 08:24:11.526824 16 service_latency.go:363] Got endpoints: latency-svc-dbj9b [746.280465ms]
  I0902 08:24:11.545263 16 service_latency.go:356] Created: latency-svc-5svw6
  I0902 08:24:11.574323 16 service_latency.go:363] Got endpoints: latency-svc-h9q2s [746.168557ms]
  I0902 08:24:11.595881 16 service_latency.go:356] Created: latency-svc-f2pxs
  I0902 08:24:11.622299 16 service_latency.go:363] Got endpoints: latency-svc-2pw5v [748.250309ms]
  I0902 08:24:11.647096 16 service_latency.go:356] Created: latency-svc-5gj49
  I0902 08:24:11.675068 16 service_latency.go:363] Got endpoints: latency-svc-zp4f6 [751.346293ms]
  I0902 08:24:11.696020 16 service_latency.go:356] Created: latency-svc-xlg44
  I0902 08:24:11.727011 16 service_latency.go:363] Got endpoints: latency-svc-5n9wz [751.798562ms]
  I0902 08:24:11.753679 16 service_latency.go:356] Created: latency-svc-cfkp4
  I0902 08:24:11.776395 16 service_latency.go:363] Got endpoints: latency-svc-l5v68 [755.792743ms]
  I0902 08:24:11.847307 16 service_latency.go:356] Created: latency-svc-7dlk9
  I0902 08:24:11.859416 16 service_latency.go:363] Got endpoints: latency-svc-cgdsq [784.084522ms]
  I0902 08:24:11.893095 16 service_latency.go:363] Got endpoints: latency-svc-4bn98 [770.243153ms]
  I0902 08:24:11.947358 16 service_latency.go:356] Created: latency-svc-45j77
  I0902 08:24:11.958488 16 service_latency.go:363] Got endpoints: latency-svc-q29fm [783.518481ms]
  I0902 08:24:12.004768 16 service_latency.go:363] Got endpoints: latency-svc-pfv7m [777.579507ms]
  I0902 08:24:12.027731 16 service_latency.go:356] Created: latency-svc-rfc6z
  I0902 08:24:12.045064 16 service_latency.go:363] Got endpoints: latency-svc-xlt5q [769.436003ms]
  I0902 08:24:12.067679 16 service_latency.go:356] Created: latency-svc-kn75p
  I0902 08:24:12.092100 16 service_latency.go:363] Got endpoints: latency-svc-jgqn7 [768.45486ms]
  I0902 08:24:12.099030 16 service_latency.go:356] Created: latency-svc-hg5rr
  E0902 08:24:12.113700      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:24:12.117406 16 service_latency.go:356] Created: latency-svc-ndsbl
  I0902 08:24:12.124189 16 service_latency.go:363] Got endpoints: latency-svc-6t7d8 [739.944776ms]
  I0902 08:24:12.154787 16 service_latency.go:356] Created: latency-svc-mlmj7
  I0902 08:24:12.168157 16 service_latency.go:356] Created: latency-svc-9pzrs
  I0902 08:24:12.195225 16 service_latency.go:363] Got endpoints: latency-svc-2jbz8 [770.557111ms]
  I0902 08:24:12.236417 16 service_latency.go:356] Created: latency-svc-qwf7c
  I0902 08:24:12.242978 16 service_latency.go:363] Got endpoints: latency-svc-xjfg7 [767.102222ms]
  I0902 08:24:12.279383 16 service_latency.go:363] Got endpoints: latency-svc-5svw6 [752.450305ms]
  I0902 08:24:12.288696 16 service_latency.go:356] Created: latency-svc-dfdpt
  I0902 08:24:12.311028 16 service_latency.go:356] Created: latency-svc-q76dc
  I0902 08:24:12.335292 16 service_latency.go:363] Got endpoints: latency-svc-f2pxs [760.738261ms]
  I0902 08:24:12.373428 16 service_latency.go:356] Created: latency-svc-nvgg4
  I0902 08:24:12.390113 16 service_latency.go:363] Got endpoints: latency-svc-5gj49 [767.68706ms]
  I0902 08:24:12.432819 16 service_latency.go:363] Got endpoints: latency-svc-xlg44 [757.663568ms]
  I0902 08:24:12.471918 16 service_latency.go:363] Got endpoints: latency-svc-cfkp4 [744.814609ms]
  I0902 08:24:12.525093 16 service_latency.go:363] Got endpoints: latency-svc-7dlk9 [748.60224ms]
  I0902 08:24:12.575411 16 service_latency.go:363] Got endpoints: latency-svc-45j77 [715.892978ms]
  I0902 08:24:12.628334 16 service_latency.go:363] Got endpoints: latency-svc-rfc6z [735.125411ms]
  I0902 08:24:12.680016 16 service_latency.go:363] Got endpoints: latency-svc-kn75p [721.39948ms]
  I0902 08:24:12.748464 16 service_latency.go:363] Got endpoints: latency-svc-hg5rr [741.45391ms]
  I0902 08:24:12.784047 16 service_latency.go:363] Got endpoints: latency-svc-ndsbl [738.829022ms]
  I0902 08:24:12.824277 16 service_latency.go:363] Got endpoints: latency-svc-mlmj7 [732.04924ms]
  I0902 08:24:12.874188 16 service_latency.go:363] Got endpoints: latency-svc-9pzrs [749.868744ms]
  I0902 08:24:12.924379 16 service_latency.go:363] Got endpoints: latency-svc-qwf7c [728.93028ms]
  I0902 08:24:12.972220 16 service_latency.go:363] Got endpoints: latency-svc-dfdpt [729.1199ms]
  I0902 08:24:13.028907 16 service_latency.go:363] Got endpoints: latency-svc-q76dc [749.440565ms]
  I0902 08:24:13.077147 16 service_latency.go:363] Got endpoints: latency-svc-nvgg4 [741.769584ms]
  I0902 08:24:13.077827 16 service_latency.go:115] Latencies: [43.870806ms 74.985991ms 100.401871ms 111.994553ms 152.870951ms 172.602834ms 222.998592ms 279.166126ms 317.753814ms 355.848551ms 382.338871ms 382.68682ms 385.490998ms 390.831833ms 390.985298ms 396.856169ms 401.439ms 405.287035ms 406.317941ms 407.288142ms 407.505098ms 408.773324ms 409.108316ms 410.742769ms 411.524972ms 412.035539ms 412.176879ms 413.922917ms 416.173873ms 416.462924ms 417.622155ms 419.249605ms 426.50635ms 427.831351ms 429.896479ms 433.65586ms 436.820254ms 440.251643ms 445.3247ms 452.44367ms 456.105667ms 470.292728ms 473.793282ms 485.483833ms 487.921177ms 494.886591ms 499.296828ms 501.041049ms 509.707793ms 522.670455ms 524.318579ms 527.033607ms 528.426349ms 537.776179ms 538.304942ms 543.264648ms 550.248231ms 552.881637ms 554.976614ms 555.162797ms 555.895144ms 557.282272ms 557.610622ms 566.674446ms 566.732442ms 570.742749ms 574.501884ms 575.837186ms 578.2879ms 578.348451ms 582.978832ms 585.269361ms 586.593435ms 587.025393ms 588.814476ms 588.915518ms 589.840501ms 590.902133ms 597.029658ms 597.547327ms 597.824073ms 599.662604ms 607.181229ms 609.410757ms 610.448386ms 614.743056ms 616.183912ms 616.227191ms 617.653341ms 625.126486ms 629.08716ms 629.67342ms 636.67924ms 639.762612ms 648.529816ms 654.491667ms 661.150519ms 661.457511ms 662.074329ms 663.923076ms 664.260058ms 664.721526ms 668.850778ms 675.432223ms 677.673042ms 685.031722ms 688.016887ms 688.167625ms 688.846925ms 689.676572ms 690.635165ms 691.624273ms 695.001615ms 698.433071ms 699.132802ms 700.064127ms 701.751709ms 708.554027ms 710.926438ms 712.378925ms 712.985941ms 713.716662ms 715.892978ms 716.331515ms 719.505111ms 721.39948ms 724.336548ms 727.079823ms 728.93028ms 729.063973ms 729.1199ms 729.123528ms 732.04924ms 732.86528ms 735.125411ms 738.829022ms 739.742579ms 739.944776ms 741.45391ms 741.47239ms 741.769584ms 741.973363ms 743.282071ms 743.729977ms 743.77733ms 744.198648ms 744.394772ms 744.814609ms 746.168557ms 746.280465ms 748.250309ms 748.60224ms 748.709464ms 749.154379ms 749.26643ms 749.440565ms 749.482377ms 749.868744ms 750.190877ms 751.346293ms 751.798562ms 751.815355ms 752.177018ms 752.450305ms 752.901778ms 753.119766ms 753.705261ms 754.219138ms 755.113047ms 755.792743ms 756.257523ms 757.663568ms 757.848936ms 759.777781ms 760.738261ms 762.877135ms 766.152703ms 767.102222ms 767.68706ms 768.439069ms 768.45486ms 769.436003ms 770.243153ms 770.557111ms 771.083837ms 775.668615ms 776.543012ms 777.579507ms 778.656764ms 783.456625ms 783.518481ms 784.084522ms 784.625232ms 789.126499ms 790.960552ms 798.439376ms 805.126842ms 807.530009ms 817.823439ms 854.525402ms]
  I0902 08:24:13.077897 16 service_latency.go:119] 50 %ile: 664.260058ms
  I0902 08:24:13.077921 16 service_latency.go:120] 90 %ile: 768.45486ms
  I0902 08:24:13.077947 16 service_latency.go:121] 99 %ile: 817.823439ms
  I0902 08:24:13.077966 16 service_latency.go:122] Total sample count: 200
  I0902 08:24:13.078148 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svc-latency-1279" for this suite. @ 09/02/25 08:24:13.093
• [10.839 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:199
  STEP: Creating a kubernetes client @ 09/02/25 08:24:13.11
  I0902 08:24:13.110174 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename emptydir @ 09/02/25 08:24:13.112
  E0902 08:24:13.113617      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:24:13.136
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:24:13.142
  STEP: Creating a pod to test emptydir 0644 on node default medium @ 09/02/25 08:24:13.149
  E0902 08:24:14.114061      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:24:15.114427      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:24:16.114481      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:24:17.114881      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/02/25 08:24:17.215
  I0902 08:24:17.227718 16 output.go:207] Trying to get logs from node ietha7evai9i-2 pod pod-71277c33-77d6-4ff5-9570-cbbdb1c5bcb5 container test-container: <nil>
  STEP: delete the pod @ 09/02/25 08:24:17.265
  I0902 08:24:17.337391 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-6038" for this suite. @ 09/02/25 08:24:17.351
• [4.258 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:948
  STEP: Creating a kubernetes client @ 09/02/25 08:24:17.368
  I0902 08:24:17.368949 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename resourcequota @ 09/02/25 08:24:17.373
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:24:17.402
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:24:17.41
  STEP: Creating a ResourceQuota @ 09/02/25 08:24:17.416
  STEP: Getting a ResourceQuota @ 09/02/25 08:24:17.425
  STEP: Updating a ResourceQuota @ 09/02/25 08:24:17.435
  STEP: Verifying a ResourceQuota was modified @ 09/02/25 08:24:17.449
  STEP: Deleting a ResourceQuota @ 09/02/25 08:24:17.459
  STEP: Verifying the deleted ResourceQuota @ 09/02/25 08:24:17.474
  I0902 08:24:17.488978 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-3558" for this suite. @ 09/02/25 08:24:17.499
• [0.147 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:468
  STEP: Creating a kubernetes client @ 09/02/25 08:24:17.515
  I0902 08:24:17.516024 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename sched-pred @ 09/02/25 08:24:17.519
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:24:17.55
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:24:17.554
  I0902 08:24:17.561005 16 helper.go:125] Waiting up to 1m0s for all (but 0) nodes to be ready
  I0902 08:24:17.608951 16 util.go:390] Waiting for terminating namespaces to be deleted...
  I0902 08:24:17.617150 16 predicates.go:120] 
  Logging pods the apiserver thinks is on node ietha7evai9i-1 before test
  I0902 08:24:17.630178 16 predicates.go:958] cilium-bn6l7 from kube-system started at 2025-09-02 06:13:04 +0000 UTC (1 container statuses recorded)
  I0902 08:24:17.630265 16 predicates.go:960] 	Container cilium-agent ready: true, restart count 1
  I0902 08:24:17.630290 16 predicates.go:958] cilium-node-init-qt8dx from kube-system started at 2025-09-02 06:13:04 +0000 UTC (1 container statuses recorded)
  I0902 08:24:17.630307 16 predicates.go:960] 	Container node-init ready: true, restart count 1
  I0902 08:24:17.630324 16 predicates.go:958] coredns-66bc5c9577-zh8kv from kube-system started at 2025-09-02 06:13:51 +0000 UTC (1 container statuses recorded)
  I0902 08:24:17.630338 16 predicates.go:960] 	Container coredns ready: true, restart count 1
  I0902 08:24:17.630355 16 predicates.go:958] kube-apiserver-ietha7evai9i-1 from kube-system started at 2025-09-02 06:29:53 +0000 UTC (1 container statuses recorded)
  I0902 08:24:17.630370 16 predicates.go:960] 	Container kube-apiserver ready: true, restart count 1
  I0902 08:24:17.630386 16 predicates.go:958] kube-controller-manager-ietha7evai9i-1 from kube-system started at 2025-09-02 06:29:53 +0000 UTC (1 container statuses recorded)
  I0902 08:24:17.630400 16 predicates.go:960] 	Container kube-controller-manager ready: true, restart count 1
  I0902 08:24:17.630418 16 predicates.go:958] kube-proxy-9czjg from kube-system started at 2025-09-02 06:11:25 +0000 UTC (1 container statuses recorded)
  I0902 08:24:17.630432 16 predicates.go:960] 	Container kube-proxy ready: true, restart count 1
  I0902 08:24:17.630447 16 predicates.go:958] kube-scheduler-ietha7evai9i-1 from kube-system started at 2025-09-02 06:29:53 +0000 UTC (1 container statuses recorded)
  I0902 08:24:17.630461 16 predicates.go:960] 	Container kube-scheduler ready: true, restart count 1
  I0902 08:24:17.630479 16 predicates.go:958] sonobuoy-systemd-logs-daemon-set-707d3c8598644e6c-hzzpm from sonobuoy started at 2025-09-02 07:30:04 +0000 UTC (2 container statuses recorded)
  I0902 08:24:17.630494 16 predicates.go:960] 	Container sonobuoy-worker ready: true, restart count 0
  I0902 08:24:17.630507 16 predicates.go:960] 	Container systemd-logs ready: true, restart count 0
  I0902 08:24:17.630522 16 predicates.go:120] 
  Logging pods the apiserver thinks is on node ietha7evai9i-2 before test
  I0902 08:24:17.639859 16 predicates.go:958] cilium-n62pl from kube-system started at 2025-09-02 06:13:04 +0000 UTC (1 container statuses recorded)
  I0902 08:24:17.639910 16 predicates.go:960] 	Container cilium-agent ready: true, restart count 1
  I0902 08:24:17.639932 16 predicates.go:958] cilium-node-init-cww5f from kube-system started at 2025-09-02 06:13:04 +0000 UTC (1 container statuses recorded)
  I0902 08:24:17.639947 16 predicates.go:960] 	Container node-init ready: true, restart count 1
  I0902 08:24:17.639969 16 predicates.go:958] kube-apiserver-ietha7evai9i-2 from kube-system started at 2025-09-02 06:30:19 +0000 UTC (1 container statuses recorded)
  I0902 08:24:17.639984 16 predicates.go:960] 	Container kube-apiserver ready: true, restart count 1
  I0902 08:24:17.640008 16 predicates.go:958] kube-controller-manager-ietha7evai9i-2 from kube-system started at 2025-09-02 06:30:19 +0000 UTC (1 container statuses recorded)
  I0902 08:24:17.640036 16 predicates.go:960] 	Container kube-controller-manager ready: true, restart count 1
  I0902 08:24:17.640070 16 predicates.go:958] kube-proxy-jp7tf from kube-system started at 2025-09-02 06:12:05 +0000 UTC (1 container statuses recorded)
  I0902 08:24:17.640091 16 predicates.go:960] 	Container kube-proxy ready: true, restart count 1
  I0902 08:24:17.640110 16 predicates.go:958] kube-scheduler-ietha7evai9i-2 from kube-system started at 2025-09-02 06:30:19 +0000 UTC (1 container statuses recorded)
  I0902 08:24:17.640124 16 predicates.go:960] 	Container kube-scheduler ready: true, restart count 1
  I0902 08:24:17.640140 16 predicates.go:958] sonobuoy-systemd-logs-daemon-set-707d3c8598644e6c-dlzrj from sonobuoy started at 2025-09-02 07:30:04 +0000 UTC (2 container statuses recorded)
  I0902 08:24:17.640154 16 predicates.go:960] 	Container sonobuoy-worker ready: true, restart count 0
  I0902 08:24:17.640168 16 predicates.go:960] 	Container systemd-logs ready: true, restart count 0
  I0902 08:24:17.640182 16 predicates.go:120] 
  Logging pods the apiserver thinks is on node ietha7evai9i-3 before test
  I0902 08:24:17.652018 16 predicates.go:958] cilium-node-init-cwq9b from kube-system started at 2025-09-02 06:13:04 +0000 UTC (1 container statuses recorded)
  I0902 08:24:17.652245 16 predicates.go:960] 	Container node-init ready: true, restart count 1
  I0902 08:24:17.652630 16 predicates.go:958] cilium-operator-f9554d685-sqbm7 from kube-system started at 2025-09-02 06:13:04 +0000 UTC (1 container statuses recorded)
  I0902 08:24:17.652672 16 predicates.go:960] 	Container cilium-operator ready: true, restart count 4
  I0902 08:24:17.652708 16 predicates.go:958] cilium-x7gr5 from kube-system started at 2025-09-02 06:13:04 +0000 UTC (1 container statuses recorded)
  I0902 08:24:17.652739 16 predicates.go:960] 	Container cilium-agent ready: true, restart count 1
  I0902 08:24:17.652772 16 predicates.go:958] coredns-66bc5c9577-fcrhx from kube-system started at 2025-09-02 06:19:32 +0000 UTC (1 container statuses recorded)
  I0902 08:24:17.652790 16 predicates.go:960] 	Container coredns ready: true, restart count 0
  I0902 08:24:17.652806 16 predicates.go:958] kube-proxy-dvcxr from kube-system started at 2025-09-02 06:12:30 +0000 UTC (1 container statuses recorded)
  I0902 08:24:17.652824 16 predicates.go:960] 	Container kube-proxy ready: true, restart count 1
  I0902 08:24:17.652840 16 predicates.go:958] sonobuoy from sonobuoy started at 2025-09-02 07:29:56 +0000 UTC (1 container statuses recorded)
  I0902 08:24:17.652858 16 predicates.go:960] 	Container kube-sonobuoy ready: true, restart count 0
  I0902 08:24:17.652874 16 predicates.go:958] sonobuoy-e2e-job-5dae80ab010f494d from sonobuoy started at 2025-09-02 07:30:04 +0000 UTC (2 container statuses recorded)
  I0902 08:24:17.652904 16 predicates.go:960] 	Container e2e ready: true, restart count 0
  I0902 08:24:17.652918 16 predicates.go:960] 	Container sonobuoy-worker ready: true, restart count 0
  I0902 08:24:17.652934 16 predicates.go:958] sonobuoy-systemd-logs-daemon-set-707d3c8598644e6c-r5bs9 from sonobuoy started at 2025-09-02 07:30:04 +0000 UTC (2 container statuses recorded)
  I0902 08:24:17.652948 16 predicates.go:960] 	Container sonobuoy-worker ready: true, restart count 0
  I0902 08:24:17.652961 16 predicates.go:960] 	Container systemd-logs ready: true, restart count 0
  I0902 08:24:17.652975 16 predicates.go:958] svc-latency-rc-54bb7c7469-j774d from svc-latency-1279 started at 2025-09-02 08:24:02 +0000 UTC (1 container statuses recorded)
  I0902 08:24:17.652989 16 predicates.go:960] 	Container svc-latency-rc ready: true, restart count 0
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 09/02/25 08:24:17.653
  E0902 08:24:18.115978      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:24:19.116371      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 09/02/25 08:24:19.714
  STEP: Trying to apply a random label on the found node. @ 09/02/25 08:24:19.785
  STEP: verifying the node has the label kubernetes.io/e2e-57f50af8-028f-4910-8f48-7bd7b5895b4f 42 @ 09/02/25 08:24:19.821
  STEP: Trying to relaunch the pod, now with labels. @ 09/02/25 08:24:19.876
  E0902 08:24:20.117332      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:24:21.117871      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: removing the label kubernetes.io/e2e-57f50af8-028f-4910-8f48-7bd7b5895b4f off the node ietha7evai9i-2 @ 09/02/25 08:24:21.974
  STEP: verifying the node doesn't have the label kubernetes.io/e2e-57f50af8-028f-4910-8f48-7bd7b5895b4f @ 09/02/25 08:24:22.021
  I0902 08:24:22.047122 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-1684" for this suite. @ 09/02/25 08:24:22.064
• [4.572 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:60
  STEP: Creating a kubernetes client @ 09/02/25 08:24:22.088
  I0902 08:24:22.088848 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename watch @ 09/02/25 08:24:22.092
  E0902 08:24:22.119164      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:24:22.158
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:24:22.17
  STEP: creating a watch on configmaps with label A @ 09/02/25 08:24:22.192
  STEP: creating a watch on configmaps with label B @ 09/02/25 08:24:22.204
  STEP: creating a watch on configmaps with label A or B @ 09/02/25 08:24:22.209
  STEP: creating a configmap with label A and ensuring the correct watchers observe the notification @ 09/02/25 08:24:22.218
  I0902 08:24:22.239074 16 watch.go:426] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9067  0b7159d0-6fbc-4277-bf01-169732a938b5 34324 0 2025-09-02 08:24:22 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2025-09-02 08:24:22 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  I0902 08:24:22.239590 16 watch.go:426] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9067  0b7159d0-6fbc-4277-bf01-169732a938b5 34324 0 2025-09-02 08:24:22 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2025-09-02 08:24:22 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying configmap A and ensuring the correct watchers observe the notification @ 09/02/25 08:24:22.239
  I0902 08:24:22.254059 16 watch.go:426] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9067  0b7159d0-6fbc-4277-bf01-169732a938b5 34325 0 2025-09-02 08:24:22 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2025-09-02 08:24:22 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0902 08:24:22.254256 16 watch.go:426] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9067  0b7159d0-6fbc-4277-bf01-169732a938b5 34325 0 2025-09-02 08:24:22 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2025-09-02 08:24:22 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying configmap A again and ensuring the correct watchers observe the notification @ 09/02/25 08:24:22.254
  I0902 08:24:22.270878 16 watch.go:426] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9067  0b7159d0-6fbc-4277-bf01-169732a938b5 34326 0 2025-09-02 08:24:22 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2025-09-02 08:24:22 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0902 08:24:22.271073 16 watch.go:426] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9067  0b7159d0-6fbc-4277-bf01-169732a938b5 34326 0 2025-09-02 08:24:22 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2025-09-02 08:24:22 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: deleting configmap A and ensuring the correct watchers observe the notification @ 09/02/25 08:24:22.271
  I0902 08:24:22.289370 16 watch.go:426] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9067  0b7159d0-6fbc-4277-bf01-169732a938b5 34328 0 2025-09-02 08:24:22 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2025-09-02 08:24:22 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0902 08:24:22.289484 16 watch.go:426] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9067  0b7159d0-6fbc-4277-bf01-169732a938b5 34328 0 2025-09-02 08:24:22 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2025-09-02 08:24:22 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: creating a configmap with label B and ensuring the correct watchers observe the notification @ 09/02/25 08:24:22.289
  I0902 08:24:22.298938 16 watch.go:426] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9067  4beca86a-ff2e-4669-93d6-34e89ea7b88c 34329 0 2025-09-02 08:24:22 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2025-09-02 08:24:22 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  I0902 08:24:22.299751 16 watch.go:426] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9067  4beca86a-ff2e-4669-93d6-34e89ea7b88c 34329 0 2025-09-02 08:24:22 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2025-09-02 08:24:22 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  E0902 08:24:23.118947      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:24:24.119639      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:24:25.122308      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:24:26.121408      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:24:27.122288      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:24:28.122863      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:24:29.123026      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:24:30.123911      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:24:31.124703      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:24:32.125689      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: deleting configmap B and ensuring the correct watchers observe the notification @ 09/02/25 08:24:32.3
  I0902 08:24:32.348720 16 watch.go:426] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9067  4beca86a-ff2e-4669-93d6-34e89ea7b88c 35011 0 2025-09-02 08:24:22 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2025-09-02 08:24:22 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  I0902 08:24:32.350316 16 watch.go:426] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9067  4beca86a-ff2e-4669-93d6-34e89ea7b88c 35011 0 2025-09-02 08:24:22 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2025-09-02 08:24:22 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  E0902 08:24:33.127632      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:24:34.126909      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:24:35.127867      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:24:36.128627      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:24:37.129118      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:24:38.129261      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:24:39.129299      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:24:40.130121      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:24:41.131147      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:24:42.132310      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:24:42.355722 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-9067" for this suite. @ 09/02/25 08:24:42.378
• [20.323 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:105
  STEP: Creating a kubernetes client @ 09/02/25 08:24:42.413
  I0902 08:24:42.413708 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename deployment @ 09/02/25 08:24:42.419
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:24:42.452
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:24:42.459
  I0902 08:24:42.467017 16 deployment.go:754] Creating replica set "test-rolling-update-controller" (going to be adopted)
  I0902 08:24:42.499161 16 resource.go:64] Pod name sample-pod: Found 0 pods out of 1
  E0902 08:24:43.132834      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:24:44.133358      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:24:45.134003      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:24:46.134165      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:24:47.134922      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:24:47.511866 16 resource.go:64] Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 09/02/25 08:24:47.512
  I0902 08:24:47.512119 16 deployment.go:769] Creating deployment "test-rolling-update-deployment"
  I0902 08:24:47.528943 16 deployment.go:775] Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
  I0902 08:24:47.549948 16 deployment.go:223] new replicaset for deployment "test-rolling-update-deployment" is yet to be created
  E0902 08:24:48.135791      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:24:49.136270      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:24:49.570845 16 deployment.go:779] Ensuring status for deployment "test-rolling-update-deployment" is the expected
  I0902 08:24:49.581462 16 deployment.go:784] Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
  I0902 08:24:49.610928 16 deployment.go:632] Deployment "test-rolling-update-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-rolling-update-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-5580",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "b9cb2307-850e-4306-9c22-c608bbc5b6dd",
      ResourceVersion: (string) (len=5) "35171",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63892398287,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=10) "sample-pod"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305833"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892398287,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=637) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 61  67 6e 68 6f 73 74 5c 22  |me\":\"agnhost\"|
              00000160  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000170  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000180  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000190  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              000001a0  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              000001b0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001c0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              000001d0  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              000001e0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001f0  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000200  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              00000210  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              00000220  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              00000230  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000270  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892398289,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=10) "sample-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=10) "sample-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.56",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          HostnameOverride: (*string)(<nil>)
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      TerminatingReplicas: (*int32)(<nil>),
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892398287,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892398287,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892398289,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892398287,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=83) "ReplicaSet \"test-rolling-update-deployment-5bd98b4894\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0902 08:24:49.673534 16 deployment.go:40] New ReplicaSet "test-rolling-update-deployment-5bd98b4894" of Deployment "test-rolling-update-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=41) "test-rolling-update-deployment-5bd98b4894",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-5580",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "6741bbbc-0bda-47a2-8e8e-206ddef47f54",
      ResourceVersion: (string) (len=5) "35160",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63892398287,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "5bd98b4894"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305833"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=30) "test-rolling-update-deployment",
          UID: (types.UID) (len=36) "b9cb2307-850e-4306-9c22-c608bbc5b6dd",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892398287,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 62 39 63 62 32 33  30 37 2d 38 35 30 65 2d  |\"b9cb2307-850e-|
              00000120  34 33 30 36 2d 39 63 32  32 2d 63 36 30 38 62 62  |4306-9c22-c608bb|
              00000130  63 35 62 36 64 64 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |c5b6dd\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892398289,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=10) "sample-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "5bd98b4894"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=17) "pod-template-hash": (string) (len=10) "5bd98b4894",
            (string) (len=4) "name": (string) (len=10) "sample-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.56",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          HostnameOverride: (*string)(<nil>)
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      TerminatingReplicas: (*int32)(<nil>),
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0902 08:24:49.679494 16 deployment.go:45] All old ReplicaSets of Deployment "test-rolling-update-deployment":
  I0902 08:24:49.680298 16 deployment.go:48] (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-rolling-update-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-5580",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "1168cce8-10fe-4cac-833f-ca87e62cf399",
      ResourceVersion: (string) (len=5) "35170",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63892398282,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305832"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=30) "test-rolling-update-deployment",
          UID: (types.UID) (len=36) "b9cb2307-850e-4306-9c22-c608bbc5b6dd",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892398282,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=533) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  2c 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |,"f:labels":{"."|
              00000060  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              00000070  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              00000080  73 70 65 63 22 3a 7b 22  66 3a 73 65 6c 65 63 74  |spec":{"f:select|
              00000090  6f 72 22 3a 7b 7d 2c 22  66 3a 74 65 6d 70 6c 61  |or":{},"f:templa|
              000000a0  74 65 22 3a 7b 22 66 3a  6d 65 74 61 64 61 74 61  |te":{"f:metadata|
              000000b0  22 3a 7b 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |":{"f:labels":{"|
              000000c0  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              000000d0  7d 2c 22 66 3a 70 6f 64  22 3a 7b 7d 7d 7d 2c 22  |},"f:pod":{}}},"|
              000000e0  66 3a 73 70 65 63 22 3a  7b 22 66 3a 63 6f 6e 74  |f:spec":{"f:cont|
              000000f0  61 69 6e 65 72 73 22 3a  7b 22 6b 3a 7b 5c 22 6e  |ainers":{"k:{\"n|
              00000100  61 6d 65 5c 22 3a 5c 22  68 74 74 70 64 5c 22 7d  |ame\":\"httpd\"}|
              00000110  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |":{".":{},"f:ima|
              00000120  67 65 22 3a 7b 7d 2c 22  66 3a 69 6d 61 67 65 50  |ge":{},"f:imageP|
              00000130  75 6c 6c 50 6f 6c 69 63  79 22 3a 7b 7d 2c 22 66  |ullPolicy":{},"f|
              00000140  3a 6e 61 6d 65 22 3a 7b  7d 2c 22 66 3a 72 65 73  |:name":{},"f:res|
              00000150  6f 75 72 63 65 73 22 3a  7b 7d 2c 22 66 3a 74 65  |ources":{},"f:te|
              00000160  72 6d 69 6e 61 74 69 6f  6e 4d 65 73 73 61 67 65  |rminationMessage|
              00000170  50 61 74 68 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |Path":{},"f:term|
              00000180  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 6f  |inationMessagePo|
              00000190  6c 69 63 79 22 3a 7b 7d  7d 7d 2c 22 66 3a 64 6e  |licy":{}}},"f:dn|
              000001a0  73 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 72  |sPolicy":{},"f:r|
              000001b0  65 73 74 61 72 74 50 6f  6c 69 63 79 22 3a 7b 7d  |estartPolicy":{}|
              000001c0  2c 22 66 3a 73 63 68 65  64 75 6c 65 72 4e 61 6d  |,"f:schedulerNam|
              000001d0  65 22 3a 7b 7d 2c 22 66  3a 73 65 63 75 72 69 74  |e":{},"f:securit|
              000001e0  79 43 6f 6e 74 65 78 74  22 3a 7b 7d 2c 22 66 3a  |yContext":{},"f:|
              000001f0  74 65 72 6d 69 6e 61 74  69 6f 6e 47 72 61 63 65  |terminationGrace|
              00000200  50 65 72 69 6f 64 53 65  63 6f 6e 64 73 22 3a 7b  |PeriodSeconds":{|
              00000210  7d 7d 7d 7d 7d                                    |}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892398289,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=242) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 66 3a 64 65 70 6c 6f  79 6d 65 6e 74 2e 6b 75  |"f:deployment.ku|
              00000030  62 65 72 6e 65 74 65 73  2e 69 6f 2f 64 65 73 69  |bernetes.io/desi|
              00000040  72 65 64 2d 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |red-replicas":{}|
              00000050  2c 22 66 3a 64 65 70 6c  6f 79 6d 65 6e 74 2e 6b  |,"f:deployment.k|
              00000060  75 62 65 72 6e 65 74 65  73 2e 69 6f 2f 6d 61 78  |ubernetes.io/max|
              00000070  2d 72 65 70 6c 69 63 61  73 22 3a 7b 7d 7d 2c 22  |-replicas":{}},"|
              00000080  66 3a 6f 77 6e 65 72 52  65 66 65 72 65 6e 63 65  |f:ownerReference|
              00000090  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 6b 3a 7b 5c  |s":{".":{},"k:{\|
              000000a0  22 75 69 64 5c 22 3a 5c  22 62 39 63 62 32 33 30  |"uid\":\"b9cb230|
              000000b0  37 2d 38 35 30 65 2d 34  33 30 36 2d 39 63 32 32  |7-850e-4306-9c22|
              000000c0  2d 63 36 30 38 62 62 63  35 62 36 64 64 5c 22 7d  |-c608bbc5b6dd\"}|
              000000d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000000e0  7b 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |{"f:replicas":{}|
              000000f0  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892398289,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=10) "sample-pod",
          (string) (len=3) "pod": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=10) "sample-pod",
            (string) (len=3) "pod": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          HostnameOverride: (*string)(<nil>)
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      TerminatingReplicas: (*int32)(<nil>),
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0902 08:24:49.699826 16 deployment.go:68] Pod "test-rolling-update-deployment-5bd98b4894-c9t8l" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=47) "test-rolling-update-deployment-5bd98b4894-c9t8l",
      GenerateName: (string) (len=42) "test-rolling-update-deployment-5bd98b4894-",
      Namespace: (string) (len=15) "deployment-5580",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "6478a34b-05d0-4cb6-9a60-f93db1289c56",
      ResourceVersion: (string) (len=5) "35159",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63892398287,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "5bd98b4894"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=41) "test-rolling-update-deployment-5bd98b4894",
          UID: (types.UID) (len=36) "6741bbbc-0bda-47a2-8e8e-206ddef47f54",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892398287,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 36 37  34 31 62 62 62 63 2d 30  |d\":\"6741bbbc-0|
              00000090  62 64 61 2d 34 37 61 32  2d 38 65 38 65 2d 32 30  |bda-47a2-8e8e-20|
              000000a0  36 64 64 65 66 34 37 66  35 34 5c 22 7d 22 3a 7b  |6ddef47f54\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892398289,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=850) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6f 62 73 65 72 76  |me":{},"f:observ|
              00000080  65 64 47 65 6e 65 72 61  74 69 6f 6e 22 3a 7b 7d  |edGeneration":{}|
              00000090  2c 22 66 3a 73 74 61 74  75 73 22 3a 7b 7d 2c 22  |,"f:status":{},"|
              000000a0  66 3a 74 79 70 65 22 3a  7b 7d 7d 2c 22 6b 3a 7b  |f:type":{}},"k:{|
              000000b0  5c 22 74 79 70 65 5c 22  3a 5c 22 49 6e 69 74 69  |\"type\":\"Initi|
              000000c0  61 6c 69 7a 65 64 5c 22  7d 22 3a 7b 22 2e 22 3a  |alized\"}":{".":|
              000000d0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000000f0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              00000100  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000110  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |eration":{},"f:s|
              00000120  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000130  65 22 3a 7b 7d 7d 2c 22  6b 3a 7b 5c 22 74 79 70  |e":{}},"k:{\"typ|
              00000140  65 5c 22 3a 5c 22 50 6f  64 52 65 61 64 79 54 6f  |e\":\"PodReadyTo|
              00000150  53 74 61 72 74 43 6f 6e  74 61 69 6e 65 72 73 5c  |StartContainers\|
              00000160  22 7d 22 3a 7b 22 2e 22  3a 7b 7d 2c 22 66 3a 6c  |"}":{".":{},"f:l|
              00000170  61 73 74 50 72 6f 62 65  54 69 6d 65 22 3a 7b 7d  |astProbeTime":{}|
              00000180  2c 22 66 3a 6c 61 73 74  54 72 61 6e 73 69 74 69  |,"f:lastTransiti|
              00000190  6f 6e 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6f 62  |onTime":{},"f:ob|
              000001a0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001b0  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              000001c0  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              000001d0  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              000001e0  6f 64 53 63 68 65 64 75  6c 65 64 5c 22 7d 22 3a  |odScheduled\"}":|
              000001f0  7b 22 66 3a 6f 62 73 65  72 76 65 64 47 65 6e 65  |{"f:observedGene|
              00000200  72 61 74 69 6f 6e 22 3a  7b 7d 7d 2c 22 6b 3a 7b  |ration":{}},"k:{|
              00000210  5c 22 74 79 70 65 5c 22  3a 5c 22 52 65 61 64 79  |\"type\":\"Ready|
              00000220  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000230  6c 61 73 74 50 72 6f 62  65 54 69 6d 65 22 3a 7b  |lastProbeTime":{|
              00000240  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000250  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6f  |ionTime":{},"f:o|
              00000260  62 73 65 72 76 65 64 47  65 6e 65 72 61 74 69 6f  |bservedGeneratio|
              00000270  6e 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |n":{},"f:status"|
              00000280  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000290  7d 2c 22 66 3a 63 6f 6e  74 61 69 6e 65 72 53 74  |},"f:containerSt|
              000002a0  61 74 75 73 65 73 22 3a  7b 7d 2c 22 66 3a 68 6f  |atuses":{},"f:ho|
              000002b0  73 74 49 50 22 3a 7b 7d  2c 22 66 3a 68 6f 73 74  |stIP":{},"f:host|
              000002c0  49 50 73 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |IPs":{},"f:obser|
              000002d0  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000002e0  7d 2c 22 66 3a 70 68 61  73 65 22 3a 7b 7d 2c 22  |},"f:phase":{},"|
              000002f0  66 3a 70 6f 64 49 50 22  3a 7b 7d 2c 22 66 3a 70  |f:podIP":{},"f:p|
              00000300  6f 64 49 50 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |odIPs":{".":{},"|
              00000310  6b 3a 7b 5c 22 69 70 5c  22 3a 5c 22 31 30 2e 32  |k:{\"ip\":\"10.2|
              00000320  33 33 2e 36 35 2e 33 5c  22 7d 22 3a 7b 22 2e 22  |33.65.3\"}":{"."|
              00000330  3a 7b 7d 2c 22 66 3a 69  70 22 3a 7b 7d 7d 7d 2c  |:{},"f:ip":{}}},|
              00000340  22 66 3a 73 74 61 72 74  54 69 6d 65 22 3a 7b 7d  |"f:startTime":{}|
              00000350  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-kgjjv",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.56",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-kgjjv",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "ietha7evai9i-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 1,
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892398289,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892398287,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892398289,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892398289,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892398287,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.52",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.121.52"
        }
      },
      PodIP: (string) (len=11) "10.233.65.3",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.233.65.3"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63892398287,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63892398288,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.56",
          ImageID: (string) (len=111) "registry.k8s.io/e2e-test-images/agnhost@sha256:30ffacb713aad721881f1c11a768df228bfad3dc366d268e82b02fc43511dfa4",
          ContainerID: (string) (len=72) "cri-o://8515560479cfbfc6fb6e256d8db3b6e138e040f08513b51a143ec8e7f2854cee",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)({
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          }),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-kgjjv",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)({
            Linux: (*v1.LinuxContainerUser)({
              UID: (int64) 0,
              GID: (int64) 0,
              SupplementalGroups: ([]int64) (len=11) {
                (int64) 0,
                (int64) 1,
                (int64) 2,
                (int64) 3,
                (int64) 4,
                (int64) 6,
                (int64) 10,
                (int64) 11,
                (int64) 20,
                (int64) 26,
                (int64) 27
              }
            })
          }),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>)
    }
  }

  I0902 08:24:49.706849 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-5580" for this suite. @ 09/02/25 08:24:49.722
• [7.329 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:175
  STEP: Creating a kubernetes client @ 09/02/25 08:24:49.745
  I0902 08:24:49.745995 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename configmap @ 09/02/25 08:24:49.751
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:24:49.78
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:24:49.79
  STEP: Creating configMap with name configmap-test-upd-ce5d4c54-6401-4bbe-807f-143813605d93 @ 09/02/25 08:24:49.821
  STEP: Creating the pod @ 09/02/25 08:24:49.839
  E0902 08:24:50.136965      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:24:51.138062      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Waiting for pod with text data @ 09/02/25 08:24:51.895
  STEP: Waiting for pod with binary data @ 09/02/25 08:24:51.918
  I0902 08:24:51.932528 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-9037" for this suite. @ 09/02/25 08:24:51.943
• [2.224 seconds]
------------------------------
[sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:208
  STEP: Creating a kubernetes client @ 09/02/25 08:24:51.969
  I0902 08:24:51.969633 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename downward-api @ 09/02/25 08:24:51.973
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:24:52.007
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:24:52.014
  STEP: Creating a pod to test downward API volume plugin @ 09/02/25 08:24:52.02
  E0902 08:24:52.138504      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:24:53.140009      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:24:54.140661      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:24:55.142709      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/02/25 08:24:56.074
  I0902 08:24:56.082688 16 output.go:207] Trying to get logs from node ietha7evai9i-3 pod downwardapi-volume-4cf9c37d-3bc5-4f09-a126-80a01874a893 container client-container: <nil>
  STEP: delete the pod @ 09/02/25 08:24:56.118
  E0902 08:24:56.142518      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:24:56.161496 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-7258" for this suite. @ 09/02/25 08:24:56.171
• [4.219 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/certificates.go:200
  STEP: Creating a kubernetes client @ 09/02/25 08:24:56.194
  I0902 08:24:56.194650 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename certificates @ 09/02/25 08:24:56.198
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:24:56.23
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:24:56.238
  E0902 08:24:57.143439      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:24:58.144195      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:24:59.144815      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: getting /apis @ 09/02/25 08:24:59.902
  STEP: getting /apis/certificates.k8s.io @ 09/02/25 08:24:59.911
  STEP: getting /apis/certificates.k8s.io/v1 @ 09/02/25 08:24:59.915
  STEP: creating @ 09/02/25 08:24:59.917
  STEP: getting @ 09/02/25 08:24:59.989
  STEP: listing @ 09/02/25 08:25:00
  STEP: watching @ 09/02/25 08:25:00.009
  I0902 08:25:00.009284 16 certificates.go:316] starting watch
  STEP: patching @ 09/02/25 08:25:00.011
  STEP: updating @ 09/02/25 08:25:00.035
  I0902 08:25:00.049501 16 certificates.go:332] waiting for watch events with expected annotations
  I0902 08:25:00.049619 16 certificates.go:345] saw patched and updated annotations
  STEP: getting /approval @ 09/02/25 08:25:00.049
  STEP: patching /approval @ 09/02/25 08:25:00.056
  STEP: updating /approval @ 09/02/25 08:25:00.091
  STEP: getting /status @ 09/02/25 08:25:00.119
  STEP: patching /status @ 09/02/25 08:25:00.13
  E0902 08:25:00.146419      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: updating /status @ 09/02/25 08:25:00.148
  STEP: deleting @ 09/02/25 08:25:00.168
  STEP: deleting a collection @ 09/02/25 08:25:00.213
  I0902 08:25:00.246175 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "certificates-4331" for this suite. @ 09/02/25 08:25:00.26
• [4.083 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/pods.go:166
  STEP: Creating a kubernetes client @ 09/02/25 08:25:00.277
  I0902 08:25:00.277505 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename pods @ 09/02/25 08:25:00.281
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:25:00.335
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:25:00.346
  STEP: creating the pod @ 09/02/25 08:25:00.356
  STEP: submitting the pod to kubernetes @ 09/02/25 08:25:00.357
  STEP: verifying QOS class is set on the pod @ 09/02/25 08:25:00.379
  I0902 08:25:00.391588 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-3224" for this suite. @ 09/02/25 08:25:00.426
• [0.169 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/proxy.go:338
  STEP: Creating a kubernetes client @ 09/02/25 08:25:00.448
  I0902 08:25:00.448253 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename proxy @ 09/02/25 08:25:00.452
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:25:00.478
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:25:00.483
  I0902 08:25:00.489258 16 proxy.go:345] Creating pod...
  E0902 08:25:01.146399      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:25:02.146729      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:25:02.539069 16 proxy.go:369] Creating service...
  I0902 08:25:02.588138 16 proxy.go:406] Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-9923/pods/agnhost/proxy/some/path/with/DELETE
  I0902 08:25:02.610991 16 proxy.go:582] http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  I0902 08:25:02.611102 16 proxy.go:406] Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-9923/pods/agnhost/proxy/some/path/with/GET
  I0902 08:25:02.626329 16 proxy.go:582] http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
  I0902 08:25:02.626409 16 proxy.go:406] Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-9923/pods/agnhost/proxy/some/path/with/HEAD
  I0902 08:25:02.637717 16 proxy.go:569] http.Client request:HEAD | StatusCode:200
  I0902 08:25:02.638093 16 proxy.go:406] Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-9923/pods/agnhost/proxy/some/path/with/OPTIONS
  I0902 08:25:02.645870 16 proxy.go:582] http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  I0902 08:25:02.645937 16 proxy.go:406] Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-9923/pods/agnhost/proxy/some/path/with/PATCH
  I0902 08:25:02.652038 16 proxy.go:582] http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  I0902 08:25:02.652104 16 proxy.go:406] Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-9923/pods/agnhost/proxy/some/path/with/POST
  I0902 08:25:02.658031 16 proxy.go:582] http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  I0902 08:25:02.658616 16 proxy.go:406] Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-9923/pods/agnhost/proxy/some/path/with/PUT
  I0902 08:25:02.670876 16 proxy.go:582] http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  I0902 08:25:02.670968 16 proxy.go:417] Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-9923/services/test-service/proxy/some/path/with/DELETE
  I0902 08:25:02.682875 16 proxy.go:582] http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  I0902 08:25:02.682941 16 proxy.go:417] Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-9923/services/test-service/proxy/some/path/with/GET
  I0902 08:25:02.693730 16 proxy.go:582] http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
  I0902 08:25:02.693815 16 proxy.go:417] Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-9923/services/test-service/proxy/some/path/with/HEAD
  I0902 08:25:02.703834 16 proxy.go:569] http.Client request:HEAD | StatusCode:200
  I0902 08:25:02.703963 16 proxy.go:417] Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-9923/services/test-service/proxy/some/path/with/OPTIONS
  I0902 08:25:02.712690 16 proxy.go:582] http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  I0902 08:25:02.712772 16 proxy.go:417] Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-9923/services/test-service/proxy/some/path/with/PATCH
  I0902 08:25:02.723382 16 proxy.go:582] http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  I0902 08:25:02.723445 16 proxy.go:417] Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-9923/services/test-service/proxy/some/path/with/POST
  I0902 08:25:02.734357 16 proxy.go:582] http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  I0902 08:25:02.734846 16 proxy.go:417] Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-9923/services/test-service/proxy/some/path/with/PUT
  I0902 08:25:02.746379 16 proxy.go:582] http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  I0902 08:25:02.746897 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-9923" for this suite. @ 09/02/25 08:25:02.758
• [2.327 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:108
  STEP: Creating a kubernetes client @ 09/02/25 08:25:02.776
  I0902 08:25:02.776188 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename pod-network-test @ 09/02/25 08:25:02.779
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:25:02.809
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:25:02.814
  STEP: Performing setup for networking test in namespace pod-network-test-2332 @ 09/02/25 08:25:02.82
  STEP: creating a selector @ 09/02/25 08:25:02.82
  STEP: Creating the service pods in kubernetes @ 09/02/25 08:25:02.821
  I0902 08:25:02.821607 16 helper.go:51] Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0902 08:25:03.147710      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:25:04.147920      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:25:05.148810      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:25:06.149012      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:25:07.149497      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:25:08.149957      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:25:09.150495      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:25:10.151688      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:25:11.152161      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:25:12.153228      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:25:13.154743      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:25:14.155517      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:25:15.156070      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:25:16.156477      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 09/02/25 08:25:17.137
  E0902 08:25:17.157250      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:25:18.157488      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:25:19.157783      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:25:19.250081 16 utils.go:803] Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  I0902 08:25:19.250199 16 utils.go:496] Going to poll 10.233.64.151 on port 8083 at least 0 times, with a maximum of 39 tries before failing
  I0902 08:25:19.257463 16 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.233.64.151:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-2332 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0902 08:25:19.257578 16 exec_util.go:68] ExecWithOptions: Clientset creation
  I0902 08:25:19.257708 16 exec_util.go:84] ExecWithOptions: execute(https://10.233.0.1:443/api/v1/namespaces/pod-network-test-2332/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.233.64.151%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&stderr=true&stdout=true)
  I0902 08:25:19.447894 16 utils.go:513] Found all 1 expected endpoints: [netserver-0]
  I0902 08:25:19.448034 16 utils.go:496] Going to poll 10.233.66.99 on port 8083 at least 0 times, with a maximum of 39 tries before failing
  I0902 08:25:19.464528 16 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.233.66.99:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-2332 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0902 08:25:19.464620 16 exec_util.go:68] ExecWithOptions: Clientset creation
  I0902 08:25:19.464697 16 exec_util.go:84] ExecWithOptions: execute(https://10.233.0.1:443/api/v1/namespaces/pod-network-test-2332/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.233.66.99%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&stderr=true&stdout=true)
  I0902 08:25:19.582410 16 utils.go:513] Found all 1 expected endpoints: [netserver-1]
  I0902 08:25:19.583711 16 utils.go:496] Going to poll 10.233.65.84 on port 8083 at least 0 times, with a maximum of 39 tries before failing
  I0902 08:25:19.598883 16 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.233.65.84:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-2332 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0902 08:25:19.598949 16 exec_util.go:68] ExecWithOptions: Clientset creation
  I0902 08:25:19.599036 16 exec_util.go:84] ExecWithOptions: execute(https://10.233.0.1:443/api/v1/namespaces/pod-network-test-2332/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.233.65.84%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&stderr=true&stdout=true)
  I0902 08:25:19.723651 16 utils.go:513] Found all 1 expected endpoints: [netserver-2]
  I0902 08:25:19.724417 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-2332" for this suite. @ 09/02/25 08:25:19.734
• [16.974 seconds]
------------------------------
[sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2230
  STEP: Creating a kubernetes client @ 09/02/25 08:25:19.75
  I0902 08:25:19.750751 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename services @ 09/02/25 08:25:19.753
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:25:19.776
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:25:19.784
  STEP: creating service in namespace services-8698 @ 09/02/25 08:25:19.789
  STEP: creating service affinity-clusterip in namespace services-8698 @ 09/02/25 08:25:19.79
  I0902 08:25:19.843941 16 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:0, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:0, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition(nil), CollisionCount:(*int32)(nil)}
  E0902 08:25:20.158700      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:25:21.159401      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:25:21.897506 16 resource.go:344] Creating new exec pod
  E0902 08:25:22.160029      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:25:23.161062      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:25:23.956617 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=services-8698 exec execpod-affinityzhcc2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
  E0902 08:25:24.162144      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:25:24.375693 16 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip 80\nConnection to affinity-clusterip (10.233.45.244) 80 port [tcp/http] succeeded!\n"
  I0902 08:25:24.375799 16 builder.go:157] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0902 08:25:24.376430 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=services-8698 exec execpod-affinityzhcc2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.45.244 80'
  I0902 08:25:24.692960 16 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.45.244 80\nConnection to 10.233.45.244 80 port [tcp/http] succeeded!\n"
  I0902 08:25:24.693161 16 builder.go:157] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0902 08:25:24.694653 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=services-8698 exec execpod-affinityzhcc2 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 --max-time 60 http://10.233.45.244:80/ ; done'
  E0902 08:25:25.163006      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:25:26.077822 16 builder.go:156] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.233.45.244:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.233.45.244:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.233.45.244:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.233.45.244:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.233.45.244:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.233.45.244:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.233.45.244:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.233.45.244:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.233.45.244:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.233.45.244:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.233.45.244:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.233.45.244:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.233.45.244:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.233.45.244:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.233.45.244:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.233.45.244:80/\n"
  I0902 08:25:26.077920 16 builder.go:157] stdout: "\naffinity-clusterip-5d4d4bb77f-zkqnd\naffinity-clusterip-5d4d4bb77f-zkqnd\naffinity-clusterip-5d4d4bb77f-zkqnd\naffinity-clusterip-5d4d4bb77f-zkqnd\naffinity-clusterip-5d4d4bb77f-zkqnd\naffinity-clusterip-5d4d4bb77f-zkqnd\naffinity-clusterip-5d4d4bb77f-zkqnd\naffinity-clusterip-5d4d4bb77f-zkqnd\naffinity-clusterip-5d4d4bb77f-zkqnd\naffinity-clusterip-5d4d4bb77f-zkqnd\naffinity-clusterip-5d4d4bb77f-zkqnd\naffinity-clusterip-5d4d4bb77f-zkqnd\naffinity-clusterip-5d4d4bb77f-zkqnd\naffinity-clusterip-5d4d4bb77f-zkqnd\naffinity-clusterip-5d4d4bb77f-zkqnd\naffinity-clusterip-5d4d4bb77f-zkqnd"
  I0902 08:25:26.077966 16 service.go:225] Received response from host: affinity-clusterip-5d4d4bb77f-zkqnd
  I0902 08:25:26.077989 16 service.go:225] Received response from host: affinity-clusterip-5d4d4bb77f-zkqnd
  I0902 08:25:26.078006 16 service.go:225] Received response from host: affinity-clusterip-5d4d4bb77f-zkqnd
  I0902 08:25:26.078023 16 service.go:225] Received response from host: affinity-clusterip-5d4d4bb77f-zkqnd
  I0902 08:25:26.078039 16 service.go:225] Received response from host: affinity-clusterip-5d4d4bb77f-zkqnd
  I0902 08:25:26.079063 16 service.go:225] Received response from host: affinity-clusterip-5d4d4bb77f-zkqnd
  I0902 08:25:26.079141 16 service.go:225] Received response from host: affinity-clusterip-5d4d4bb77f-zkqnd
  I0902 08:25:26.079184 16 service.go:225] Received response from host: affinity-clusterip-5d4d4bb77f-zkqnd
  I0902 08:25:26.079226 16 service.go:225] Received response from host: affinity-clusterip-5d4d4bb77f-zkqnd
  I0902 08:25:26.079263 16 service.go:225] Received response from host: affinity-clusterip-5d4d4bb77f-zkqnd
  I0902 08:25:26.079298 16 service.go:225] Received response from host: affinity-clusterip-5d4d4bb77f-zkqnd
  I0902 08:25:26.079332 16 service.go:225] Received response from host: affinity-clusterip-5d4d4bb77f-zkqnd
  I0902 08:25:26.079366 16 service.go:225] Received response from host: affinity-clusterip-5d4d4bb77f-zkqnd
  I0902 08:25:26.079399 16 service.go:225] Received response from host: affinity-clusterip-5d4d4bb77f-zkqnd
  I0902 08:25:26.079432 16 service.go:225] Received response from host: affinity-clusterip-5d4d4bb77f-zkqnd
  I0902 08:25:26.079466 16 service.go:225] Received response from host: affinity-clusterip-5d4d4bb77f-zkqnd
  I0902 08:25:26.079741 16 service.go:4469] Cleaning up the exec pod
  E0902 08:25:26.165775      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:25:26.245027 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-8698" for this suite. @ 09/02/25 08:25:26.268
• [6.547 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:144
  STEP: Creating a kubernetes client @ 09/02/25 08:25:26.326
  I0902 08:25:26.326434 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename disruption @ 09/02/25 08:25:26.33
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:25:26.435
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:25:26.448
  STEP: Waiting for the pdb to be processed @ 09/02/25 08:25:26.501
  E0902 08:25:27.164589      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:25:28.165172      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Waiting for all pods to be running @ 09/02/25 08:25:28.67
  I0902 08:25:28.705379 16 disruption.go:691] running pods: 0 < 3
  E0902 08:25:29.165855      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:25:30.166536      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:25:30.701053 16 disruption.go:691] running pods: 2 < 3
  E0902 08:25:31.166456      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:25:32.167334      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:25:32.697611 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-7614" for this suite. @ 09/02/25 08:25:32.734
• [6.432 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:826
  STEP: Creating a kubernetes client @ 09/02/25 08:25:32.759
  I0902 08:25:32.759445 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename gc @ 09/02/25 08:25:32.761
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:25:32.794
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:25:32.799
  I0902 08:25:32.905714 16 garbage_collector.go:848] pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"ad68ec32-fb53-4160-92fc-7eb42edb031b", Controller:(*bool)(0xc00452bc7a), BlockOwnerDeletion:(*bool)(0xc00452bc7b)}}
  I0902 08:25:32.971086 16 garbage_collector.go:852] pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"ebdb5b94-a4fb-447a-9881-b8afaabe577e", Controller:(*bool)(0xc00452be56), BlockOwnerDeletion:(*bool)(0xc00452be57)}}
  I0902 08:25:32.985837 16 garbage_collector.go:856] pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"4099bb4d-717a-4dd2-bea1-84ca7f22a3bf", Controller:(*bool)(0xc0033874d6), BlockOwnerDeletion:(*bool)(0xc0033874d7)}}
  E0902 08:25:33.167423      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:25:34.168388      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:25:35.168867      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:25:36.169073      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:25:37.169977      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:25:38.030262 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-1061" for this suite. @ 09/02/25 08:25:38.042
• [5.332 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:177
  STEP: Creating a kubernetes client @ 09/02/25 08:25:38.096
  I0902 08:25:38.097769 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename daemonsets @ 09/02/25 08:25:38.1
  E0902 08:25:38.169812      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:25:38.278
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:25:38.374
  STEP: Creating simple DaemonSet "daemon-set" @ 09/02/25 08:25:38.488
  STEP: Check that daemon pods launch on every node of the cluster. @ 09/02/25 08:25:38.505
  I0902 08:25:38.577830 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0902 08:25:38.577911 16 fixtures.go:131] Node ietha7evai9i-1 is running 0 daemon pod, expected 1
  E0902 08:25:39.171102      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:25:39.533940 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0902 08:25:39.534046 16 fixtures.go:131] Node ietha7evai9i-1 is running 0 daemon pod, expected 1
  E0902 08:25:40.173185      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:25:40.526248 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0902 08:25:40.526348 16 fixtures.go:131] Node ietha7evai9i-1 is running 0 daemon pod, expected 1
  E0902 08:25:41.173270      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:25:41.540030 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0902 08:25:41.540168 16 fixtures.go:131] Node ietha7evai9i-1 is running 0 daemon pod, expected 1
  E0902 08:25:42.174007      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:25:42.543665 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I0902 08:25:42.543774 16 fixtures.go:136] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Stop a daemon pod, check that the daemon pod is revived. @ 09/02/25 08:25:42.554
  I0902 08:25:42.640648 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0902 08:25:42.640724 16 fixtures.go:131] Node ietha7evai9i-3 is running 0 daemon pod, expected 1
  E0902 08:25:43.175032      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:25:43.606404 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0902 08:25:43.606938 16 fixtures.go:131] Node ietha7evai9i-3 is running 0 daemon pod, expected 1
  E0902 08:25:44.179391      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:25:44.604634 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0902 08:25:44.604708 16 fixtures.go:131] Node ietha7evai9i-3 is running 0 daemon pod, expected 1
  E0902 08:25:45.175850      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:25:45.618153 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I0902 08:25:45.618653 16 fixtures.go:136] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 09/02/25 08:25:45.631
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7069, will wait for the garbage collector to delete the pods @ 09/02/25 08:25:45.631
  I0902 08:25:45.713714 16 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 19.808834ms
  I0902 08:25:45.814391 16 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 100.575547ms
  E0902 08:25:46.175873      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:25:47.026053 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0902 08:25:47.026148 16 fixtures.go:136] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I0902 08:25:47.036283 16 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"35890"},"items":null}

  I0902 08:25:47.049838 16 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"35890"},"items":null}

  I0902 08:25:47.097011 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-7069" for this suite. @ 09/02/25 08:25:47.171
  E0902 08:25:47.176759      16 retrywatcher.go:169] "Watch failed" err="context canceled"
• [9.109 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate everything except 'skip-me' configmaps [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:865
  STEP: Creating a kubernetes client @ 09/02/25 08:25:47.205
  I0902 08:25:47.205936 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename webhook @ 09/02/25 08:25:47.209
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:25:47.238
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:25:47.247
  STEP: Setting up server cert @ 09/02/25 08:25:47.294
  E0902 08:25:48.177744      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 09/02/25 08:25:48.493
  STEP: Deploying the webhook pod @ 09/02/25 08:25:48.509
  STEP: Wait for the deployment to be ready @ 09/02/25 08:25:48.543
  I0902 08:25:48.567872 16 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0902 08:25:49.178301      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:25:50.179360      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:25:50.606863 16 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.September, 2, 8, 25, 48, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 8, 25, 48, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.September, 2, 8, 25, 48, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 8, 25, 48, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7d44fffc8\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0902 08:25:51.179423      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:25:52.179667      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 09/02/25 08:25:52.617
  STEP: Verifying the service has paired with the endpoint @ 09/02/25 08:25:52.645
  E0902 08:25:53.180209      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:25:53.645412 16 util.go:419] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: creating a mutating webhook with match conditions @ 09/02/25 08:25:53.656
  I0902 08:25:53.715230 16 webhook.go:2701] Waiting for webhook configuration to be ready...
  STEP: create the configmap with a random name @ 09/02/25 08:25:53.847
  STEP: verify the configmap is mutated @ 09/02/25 08:25:53.891
  STEP: create the configmap with 'skip-me' name @ 09/02/25 08:25:53.892
  I0902 08:25:54.030629 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-792" for this suite. @ 09/02/25 08:25:54.042
  STEP: Destroying namespace "webhook-markers-696" for this suite. @ 09/02/25 08:25:54.058
• [6.880 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Deployment should validate Deployment Status endpoints [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:488
  STEP: Creating a kubernetes client @ 09/02/25 08:25:54.086
  I0902 08:25:54.086246 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename deployment @ 09/02/25 08:25:54.089
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:25:54.126
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:25:54.134
  STEP: creating a Deployment @ 09/02/25 08:25:54.146
  I0902 08:25:54.147308 16 deployment.go:506] Creating simple deployment test-deployment-tnnjn
  I0902 08:25:54.178719 16 deployment.go:223] deployment "test-deployment-tnnjn" doesn't have the required revision set
  E0902 08:25:54.180403      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:25:55.180705      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:25:56.180833      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Getting /status @ 09/02/25 08:25:56.22
  I0902 08:25:56.232525 16 deployment.go:531] Deployment test-deployment-tnnjn has Conditions: [{Available True 2025-09-02 08:25:55 +0000 UTC 2025-09-02 08:25:55 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2025-09-02 08:25:55 +0000 UTC 2025-09-02 08:25:54 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-tnnjn-6dcdd4444f" has successfully progressed.}]
  STEP: updating Deployment Status @ 09/02/25 08:25:56.233
  I0902 08:25:56.252863 16 deployment.go:551] updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2025, time.September, 2, 8, 25, 55, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 8, 25, 55, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.September, 2, 8, 25, 55, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 8, 25, 54, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-tnnjn-6dcdd4444f\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the Deployment status to be updated @ 09/02/25 08:25:56.252
  I0902 08:25:56.258443 16 deployment.go:578] Observed &Deployment event: ADDED
  I0902 08:25:56.259129 16 deployment.go:574] Observed Deployment test-deployment-tnnjn in namespace deployment-3796 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2025-09-02 08:25:54 +0000 UTC 2025-09-02 08:25:54 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-tnnjn-6dcdd4444f"}
  I0902 08:25:56.260332 16 deployment.go:578] Observed &Deployment event: MODIFIED
  I0902 08:25:56.260642 16 deployment.go:574] Observed Deployment test-deployment-tnnjn in namespace deployment-3796 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2025-09-02 08:25:54 +0000 UTC 2025-09-02 08:25:54 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-tnnjn-6dcdd4444f"}
  I0902 08:25:56.261108 16 deployment.go:574] Observed Deployment test-deployment-tnnjn in namespace deployment-3796 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2025-09-02 08:25:54 +0000 UTC 2025-09-02 08:25:54 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  I0902 08:25:56.261695 16 deployment.go:578] Observed &Deployment event: MODIFIED
  I0902 08:25:56.261824 16 deployment.go:574] Observed Deployment test-deployment-tnnjn in namespace deployment-3796 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2025-09-02 08:25:54 +0000 UTC 2025-09-02 08:25:54 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  I0902 08:25:56.262324 16 deployment.go:574] Observed Deployment test-deployment-tnnjn in namespace deployment-3796 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2025-09-02 08:25:54 +0000 UTC 2025-09-02 08:25:54 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-tnnjn-6dcdd4444f" is progressing.}
  I0902 08:25:56.262732 16 deployment.go:578] Observed &Deployment event: MODIFIED
  I0902 08:25:56.262789 16 deployment.go:574] Observed Deployment test-deployment-tnnjn in namespace deployment-3796 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2025-09-02 08:25:55 +0000 UTC 2025-09-02 08:25:55 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  I0902 08:25:56.262816 16 deployment.go:574] Observed Deployment test-deployment-tnnjn in namespace deployment-3796 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2025-09-02 08:25:55 +0000 UTC 2025-09-02 08:25:54 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-tnnjn-6dcdd4444f" has successfully progressed.}
  I0902 08:25:56.263025 16 deployment.go:578] Observed &Deployment event: MODIFIED
  I0902 08:25:56.263098 16 deployment.go:574] Observed Deployment test-deployment-tnnjn in namespace deployment-3796 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2025-09-02 08:25:55 +0000 UTC 2025-09-02 08:25:55 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  I0902 08:25:56.263126 16 deployment.go:574] Observed Deployment test-deployment-tnnjn in namespace deployment-3796 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2025-09-02 08:25:55 +0000 UTC 2025-09-02 08:25:54 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-tnnjn-6dcdd4444f" has successfully progressed.}
  I0902 08:25:56.263161 16 deployment.go:571] Found Deployment test-deployment-tnnjn in namespace deployment-3796 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I0902 08:25:56.263200 16 deployment.go:582] Deployment test-deployment-tnnjn has an updated status
  STEP: patching the Statefulset Status @ 09/02/25 08:25:56.263
  I0902 08:25:56.263264 16 deployment.go:586] Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  I0902 08:25:56.283288 16 deployment.go:590] Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Deployment status to be patched @ 09/02/25 08:25:56.283
  I0902 08:25:56.288009 16 deployment.go:615] Observed &Deployment event: ADDED
  I0902 08:25:56.288123 16 deployment.go:611] Observed deployment test-deployment-tnnjn in namespace deployment-3796 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2025-09-02 08:25:54 +0000 UTC 2025-09-02 08:25:54 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-tnnjn-6dcdd4444f"}
  I0902 08:25:56.288351 16 deployment.go:615] Observed &Deployment event: MODIFIED
  I0902 08:25:56.292425 16 deployment.go:611] Observed deployment test-deployment-tnnjn in namespace deployment-3796 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2025-09-02 08:25:54 +0000 UTC 2025-09-02 08:25:54 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-tnnjn-6dcdd4444f"}
  I0902 08:25:56.292541 16 deployment.go:611] Observed deployment test-deployment-tnnjn in namespace deployment-3796 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2025-09-02 08:25:54 +0000 UTC 2025-09-02 08:25:54 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  I0902 08:25:56.293292 16 deployment.go:615] Observed &Deployment event: MODIFIED
  I0902 08:25:56.293358 16 deployment.go:611] Observed deployment test-deployment-tnnjn in namespace deployment-3796 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2025-09-02 08:25:54 +0000 UTC 2025-09-02 08:25:54 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  I0902 08:25:56.293406 16 deployment.go:611] Observed deployment test-deployment-tnnjn in namespace deployment-3796 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2025-09-02 08:25:54 +0000 UTC 2025-09-02 08:25:54 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-tnnjn-6dcdd4444f" is progressing.}
  I0902 08:25:56.294738 16 deployment.go:615] Observed &Deployment event: MODIFIED
  I0902 08:25:56.295493 16 deployment.go:611] Observed deployment test-deployment-tnnjn in namespace deployment-3796 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2025-09-02 08:25:55 +0000 UTC 2025-09-02 08:25:55 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  I0902 08:25:56.296620 16 deployment.go:611] Observed deployment test-deployment-tnnjn in namespace deployment-3796 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2025-09-02 08:25:55 +0000 UTC 2025-09-02 08:25:54 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-tnnjn-6dcdd4444f" has successfully progressed.}
  I0902 08:25:56.297690 16 deployment.go:615] Observed &Deployment event: MODIFIED
  I0902 08:25:56.298397 16 deployment.go:611] Observed deployment test-deployment-tnnjn in namespace deployment-3796 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2025-09-02 08:25:55 +0000 UTC 2025-09-02 08:25:55 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  I0902 08:25:56.298482 16 deployment.go:611] Observed deployment test-deployment-tnnjn in namespace deployment-3796 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2025-09-02 08:25:55 +0000 UTC 2025-09-02 08:25:54 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-tnnjn-6dcdd4444f" has successfully progressed.}
  I0902 08:25:56.298781 16 deployment.go:611] Observed deployment test-deployment-tnnjn in namespace deployment-3796 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I0902 08:25:56.299725 16 deployment.go:615] Observed &Deployment event: MODIFIED
  I0902 08:25:56.300140 16 deployment.go:608] Found deployment test-deployment-tnnjn in namespace deployment-3796 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
  I0902 08:25:56.301005 16 deployment.go:619] Deployment test-deployment-tnnjn has a patched status
  I0902 08:25:56.331224 16 deployment.go:632] Deployment "test-deployment-tnnjn":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=21) "test-deployment-tnnjn",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-3796",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "08912a75-430b-4731-a961-c61dc102069a",
      ResourceVersion: (string) (len=5) "36020",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63892398354,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892398354,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=657) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 65 32 65  22 3a 7b 7d 2c 22 66 3a  |},"f:e2e":{},"f:|
              00000030  6e 61 6d 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |name":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  70 72 6f 67 72 65 73 73  |ec":{"f:progress|
              00000050  44 65 61 64 6c 69 6e 65  53 65 63 6f 6e 64 73 22  |DeadlineSeconds"|
              00000060  3a 7b 7d 2c 22 66 3a 72  65 70 6c 69 63 61 73 22  |:{},"f:replicas"|
              00000070  3a 7b 7d 2c 22 66 3a 72  65 76 69 73 69 6f 6e 48  |:{},"f:revisionH|
              00000080  69 73 74 6f 72 79 4c 69  6d 69 74 22 3a 7b 7d 2c  |istoryLimit":{},|
              00000090  22 66 3a 73 65 6c 65 63  74 6f 72 22 3a 7b 7d 2c  |"f:selector":{},|
              000000a0  22 66 3a 73 74 72 61 74  65 67 79 22 3a 7b 22 66  |"f:strategy":{"f|
              000000b0  3a 72 6f 6c 6c 69 6e 67  55 70 64 61 74 65 22 3a  |:rollingUpdate":|
              000000c0  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6d 61 78 53 75  |{".":{},"f:maxSu|
              000000d0  72 67 65 22 3a 7b 7d 2c  22 66 3a 6d 61 78 55 6e  |rge":{},"f:maxUn|
              000000e0  61 76 61 69 6c 61 62 6c  65 22 3a 7b 7d 7d 2c 22  |available":{}},"|
              000000f0  66 3a 74 79 70 65 22 3a  7b 7d 7d 2c 22 66 3a 74  |f:type":{}},"f:t|
              00000100  65 6d 70 6c 61 74 65 22  3a 7b 22 66 3a 6d 65 74  |emplate":{"f:met|
              00000110  61 64 61 74 61 22 3a 7b  22 66 3a 6c 61 62 65 6c  |adata":{"f:label|
              00000120  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 65 32  |s":{".":{},"f:e2|
              00000130  65 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |e":{},"f:name":{|
              00000140  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              00000150  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              00000160  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              00000170  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              00000180  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000190  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              000001a0  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              000001b0  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              000001c0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000001d0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000001e0  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000210  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000220  69 63 79 22 3a 7b 7d 2c  22 66 3a 72 65 73 74 61  |icy":{},"f:resta|
              00000230  72 74 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |rtPolicy":{},"f:|
              00000240  73 63 68 65 64 75 6c 65  72 4e 61 6d 65 22 3a 7b  |schedulerName":{|
              00000250  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000260  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000270  69 6e 61 74 69 6f 6e 47  72 61 63 65 50 65 72 69  |inationGracePeri|
              00000280  6f 64 53 65 63 6f 6e 64  73 22 3a 7b 7d 7d 7d 7d  |odSeconds":{}}}}|
              00000290  7d                                                |}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892398356,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=147) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 53 74 61 74  |{\"type\":\"Stat|
              00000030  75 73 50 61 74 63 68 65  64 5c 22 7d 22 3a 7b 22  |usPatched\"}":{"|
              00000040  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 54 72 61  |.":{},"f:lastTra|
              00000050  6e 73 69 74 69 6f 6e 54  69 6d 65 22 3a 7b 7d 2c  |nsitionTime":{},|
              00000060  22 66 3a 6c 61 73 74 55  70 64 61 74 65 54 69 6d  |"f:lastUpdateTim|
              00000070  65 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |e":{},"f:status"|
              00000080  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000090  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892398356,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=373) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 50 72 6f  |:{\"type\":\"Pro|
              000000a0  67 72 65 73 73 69 6e 67  5c 22 7d 22 3a 7b 22 2e  |gressing\"}":{".|
              000000b0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000000c0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000000d0  66 3a 6c 61 73 74 55 70  64 61 74 65 54 69 6d 65  |f:lastUpdateTime|
              000000e0  22 3a 7b 7d 2c 22 66 3a  6d 65 73 73 61 67 65 22  |":{},"f:message"|
              000000f0  3a 7b 7d 2c 22 66 3a 72  65 61 73 6f 6e 22 3a 7b  |:{},"f:reason":{|
              00000100  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              00000110  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              00000120  3a 6f 62 73 65 72 76 65  64 47 65 6e 65 72 61 74  |:observedGenerat|
              00000130  69 6f 6e 22 3a 7b 7d 2c  22 66 3a 72 65 61 64 79  |ion":{},"f:ready|
              00000140  52 65 70 6c 69 63 61 73  22 3a 7b 7d 2c 22 66 3a  |Replicas":{},"f:|
              00000150  72 65 70 6c 69 63 61 73  22 3a 7b 7d 2c 22 66 3a  |replicas":{},"f:|
              00000160  75 70 64 61 74 65 64 52  65 70 6c 69 63 61 73 22  |updatedReplicas"|
              00000170  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=3) "e2e": (string) (len=7) "testing",
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=3) "e2e": (string) (len=7) "testing",
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          HostnameOverride: (*string)(<nil>)
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      TerminatingReplicas: (*int32)(<nil>),
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=13) "StatusPatched",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892398356,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892398356,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "FoundNewReplicaSet",
          Message: (string) (len=56) "Found new replica set \"test-deployment-tnnjn-6dcdd4444f\""
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0902 08:25:56.364016 16 deployment.go:40] New ReplicaSet "test-deployment-tnnjn-6dcdd4444f" of Deployment "test-deployment-tnnjn":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=32) "test-deployment-tnnjn-6dcdd4444f",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-3796",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "7be9ea83-3d90-4fbc-b02d-3cd69c81499e",
      ResourceVersion: (string) (len=5) "36015",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63892398354,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=3) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "6dcdd4444f",
        (string) (len=3) "e2e": (string) (len=7) "testing"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=21) "test-deployment-tnnjn",
          UID: (types.UID) (len=36) "08912a75-430b-4731-a961-c61dc102069a",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892398354,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=803) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 65 32 65  22 3a 7b 7d 2c 22 66 3a  |},"f:e2e":{},"f:|
              000000d0  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 70 6f 64 2d  |name":{},"f:pod-|
              000000e0  74 65 6d 70 6c 61 74 65  2d 68 61 73 68 22 3a 7b  |template-hash":{|
              000000f0  7d 7d 2c 22 66 3a 6f 77  6e 65 72 52 65 66 65 72  |}},"f:ownerRefer|
              00000100  65 6e 63 65 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |ences":{".":{},"|
              00000110  6b 3a 7b 5c 22 75 69 64  5c 22 3a 5c 22 30 38 39  |k:{\"uid\":\"089|
              00000120  31 32 61 37 35 2d 34 33  30 62 2d 34 37 33 31 2d  |12a75-430b-4731-|
              00000130  61 39 36 31 2d 63 36 31  64 63 31 30 32 30 36 39  |a961-c61dc102069|
              00000140  61 5c 22 7d 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |a\"}":{}}},"f:sp|
              00000150  65 63 22 3a 7b 22 66 3a  72 65 70 6c 69 63 61 73  |ec":{"f:replicas|
              00000160  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000180  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000190  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              000001a0  3a 7b 7d 2c 22 66 3a 65  32 65 22 3a 7b 7d 2c 22  |:{},"f:e2e":{},"|
              000001b0  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 70 6f  |f:name":{},"f:po|
              000001c0  64 2d 74 65 6d 70 6c 61  74 65 2d 68 61 73 68 22  |d-template-hash"|
              000001d0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000001e0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000001f0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 68  |"k:{\"name\":\"h|
              00000200  74 74 70 64 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |ttpd\"}":{".":{}|
              00000210  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000220  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000230  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000240  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000250  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000260  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000270  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000280  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000290  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              000002a0  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              000002b0  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 72 65 73  |olicy":{},"f:res|
              000002c0  74 61 72 74 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |tartPolicy":{},"|
              000002d0  66 3a 73 63 68 65 64 75  6c 65 72 4e 61 6d 65 22  |f:schedulerName"|
              000002e0  3a 7b 7d 2c 22 66 3a 73  65 63 75 72 69 74 79 43  |:{},"f:securityC|
              000002f0  6f 6e 74 65 78 74 22 3a  7b 7d 2c 22 66 3a 74 65  |ontext":{},"f:te|
              00000300  72 6d 69 6e 61 74 69 6f  6e 47 72 61 63 65 50 65  |rminationGracePe|
              00000310  72 69 6f 64 53 65 63 6f  6e 64 73 22 3a 7b 7d 7d  |riodSeconds":{}}|
              00000320  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892398355,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=3) {
          (string) (len=3) "e2e": (string) (len=7) "testing",
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=10) "6dcdd4444f"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=3) {
            (string) (len=3) "e2e": (string) (len=7) "testing",
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=10) "6dcdd4444f"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          HostnameOverride: (*string)(<nil>)
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      TerminatingReplicas: (*int32)(<nil>),
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0902 08:25:56.384992 16 deployment.go:68] Pod "test-deployment-tnnjn-6dcdd4444f-cqgd6" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=38) "test-deployment-tnnjn-6dcdd4444f-cqgd6",
      GenerateName: (string) (len=33) "test-deployment-tnnjn-6dcdd4444f-",
      Namespace: (string) (len=15) "deployment-3796",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "7c9c55fe-328d-4e5d-8a2f-35039a4f7e50",
      ResourceVersion: (string) (len=5) "36014",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63892398354,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=3) {
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "6dcdd4444f"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=32) "test-deployment-tnnjn-6dcdd4444f",
          UID: (types.UID) (len=36) "7be9ea83-3d90-4fbc-b02d-3cd69c81499e",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892398354,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=548) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 65 32 65 22 3a 7b 7d  |.":{},"f:e2e":{}|
              00000040  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000050  70 6f 64 2d 74 65 6d 70  6c 61 74 65 2d 68 61 73  |pod-template-has|
              00000060  68 22 3a 7b 7d 7d 2c 22  66 3a 6f 77 6e 65 72 52  |h":{}},"f:ownerR|
              00000070  65 66 65 72 65 6e 63 65  73 22 3a 7b 22 2e 22 3a  |eferences":{".":|
              00000080  7b 7d 2c 22 6b 3a 7b 5c  22 75 69 64 5c 22 3a 5c  |{},"k:{\"uid\":\|
              00000090  22 37 62 65 39 65 61 38  33 2d 33 64 39 30 2d 34  |"7be9ea83-3d90-4|
              000000a0  66 62 63 2d 62 30 32 64  2d 33 63 64 36 39 63 38  |fbc-b02d-3cd69c8|
              000000b0  31 34 39 39 65 5c 22 7d  22 3a 7b 7d 7d 7d 2c 22  |1499e\"}":{}}},"|
              000000c0  66 3a 73 70 65 63 22 3a  7b 22 66 3a 63 6f 6e 74  |f:spec":{"f:cont|
              000000d0  61 69 6e 65 72 73 22 3a  7b 22 6b 3a 7b 5c 22 6e  |ainers":{"k:{\"n|
              000000e0  61 6d 65 5c 22 3a 5c 22  68 74 74 70 64 5c 22 7d  |ame\":\"httpd\"}|
              000000f0  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |":{".":{},"f:ima|
              00000100  67 65 22 3a 7b 7d 2c 22  66 3a 69 6d 61 67 65 50  |ge":{},"f:imageP|
              00000110  75 6c 6c 50 6f 6c 69 63  79 22 3a 7b 7d 2c 22 66  |ullPolicy":{},"f|
              00000120  3a 6e 61 6d 65 22 3a 7b  7d 2c 22 66 3a 72 65 73  |:name":{},"f:res|
              00000130  6f 75 72 63 65 73 22 3a  7b 7d 2c 22 66 3a 73 65  |ources":{},"f:se|
              00000140  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000150  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000160  4d 65 73 73 61 67 65 50  61 74 68 22 3a 7b 7d 2c  |MessagePath":{},|
              00000170  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000180  73 73 61 67 65 50 6f 6c  69 63 79 22 3a 7b 7d 7d  |ssagePolicy":{}}|
              00000190  7d 2c 22 66 3a 64 6e 73  50 6f 6c 69 63 79 22 3a  |},"f:dnsPolicy":|
              000001a0  7b 7d 2c 22 66 3a 65 6e  61 62 6c 65 53 65 72 76  |{},"f:enableServ|
              000001b0  69 63 65 4c 69 6e 6b 73  22 3a 7b 7d 2c 22 66 3a  |iceLinks":{},"f:|
              000001c0  72 65 73 74 61 72 74 50  6f 6c 69 63 79 22 3a 7b  |restartPolicy":{|
              000001d0  7d 2c 22 66 3a 73 63 68  65 64 75 6c 65 72 4e 61  |},"f:schedulerNa|
              000001e0  6d 65 22 3a 7b 7d 2c 22  66 3a 73 65 63 75 72 69  |me":{},"f:securi|
              000001f0  74 79 43 6f 6e 74 65 78  74 22 3a 7b 7d 2c 22 66  |tyContext":{},"f|
              00000200  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 47 72 61 63  |:terminationGrac|
              00000210  65 50 65 72 69 6f 64 53  65 63 6f 6e 64 73 22 3a  |ePeriodSeconds":|
              00000220  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892398355,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=851) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6f 62 73 65 72 76  |me":{},"f:observ|
              00000080  65 64 47 65 6e 65 72 61  74 69 6f 6e 22 3a 7b 7d  |edGeneration":{}|
              00000090  2c 22 66 3a 73 74 61 74  75 73 22 3a 7b 7d 2c 22  |,"f:status":{},"|
              000000a0  66 3a 74 79 70 65 22 3a  7b 7d 7d 2c 22 6b 3a 7b  |f:type":{}},"k:{|
              000000b0  5c 22 74 79 70 65 5c 22  3a 5c 22 49 6e 69 74 69  |\"type\":\"Initi|
              000000c0  61 6c 69 7a 65 64 5c 22  7d 22 3a 7b 22 2e 22 3a  |alized\"}":{".":|
              000000d0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000000f0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              00000100  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000110  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |eration":{},"f:s|
              00000120  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000130  65 22 3a 7b 7d 7d 2c 22  6b 3a 7b 5c 22 74 79 70  |e":{}},"k:{\"typ|
              00000140  65 5c 22 3a 5c 22 50 6f  64 52 65 61 64 79 54 6f  |e\":\"PodReadyTo|
              00000150  53 74 61 72 74 43 6f 6e  74 61 69 6e 65 72 73 5c  |StartContainers\|
              00000160  22 7d 22 3a 7b 22 2e 22  3a 7b 7d 2c 22 66 3a 6c  |"}":{".":{},"f:l|
              00000170  61 73 74 50 72 6f 62 65  54 69 6d 65 22 3a 7b 7d  |astProbeTime":{}|
              00000180  2c 22 66 3a 6c 61 73 74  54 72 61 6e 73 69 74 69  |,"f:lastTransiti|
              00000190  6f 6e 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6f 62  |onTime":{},"f:ob|
              000001a0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001b0  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              000001c0  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              000001d0  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              000001e0  6f 64 53 63 68 65 64 75  6c 65 64 5c 22 7d 22 3a  |odScheduled\"}":|
              000001f0  7b 22 66 3a 6f 62 73 65  72 76 65 64 47 65 6e 65  |{"f:observedGene|
              00000200  72 61 74 69 6f 6e 22 3a  7b 7d 7d 2c 22 6b 3a 7b  |ration":{}},"k:{|
              00000210  5c 22 74 79 70 65 5c 22  3a 5c 22 52 65 61 64 79  |\"type\":\"Ready|
              00000220  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000230  6c 61 73 74 50 72 6f 62  65 54 69 6d 65 22 3a 7b  |lastProbeTime":{|
              00000240  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000250  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6f  |ionTime":{},"f:o|
              00000260  62 73 65 72 76 65 64 47  65 6e 65 72 61 74 69 6f  |bservedGeneratio|
              00000270  6e 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |n":{},"f:status"|
              00000280  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000290  7d 2c 22 66 3a 63 6f 6e  74 61 69 6e 65 72 53 74  |},"f:containerSt|
              000002a0  61 74 75 73 65 73 22 3a  7b 7d 2c 22 66 3a 68 6f  |atuses":{},"f:ho|
              000002b0  73 74 49 50 22 3a 7b 7d  2c 22 66 3a 68 6f 73 74  |stIP":{},"f:host|
              000002c0  49 50 73 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |IPs":{},"f:obser|
              000002d0  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000002e0  7d 2c 22 66 3a 70 68 61  73 65 22 3a 7b 7d 2c 22  |},"f:phase":{},"|
              000002f0  66 3a 70 6f 64 49 50 22  3a 7b 7d 2c 22 66 3a 70  |f:podIP":{},"f:p|
              00000300  6f 64 49 50 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |odIPs":{".":{},"|
              00000310  6b 3a 7b 5c 22 69 70 5c  22 3a 5c 22 31 30 2e 32  |k:{\"ip\":\"10.2|
              00000320  33 33 2e 36 36 2e 36 32  5c 22 7d 22 3a 7b 22 2e  |33.66.62\"}":{".|
              00000330  22 3a 7b 7d 2c 22 66 3a  69 70 22 3a 7b 7d 7d 7d  |":{},"f:ip":{}}}|
              00000340  2c 22 66 3a 73 74 61 72  74 54 69 6d 65 22 3a 7b  |,"f:startTime":{|
              00000350  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-xdsnx",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-xdsnx",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "ietha7evai9i-2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 1,
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892398355,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892398354,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892398355,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892398355,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892398354,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.46",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.121.46"
        }
      },
      PodIP: (string) (len=12) "10.233.66.62",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "10.233.66.62"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63892398354,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63892398355,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=72) "cri-o://cca9e4b352aa8061289c3527baa4e68ae5d6771963c58e6adb56675d54467d5d",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)({
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          }),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-xdsnx",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)({
            Linux: (*v1.LinuxContainerUser)({
              UID: (int64) 0,
              GID: (int64) 0,
              SupplementalGroups: ([]int64) (len=11) {
                (int64) 0,
                (int64) 1,
                (int64) 2,
                (int64) 3,
                (int64) 4,
                (int64) 6,
                (int64) 10,
                (int64) 11,
                (int64) 20,
                (int64) 26,
                (int64) 27
              }
            })
          }),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>)
    }
  }

  I0902 08:25:56.401228 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-3796" for this suite. @ 09/02/25 08:25:56.414
• [2.353 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:770
  STEP: Creating a kubernetes client @ 09/02/25 08:25:56.441
  I0902 08:25:56.441814 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename svcaccounts @ 09/02/25 08:25:56.444
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:25:56.472
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:25:56.478
  I0902 08:25:56.494219 16 service_accounts.go:782] Got root ca configmap in namespace "svcaccounts-692"
  I0902 08:25:56.515183 16 service_accounts.go:785] Deleted root ca configmap in namespace "svcaccounts-692"
  STEP: waiting for a new root ca configmap created @ 09/02/25 08:25:57.016
  I0902 08:25:57.025366 16 service_accounts.go:799] Recreated root ca configmap in namespace "svcaccounts-692"
  I0902 08:25:57.036291 16 service_accounts.go:810] Updated root ca configmap in namespace "svcaccounts-692"
  E0902 08:25:57.181508      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: waiting for the root ca configmap reconciled @ 09/02/25 08:25:57.536
  I0902 08:25:57.562761 16 service_accounts.go:828] Reconciled root ca configmap in namespace "svcaccounts-692"
  I0902 08:25:57.563012 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-692" for this suite. @ 09/02/25 08:25:57.579
• [1.156 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Secrets should be consumable as environment variable names variable names with various prefixes [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:249
  STEP: Creating a kubernetes client @ 09/02/25 08:25:57.601
  I0902 08:25:57.602275 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename secrets @ 09/02/25 08:25:57.606
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:25:57.636
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:25:57.642
  STEP: creating secret secrets-830/secret-test-3c130554-04ba-4a4b-9580-e90856bcd3d9 @ 09/02/25 08:25:57.651
  STEP: Creating a pod to test consume secrets @ 09/02/25 08:25:57.662
  E0902 08:25:58.181314      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:25:59.181538      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:26:00.181821      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:26:01.182959      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/02/25 08:26:01.737
  I0902 08:26:01.746476 16 output.go:207] Trying to get logs from node ietha7evai9i-3 pod pod-secret-88d0e67e-c46b-4c99-a637-d94ed5d3da45 container env-test: <nil>
  STEP: delete the pod @ 09/02/25 08:26:01.785
  I0902 08:26:01.834280 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-830" for this suite. @ 09/02/25 08:26:01.858
• [4.281 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:459
  STEP: Creating a kubernetes client @ 09/02/25 08:26:01.891
  I0902 08:26:01.891972 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename init-container @ 09/02/25 08:26:01.895
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:26:01.934
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:26:01.942
  STEP: creating the pod @ 09/02/25 08:26:01.954
  I0902 08:26:01.955439 16 init_container.go:499] PodSpec: initContainers in spec.initContainers
  E0902 08:26:02.182877      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:26:03.184197      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:26:04.185517      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:26:05.184853      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:26:06.185607      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:26:06.239924 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-9826" for this suite. @ 09/02/25 08:26:06.258
• [4.415 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:311
  STEP: Creating a kubernetes client @ 09/02/25 08:26:06.311
  I0902 08:26:06.311921 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename crd-publish-openapi @ 09/02/25 08:26:06.315
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:26:06.368
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:26:06.375
  STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation @ 09/02/25 08:26:06.419
  I0902 08:26:06.420471 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  E0902 08:26:07.186580      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:26:08.187427      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:26:09.187710      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:26:10.200517      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:26:11.200768      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:26:12.202198      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:26:13.202815      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:26:14.204303      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:26:15.203419      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:26:16.203719      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation @ 09/02/25 08:26:16.466
  I0902 08:26:16.467896 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  E0902 08:26:17.204972      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:26:18.204763      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:26:19.103331 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  E0902 08:26:19.205837      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:26:20.206805      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:26:21.207532      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:26:22.208349      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:26:23.208894      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:26:24.209457      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:26:25.209644      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:26:26.215046      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:26:27.216049      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:26:28.216598      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:26:28.660792 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-3078" for this suite. @ 09/02/25 08:26:28.695
• [22.405 seconds]
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:216
  STEP: Creating a kubernetes client @ 09/02/25 08:26:28.718
  I0902 08:26:28.718480 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename sched-preemption @ 09/02/25 08:26:28.72
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:26:28.789
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:26:28.796
  I0902 08:26:28.830918 16 wait.go:51] Waiting up to 1m0s for all nodes to be ready
  E0902 08:26:29.217407      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:26:30.218144      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:26:31.218284      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:26:32.218855      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:26:33.220043      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:26:34.220200      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:26:35.220410      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:26:36.220761      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:26:37.221793      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:26:38.222091      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:26:39.223313      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:26:40.223062      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:26:41.224157      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:26:42.224492      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:26:43.225474      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:26:44.225873      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:26:45.226424      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:26:46.226657      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:26:47.227321      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:26:48.227772      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:26:49.228674      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:26:50.228956      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:26:51.229460      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:26:52.229750      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:26:53.229964      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:26:54.230911      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:26:55.231095      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:26:56.231897      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:26:57.232871      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:26:58.232863      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:26:59.233949      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:27:00.234970      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:27:01.235241      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:27:02.235766      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:27:03.236933      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:27:04.237276      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:27:05.237671      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:27:06.238748      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:27:07.239665      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:27:08.239825      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:27:09.240152      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:27:10.240773      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:27:11.241719      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:27:12.241942      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:27:13.242674      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:27:14.242916      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:27:15.243375      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:27:16.244063      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:27:17.244736      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:27:18.245173      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:27:19.245633      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:27:20.245758      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:27:21.246693      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:27:22.247679      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:27:23.247861      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:27:24.249328      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:27:25.248281      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:27:26.249060      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:27:27.249846      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:27:28.250468      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:27:28.842699 16 util.go:390] Waiting for terminating namespaces to be deleted...
  STEP: Create pods that use 4/5 of node resources. @ 09/02/25 08:27:28.849
  STEP: Adding a custom resource @ 09/02/25 08:27:28.849
  I0902 08:27:28.913065 16 preemption.go:257] Created pod: pod0-0-sched-preemption-low-priority
  I0902 08:27:28.943973 16 preemption.go:257] Created pod: pod0-1-sched-preemption-medium-priority
  STEP: Adding a custom resource @ 09/02/25 08:27:28.944
  I0902 08:27:29.073032 16 preemption.go:257] Created pod: pod1-0-sched-preemption-medium-priority
  I0902 08:27:29.099344 16 preemption.go:257] Created pod: pod1-1-sched-preemption-medium-priority
  STEP: Adding a custom resource @ 09/02/25 08:27:29.099
  I0902 08:27:29.172762 16 preemption.go:257] Created pod: pod2-0-sched-preemption-medium-priority
  I0902 08:27:29.190730 16 preemption.go:257] Created pod: pod2-1-sched-preemption-medium-priority
  STEP: Wait for pods to be scheduled. @ 09/02/25 08:27:29.19
  E0902 08:27:29.250813      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:27:30.251029      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:27:31.251982      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:27:32.252766      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:27:33.253189      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Run a critical pod that use same resources as that of a lower priority pod @ 09/02/25 08:27:33.312
  E0902 08:27:34.253776      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:27:35.254314      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:27:36.255848      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:27:37.255210      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Removing a custom resource @ 09/02/25 08:27:37.642
  STEP: Removing a custom resource @ 09/02/25 08:27:37.709
  STEP: Removing a custom resource @ 09/02/25 08:27:37.746
  I0902 08:27:37.796825 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-3616" for this suite. @ 09/02/25 08:27:37.809
• [69.108 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Ephemeral Containers [NodeConformance] will start an ephemeral container in an existing pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/ephemeral_containers.go:51
  STEP: Creating a kubernetes client @ 09/02/25 08:27:37.825
  I0902 08:27:37.825512 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename ephemeral-containers-test @ 09/02/25 08:27:37.828
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:27:37.929
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:27:37.938
  STEP: creating a target pod @ 09/02/25 08:27:37.944
  E0902 08:27:38.256055      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:27:39.256828      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: adding an ephemeral container @ 09/02/25 08:27:39.998
  E0902 08:27:40.257784      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:27:41.258811      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: verifying the pod's generation is 2 @ 09/02/25 08:27:42.058
  STEP: checking pod container endpoints @ 09/02/25 08:27:42.067
  I0902 08:27:42.067356 16 exec_util.go:63] ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-9359 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0902 08:27:42.067404 16 exec_util.go:68] ExecWithOptions: Clientset creation
  I0902 08:27:42.067476 16 exec_util.go:84] ExecWithOptions: execute(https://10.233.0.1:443/api/v1/namespaces/ephemeral-containers-test-9359/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&stderr=true&stdout=true)
  I0902 08:27:42.170923 16 exec_util.go:112] Exec stderr: ""
  I0902 08:27:42.210319 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ephemeral-containers-test-9359" for this suite. @ 09/02/25 08:27:42.22
• [4.411 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:706
  STEP: Creating a kubernetes client @ 09/02/25 08:27:42.237
  I0902 08:27:42.237528 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename sched-pred @ 09/02/25 08:27:42.24
  E0902 08:27:42.259366      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:27:42.27
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:27:42.277
  I0902 08:27:42.284736 16 helper.go:125] Waiting up to 1m0s for all (but 0) nodes to be ready
  I0902 08:27:42.330286 16 util.go:390] Waiting for terminating namespaces to be deleted...
  I0902 08:27:42.339505 16 predicates.go:120] 
  Logging pods the apiserver thinks is on node ietha7evai9i-1 before test
  I0902 08:27:42.354145 16 predicates.go:958] ephemeral-containers-target-pod from ephemeral-containers-test-9359 started at 2025-09-02 08:27:37 +0000 UTC (1 container statuses recorded)
  I0902 08:27:42.354223 16 predicates.go:960] 	Container test-container-1 ready: true, restart count 0
  I0902 08:27:42.354262 16 predicates.go:958] cilium-bn6l7 from kube-system started at 2025-09-02 06:13:04 +0000 UTC (1 container statuses recorded)
  I0902 08:27:42.354936 16 predicates.go:960] 	Container cilium-agent ready: true, restart count 1
  I0902 08:27:42.354974 16 predicates.go:958] cilium-node-init-qt8dx from kube-system started at 2025-09-02 06:13:04 +0000 UTC (1 container statuses recorded)
  I0902 08:27:42.355070 16 predicates.go:960] 	Container node-init ready: true, restart count 1
  I0902 08:27:42.355099 16 predicates.go:958] coredns-66bc5c9577-zh8kv from kube-system started at 2025-09-02 06:13:51 +0000 UTC (1 container statuses recorded)
  I0902 08:27:42.355114 16 predicates.go:960] 	Container coredns ready: true, restart count 1
  I0902 08:27:42.355130 16 predicates.go:958] kube-apiserver-ietha7evai9i-1 from kube-system started at 2025-09-02 06:29:53 +0000 UTC (1 container statuses recorded)
  I0902 08:27:42.355144 16 predicates.go:960] 	Container kube-apiserver ready: true, restart count 1
  I0902 08:27:42.355159 16 predicates.go:958] kube-controller-manager-ietha7evai9i-1 from kube-system started at 2025-09-02 06:29:53 +0000 UTC (1 container statuses recorded)
  I0902 08:27:42.355173 16 predicates.go:960] 	Container kube-controller-manager ready: true, restart count 1
  I0902 08:27:42.355188 16 predicates.go:958] kube-proxy-9czjg from kube-system started at 2025-09-02 06:11:25 +0000 UTC (1 container statuses recorded)
  I0902 08:27:42.355204 16 predicates.go:960] 	Container kube-proxy ready: true, restart count 1
  I0902 08:27:42.355219 16 predicates.go:958] kube-scheduler-ietha7evai9i-1 from kube-system started at 2025-09-02 06:29:53 +0000 UTC (1 container statuses recorded)
  I0902 08:27:42.355235 16 predicates.go:960] 	Container kube-scheduler ready: true, restart count 1
  I0902 08:27:42.355251 16 predicates.go:958] pod0-1-sched-preemption-medium-priority from sched-preemption-3616 started at 2025-09-02 08:27:29 +0000 UTC (1 container statuses recorded)
  I0902 08:27:42.355287 16 predicates.go:960] 	Container pod0-1-sched-preemption-medium-priority ready: true, restart count 0
  I0902 08:27:42.355304 16 predicates.go:958] sonobuoy-systemd-logs-daemon-set-707d3c8598644e6c-hzzpm from sonobuoy started at 2025-09-02 07:30:04 +0000 UTC (2 container statuses recorded)
  I0902 08:27:42.355331 16 predicates.go:960] 	Container sonobuoy-worker ready: true, restart count 0
  I0902 08:27:42.355392 16 predicates.go:960] 	Container systemd-logs ready: true, restart count 0
  I0902 08:27:42.355410 16 predicates.go:120] 
  Logging pods the apiserver thinks is on node ietha7evai9i-2 before test
  I0902 08:27:42.366619 16 predicates.go:958] cilium-n62pl from kube-system started at 2025-09-02 06:13:04 +0000 UTC (1 container statuses recorded)
  I0902 08:27:42.366887 16 predicates.go:960] 	Container cilium-agent ready: true, restart count 1
  I0902 08:27:42.366918 16 predicates.go:958] cilium-node-init-cww5f from kube-system started at 2025-09-02 06:13:04 +0000 UTC (1 container statuses recorded)
  I0902 08:27:42.367098 16 predicates.go:960] 	Container node-init ready: true, restart count 1
  I0902 08:27:42.367126 16 predicates.go:958] kube-apiserver-ietha7evai9i-2 from kube-system started at 2025-09-02 06:30:19 +0000 UTC (1 container statuses recorded)
  I0902 08:27:42.367376 16 predicates.go:960] 	Container kube-apiserver ready: true, restart count 1
  I0902 08:27:42.367403 16 predicates.go:958] kube-controller-manager-ietha7evai9i-2 from kube-system started at 2025-09-02 06:30:19 +0000 UTC (1 container statuses recorded)
  I0902 08:27:42.367432 16 predicates.go:960] 	Container kube-controller-manager ready: true, restart count 1
  I0902 08:27:42.367821 16 predicates.go:958] kube-proxy-jp7tf from kube-system started at 2025-09-02 06:12:05 +0000 UTC (1 container statuses recorded)
  I0902 08:27:42.367843 16 predicates.go:960] 	Container kube-proxy ready: true, restart count 1
  I0902 08:27:42.367860 16 predicates.go:958] kube-scheduler-ietha7evai9i-2 from kube-system started at 2025-09-02 06:30:19 +0000 UTC (1 container statuses recorded)
  I0902 08:27:42.368064 16 predicates.go:960] 	Container kube-scheduler ready: true, restart count 1
  I0902 08:27:42.368322 16 predicates.go:958] pod1-0-sched-preemption-medium-priority from sched-preemption-3616 started at 2025-09-02 08:27:29 +0000 UTC (1 container statuses recorded)
  I0902 08:27:42.368344 16 predicates.go:960] 	Container pod1-0-sched-preemption-medium-priority ready: true, restart count 0
  I0902 08:27:42.368805 16 predicates.go:958] pod1-1-sched-preemption-medium-priority from sched-preemption-3616 started at 2025-09-02 08:27:29 +0000 UTC (1 container statuses recorded)
  I0902 08:27:42.369103 16 predicates.go:960] 	Container pod1-1-sched-preemption-medium-priority ready: true, restart count 0
  I0902 08:27:42.369645 16 predicates.go:958] sonobuoy-systemd-logs-daemon-set-707d3c8598644e6c-dlzrj from sonobuoy started at 2025-09-02 07:30:04 +0000 UTC (2 container statuses recorded)
  I0902 08:27:42.370204 16 predicates.go:960] 	Container sonobuoy-worker ready: true, restart count 0
  I0902 08:27:42.370231 16 predicates.go:960] 	Container systemd-logs ready: true, restart count 0
  I0902 08:27:42.370641 16 predicates.go:120] 
  Logging pods the apiserver thinks is on node ietha7evai9i-3 before test
  I0902 08:27:42.384537 16 predicates.go:958] cilium-node-init-cwq9b from kube-system started at 2025-09-02 06:13:04 +0000 UTC (1 container statuses recorded)
  I0902 08:27:42.384721 16 predicates.go:960] 	Container node-init ready: true, restart count 1
  I0902 08:27:42.384747 16 predicates.go:958] cilium-operator-f9554d685-sqbm7 from kube-system started at 2025-09-02 06:13:04 +0000 UTC (1 container statuses recorded)
  I0902 08:27:42.384763 16 predicates.go:960] 	Container cilium-operator ready: true, restart count 4
  I0902 08:27:42.385016 16 predicates.go:958] cilium-x7gr5 from kube-system started at 2025-09-02 06:13:04 +0000 UTC (1 container statuses recorded)
  I0902 08:27:42.385090 16 predicates.go:960] 	Container cilium-agent ready: true, restart count 1
  I0902 08:27:42.385114 16 predicates.go:958] coredns-66bc5c9577-fcrhx from kube-system started at 2025-09-02 06:19:32 +0000 UTC (1 container statuses recorded)
  I0902 08:27:42.385270 16 predicates.go:960] 	Container coredns ready: true, restart count 0
  I0902 08:27:42.385356 16 predicates.go:958] kube-proxy-dvcxr from kube-system started at 2025-09-02 06:12:30 +0000 UTC (1 container statuses recorded)
  I0902 08:27:42.385397 16 predicates.go:960] 	Container kube-proxy ready: true, restart count 1
  I0902 08:27:42.385531 16 predicates.go:958] pod2-0-sched-preemption-medium-priority from sched-preemption-3616 started at 2025-09-02 08:27:29 +0000 UTC (1 container statuses recorded)
  I0902 08:27:42.385617 16 predicates.go:960] 	Container pod2-0-sched-preemption-medium-priority ready: true, restart count 0
  I0902 08:27:42.385752 16 predicates.go:958] pod2-1-sched-preemption-medium-priority from sched-preemption-3616 started at 2025-09-02 08:27:29 +0000 UTC (1 container statuses recorded)
  I0902 08:27:42.385792 16 predicates.go:960] 	Container pod2-1-sched-preemption-medium-priority ready: true, restart count 0
  I0902 08:27:42.385942 16 predicates.go:958] sonobuoy from sonobuoy started at 2025-09-02 07:29:56 +0000 UTC (1 container statuses recorded)
  I0902 08:27:42.385981 16 predicates.go:960] 	Container kube-sonobuoy ready: true, restart count 0
  I0902 08:27:42.386037 16 predicates.go:958] sonobuoy-e2e-job-5dae80ab010f494d from sonobuoy started at 2025-09-02 07:30:04 +0000 UTC (2 container statuses recorded)
  I0902 08:27:42.386067 16 predicates.go:960] 	Container e2e ready: true, restart count 0
  I0902 08:27:42.386220 16 predicates.go:960] 	Container sonobuoy-worker ready: true, restart count 0
  I0902 08:27:42.386245 16 predicates.go:958] sonobuoy-systemd-logs-daemon-set-707d3c8598644e6c-r5bs9 from sonobuoy started at 2025-09-02 07:30:04 +0000 UTC (2 container statuses recorded)
  I0902 08:27:42.386315 16 predicates.go:960] 	Container sonobuoy-worker ready: true, restart count 0
  I0902 08:27:42.386461 16 predicates.go:960] 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 09/02/25 08:27:42.386
  E0902 08:27:43.259977      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:27:44.259930      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 09/02/25 08:27:44.435
  STEP: Trying to apply a random label on the found node. @ 09/02/25 08:27:44.472
  STEP: verifying the node has the label kubernetes.io/e2e-6536959c-71b4-4c24-8955-4ae69b011df1 95 @ 09/02/25 08:27:44.506
  STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled @ 09/02/25 08:27:44.513
  E0902 08:27:45.261360      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:27:46.262373      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 192.168.121.46 on the node which pod4 resides and expect not scheduled @ 09/02/25 08:27:46.55
  E0902 08:27:47.262868      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:27:48.263441      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:27:49.264246      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:27:50.264773      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:27:51.265714      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:27:52.265726      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:27:53.267502      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:27:54.267639      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:27:55.267830      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:27:56.268402      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:27:57.268779      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:27:58.269184      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:27:59.269496      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:28:00.269660      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:28:01.269919      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:28:02.271041      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:28:03.271198      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:28:04.271873      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:28:05.272048      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:28:06.272502      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:28:07.272908      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:28:08.273020      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:28:09.273597      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:28:10.274203      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:28:11.274878      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:28:12.275388      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:28:13.275968      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:28:14.276733      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:28:15.277898      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:28:16.278721      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:28:17.279458      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:28:18.280257      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:28:19.280537      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:28:20.280816      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:28:21.282665      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:28:22.282502      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:28:23.282866      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:28:24.283653      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:28:25.284401      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:28:26.284944      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:28:27.285812      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:28:28.286465      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:28:29.286684      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:28:30.287268      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:28:31.287436      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:28:32.287797      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:28:33.288008      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:28:34.289200      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:28:35.290152      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:28:36.290885      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:28:37.291467      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:28:38.292305      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:28:39.293232      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:28:40.293691      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:28:41.294684      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:28:42.294883      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:28:43.295662      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:28:44.295963      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:28:45.296670      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:28:46.296898      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:28:47.297145      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:28:48.297295      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:28:49.298458      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:28:50.298752      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:28:51.299421      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:28:52.299878      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:28:53.300940      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:28:54.301781      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:28:55.302798      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:28:56.303268      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:28:57.305074      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:28:58.304952      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:28:59.305232      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:29:00.305443      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:29:01.305914      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:29:02.306533      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:29:03.306907      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:29:04.307083      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:29:05.308125      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:29:06.308120      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:29:07.309129      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:29:08.309875      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:29:09.310601      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:29:10.310835      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:29:11.311878      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:29:12.312702      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:29:13.313295      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:29:14.314116      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:29:15.314488      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:29:16.315287      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:29:17.316100      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:29:18.317385      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:29:19.317753      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:29:20.318465      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:29:21.318856      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:29:22.319842      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:29:23.319664      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:29:24.320461      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:29:25.320598      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:29:26.321243      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:29:27.321499      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:29:28.322058      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:29:29.322758      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:29:30.325167      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:29:31.325670      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:29:32.325797      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:29:33.327101      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:29:34.327126      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:29:35.328224      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:29:36.328911      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:29:37.329328      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:29:38.329731      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:29:39.329907      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:29:40.330346      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:29:41.330608      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:29:42.332810      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:29:43.331867      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:29:44.332443      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:29:45.332343      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:29:46.332876      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:29:47.333901      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:29:48.334026      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:29:49.334816      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:29:50.335371      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:29:51.335786      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:29:52.336806      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:29:53.337998      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:29:54.338751      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:29:55.339653      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:29:56.340120      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:29:57.341002      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:29:58.342052      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:29:59.343531      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:30:00.343462      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:30:01.343926      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:30:02.344807      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:30:03.344785      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:30:04.345818      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:30:05.345878      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:30:06.347534      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:30:07.347989      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:30:08.348705      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:30:09.348898      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:30:10.349239      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:30:11.349507      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:30:12.350422      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:30:13.350972      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:30:14.351627      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:30:15.354062      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:30:16.352726      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:30:17.353265      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:30:18.353827      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:30:19.354069      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:30:20.354917      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:30:21.355166      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:30:22.355918      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:30:23.356717      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:30:24.357176      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:30:25.357678      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:30:26.358009      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:30:27.358292      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:30:28.358890      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:30:29.359203      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:30:30.360090      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:30:31.360708      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:30:32.360747      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:30:33.360831      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:30:34.361601      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:30:35.362323      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:30:36.362496      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:30:37.362809      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:30:38.363111      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:30:39.363321      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:30:40.364396      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:30:41.365103      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:30:42.365910      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:30:43.366579      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:30:44.367624      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:30:45.367884      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:30:46.368344      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:30:47.368663      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:30:48.368806      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:30:49.369696      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:30:50.371170      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:30:51.371848      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:30:52.373240      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:30:53.373757      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:30:54.373367      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:30:55.373919      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:30:56.375087      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:30:57.376203      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:30:58.375910      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:30:59.376116      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:31:00.376496      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:31:01.376883      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:31:02.378191      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:31:03.379033      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:31:04.379168      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:31:05.379913      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:31:06.379974      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:31:07.380891      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:31:08.381633      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:31:09.381805      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:31:10.382093      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:31:11.382682      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:31:12.382991      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:31:13.383159      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:31:14.383539      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:31:15.384243      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:31:16.384643      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:31:17.385527      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:31:18.386027      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:31:19.386211      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:31:20.387180      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:31:21.387375      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:31:22.387607      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:31:23.390297      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:31:24.388306      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:31:25.388316      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:31:26.388979      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:31:27.389961      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:31:28.390122      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:31:29.390274      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:31:30.391355      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:31:31.391896      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:31:32.392617      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:31:33.392819      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:31:34.393159      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:31:35.393304      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:31:36.393710      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:31:37.394171      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:31:38.394415      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:31:39.394655      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:31:40.394811      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:31:41.395331      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:31:42.395732      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:31:43.395840      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:31:44.396773      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:31:45.396982      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:31:46.397837      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:31:47.398742      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:31:48.399703      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:31:49.400803      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:31:50.400892      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:31:51.401232      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:31:52.402104      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:31:53.403241      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:31:54.404405      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:31:55.405005      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:31:56.406059      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:31:57.406962      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:31:58.407423      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:31:59.408322      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:32:00.408804      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:32:01.408791      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:32:02.409528      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:32:03.409801      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:32:04.410590      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:32:05.411507      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:32:06.412063      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:32:07.413235      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:32:08.414456      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:32:09.415109      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:32:10.415984      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:32:11.416427      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:32:12.416771      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:32:13.417125      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:32:14.417067      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:32:15.418224      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:32:16.418828      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:32:17.420035      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:32:18.420997      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:32:19.421860      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:32:20.421999      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:32:21.422110      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:32:22.423284      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:32:23.423851      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:32:24.425101      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:32:25.425626      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:32:26.425797      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:32:27.426012      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:32:28.426957      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:32:29.427163      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:32:30.427513      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:32:31.428219      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:32:32.429012      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:32:33.429331      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:32:34.430244      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:32:35.431884      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:32:36.433012      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:32:37.433533      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:32:38.433953      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:32:39.434217      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:32:40.434813      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:32:41.435507      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:32:42.435983      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:32:43.436128      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:32:44.436967      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:32:45.437220      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:32:46.437355      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: removing the label kubernetes.io/e2e-6536959c-71b4-4c24-8955-4ae69b011df1 off the node ietha7evai9i-2 @ 09/02/25 08:32:46.566
  STEP: verifying the node doesn't have the label kubernetes.io/e2e-6536959c-71b4-4c24-8955-4ae69b011df1 @ 09/02/25 08:32:46.594
  I0902 08:32:46.603144 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-7333" for this suite. @ 09/02/25 08:32:46.614
• [304.402 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:152
  STEP: Creating a kubernetes client @ 09/02/25 08:32:46.641
  I0902 08:32:46.641094 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename container-probe @ 09/02/25 08:32:46.645
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:32:46.675
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:32:46.682
  STEP: Creating pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338 @ 09/02/25 08:32:46.725
  E0902 08:32:47.438605      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:32:48.439345      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 09/02/25 08:32:48.771
  I0902 08:32:48.779719 16 container_probe.go:1749] Initial restart count of pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed is 0
  I0902 08:32:48.801934 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:32:49.439857      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:32:50.440113      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:32:50.813541 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:32:51.440190      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:32:52.448873      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:32:52.839009 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:32:53.441621      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:32:54.442354      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:32:54.848695 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:32:55.442115      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:32:56.442667      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:32:56.866520 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:32:57.442770      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:32:58.442993      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:32:58.875603 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:32:59.443157      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:33:00.443992      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:33:00.890758 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:33:01.444285      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:33:02.444334      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:33:02.905083 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:33:03.445643      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:33:04.446321      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:33:04.922234 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:33:05.447365      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:33:06.447846      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:33:06.933040 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:33:07.448028      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:33:08.449070      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:33:08.944240 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:33:09.449275      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:33:10.450006      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:33:10.954191 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:33:11.450997      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:33:12.451895      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:33:12.967379 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:33:13.452261      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:33:14.453049      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:33:14.979217 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:33:15.454129      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:33:16.454354      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:33:16.989263 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:33:17.455602      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:33:18.456462      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:33:19.000980 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:33:19.457086      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:33:20.457129      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:33:21.013734 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:33:21.458107      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:33:22.458821      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:33:23.026732 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:33:23.459301      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:33:24.459730      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:33:25.036039 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:33:25.460450      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:33:26.460500      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:33:27.047953 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:33:27.461720      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:33:28.462896      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:33:29.059469 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:33:29.462733      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:33:30.463263      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:33:31.069988 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:33:31.463629      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:33:32.463937      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:33:33.079103 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:33:33.464873      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:33:34.464941      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:33:35.095195 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:33:35.465459      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:33:36.466056      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:33:37.104642 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:33:37.466287      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:33:38.466480      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:33:39.113257 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:33:39.466900      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:33:40.467282      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:33:41.120875 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:33:41.468902      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:33:42.469056      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:33:43.135661 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:33:43.469174      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:33:44.469647      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:33:45.147978 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:33:45.469663      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:33:46.470054      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:33:47.163529 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:33:47.471025      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:33:48.471238      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:33:49.174467 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:33:49.471883      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:33:50.472062      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:33:51.190482 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:33:51.472642      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:33:52.472945      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:33:53.221895 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:33:53.473786      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:33:54.474460      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:33:55.233689 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:33:55.476135      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:33:56.476507      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:33:57.243189 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:33:57.477357      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:33:58.477899      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:33:59.254527 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:33:59.477766      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:34:00.478209      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:34:01.264416 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:34:01.478969      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:34:02.479388      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:34:03.275211 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:34:03.480477      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:34:04.480942      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:34:05.286632 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:34:05.482118      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:34:06.482878      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:34:07.307646 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:34:07.483792      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:34:08.483993      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:34:09.319836 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:34:09.484108      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:34:10.484450      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:34:11.341060 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:34:11.485263      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:34:12.485586      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:34:13.351494 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:34:13.485826      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:34:14.486091      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:34:15.359938 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:34:15.486935      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:34:16.487950      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:34:17.369190 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:34:17.488499      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:34:18.489216      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:34:19.377444 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:34:19.490331      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:34:20.489859      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:34:21.387198 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:34:21.491093      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:34:22.491684      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:34:23.396465 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:34:23.492830      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:34:24.492871      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:34:25.403824 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:34:25.493440      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:34:26.493684      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:34:27.429676 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:34:27.494321      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:34:28.494455      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:34:29.443474 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:34:29.496075      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:34:30.495943      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:34:31.455616 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:34:31.496127      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:34:32.496947      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:34:33.464433 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:34:33.497644      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:34:34.497693      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:34:35.475128 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:34:35.497790      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:34:36.498112      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:34:37.485386 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:34:37.498707      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:34:38.499259      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:34:39.494213 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:34:39.499320      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:34:40.499945      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:34:41.500167      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:34:41.503446 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:34:42.501203      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:34:43.501231      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:34:43.517262 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:34:44.501607      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:34:45.502213      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:34:45.528955 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:34:46.502879      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:34:47.503054      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:34:47.544511 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:34:48.503435      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:34:49.503793      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:34:49.556412 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:34:50.504293      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:34:51.504996      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:34:51.570862 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:34:52.504980      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:34:53.505394      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:34:53.581145 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:34:54.505529      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:34:55.511673      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:34:55.591526 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:34:56.506153      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:34:57.507016      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:34:57.605052 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:34:58.507638      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:34:59.508119      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:34:59.622170 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:35:00.508866      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:35:01.509015      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:35:01.637839 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:35:02.510215      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:35:03.510537      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:35:03.651439 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:35:04.511247      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:35:05.514631      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:35:05.662749 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:35:06.512151      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:35:07.512523      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:35:07.674883 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:35:08.512834      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:35:09.513204      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:35:09.683841 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:35:10.513334      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:35:11.513879      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:35:11.695188 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:35:12.513910      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:35:13.514345      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:35:13.706980 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:35:14.514740      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:35:15.516364      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:35:15.724812 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:35:16.516525      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:35:17.517289      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:35:17.736608 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:35:18.517708      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:35:19.518289      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:35:19.747060 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:35:20.519127      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:35:21.519397      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:35:21.759678 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:35:22.520006      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:35:23.519951      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:35:23.771105 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:35:24.520478      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:35:25.521083      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:35:25.781091 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:35:26.521860      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:35:27.522238      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:35:27.791873 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:35:28.523024      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:35:29.523183      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:35:29.804027 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:35:30.523598      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:35:31.523879      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:35:31.817820 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:35:32.525124      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:35:33.525134      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:35:33.831385 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:35:34.526147      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:35:35.527346      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:35:35.841874 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:35:36.528651      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:35:37.528994      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:35:37.854112 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:35:38.530084      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:35:39.530968      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:35:39.866107 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:35:40.531262      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:35:41.532137      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:35:41.883799 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:35:42.533633      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:35:43.533367      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:35:43.897030 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:35:44.533914      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:35:45.534644      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:35:45.907304 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:35:46.534890      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:35:47.535054      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:35:47.917804 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:35:48.535336      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:35:49.535906      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:35:49.929094 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:35:50.537005      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:35:51.537407      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:35:51.939691 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:35:52.537426      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:35:53.537687      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:35:53.948537 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:35:54.537932      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:35:55.538716      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:35:55.960582 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:35:56.539785      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:35:57.540311      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:35:57.970827 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:35:58.540393      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:35:59.540702      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:36:00.004086 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:36:00.541163      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:36:01.541256      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:36:02.016525 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:36:02.541674      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:36:03.542506      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:36:04.042529 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:36:04.544875      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:36:05.544301      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:36:06.053422 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:36:06.544779      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:36:07.544754      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:36:08.068868 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:36:08.545312      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:36:09.546326      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:36:10.082354 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:36:10.546423      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:36:11.547454      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:36:12.095246 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:36:12.547763      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:36:13.548313      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:36:14.105326 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:36:14.548828      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:36:15.549348      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:36:16.116118 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:36:16.549398      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:36:17.549662      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:36:18.128449 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:36:18.550004      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:36:19.550097      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:36:20.137409 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:36:20.551108      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:36:21.552185      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:36:22.148744 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:36:22.552981      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:36:23.553116      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:36:24.163437 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:36:24.554113      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:36:25.554800      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:36:26.183728 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:36:26.555283      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:36:27.555852      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:36:28.198904 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:36:28.555809      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:36:29.556738      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:36:30.208965 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:36:30.556177      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:36:31.556365      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:36:32.217158 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:36:32.556642      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:36:33.557160      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:36:34.229957 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:36:34.557367      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:36:35.557790      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:36:36.238864 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:36:36.558036      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:36:37.558348      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:36:38.249113 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:36:38.558629      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:36:39.558730      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:36:40.260475 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:36:40.560116      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:36:41.560939      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:36:42.269840 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:36:42.562079      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:36:43.563128      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:36:44.277000 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:36:44.563279      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:36:45.563410      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:36:46.285439 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:36:46.564187      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:36:47.564433      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:36:48.297096 16 container_probe.go:1759] Get pod busybox-a585c83e-8160-43a9-ad23-966fa2b7e1ed in namespace container-probe-338
  E0902 08:36:48.565082      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:36:49.565352      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 09/02/25 08:36:50.298
  I0902 08:36:50.352237 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-338" for this suite. @ 09/02/25 08:36:50.37
• [243.745 seconds]
------------------------------
S
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:327
  STEP: Creating a kubernetes client @ 09/02/25 08:36:50.387
  I0902 08:36:50.387496 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename statefulset @ 09/02/25 08:36:50.398
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:36:50.436
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:36:50.442
  STEP: Creating service test in namespace statefulset-3717 @ 09/02/25 08:36:50.449
  I0902 08:36:50.468500      16 warnings.go:110] "Warning: spec.SessionAffinity is ignored for headless services"
  STEP: Creating a new StatefulSet @ 09/02/25 08:36:50.468
  I0902 08:36:50.504075 16 wait.go:44] Found 0 stateful pods, waiting for 3
  E0902 08:36:50.565463      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:36:51.565830      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:36:52.566961      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:36:53.567165      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:36:54.567197      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:36:55.567391      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:36:56.567635      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:36:57.567914      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:36:58.568670      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:36:59.568853      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:37:00.507482 16 wait.go:54] Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  I0902 08:37:00.507663 16 wait.go:54] Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  I0902 08:37:00.507900 16 wait.go:54] Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  I0902 08:37:00.546047 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=statefulset-3717 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  E0902 08:37:00.569504      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:37:00.876423 16 builder.go:156] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0902 08:37:00.876819 16 builder.go:157] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0902 08:37:00.876853 16 statefulset.go:2447] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  E0902 08:37:01.570754      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:37:02.571098      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:37:03.571727      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:37:04.572152      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:37:05.572794      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:37:06.573664      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:37:07.574166      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:37:08.574310      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:37:09.574868      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:37:10.575043      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-4 to registry.k8s.io/e2e-test-images/httpd:2.4.39-4 @ 09/02/25 08:37:10.899
  I0902 08:37:10.928490 16 statefulset.go:2504] Updating stateful set ss2
  STEP: Creating a new revision @ 09/02/25 08:37:10.928
  E0902 08:37:11.575340      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:37:12.575537      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:37:13.576235      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:37:14.576594      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:37:15.577044      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:37:16.577138      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:37:17.577466      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:37:18.577973      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:37:19.578159      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:37:20.578368      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Updating Pods in reverse ordinal order @ 09/02/25 08:37:20.959
  I0902 08:37:20.967741 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=statefulset-3717 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0902 08:37:21.299238 16 builder.go:156] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I0902 08:37:21.299331 16 builder.go:157] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0902 08:37:21.299356 16 statefulset.go:2471] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  E0902 08:37:21.578706      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:37:22.578709      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:37:23.579041      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:37:24.579445      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:37:25.583529      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:37:26.580222      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:37:27.580962      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:37:28.581433      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:37:29.581991      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:37:30.582655      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:37:31.337175 16 wait.go:158] Waiting for StatefulSet statefulset-3717/ss2 to complete update
  E0902 08:37:31.583109      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:37:32.583815      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:37:33.583964      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:37:34.584450      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:37:35.584949      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:37:36.585119      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:37:37.585505      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:37:38.586067      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:37:39.586388      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:37:40.586602      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Rolling back to a previous revision @ 09/02/25 08:37:41.337
  I0902 08:37:41.338483 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=statefulset-3717 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0902 08:37:41.585318 16 builder.go:156] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0902 08:37:41.585455 16 builder.go:157] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0902 08:37:41.585498 16 statefulset.go:2447] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  E0902 08:37:41.587714      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:37:42.587822      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:37:43.587964      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:37:44.588516      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:37:45.588467      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:37:46.588824      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:37:47.589140      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:37:48.589303      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:37:49.589805      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:37:50.589787      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:37:51.590125      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:37:51.620168 16 statefulset.go:2504] Updating stateful set ss2
  E0902 08:37:52.590631      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:37:53.591342      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:37:54.591535      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:37:55.592034      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:37:56.592810      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:37:57.593011      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:37:58.593187      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:37:59.593388      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:38:00.594216      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:38:01.594438      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Rolling back update in reverse ordinal order @ 09/02/25 08:38:01.637
  I0902 08:38:01.643487 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=statefulset-3717 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0902 08:38:01.901901 16 builder.go:156] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I0902 08:38:01.902001 16 builder.go:157] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0902 08:38:01.902053 16 statefulset.go:2471] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  E0902 08:38:02.595463      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:38:03.595778      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:38:04.596269      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:38:05.596504      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:38:06.596804      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:38:07.596956      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:38:08.597223      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:38:09.597850      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:38:10.598148      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:38:11.598919      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:38:11.941192 16 statefulset.go:136] Deleting all statefulset in ns statefulset-3717
  I0902 08:38:11.953320 16 rest.go:153] Scaling statefulset ss2 to 0
  E0902 08:38:12.599210      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:38:13.600005      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:38:14.600129      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:38:15.600248      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:38:16.600726      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:38:17.600884      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:38:18.601377      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:38:19.601734      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:38:20.601891      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:38:21.602252      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:38:22.002515 16 wait.go:159] Waiting for statefulset status.replicas updated to 0
  I0902 08:38:22.007625 16 rest.go:91] Deleting statefulset ss2
  I0902 08:38:22.038534 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-3717" for this suite. @ 09/02/25 08:38:22.05
• [91.681 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:262
  STEP: Creating a kubernetes client @ 09/02/25 08:38:22.072
  I0902 08:38:22.072760 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename downward-api @ 09/02/25 08:38:22.076
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:38:22.1
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:38:22.112
  STEP: Creating a pod to test downward API volume plugin @ 09/02/25 08:38:22.121
  E0902 08:38:22.602638      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:38:23.603614      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:38:24.604610      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:38:25.605539      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/02/25 08:38:26.176
  I0902 08:38:26.190093 16 output.go:207] Trying to get logs from node ietha7evai9i-2 pod downwardapi-volume-1ad067ac-a171-49dd-8ae7-423dbe651a29 container client-container: <nil>
  STEP: delete the pod @ 09/02/25 08:38:26.251
  I0902 08:38:26.282895 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-4874" for this suite. @ 09/02/25 08:38:26.296
• [4.240 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Ephemeral Containers [NodeConformance] should update the ephemeral containers in an existing pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/ephemeral_containers.go:104
  STEP: Creating a kubernetes client @ 09/02/25 08:38:26.316
  I0902 08:38:26.316326 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename ephemeral-containers-test @ 09/02/25 08:38:26.319
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:38:26.351
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:38:26.355
  STEP: creating a target pod @ 09/02/25 08:38:26.363
  E0902 08:38:26.605964      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:38:27.606137      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: adding an ephemeral container @ 09/02/25 08:38:28.413
  E0902 08:38:28.606156      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:38:29.606743      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: verifying the pod's generation is 2 @ 09/02/25 08:38:30.469
  STEP: checking pod container endpoints @ 09/02/25 08:38:30.486
  I0902 08:38:30.486411 16 exec_util.go:63] ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-8954 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0902 08:38:30.486602 16 exec_util.go:68] ExecWithOptions: Clientset creation
  I0902 08:38:30.487185 16 exec_util.go:84] ExecWithOptions: execute(https://10.233.0.1:443/api/v1/namespaces/ephemeral-containers-test-8954/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&stderr=true&stdout=true)
  E0902 08:38:30.606938      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:38:30.645892 16 exec_util.go:112] Exec stderr: ""
  STEP: checking pod "ephemeral-containers-target-pod" has only one ephemeralcontainer @ 09/02/25 08:38:30.676
  STEP: adding another ephemeralcontainer to pod "ephemeral-containers-target-pod" @ 09/02/25 08:38:30.704
  STEP: checking pod "ephemeral-containers-target-pod" has only two ephemeralcontainers @ 09/02/25 08:38:30.754
  I0902 08:38:30.769342 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ephemeral-containers-test-8954" for this suite. @ 09/02/25 08:38:30.793
• [4.504 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:62
  STEP: Creating a kubernetes client @ 09/02/25 08:38:30.82
  I0902 08:38:30.820838 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename containers @ 09/02/25 08:38:30.824
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:38:30.855
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:38:30.867
  STEP: Creating a pod to test override arguments @ 09/02/25 08:38:30.874
  E0902 08:38:31.607111      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:38:32.607011      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:38:33.608108      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:38:34.608223      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/02/25 08:38:34.926
  I0902 08:38:34.936893 16 output.go:207] Trying to get logs from node ietha7evai9i-3 pod client-containers-1f9b3018-5d06-4025-b5cf-efd896556253 container agnhost-container: <nil>
  STEP: delete the pod @ 09/02/25 08:38:34.988
  I0902 08:38:35.046800 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-1852" for this suite. @ 09/02/25 08:38:35.066
• [4.267 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:124
  STEP: Creating a kubernetes client @ 09/02/25 08:38:35.09
  I0902 08:38:35.090307 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename configmap @ 09/02/25 08:38:35.095
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:38:35.137
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:38:35.143
  STEP: Creating configMap with name configmap-test-upd-bde90dc9-a198-4165-9a23-dccda2e61223 @ 09/02/25 08:38:35.169
  STEP: Creating the pod @ 09/02/25 08:38:35.187
  E0902 08:38:35.608960      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:38:36.609213      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Updating configmap configmap-test-upd-bde90dc9-a198-4165-9a23-dccda2e61223 @ 09/02/25 08:38:37.274
  STEP: waiting to observe update in volume @ 09/02/25 08:38:37.288
  E0902 08:38:37.609325      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:38:38.609849      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:38:39.610664      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:38:40.611184      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:38:41.611756      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:38:42.612666      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:38:43.612937      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:38:44.613724      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:38:45.614289      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:38:46.614517      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:38:47.615100      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:38:48.615741      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:38:49.615861      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:38:50.617067      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:38:51.617118      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:38:52.617363      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:38:53.618125      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:38:54.618437      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:38:55.618689      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:38:56.619290      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:38:57.620115      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:38:58.622165      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:38:59.622291      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:39:00.623233      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:39:01.624282      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:39:02.624098      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:39:03.624228      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:39:04.625169      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:39:05.625722      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:39:06.626539      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:39:07.627056      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:39:08.627820      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:39:09.628381      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:39:10.628892      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:39:11.629950      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:39:12.629854      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:39:13.630075      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:39:14.630467      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:39:15.630802      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:39:16.630823      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:39:17.631329      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:39:18.631633      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:39:19.632035      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:39:20.632931      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:39:21.633360      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:39:22.633288      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:39:23.633645      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:39:24.633821      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:39:25.634043      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:39:26.634376      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:39:27.634887      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:39:28.635607      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:39:29.636049      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:39:30.637089      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:39:31.637346      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:39:32.637800      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:39:33.638301      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:39:34.638916      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:39:35.639257      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:39:36.640284      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:39:37.640792      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:39:38.641210      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:39:39.642342      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:39:40.643440      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:39:41.643623      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:39:42.643698      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:39:43.643898      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:39:44.644305      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:39:45.644811      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:39:46.103941 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-9995" for this suite. @ 09/02/25 08:39:46.118
• [71.050 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:133
  STEP: Creating a kubernetes client @ 09/02/25 08:39:46.142
  I0902 08:39:46.143016 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename runtimeclass @ 09/02/25 08:39:46.147
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:39:46.193
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:39:46.2
  E0902 08:39:46.644840      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:39:47.645154      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:39:48.336400 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-872" for this suite. @ 09/02/25 08:39:48.348
• [2.219 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:726
  STEP: Creating a kubernetes client @ 09/02/25 08:39:48.363
  I0902 08:39:48.363598 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename security-context-test @ 09/02/25 08:39:48.366
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:39:48.402
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:39:48.411
  E0902 08:39:48.645817      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:39:49.647941      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:39:50.650158      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:39:51.650604      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:39:52.651497      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:39:53.652042      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:39:54.652140      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:39:55.652620      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:39:56.653915      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:39:57.654054      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:39:58.533809 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-3576" for this suite. @ 09/02/25 08:39:58.545
• [10.197 seconds]
------------------------------
SS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:109
  STEP: Creating a kubernetes client @ 09/02/25 08:39:58.56
  I0902 08:39:58.560231 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename projected @ 09/02/25 08:39:58.564
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:39:58.598
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:39:58.607
  STEP: Creating configMap with name projected-configmap-test-volume-map-894a905c-812a-46f2-bfbe-53753dc5be15 @ 09/02/25 08:39:58.614
  STEP: Creating a pod to test consume configMaps @ 09/02/25 08:39:58.625
  E0902 08:39:58.654959      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:39:59.655199      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:40:00.655630      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:40:01.655688      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:40:02.656165      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/02/25 08:40:02.679
  I0902 08:40:02.685851 16 output.go:207] Trying to get logs from node ietha7evai9i-2 pod pod-projected-configmaps-3583bee2-4199-448d-ab95-305018662538 container agnhost-container: <nil>
  STEP: delete the pod @ 09/02/25 08:40:02.701
  I0902 08:40:02.730661 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4834" for this suite. @ 09/02/25 08:40:02.743
• [4.197 seconds]
------------------------------
SSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:68
  STEP: Creating a kubernetes client @ 09/02/25 08:40:02.758
  I0902 08:40:02.758525 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename secrets @ 09/02/25 08:40:02.761
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:40:02.787
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:40:02.794
  STEP: Creating secret with name secret-test-d9113617-043b-42d6-91ab-b35c3b8d97b0 @ 09/02/25 08:40:02.799
  STEP: Creating a pod to test consume secrets @ 09/02/25 08:40:02.812
  E0902 08:40:03.656887      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:40:04.657277      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:40:05.657825      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:40:06.658264      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/02/25 08:40:06.866
  I0902 08:40:06.874336 16 output.go:207] Trying to get logs from node ietha7evai9i-2 pod pod-secrets-75b2821b-e3f3-4f5a-bb48-859b49852f45 container secret-volume-test: <nil>
  STEP: delete the pod @ 09/02/25 08:40:06.893
  I0902 08:40:06.936133 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-9048" for this suite. @ 09/02/25 08:40:06.945
• [4.202 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:445
  STEP: Creating a kubernetes client @ 09/02/25 08:40:06.961
  I0902 08:40:06.961965 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename sched-pred @ 09/02/25 08:40:06.964
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:40:07.039
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:40:07.043
  I0902 08:40:07.049118 16 helper.go:125] Waiting up to 1m0s for all (but 0) nodes to be ready
  I0902 08:40:07.068470 16 util.go:390] Waiting for terminating namespaces to be deleted...
  I0902 08:40:07.077090 16 predicates.go:120] 
  Logging pods the apiserver thinks is on node ietha7evai9i-1 before test
  I0902 08:40:07.089956 16 predicates.go:958] cilium-bn6l7 from kube-system started at 2025-09-02 06:13:04 +0000 UTC (1 container statuses recorded)
  I0902 08:40:07.090025 16 predicates.go:960] 	Container cilium-agent ready: true, restart count 1
  I0902 08:40:07.090050 16 predicates.go:958] cilium-node-init-qt8dx from kube-system started at 2025-09-02 06:13:04 +0000 UTC (1 container statuses recorded)
  I0902 08:40:07.090066 16 predicates.go:960] 	Container node-init ready: true, restart count 1
  I0902 08:40:07.090082 16 predicates.go:958] coredns-66bc5c9577-zh8kv from kube-system started at 2025-09-02 06:13:51 +0000 UTC (1 container statuses recorded)
  I0902 08:40:07.090099 16 predicates.go:960] 	Container coredns ready: true, restart count 1
  I0902 08:40:07.090124 16 predicates.go:958] kube-apiserver-ietha7evai9i-1 from kube-system started at 2025-09-02 06:29:53 +0000 UTC (1 container statuses recorded)
  I0902 08:40:07.090138 16 predicates.go:960] 	Container kube-apiserver ready: true, restart count 1
  I0902 08:40:07.090154 16 predicates.go:958] kube-controller-manager-ietha7evai9i-1 from kube-system started at 2025-09-02 06:29:53 +0000 UTC (1 container statuses recorded)
  I0902 08:40:07.090168 16 predicates.go:960] 	Container kube-controller-manager ready: true, restart count 1
  I0902 08:40:07.090183 16 predicates.go:958] kube-proxy-9czjg from kube-system started at 2025-09-02 06:11:25 +0000 UTC (1 container statuses recorded)
  I0902 08:40:07.090196 16 predicates.go:960] 	Container kube-proxy ready: true, restart count 1
  I0902 08:40:07.090211 16 predicates.go:958] kube-scheduler-ietha7evai9i-1 from kube-system started at 2025-09-02 06:29:53 +0000 UTC (1 container statuses recorded)
  I0902 08:40:07.090225 16 predicates.go:960] 	Container kube-scheduler ready: true, restart count 1
  I0902 08:40:07.090257 16 predicates.go:958] sonobuoy-systemd-logs-daemon-set-707d3c8598644e6c-hzzpm from sonobuoy started at 2025-09-02 07:30:04 +0000 UTC (2 container statuses recorded)
  I0902 08:40:07.090272 16 predicates.go:960] 	Container sonobuoy-worker ready: true, restart count 0
  I0902 08:40:07.090285 16 predicates.go:960] 	Container systemd-logs ready: true, restart count 0
  I0902 08:40:07.090317 16 predicates.go:120] 
  Logging pods the apiserver thinks is on node ietha7evai9i-2 before test
  I0902 08:40:07.101266 16 predicates.go:958] cilium-n62pl from kube-system started at 2025-09-02 06:13:04 +0000 UTC (1 container statuses recorded)
  I0902 08:40:07.101531 16 predicates.go:960] 	Container cilium-agent ready: true, restart count 1
  I0902 08:40:07.101711 16 predicates.go:958] cilium-node-init-cww5f from kube-system started at 2025-09-02 06:13:04 +0000 UTC (1 container statuses recorded)
  I0902 08:40:07.101732 16 predicates.go:960] 	Container node-init ready: true, restart count 1
  I0902 08:40:07.101750 16 predicates.go:958] kube-apiserver-ietha7evai9i-2 from kube-system started at 2025-09-02 06:30:19 +0000 UTC (1 container statuses recorded)
  I0902 08:40:07.101768 16 predicates.go:960] 	Container kube-apiserver ready: true, restart count 1
  I0902 08:40:07.101784 16 predicates.go:958] kube-controller-manager-ietha7evai9i-2 from kube-system started at 2025-09-02 06:30:19 +0000 UTC (1 container statuses recorded)
  I0902 08:40:07.101842 16 predicates.go:960] 	Container kube-controller-manager ready: true, restart count 1
  I0902 08:40:07.101861 16 predicates.go:958] kube-proxy-jp7tf from kube-system started at 2025-09-02 06:12:05 +0000 UTC (1 container statuses recorded)
  I0902 08:40:07.101875 16 predicates.go:960] 	Container kube-proxy ready: true, restart count 1
  I0902 08:40:07.101889 16 predicates.go:958] kube-scheduler-ietha7evai9i-2 from kube-system started at 2025-09-02 06:30:19 +0000 UTC (1 container statuses recorded)
  I0902 08:40:07.101903 16 predicates.go:960] 	Container kube-scheduler ready: true, restart count 1
  I0902 08:40:07.101919 16 predicates.go:958] sonobuoy-systemd-logs-daemon-set-707d3c8598644e6c-dlzrj from sonobuoy started at 2025-09-02 07:30:04 +0000 UTC (2 container statuses recorded)
  I0902 08:40:07.101932 16 predicates.go:960] 	Container sonobuoy-worker ready: true, restart count 0
  I0902 08:40:07.101945 16 predicates.go:960] 	Container systemd-logs ready: true, restart count 0
  I0902 08:40:07.101960 16 predicates.go:120] 
  Logging pods the apiserver thinks is on node ietha7evai9i-3 before test
  I0902 08:40:07.116899 16 predicates.go:958] cilium-node-init-cwq9b from kube-system started at 2025-09-02 06:13:04 +0000 UTC (1 container statuses recorded)
  I0902 08:40:07.117239 16 predicates.go:960] 	Container node-init ready: true, restart count 1
  I0902 08:40:07.117884 16 predicates.go:958] cilium-operator-f9554d685-sqbm7 from kube-system started at 2025-09-02 06:13:04 +0000 UTC (1 container statuses recorded)
  I0902 08:40:07.118043 16 predicates.go:960] 	Container cilium-operator ready: true, restart count 4
  I0902 08:40:07.118067 16 predicates.go:958] cilium-x7gr5 from kube-system started at 2025-09-02 06:13:04 +0000 UTC (1 container statuses recorded)
  I0902 08:40:07.118530 16 predicates.go:960] 	Container cilium-agent ready: true, restart count 1
  I0902 08:40:07.118654 16 predicates.go:958] coredns-66bc5c9577-fcrhx from kube-system started at 2025-09-02 06:19:32 +0000 UTC (1 container statuses recorded)
  I0902 08:40:07.118674 16 predicates.go:960] 	Container coredns ready: true, restart count 0
  I0902 08:40:07.118691 16 predicates.go:958] kube-proxy-dvcxr from kube-system started at 2025-09-02 06:12:30 +0000 UTC (1 container statuses recorded)
  I0902 08:40:07.118705 16 predicates.go:960] 	Container kube-proxy ready: true, restart count 1
  I0902 08:40:07.118721 16 predicates.go:958] sonobuoy from sonobuoy started at 2025-09-02 07:29:56 +0000 UTC (1 container statuses recorded)
  I0902 08:40:07.118735 16 predicates.go:960] 	Container kube-sonobuoy ready: true, restart count 0
  I0902 08:40:07.118750 16 predicates.go:958] sonobuoy-e2e-job-5dae80ab010f494d from sonobuoy started at 2025-09-02 07:30:04 +0000 UTC (2 container statuses recorded)
  I0902 08:40:07.118791 16 predicates.go:960] 	Container e2e ready: true, restart count 0
  I0902 08:40:07.118823 16 predicates.go:960] 	Container sonobuoy-worker ready: true, restart count 0
  I0902 08:40:07.118852 16 predicates.go:958] sonobuoy-systemd-logs-daemon-set-707d3c8598644e6c-r5bs9 from sonobuoy started at 2025-09-02 07:30:04 +0000 UTC (2 container statuses recorded)
  I0902 08:40:07.118870 16 predicates.go:960] 	Container sonobuoy-worker ready: true, restart count 0
  I0902 08:40:07.118883 16 predicates.go:960] 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to schedule Pod with nonempty NodeSelector. @ 09/02/25 08:40:07.119
  STEP: Considering event: 
  Type = [Warning], Name = [restricted-pod.18616a7b404f747d], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match Pod's node affinity/selector. no new claims to deallocate, preemption: 0/3 nodes are available: 3 Preemption is not helpful for scheduling.] @ 09/02/25 08:40:07.253
  E0902 08:40:07.658295      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:40:08.244144 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-7219" for this suite. @ 09/02/25 08:40:08.254
• [1.310 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:464
  STEP: Creating a kubernetes client @ 09/02/25 08:40:08.272
  I0902 08:40:08.273013 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename security-context-test @ 09/02/25 08:40:08.276
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:40:08.304
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:40:08.316
  E0902 08:40:08.658278      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:40:09.659252      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:40:10.660077      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:40:11.661277      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:40:12.379037 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-8792" for this suite. @ 09/02/25 08:40:12.393
• [4.136 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:262
  STEP: Creating a kubernetes client @ 09/02/25 08:40:12.41
  I0902 08:40:12.410265 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename projected @ 09/02/25 08:40:12.414
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:40:12.444
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:40:12.452
  STEP: Creating a pod to test downward API volume plugin @ 09/02/25 08:40:12.46
  E0902 08:40:12.661463      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:40:13.662244      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:40:14.662888      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:40:15.663378      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/02/25 08:40:16.507
  I0902 08:40:16.512223 16 output.go:207] Trying to get logs from node ietha7evai9i-2 pod downwardapi-volume-e52ea2a7-9cee-496e-8dde-7f3a8f18a1a0 container client-container: <nil>
  STEP: delete the pod @ 09/02/25 08:40:16.526
  I0902 08:40:16.560146 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-29" for this suite. @ 09/02/25 08:40:16.569
• [4.175 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:126
  STEP: Creating a kubernetes client @ 09/02/25 08:40:16.585
  I0902 08:40:16.585319 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename sched-preemption @ 09/02/25 08:40:16.588
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:40:16.615
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:40:16.62
  I0902 08:40:16.651066 16 wait.go:51] Waiting up to 1m0s for all nodes to be ready
  E0902 08:40:16.664859      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:40:17.665179      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:40:18.665387      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:40:19.666736      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:40:20.666903      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:40:21.667643      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:40:22.668658      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:40:23.669014      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:40:24.669764      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:40:25.670071      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:40:26.670770      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:40:27.671191      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:40:28.671160      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:40:29.672030      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:40:30.672999      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:40:31.673474      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:40:32.673743      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:40:33.674142      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:40:34.675176      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:40:35.675918      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:40:36.676709      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:40:37.676984      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:40:38.677129      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:40:39.678168      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:40:40.679730      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:40:41.680163      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:40:42.682849      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:40:43.683320      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:40:44.683706      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:40:45.684226      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:40:46.684701      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:40:47.685191      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:40:48.685616      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:40:49.686060      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:40:50.686148      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:40:51.686772      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:40:52.687718      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:40:53.686910      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:40:54.687971      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:40:55.689095      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:40:56.689275      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:40:57.689514      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:40:58.690793      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:40:59.690981      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:41:00.692066      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:41:01.692444      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:41:02.692669      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:41:03.693168      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:41:04.694626      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:41:05.694209      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:41:06.695004      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:41:07.695758      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:41:08.696131      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:41:09.696591      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:41:10.697609      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:41:11.697824      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:41:12.699045      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:41:13.699317      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:41:14.699796      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:41:15.700113      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:41:16.664993 16 util.go:390] Waiting for terminating namespaces to be deleted...
  STEP: Create pods that use 4/5 of node resources. @ 09/02/25 08:41:16.679
  STEP: Adding a custom resource @ 09/02/25 08:41:16.679
  E0902 08:41:16.700700      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:41:16.802994 16 preemption.go:170] Created pod: pod0-0-sched-preemption-low-priority
  I0902 08:41:16.856817 16 preemption.go:170] Created pod: pod0-1-sched-preemption-medium-priority
  STEP: Adding a custom resource @ 09/02/25 08:41:16.856
  I0902 08:41:16.967266 16 preemption.go:170] Created pod: pod1-0-sched-preemption-medium-priority
  I0902 08:41:17.002135 16 preemption.go:170] Created pod: pod1-1-sched-preemption-medium-priority
  STEP: Adding a custom resource @ 09/02/25 08:41:17.003
  I0902 08:41:17.092820 16 preemption.go:170] Created pod: pod2-0-sched-preemption-medium-priority
  I0902 08:41:17.163381 16 preemption.go:170] Created pod: pod2-1-sched-preemption-medium-priority
  STEP: Wait for pods to be scheduled. @ 09/02/25 08:41:17.163
  E0902 08:41:17.703758      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:41:18.705183      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Run a high priority pod that has same requirements as that of lower priority pod @ 09/02/25 08:41:19.269
  E0902 08:41:19.704221      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:41:20.704101      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:41:21.704821      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:41:22.705456      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Removing a custom resource @ 09/02/25 08:41:23.449
  STEP: Removing a custom resource @ 09/02/25 08:41:23.48
  STEP: Removing a custom resource @ 09/02/25 08:41:23.52
  I0902 08:41:23.553016 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-9728" for this suite. @ 09/02/25 08:41:23.568
• [67.005 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:89
  STEP: Creating a kubernetes client @ 09/02/25 08:41:23.593
  I0902 08:41:23.593355 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename configmap @ 09/02/25 08:41:23.6
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:41:23.624
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:41:23.631
  STEP: Creating configMap with name configmap-test-volume-map-b1b1ca79-94ed-4e3c-8a1a-62d6d940a606 @ 09/02/25 08:41:23.639
  STEP: Creating a pod to test consume configMaps @ 09/02/25 08:41:23.65
  E0902 08:41:23.706137      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:41:24.707317      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:41:25.708098      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:41:26.708792      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:41:27.709773      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/02/25 08:41:27.712
  I0902 08:41:27.724409 16 output.go:207] Trying to get logs from node ietha7evai9i-2 pod pod-configmaps-5cccddaa-5be3-4005-b1f2-53a5bd322329 container agnhost-container: <nil>
  STEP: delete the pod @ 09/02/25 08:41:27.748
  I0902 08:41:27.801847 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-5130" for this suite. @ 09/02/25 08:41:27.821
• [4.259 seconds]
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:119
  STEP: Creating a kubernetes client @ 09/02/25 08:41:27.852
  I0902 08:41:27.852646 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename emptydir @ 09/02/25 08:41:27.859
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:41:27.895
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:41:27.901
  STEP: Creating a pod to test emptydir 0777 on tmpfs @ 09/02/25 08:41:27.908
  E0902 08:41:28.717444      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:41:29.717272      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:41:30.717682      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:41:31.718256      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/02/25 08:41:32.007
  I0902 08:41:32.017862 16 output.go:207] Trying to get logs from node ietha7evai9i-2 pod pod-dbcf474d-9d6b-4550-88f7-4a25f034bb5e container test-container: <nil>
  STEP: delete the pod @ 09/02/25 08:41:32.038
  I0902 08:41:32.089804 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-3849" for this suite. @ 09/02/25 08:41:32.104
• [4.270 seconds]
------------------------------
S
------------------------------
[sig-network] Services should test the lifecycle of an Endpoint [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3247
  STEP: Creating a kubernetes client @ 09/02/25 08:41:32.123
  I0902 08:41:32.123138 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename services @ 09/02/25 08:41:32.126
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:41:32.154
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:41:32.159
  I0902 08:41:32.182219      16 warnings.go:110] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  STEP: creating an Endpoint @ 09/02/25 08:41:32.182
  I0902 08:41:32.199826      16 warnings.go:110] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  STEP: waiting for available Endpoint @ 09/02/25 08:41:32.199
  I0902 08:41:32.202258      16 warnings.go:110] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  STEP: listing all Endpoints @ 09/02/25 08:41:32.203
  I0902 08:41:32.210444      16 warnings.go:110] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  STEP: updating the Endpoint @ 09/02/25 08:41:32.21
  I0902 08:41:32.221061      16 warnings.go:110] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  I0902 08:41:32.226845      16 warnings.go:110] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  STEP: fetching the Endpoint @ 09/02/25 08:41:32.227
  I0902 08:41:32.233802      16 warnings.go:110] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  STEP: patching the Endpoint @ 09/02/25 08:41:32.234
  I0902 08:41:32.259696      16 warnings.go:110] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  I0902 08:41:32.266907      16 warnings.go:110] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  STEP: fetching the Endpoint @ 09/02/25 08:41:32.267
  I0902 08:41:32.282709      16 warnings.go:110] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  STEP: deleting the Endpoint by Collection @ 09/02/25 08:41:32.283
  I0902 08:41:32.307753      16 warnings.go:110] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  STEP: waiting for Endpoint deletion @ 09/02/25 08:41:32.308
  I0902 08:41:32.312511      16 warnings.go:110] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  STEP: fetching the Endpoint @ 09/02/25 08:41:32.312
  I0902 08:41:32.326999      16 warnings.go:110] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  I0902 08:41:32.327452 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-3546" for this suite. @ 09/02/25 08:41:32.34
• [0.270 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Pods should be updated [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:345
  STEP: Creating a kubernetes client @ 09/02/25 08:41:32.393
  I0902 08:41:32.393753 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename pods @ 09/02/25 08:41:32.396
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:41:32.469
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:41:32.478
  STEP: creating the pod @ 09/02/25 08:41:32.484
  STEP: submitting the pod to kubernetes @ 09/02/25 08:41:32.484
  E0902 08:41:32.719181      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:41:33.719646      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: verifying the pod is in kubernetes @ 09/02/25 08:41:34.526
  STEP: updating the pod @ 09/02/25 08:41:34.535
  E0902 08:41:34.720628      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:41:35.072684 16 pod_client.go:186] Successfully updated pod "pod-update-ade8d0ee-7894-4527-9f52-57e42d2abcf1"
  STEP: verifying the updated pod is in kubernetes @ 09/02/25 08:41:35.086
  I0902 08:41:35.099486 16 pods.go:391] Pod update OK
  I0902 08:41:35.099952 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-7923" for this suite. @ 09/02/25 08:41:35.113
• [2.733 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:274
  STEP: Creating a kubernetes client @ 09/02/25 08:41:35.127
  I0902 08:41:35.127407 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename namespaces @ 09/02/25 08:41:35.13
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:41:35.152
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:41:35.161
  STEP: creating a Namespace @ 09/02/25 08:41:35.17
  STEP: patching the Namespace @ 09/02/25 08:41:35.225
  STEP: get the Namespace and ensuring it has the label @ 09/02/25 08:41:35.255
  I0902 08:41:35.263110 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-6525" for this suite. @ 09/02/25 08:41:35.274
  STEP: Destroying namespace "nspatchtest-f6b67b67-7cc0-47c0-9da1-5fe09f8ce20b-2785" for this suite. @ 09/02/25 08:41:35.291
• [0.185 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:335
  STEP: Creating a kubernetes client @ 09/02/25 08:41:35.314
  I0902 08:41:35.314639 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename init-container @ 09/02/25 08:41:35.32
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:41:35.373
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:41:35.384
  STEP: creating the pod @ 09/02/25 08:41:35.396
  I0902 08:41:35.397141 16 init_container.go:374] PodSpec: initContainers in spec.initContainers
  E0902 08:41:35.720925      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:41:36.721152      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:41:37.721427      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:41:38.722001      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:41:39.722310      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:41:40.722995      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:41:41.723699      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:41:42.724179      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:41:43.724826      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:41:44.724850      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:41:45.725233      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:41:46.725711      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:41:47.726044      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:41:48.726229      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:41:49.726885      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:41:50.727294      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:41:51.727678      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:41:52.728028      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:41:53.728727      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:41:54.729800      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:41:55.729805      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:41:56.729958      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:41:57.730179      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:41:58.731017      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:41:59.731527      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:42:00.732299      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:42:01.732907      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:42:02.733314      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:42:03.733429      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:42:04.733911      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:42:05.735159      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:42:06.735385      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:42:07.735276      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:42:08.735655      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:42:09.736197      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:42:10.736383      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:42:11.736848      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:42:12.736872      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:42:13.737184      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:42:14.738094      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:42:15.738527      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:42:16.738825      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:42:17.739100      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:42:18.739818      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:42:19.740077      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:42:20.740760      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:42:21.097991 16 init_container.go:432] init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-cb4bf5f3-d785-4d7c-82bc-f40de93f06a0", GenerateName:"", Namespace:"init-container-8943", SelfLink:"", UID:"337d58f6-26bc-430a-a1df-1ca383615d02", ResourceVersion:"39743", Generation:1, CreationTimestamp:time.Date(2025, time.September, 2, 8, 41, 35, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"397100125"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.September, 2, 8, 41, 35, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0012de438), Subresource:""}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.September, 2, 8, 42, 21, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0012de480), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-l25pq", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc001028aa0), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil), Image:(*v1.ImageVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.37.0-1", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), RestartPolicyRules:[]v1.ContainerRestartRule(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-l25pq", ReadOnly:true, RecursiveReadOnly:(*v1.RecursiveReadOnlyMode)(nil), MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.37.0-1", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), RestartPolicyRules:[]v1.ContainerRestartRule(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-l25pq", ReadOnly:true, RecursiveReadOnly:(*v1.RecursiveReadOnlyMode)(nil), MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.10.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), RestartPolicyRules:[]v1.ContainerRestartRule(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-l25pq", ReadOnly:true, RecursiveReadOnly:(*v1.RecursiveReadOnlyMode)(nil), MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0045bc410), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ietha7evai9i-3", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc004467710), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0045bc4a0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0045bc4c0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0045bc4c8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0045bc4cc), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc0038368f0), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil), SchedulingGates:[]v1.PodSchedulingGate(nil), ResourceClaims:[]v1.PodResourceClaim(nil), Resources:(*v1.ResourceRequirements)(nil), HostnameOverride:(*string)(nil)}, Status:v1.PodStatus{ObservedGeneration:1, Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"PodReadyToStartContainers", ObservedGeneration:1, Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2025, time.September, 2, 8, 41, 36, 0, time.Local), Reason:"", Message:""}, v1.PodCondition{Type:"Initialized", ObservedGeneration:1, Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2025, time.September, 2, 8, 41, 35, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", ObservedGeneration:1, Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2025, time.September, 2, 8, 41, 35, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", ObservedGeneration:1, Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2025, time.September, 2, 8, 41, 35, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", ObservedGeneration:1, Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2025, time.September, 2, 8, 41, 35, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.121.52", HostIPs:[]v1.HostIP{v1.HostIP{IP:"192.168.121.52"}}, PodIP:"10.233.65.157", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.233.65.157"}}, StartTime:time.Date(2025, time.September, 2, 8, 41, 35, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0004e3ea0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0004fa070)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.37.0-1", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:0ffbe172f8d245c83f285c6992b452c53d085661e03ddfd3b484332026e6c8bb", ContainerID:"cri-o://8daa5754afd3d2c5f8e5cbf0dfacbee5ec7f1c0a2a01b8b0d72c5cfa4c531a48", Started:(*bool)(0xc0045bc57a), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(0xc0057efe00), VolumeMounts:[]v1.VolumeMountStatus{v1.VolumeMountStatus{Name:"kube-api-access-l25pq", MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", ReadOnly:true, RecursiveReadOnly:(*v1.RecursiveReadOnlyMode)(0xc003836930)}}, User:(*v1.ContainerUser)(0xc001614098), AllocatedResourcesStatus:[]v1.ResourceStatus(nil), StopSignal:(*v1.Signal)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001028b20), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.37.0-1", ImageID:"", ContainerID:"", Started:(*bool)(0xc0045bc5a5), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil), VolumeMounts:[]v1.VolumeMountStatus{v1.VolumeMountStatus{Name:"kube-api-access-l25pq", MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", ReadOnly:true, RecursiveReadOnly:(*v1.RecursiveReadOnlyMode)(0xc003836940)}}, User:(*v1.ContainerUser)(nil), AllocatedResourcesStatus:[]v1.ResourceStatus(nil), StopSignal:(*v1.Signal)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001028b00), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.10.1", ImageID:"", ContainerID:"", Started:(*bool)(0xc0045bc544), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil), VolumeMounts:[]v1.VolumeMountStatus{v1.VolumeMountStatus{Name:"kube-api-access-l25pq", MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", ReadOnly:true, RecursiveReadOnly:(*v1.RecursiveReadOnlyMode)(0xc003836900)}}, User:(*v1.ContainerUser)(nil), AllocatedResourcesStatus:[]v1.ResourceStatus(nil), StopSignal:(*v1.Signal)(nil)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil), Resize:"", ResourceClaimStatuses:[]v1.PodResourceClaimStatus(nil), ExtendedResourceClaimStatus:(*v1.PodExtendedResourceClaimStatus)(nil)}}
  I0902 08:42:21.098435 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-8943" for this suite. @ 09/02/25 08:42:21.115
• [45.825 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] server version should find the server version [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/server_version.go:41
  STEP: Creating a kubernetes client @ 09/02/25 08:42:21.141
  I0902 08:42:21.141458 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename server-version @ 09/02/25 08:42:21.143
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:42:21.208
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:42:21.213
  STEP: Request ServerVersion @ 09/02/25 08:42:21.218
  STEP: Confirm major version @ 09/02/25 08:42:21.222
  I0902 08:42:21.222314 16 server_version.go:52] Major version: 1
  STEP: Confirm minor version @ 09/02/25 08:42:21.222
  I0902 08:42:21.222375 16 server_version.go:58] cleanMinorVersion: 34
  I0902 08:42:21.222403 16 server_version.go:62] Minor version: 34
  I0902 08:42:21.222534 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "server-version-9647" for this suite. @ 09/02/25 08:42:21.257
• [0.136 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application should create and stop a working application [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:413
  STEP: Creating a kubernetes client @ 09/02/25 08:42:21.278
  I0902 08:42:21.278456 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename kubectl @ 09/02/25 08:42:21.28
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:42:21.334
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:42:21.346
  STEP: creating all guestbook components @ 09/02/25 08:42:21.355
  I0902 08:42:21.356139 16 kubectl.go:419] apiVersion: v1
  kind: Service
  metadata:
    name: agnhost-replica
    labels:
      app: agnhost
      role: replica
      tier: backend
  spec:
    ports:
    - port: 6379
    selector:
      app: agnhost
      role: replica
      tier: backend

  I0902 08:42:21.357024 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-8427 create -f -'
  E0902 08:42:21.741826      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:42:21.769408 16 builder.go:156] stderr: ""
  I0902 08:42:21.769481 16 builder.go:157] stdout: "service/agnhost-replica created\n"
  I0902 08:42:21.769604 16 kubectl.go:419] apiVersion: v1
  kind: Service
  metadata:
    name: agnhost-primary
    labels:
      app: agnhost
      role: primary
      tier: backend
  spec:
    ports:
    - port: 6379
      targetPort: 6379
    selector:
      app: agnhost
      role: primary
      tier: backend

  I0902 08:42:21.770269 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-8427 create -f -'
  I0902 08:42:22.193490 16 builder.go:156] stderr: ""
  I0902 08:42:22.193606 16 builder.go:157] stdout: "service/agnhost-primary created\n"
  I0902 08:42:22.193702 16 kubectl.go:419] apiVersion: v1
  kind: Service
  metadata:
    name: frontend
    labels:
      app: guestbook
      tier: frontend
  spec:
    # if your cluster supports it, uncomment the following to automatically create
    # an external load-balanced IP for the frontend service.
    # type: LoadBalancer
    ports:
    - port: 80
    selector:
      app: guestbook
      tier: frontend

  I0902 08:42:22.194145 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-8427 create -f -'
  I0902 08:42:22.558906 16 builder.go:156] stderr: ""
  I0902 08:42:22.559004 16 builder.go:157] stdout: "service/frontend created\n"
  I0902 08:42:22.559159 16 kubectl.go:419] apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: frontend
  spec:
    replicas: 3
    selector:
      matchLabels:
        app: guestbook
        tier: frontend
    template:
      metadata:
        labels:
          app: guestbook
          tier: frontend
      spec:
        containers:
        - name: guestbook-frontend
          image: registry.k8s.io/e2e-test-images/agnhost:2.56
          args: [ "guestbook", "--backend-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 80

  I0902 08:42:22.562326 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-8427 create -f -'
  E0902 08:42:22.742894      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:42:22.822656 16 builder.go:156] stderr: ""
  I0902 08:42:22.823080 16 builder.go:157] stdout: "deployment.apps/frontend created\n"
  I0902 08:42:22.823498 16 kubectl.go:419] apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: agnhost-primary
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: agnhost
        role: primary
        tier: backend
    template:
      metadata:
        labels:
          app: agnhost
          role: primary
          tier: backend
      spec:
        containers:
        - name: primary
          image: registry.k8s.io/e2e-test-images/agnhost:2.56
          args: [ "guestbook", "--http-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 6379

  I0902 08:42:22.824098 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-8427 create -f -'
  I0902 08:42:23.148247 16 builder.go:156] stderr: ""
  I0902 08:42:23.148345 16 builder.go:157] stdout: "deployment.apps/agnhost-primary created\n"
  I0902 08:42:23.148457 16 kubectl.go:419] apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: agnhost-replica
  spec:
    replicas: 2
    selector:
      matchLabels:
        app: agnhost
        role: replica
        tier: backend
    template:
      metadata:
        labels:
          app: agnhost
          role: replica
          tier: backend
      spec:
        containers:
        - name: replica
          image: registry.k8s.io/e2e-test-images/agnhost:2.56
          args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 6379

  I0902 08:42:23.148844 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-8427 create -f -'
  I0902 08:42:23.597731 16 builder.go:156] stderr: ""
  I0902 08:42:23.597888 16 builder.go:157] stdout: "deployment.apps/agnhost-replica created\n"
  STEP: validating guestbook app @ 09/02/25 08:42:23.597
  I0902 08:42:23.598088 16 kubectl.go:2307] Waiting for all frontend pods to be Running.
  E0902 08:42:23.745139      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:42:24.744657      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:42:25.744841      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:42:26.745531      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:42:27.745509      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:42:28.650521 16 kubectl.go:2311] Waiting for frontend to serve content.
  I0902 08:42:28.694984 16 kubectl.go:2316] Trying to add a new entry to the guestbook.
  E0902 08:42:28.745754      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:42:28.758873 16 kubectl.go:2321] Verifying that added entry can be retrieved.
  I0902 08:42:28.798154 16 kubectl.go:2334] Failed to get response from guestbook. err: <nil>, response: {"data":""}
  E0902 08:42:29.746464      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:42:30.746894      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:42:31.747246      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:42:32.747823      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:42:33.747820      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: using delete to clean up resources @ 09/02/25 08:42:33.849
  I0902 08:42:33.850263 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-8427 delete --grace-period=0 --force -f -'
  I0902 08:42:34.062883 16 builder.go:156] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0902 08:42:34.062962 16 builder.go:157] stdout: "service \"agnhost-replica\" force deleted from kubectl-8427 namespace\n"
  STEP: using delete to clean up resources @ 09/02/25 08:42:34.063
  I0902 08:42:34.063411 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-8427 delete --grace-period=0 --force -f -'
  I0902 08:42:34.258906 16 builder.go:156] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0902 08:42:34.258987 16 builder.go:157] stdout: "service \"agnhost-primary\" force deleted from kubectl-8427 namespace\n"
  STEP: using delete to clean up resources @ 09/02/25 08:42:34.259
  I0902 08:42:34.259415 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-8427 delete --grace-period=0 --force -f -'
  I0902 08:42:34.459257 16 builder.go:156] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0902 08:42:34.459393 16 builder.go:157] stdout: "service \"frontend\" force deleted from kubectl-8427 namespace\n"
  STEP: using delete to clean up resources @ 09/02/25 08:42:34.459
  I0902 08:42:34.460131 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-8427 delete --grace-period=0 --force -f -'
  I0902 08:42:34.634722 16 builder.go:156] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0902 08:42:34.634823 16 builder.go:157] stdout: "deployment.apps \"frontend\" force deleted from kubectl-8427 namespace\n"
  STEP: using delete to clean up resources @ 09/02/25 08:42:34.635
  I0902 08:42:34.635425 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-8427 delete --grace-period=0 --force -f -'
  E0902 08:42:34.751664      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:42:34.939452 16 builder.go:156] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0902 08:42:34.939621 16 builder.go:157] stdout: "deployment.apps \"agnhost-primary\" force deleted from kubectl-8427 namespace\n"
  STEP: using delete to clean up resources @ 09/02/25 08:42:34.939
  I0902 08:42:34.940655 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-8427 delete --grace-period=0 --force -f -'
  I0902 08:42:35.338269 16 builder.go:156] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0902 08:42:35.339192 16 builder.go:157] stdout: "deployment.apps \"agnhost-replica\" force deleted from kubectl-8427 namespace\n"
  I0902 08:42:35.340494 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-8427" for this suite. @ 09/02/25 08:42:35.36
• [14.124 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:213
  STEP: Creating a kubernetes client @ 09/02/25 08:42:35.403
  I0902 08:42:35.403816 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename container-runtime @ 09/02/25 08:42:35.419
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:42:35.463
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:42:35.48
  STEP: create the container @ 09/02/25 08:42:35.499
  I0902 08:42:35.531865      16 warnings.go:110] "Warning: metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]"
  STEP: wait for the container to reach Failed @ 09/02/25 08:42:35.532
  E0902 08:42:35.753204      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:42:36.753034      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:42:37.753912      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: get the container status @ 09/02/25 08:42:38.596
  STEP: the container should be terminated @ 09/02/25 08:42:38.606
  STEP: the termination message should be set @ 09/02/25 08:42:38.606
  I0902 08:42:38.606463 16 runtime.go:164] Expected: &{DONE} to match Container's Termination Message: DONE --
  STEP: delete the container @ 09/02/25 08:42:38.606
  I0902 08:42:38.663768 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-2379" for this suite. @ 09/02/25 08:42:38.681
• [3.304 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should allow opting out of API token automount [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:191
  STEP: Creating a kubernetes client @ 09/02/25 08:42:38.709
  I0902 08:42:38.709422 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename svcaccounts @ 09/02/25 08:42:38.713
  E0902 08:42:38.754587      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:42:38.761
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:42:38.767
  I0902 08:42:38.828394 16 service_accounts.go:281] created pod pod-service-account-defaultsa
  I0902 08:42:38.828538 16 service_accounts.go:295] pod pod-service-account-defaultsa service account token volume mount: true
  I0902 08:42:38.844962 16 service_accounts.go:281] created pod pod-service-account-mountsa
  I0902 08:42:38.845059 16 service_accounts.go:295] pod pod-service-account-mountsa service account token volume mount: true
  I0902 08:42:38.875520 16 service_accounts.go:281] created pod pod-service-account-nomountsa
  I0902 08:42:38.875649 16 service_accounts.go:295] pod pod-service-account-nomountsa service account token volume mount: false
  I0902 08:42:38.894832 16 service_accounts.go:281] created pod pod-service-account-defaultsa-mountspec
  I0902 08:42:38.894926 16 service_accounts.go:295] pod pod-service-account-defaultsa-mountspec service account token volume mount: true
  I0902 08:42:38.953686 16 service_accounts.go:281] created pod pod-service-account-mountsa-mountspec
  I0902 08:42:38.953762 16 service_accounts.go:295] pod pod-service-account-mountsa-mountspec service account token volume mount: true
  I0902 08:42:39.052534 16 service_accounts.go:281] created pod pod-service-account-nomountsa-mountspec
  I0902 08:42:39.053336 16 service_accounts.go:295] pod pod-service-account-nomountsa-mountspec service account token volume mount: true
  I0902 08:42:39.148033 16 service_accounts.go:281] created pod pod-service-account-defaultsa-nomountspec
  I0902 08:42:39.148399 16 service_accounts.go:295] pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
  I0902 08:42:39.161990 16 service_accounts.go:281] created pod pod-service-account-mountsa-nomountspec
  I0902 08:42:39.162084 16 service_accounts.go:295] pod pod-service-account-mountsa-nomountspec service account token volume mount: false
  I0902 08:42:39.182217 16 service_accounts.go:281] created pod pod-service-account-nomountsa-nomountspec
  I0902 08:42:39.182307 16 service_accounts.go:295] pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
  I0902 08:42:39.182596 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-7723" for this suite. @ 09/02/25 08:42:39.378
• [0.715 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply changes to a namespace status [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:305
  STEP: Creating a kubernetes client @ 09/02/25 08:42:39.424
  I0902 08:42:39.424413 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename namespaces @ 09/02/25 08:42:39.428
  E0902 08:42:39.905986      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:42:39.907
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:42:39.926
  STEP: Read namespace status @ 09/02/25 08:42:39.977
  I0902 08:42:40.003262 16 namespace.go:318] Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
  STEP: Patch namespace status @ 09/02/25 08:42:40.003
  I0902 08:42:40.020818 16 namespace.go:338] Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
  STEP: Update namespace status @ 09/02/25 08:42:40.02
  I0902 08:42:40.067049 16 namespace.go:363] Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
  I0902 08:42:40.079936 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-7555" for this suite. @ 09/02/25 08:42:40.094
• [0.695 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should reject mutating webhook configurations with invalid match conditions [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:840
  STEP: Creating a kubernetes client @ 09/02/25 08:42:40.138
  I0902 08:42:40.138283 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename webhook @ 09/02/25 08:42:40.155
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:42:40.308
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:42:40.32
  STEP: Setting up server cert @ 09/02/25 08:42:40.463
  E0902 08:42:40.906984      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 09/02/25 08:42:41.081
  STEP: Deploying the webhook pod @ 09/02/25 08:42:41.09
  STEP: Wait for the deployment to be ready @ 09/02/25 08:42:41.115
  I0902 08:42:41.138124 16 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0902 08:42:41.907694      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:42:42.908159      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 09/02/25 08:42:43.161
  STEP: Verifying the service has paired with the endpoint @ 09/02/25 08:42:43.186
  E0902 08:42:43.908709      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:42:44.188011 16 util.go:419] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: creating a mutating webhook with match conditions @ 09/02/25 08:42:44.199
  I0902 08:42:44.351208 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-6038" for this suite. @ 09/02/25 08:42:44.371
  STEP: Destroying namespace "webhook-markers-6940" for this suite. @ 09/02/25 08:42:44.393
• [4.282 seconds]
------------------------------
SS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:140
  STEP: Creating a kubernetes client @ 09/02/25 08:42:44.419
  I0902 08:42:44.419947 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 09/02/25 08:42:44.425
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:42:44.451
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:42:44.458
  STEP: create the container to handle the HTTPGet hook request. @ 09/02/25 08:42:44.473
  E0902 08:42:44.910489      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:42:45.910749      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:42:46.910798      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:42:47.911245      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 09/02/25 08:42:48.558
  E0902 08:42:48.912738      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:42:49.912431      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: check poststart hook @ 09/02/25 08:42:50.608
  STEP: delete the pod with lifecycle hook @ 09/02/25 08:42:50.66
  E0902 08:42:50.913394      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:42:51.913383      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:42:52.701293 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-7626" for this suite. @ 09/02/25 08:42:52.716
• [8.364 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:108
  STEP: Creating a kubernetes client @ 09/02/25 08:42:52.785
  I0902 08:42:52.785446 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename runtimeclass @ 09/02/25 08:42:52.787
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:42:52.82
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:42:52.826
  E0902 08:42:52.914286      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:42:53.914911      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:42:54.906349 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  E0902 08:42:54.915021      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Destroying namespace "runtimeclass-489" for this suite. @ 09/02/25 08:42:54.916
• [2.147 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] CSINodes CSI Conformance should run through the lifecycle of a csinode [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/csi_node.go:54
  STEP: Creating a kubernetes client @ 09/02/25 08:42:54.935
  I0902 08:42:54.935182 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename csinodes @ 09/02/25 08:42:54.938
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:42:54.975
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:42:54.983
  STEP: Creating initial csiNode "e2e-csinode-jplgg" @ 09/02/25 08:42:54.99
  STEP: Getting initial csiNode "e2e-csinode-jplgg" @ 09/02/25 08:42:55.003
  STEP: Patching initial csiNode: "e2e-csinode-jplgg" @ 09/02/25 08:42:55.014
  STEP: Listing csiNodes with LabelSelector "e2e-csinode-jplgg=patched" @ 09/02/25 08:42:55.03
  STEP: Delete initial csiNode: "e2e-csinode-jplgg" @ 09/02/25 08:42:55.038
  STEP: Confirm deletion of csiNode "e2e-csinode-jplgg" @ 09/02/25 08:42:55.051
  STEP: Creating replacement csiNode "e2e-csinode-6xt68" @ 09/02/25 08:42:55.059
  STEP: Getting replacement csiNode "e2e-csinode-6xt68" @ 09/02/25 08:42:55.067
  STEP: Updating replacement csiNode "e2e-csinode-6xt68" @ 09/02/25 08:42:55.072
  STEP: DeleteCollection of CSINodes with "e2e-csinode-6xt68=updated" label @ 09/02/25 08:42:55.086
  STEP: Confirm deletion of replacement csiNode with LabelSelector "e2e-csinode-6xt68=updated" @ 09/02/25 08:42:55.1
  I0902 08:42:55.106184 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csinodes-8506" for this suite. @ 09/02/25 08:42:55.113
• [0.190 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should create a serviceAccountToken and ensure a successful TokenReview [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:877
  STEP: Creating a kubernetes client @ 09/02/25 08:42:55.126
  I0902 08:42:55.126741 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename svcaccounts @ 09/02/25 08:42:55.13
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:42:55.15
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:42:55.157
  STEP: Creating a Serviceaccount "e2e-sa-kw9pw" in namespace "svcaccounts-8466" @ 09/02/25 08:42:55.163
  STEP: Creating a ServiceaccountToken "e2e-sa-kw9pw" in namespace "svcaccounts-8466" @ 09/02/25 08:42:55.177
  STEP: Creating a TokenReview for "e2e-sa-kw9pw" in namespace "svcaccounts-8466" @ 09/02/25 08:42:55.195
  I0902 08:42:55.199836 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-8466" for this suite. @ 09/02/25 08:42:55.214
• [0.101 seconds]
------------------------------
SS
------------------------------
[sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:167
  STEP: Creating a kubernetes client @ 09/02/25 08:42:55.228
  I0902 08:42:55.228117 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename disruption @ 09/02/25 08:42:55.23
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:42:55.252
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:42:55.259
  STEP: Waiting for the pdb to be processed @ 09/02/25 08:42:55.275
  E0902 08:42:55.916357      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:42:56.916747      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Updating PodDisruptionBudget status @ 09/02/25 08:42:57.288
  STEP: Waiting for all pods to be running @ 09/02/25 08:42:57.332
  I0902 08:42:57.349605 16 disruption.go:691] running pods: 0 < 1
  E0902 08:42:57.916876      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:42:58.917124      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: locating a running pod @ 09/02/25 08:42:59.347
  STEP: Waiting for the pdb to be processed @ 09/02/25 08:42:59.395
  STEP: Patching PodDisruptionBudget status @ 09/02/25 08:42:59.423
  STEP: Waiting for the pdb to be processed @ 09/02/25 08:42:59.447
  I0902 08:42:59.471528 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-6609" for this suite. @ 09/02/25 08:42:59.482
• [4.272 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:49
  STEP: Creating a kubernetes client @ 09/02/25 08:42:59.501
  I0902 08:42:59.501313 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename container-runtime @ 09/02/25 08:42:59.504
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:42:59.531
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:42:59.538
  STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' @ 09/02/25 08:42:59.561
  E0902 08:42:59.918276      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:43:00.918237      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:43:01.918649      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:43:02.918977      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:43:03.919062      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:43:04.919914      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:43:05.922226      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:43:06.921032      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:43:07.922616      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:43:08.922660      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:43:09.922780      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:43:10.923518      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:43:11.923945      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:43:12.924758      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:43:13.926023      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:43:14.926027      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:43:15.927102      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:43:16.928023      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:43:17.928037      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' @ 09/02/25 08:43:18.809
  STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition @ 09/02/25 08:43:18.82
  STEP: Container 'terminate-cmd-rpa': should get the expected 'State' @ 09/02/25 08:43:18.842
  STEP: Container 'terminate-cmd-rpa': should be possible to delete @ 09/02/25 08:43:18.842
  STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' @ 09/02/25 08:43:18.907
  E0902 08:43:18.928059      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:43:19.929359      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:43:20.930222      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:43:21.931285      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' @ 09/02/25 08:43:21.948
  E0902 08:43:22.931961      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition @ 09/02/25 08:43:22.963
  STEP: Container 'terminate-cmd-rpof': should get the expected 'State' @ 09/02/25 08:43:22.976
  STEP: Container 'terminate-cmd-rpof': should be possible to delete @ 09/02/25 08:43:22.976
  STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' @ 09/02/25 08:43:23.021
  E0902 08:43:23.933192      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' @ 09/02/25 08:43:24.047
  E0902 08:43:24.933279      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:43:25.933921      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition @ 09/02/25 08:43:26.072
  STEP: Container 'terminate-cmd-rpn': should get the expected 'State' @ 09/02/25 08:43:26.088
  STEP: Container 'terminate-cmd-rpn': should be possible to delete @ 09/02/25 08:43:26.088
  I0902 08:43:26.144149 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-3818" for this suite. @ 09/02/25 08:43:26.152
• [26.668 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:619
  STEP: Creating a kubernetes client @ 09/02/25 08:43:26.169
  I0902 08:43:26.169472 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename pods @ 09/02/25 08:43:26.176
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:43:26.212
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:43:26.219
  I0902 08:43:26.225705 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: creating the pod @ 09/02/25 08:43:26.227
  STEP: submitting the pod to kubernetes @ 09/02/25 08:43:26.228
  E0902 08:43:26.934806      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:43:27.935818      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: waiting for the container to be running @ 09/02/25 08:43:28.275
  I0902 08:43:28.346240 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-8379" for this suite. @ 09/02/25 08:43:28.36
• [2.206 seconds]
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:250
  STEP: Creating a kubernetes client @ 09/02/25 08:43:28.375
  I0902 08:43:28.375170 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename projected @ 09/02/25 08:43:28.377
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:43:28.404
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:43:28.408
  STEP: Creating a pod to test downward API volume plugin @ 09/02/25 08:43:28.414
  E0902 08:43:28.943809      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:43:29.945046      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:43:30.945075      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:43:31.945252      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/02/25 08:43:32.479
  I0902 08:43:32.492974 16 output.go:207] Trying to get logs from node ietha7evai9i-3 pod downwardapi-volume-6cd286d8-83a4-4e4c-916a-4b8a37cfce89 container client-container: <nil>
  STEP: delete the pod @ 09/02/25 08:43:32.523
  I0902 08:43:32.566164 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-770" for this suite. @ 09/02/25 08:43:32.581
• [4.225 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:639
  STEP: Creating a kubernetes client @ 09/02/25 08:43:32.601
  I0902 08:43:32.601365 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename webhook @ 09/02/25 08:43:32.604
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:43:32.687
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:43:32.699
  STEP: Setting up server cert @ 09/02/25 08:43:32.821
  E0902 08:43:32.946359      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 09/02/25 08:43:33.732
  STEP: Deploying the webhook pod @ 09/02/25 08:43:33.745
  STEP: Wait for the deployment to be ready @ 09/02/25 08:43:33.777
  I0902 08:43:33.806190 16 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0902 08:43:33.947629      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:43:34.948037      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 09/02/25 08:43:35.841
  STEP: Verifying the service has paired with the endpoint @ 09/02/25 08:43:35.863
  E0902 08:43:35.948518      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:43:36.864447 16 util.go:419] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  E0902 08:43:36.949446      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Listing all of the created validation webhooks @ 09/02/25 08:43:37.023
  E0902 08:43:37.949766      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:43:38.950226      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:43:39.950219      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:43:40.950713      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:43:41.950905      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:43:42.951441      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:43:43.952286      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:43:44.952379      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:43:45.952955      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:43:46.953488      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Creating a configMap that should be mutated @ 09/02/25 08:43:47.059
  STEP: Deleting the collection of validation webhooks @ 09/02/25 08:43:47.125
  STEP: Creating a configMap that should not be mutated @ 09/02/25 08:43:47.252
  I0902 08:43:47.406363 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-8354" for this suite. @ 09/02/25 08:43:47.457
  STEP: Destroying namespace "webhook-markers-3199" for this suite. @ 09/02/25 08:43:47.489
• [14.910 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-network] EndpointSlice should support a Service with multiple ports specified in multiple EndpointSlices [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:538
  STEP: Creating a kubernetes client @ 09/02/25 08:43:47.513
  I0902 08:43:47.513283 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename endpointslice @ 09/02/25 08:43:47.518
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:43:47.546
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:43:47.551
  E0902 08:43:47.953827      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:43:48.953969      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: creating @ 09/02/25 08:43:49.708
  STEP: Creating a pause pods that will try to connect to the webserver @ 09/02/25 08:43:49.745
  E0902 08:43:49.955069      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:43:50.955503      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:43:51.787886 16 util.go:162] Waiting up to 2m0s to get response from 10.233.51.218:80
  I0902 08:43:51.788523 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=endpointslice-2847 exec pause-pod-0 -- /bin/sh -x -c curl -q -s --max-time 30 10.233.51.218:80/hostname'
  E0902 08:43:51.956048      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:43:52.206976 16 builder.go:156] stderr: "+ curl -q -s --max-time 30 10.233.51.218:80/hostname\n"
  I0902 08:43:52.207074 16 builder.go:157] stdout: "pod-handle-http-request"
  I0902 08:43:52.207137 16 util.go:162] Waiting up to 2m0s to get response from 10.233.51.218:81
  I0902 08:43:52.207388 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=endpointslice-2847 exec pause-pod-0 -- /bin/sh -x -c curl -q -s --max-time 30 10.233.51.218:81/hostname'
  I0902 08:43:52.557131 16 builder.go:156] stderr: "+ curl -q -s --max-time 30 10.233.51.218:81/hostname\n"
  I0902 08:43:52.557239 16 builder.go:157] stdout: "pod-handle-http-request"
  I0902 08:43:52.558082 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-2847" for this suite. @ 09/02/25 08:43:52.577
• [5.081 seconds]
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:179
  STEP: Creating a kubernetes client @ 09/02/25 08:43:52.595
  I0902 08:43:52.595374 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename emptydir @ 09/02/25 08:43:52.599
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:43:52.628
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:43:52.639
  STEP: Creating a pod to test emptydir 0666 on node default medium @ 09/02/25 08:43:52.645
  E0902 08:43:52.957175      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:43:53.957296      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:43:54.957912      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:43:55.959019      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/02/25 08:43:56.712
  I0902 08:43:56.755777 16 output.go:207] Trying to get logs from node ietha7evai9i-2 pod pod-833c50d8-57c0-4b26-8a8f-dee93b19b572 container test-container: <nil>
  STEP: delete the pod @ 09/02/25 08:43:56.795
  I0902 08:43:56.833973 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-5652" for this suite. @ 09/02/25 08:43:56.846
• [4.270 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:95
  STEP: Creating a kubernetes client @ 09/02/25 08:43:56.865
  I0902 08:43:56.865732 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename downward-api @ 09/02/25 08:43:56.87
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:43:56.898
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:43:56.905
  STEP: Creating a pod to test downward api env vars @ 09/02/25 08:43:56.913
  E0902 08:43:56.960100      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:43:57.962879      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:43:58.960453      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:43:59.962061      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:44:00.964932      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/02/25 08:44:01.005
  I0902 08:44:01.018431 16 output.go:207] Trying to get logs from node ietha7evai9i-3 pod downward-api-0050ccab-8480-4249-8e07-165e5236ca56 container dapi-container: <nil>
  STEP: delete the pod @ 09/02/25 08:44:01.051
  I0902 08:44:01.088334 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-7092" for this suite. @ 09/02/25 08:44:01.103
• [4.252 seconds]
------------------------------
SS
------------------------------
[sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:163
  STEP: Creating a kubernetes client @ 09/02/25 08:44:01.118
  I0902 08:44:01.118638 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename downward-api @ 09/02/25 08:44:01.126
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:44:01.153
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:44:01.159
  STEP: Creating the pod @ 09/02/25 08:44:01.165
  E0902 08:44:01.963882      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:44:02.964638      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:44:03.767075 16 pod_client.go:186] Successfully updated pod "annotationupdate1d7b8e88-e4d9-4264-aab7-4b1a8e9515c8"
  E0902 08:44:03.965673      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:44:04.966155      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:44:05.818270 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-3495" for this suite. @ 09/02/25 08:44:05.83
• [4.733 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/sysctl.go:125
  STEP: Creating a kubernetes client @ 09/02/25 08:44:05.852
  I0902 08:44:05.853166 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename sysctl @ 09/02/25 08:44:05.857
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:44:05.899
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:44:05.909
  STEP: Creating a pod with one valid and two invalid sysctls @ 09/02/25 08:44:05.917
  I0902 08:44:05.936768 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sysctl-5656" for this suite. @ 09/02/25 08:44:05.95
  E0902 08:44:05.966999      16 retrywatcher.go:169] "Watch failed" err="context canceled"
• [0.118 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:208
  STEP: Creating a kubernetes client @ 09/02/25 08:44:05.975
  I0902 08:44:05.975371 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename projected @ 09/02/25 08:44:05.978
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:44:06.012
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:44:06.017
  STEP: Creating a pod to test downward API volume plugin @ 09/02/25 08:44:06.023
  E0902 08:44:06.968052      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:44:07.968809      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:44:08.968367      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:44:09.968702      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/02/25 08:44:10.071
  I0902 08:44:10.080056 16 output.go:207] Trying to get logs from node ietha7evai9i-3 pod downwardapi-volume-34b69aef-4e79-4b82-ae87-5916f9ac745b container client-container: <nil>
  STEP: delete the pod @ 09/02/25 08:44:10.095
  I0902 08:44:10.132414 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5653" for this suite. @ 09/02/25 08:44:10.143
• [4.183 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:115
  STEP: Creating a kubernetes client @ 09/02/25 08:44:10.167
  I0902 08:44:10.168011 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename webhook @ 09/02/25 08:44:10.172
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:44:10.201
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:44:10.209
  STEP: Setting up server cert @ 09/02/25 08:44:10.256
  E0902 08:44:10.969323      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 09/02/25 08:44:11.4
  STEP: Deploying the webhook pod @ 09/02/25 08:44:11.416
  STEP: Wait for the deployment to be ready @ 09/02/25 08:44:11.447
  I0902 08:44:11.469968 16 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0902 08:44:11.969795      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:44:12.970801      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 09/02/25 08:44:13.5
  STEP: Verifying the service has paired with the endpoint @ 09/02/25 08:44:13.521
  E0902 08:44:13.971232      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:44:14.523008 16 util.go:419] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: fetching the /apis discovery document @ 09/02/25 08:44:14.541
  STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document @ 09/02/25 08:44:14.547
  STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document @ 09/02/25 08:44:14.547
  STEP: fetching the /apis/admissionregistration.k8s.io discovery document @ 09/02/25 08:44:14.547
  STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document @ 09/02/25 08:44:14.551
  STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document @ 09/02/25 08:44:14.553
  STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document @ 09/02/25 08:44:14.558
  I0902 08:44:14.683656 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-2136" for this suite. @ 09/02/25 08:44:14.695
  STEP: Destroying namespace "webhook-markers-9632" for this suite. @ 09/02/25 08:44:14.721
• [4.571 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1469
  STEP: Creating a kubernetes client @ 09/02/25 08:44:14.74
  I0902 08:44:14.740334 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename services @ 09/02/25 08:44:14.743
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:44:14.787
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:44:14.793
  STEP: creating a service externalname-service with the type=ExternalName in namespace services-5585 @ 09/02/25 08:44:14.803
  STEP: changing the ExternalName service to type=NodePort @ 09/02/25 08:44:14.816
  I0902 08:44:14.904860 16 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:0, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:0, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition(nil), CollisionCount:(*int32)(nil)}
  E0902 08:44:14.972483      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:44:15.972860      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:44:16.914181 16 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:2, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.September, 2, 8, 44, 14, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 8, 44, 14, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.September, 2, 8, 44, 16, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 8, 44, 14, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"externalname-service-8996df495\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0902 08:44:16.973616      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:44:17.973918      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:44:18.913936 16 resource.go:344] Creating new exec pod
  E0902 08:44:18.974247      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:44:19.974371      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:44:20.975357      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:44:21.006417 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=services-5585 exec execpodcfslp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  I0902 08:44:21.332195 16 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service (10.233.8.239) 80 port [tcp/http] succeeded!\n"
  I0902 08:44:21.332277 16 builder.go:157] stdout: ""
  E0902 08:44:21.976270      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:44:22.007154 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=services-5585 exec execpodcfslp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  I0902 08:44:22.348273 16 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service (10.233.8.239) 80 port [tcp/http] succeeded!\n"
  I0902 08:44:22.348455 16 builder.go:157] stdout: ""
  E0902 08:44:22.976646      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:44:23.007000 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=services-5585 exec execpodcfslp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  I0902 08:44:23.288890 16 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service (10.233.8.239) 80 port [tcp/http] succeeded!\n"
  I0902 08:44:23.289004 16 builder.go:157] stdout: "externalname-service-8996df495-ggj8k"
  I0902 08:44:23.290105 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=services-5585 exec execpodcfslp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.8.239 80'
  I0902 08:44:23.569901 16 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.8.239 80\nConnection to 10.233.8.239 80 port [tcp/http] succeeded!\n"
  I0902 08:44:23.569983 16 builder.go:157] stdout: "externalname-service-8996df495-njs52"
  I0902 08:44:23.570699 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=services-5585 exec execpodcfslp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.25 31201'
  I0902 08:44:23.849502 16 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.25 31201\nConnection to 192.168.121.25 31201 port [tcp/*] succeeded!\n"
  I0902 08:44:23.849610 16 builder.go:157] stdout: "externalname-service-8996df495-njs52"
  I0902 08:44:23.850094 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=services-5585 exec execpodcfslp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.46 31201'
  E0902 08:44:23.977155      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:44:24.151191 16 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.46 31201\nConnection to 192.168.121.46 31201 port [tcp/*] succeeded!\n"
  I0902 08:44:24.151284 16 builder.go:157] stdout: ""
  I0902 08:44:24.850923 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=services-5585 exec execpodcfslp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.46 31201'
  E0902 08:44:24.977609      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:44:25.159757 16 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.46 31201\nConnection to 192.168.121.46 31201 port [tcp/*] succeeded!\n"
  I0902 08:44:25.159892 16 builder.go:157] stdout: "externalname-service-8996df495-ggj8k"
  I0902 08:44:25.160329 16 service.go:1478] Cleaning up the ExternalName to NodePort test service
  I0902 08:44:25.304256 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-5585" for this suite. @ 09/02/25 08:44:25.328
• [10.625 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:46
  STEP: Creating a kubernetes client @ 09/02/25 08:44:25.365
  I0902 08:44:25.365766 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename configmap @ 09/02/25 08:44:25.368
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:44:25.418
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:44:25.424
  STEP: Creating configMap configmap-9301/configmap-test-3cd52b8e-9757-4819-a950-80243b975c05 @ 09/02/25 08:44:25.432
  STEP: Creating a pod to test consume configMaps @ 09/02/25 08:44:25.45
  E0902 08:44:25.979778      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:44:26.980400      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:44:27.980447      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:44:28.980815      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/02/25 08:44:29.516
  I0902 08:44:29.523231 16 output.go:207] Trying to get logs from node ietha7evai9i-2 pod pod-configmaps-7cd6e254-b7f7-4550-b7b6-665e81a1cc8a container env-test: <nil>
  STEP: delete the pod @ 09/02/25 08:44:29.54
  I0902 08:44:29.582359 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-9301" for this suite. @ 09/02/25 08:44:29.596
• [4.250 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:491
  STEP: Creating a kubernetes client @ 09/02/25 08:44:29.618
  I0902 08:44:29.618917 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename webhook @ 09/02/25 08:44:29.621
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:44:29.657
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:44:29.665
  STEP: Setting up server cert @ 09/02/25 08:44:29.73
  E0902 08:44:29.981124      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:44:30.981763      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 09/02/25 08:44:31.588
  STEP: Deploying the webhook pod @ 09/02/25 08:44:31.601
  STEP: Wait for the deployment to be ready @ 09/02/25 08:44:31.627
  I0902 08:44:31.651741 16 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0902 08:44:31.982913      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:44:32.983284      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 09/02/25 08:44:33.677
  STEP: Verifying the service has paired with the endpoint @ 09/02/25 08:44:33.7
  E0902 08:44:33.983994      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:44:34.701109 16 util.go:419] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Creating a mutating webhook configuration @ 09/02/25 08:44:34.71
  I0902 08:44:34.751699 16 webhook.go:2701] Waiting for webhook configuration to be ready...
  STEP: Updating a mutating webhook configuration's rules to not include the create operation @ 09/02/25 08:44:34.883
  STEP: Creating a configMap that should not be mutated @ 09/02/25 08:44:34.9
  STEP: Patching a mutating webhook configuration's rules to include the create operation @ 09/02/25 08:44:34.929
  STEP: Creating a configMap that should be mutated @ 09/02/25 08:44:34.946
  E0902 08:44:34.984733      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:44:35.145899 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-2697" for this suite. @ 09/02/25 08:44:35.157
  STEP: Destroying namespace "webhook-markers-6156" for this suite. @ 09/02/25 08:44:35.188
• [5.603 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a GRPC liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:528
  STEP: Creating a kubernetes client @ 09/02/25 08:44:35.223
  I0902 08:44:35.224098 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename container-probe @ 09/02/25 08:44:35.226
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:44:35.289
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:44:35.294
  STEP: Creating pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28 @ 09/02/25 08:44:35.297
  E0902 08:44:35.985883      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:44:36.986089      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 09/02/25 08:44:37.36
  I0902 08:44:37.370216 16 container_probe.go:1749] Initial restart count of pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 is 0
  I0902 08:44:37.377318 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:44:37.986970      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:44:38.987526      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:44:39.388153 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:44:39.987877      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:44:40.987812      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:44:41.397046 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:44:41.988704      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:44:42.989645      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:44:43.405465 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:44:43.989917      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:44:44.990386      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:44:45.413585 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:44:45.991289      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:44:46.992006      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:44:47.423530 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:44:47.993773      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:44:48.993846      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:44:49.432127 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:44:49.994985      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:44:50.995487      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:44:51.441763 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:44:51.996420      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:44:52.996794      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:44:53.449423 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:44:53.996945      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:44:54.997184      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:44:55.456465 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:44:55.998117      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:44:56.998790      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:44:57.467445 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:44:58.000016      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:44:59.000256      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:44:59.476850 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:45:00.000203      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:45:01.000356      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:45:01.490412 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:45:02.000766      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:45:03.001011      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:45:03.499905 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:45:04.001317      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:45:05.002052      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:45:05.512214 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:45:06.002887      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:45:07.003477      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:45:07.522148 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:45:08.004330      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:45:09.004724      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:45:09.531406 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:45:10.005510      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:45:11.005879      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:45:11.539841 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:45:12.005878      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:45:13.006168      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:45:13.550197 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:45:14.006290      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:45:15.006751      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:45:15.557916 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:45:16.007216      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:45:17.007810      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:45:17.567381 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:45:18.008853      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:45:19.009783      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:45:19.585607 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:45:20.009902      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:45:21.010086      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:45:21.612194 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:45:22.011194      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:45:23.011411      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:45:23.621791 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:45:24.012124      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:45:25.012282      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:45:25.630734 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:45:26.012888      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:45:27.014193      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:45:27.641585 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:45:28.014428      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:45:29.014703      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:45:29.667263 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:45:30.015657      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:45:31.016460      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:45:31.676318 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:45:32.016534      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:45:33.016844      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:45:33.683455 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:45:34.017964      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:45:35.018978      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:45:35.692877 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:45:36.019677      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:45:37.020425      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:45:37.701414 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:45:38.020952      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:45:39.021388      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:45:39.709268 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:45:40.022340      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:45:41.022621      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:45:41.716890 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:45:42.023072      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:45:43.023280      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:45:43.727024 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:45:44.023408      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:45:45.023783      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:45:45.738248 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:45:46.025287      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:45:47.025012      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:45:47.746684 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:45:48.026168      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:45:49.026652      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:45:49.766032 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:45:50.027448      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:45:51.027142      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:45:51.773109 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:45:52.027505      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:45:53.028180      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:45:53.786033 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:45:54.029134      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:45:55.029313      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:45:55.798201 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:45:56.029425      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:45:57.029732      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:45:57.813966 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:45:58.029990      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:45:59.030524      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:45:59.823754 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:46:00.031780      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:46:01.032079      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:46:01.835763 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:46:02.032959      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:46:03.033640      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:46:03.848944 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:46:04.034473      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:46:05.034435      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:46:05.859843 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:46:06.035052      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:46:07.035743      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:46:07.869528 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:46:08.036442      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:46:09.037448      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:46:09.881520 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:46:10.038419      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:46:11.038822      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:46:11.893364 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:46:12.039716      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:46:13.039726      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:46:13.906593 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:46:14.040187      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:46:15.040695      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:46:15.920781 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:46:16.041428      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:46:17.042018      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:46:17.929464 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:46:18.042485      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:46:19.042760      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:46:19.939438 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:46:20.043311      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:46:21.043241      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:46:21.948944 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:46:22.044008      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:46:23.044411      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:46:23.972943 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:46:24.044885      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:46:25.045043      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:46:25.983161 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:46:26.045238      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:46:27.045343      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:46:27.992461 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:46:28.046456      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:46:29.046684      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:46:30.000486 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:46:30.047764      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:46:31.047867      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:46:32.008714 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:46:32.049045      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:46:33.049720      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:46:34.018665 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:46:34.050905      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:46:35.051602      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:46:36.026784 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:46:36.051940      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:46:37.052128      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:46:38.033908 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:46:38.053085      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:46:39.053337      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:46:40.041995 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:46:40.054328      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:46:41.054923      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:46:42.054787 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:46:42.055113      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:46:43.055971      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:46:44.059526      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:46:44.067516 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:46:45.057011      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:46:46.057748      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:46:46.075853 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:46:47.057844      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:46:48.058728      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:46:48.087166 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:46:49.059024      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:46:50.059293      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:46:50.102958 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:46:51.059780      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:46:52.060153      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:46:52.114365 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:46:53.061197      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:46:54.060938      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:46:54.130325 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:46:55.062094      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:46:56.062983      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:46:56.146948 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:46:57.063886      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:46:58.063963      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:46:58.156371 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:46:59.064202      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:47:00.065025      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:47:00.170578 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:47:01.066767      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:47:02.065833      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:47:02.182422 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:47:03.065978      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:47:04.066899      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:47:04.191495 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:47:05.067656      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:47:06.068923      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:47:06.204140 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:47:07.069703      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:47:08.070143      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:47:08.214797 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:47:09.070680      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:47:10.070889      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:47:10.224638 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:47:11.070955      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:47:12.071166      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:47:12.243497 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:47:13.071496      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:47:14.071767      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:47:14.256527 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:47:15.072060      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:47:16.072941      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:47:16.269122 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:47:17.073380      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:47:18.073714      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:47:18.278616 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:47:19.074122      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:47:20.074843      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:47:20.288868 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:47:21.074995      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:47:22.075387      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:47:22.297208 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:47:23.075849      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:47:24.076111      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:47:24.307005 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:47:25.076300      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:47:26.077052      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:47:26.318066 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:47:27.077637      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:47:28.077932      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:47:28.327749 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:47:29.078853      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:47:30.079209      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:47:30.336221 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:47:31.079457      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:47:32.079784      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:47:32.346281 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:47:33.080145      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:47:34.080990      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:47:34.356214 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:47:35.082220      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:47:36.082731      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:47:36.364137 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:47:37.083669      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:47:38.083688      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:47:38.376860 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:47:39.084635      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:47:40.085257      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:47:40.385733 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:47:41.085508      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:47:42.085632      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:47:42.394233 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:47:43.085919      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:47:44.086501      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:47:44.404943 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:47:45.086942      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:47:46.086855      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:47:46.415414 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:47:47.087870      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:47:48.088688      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:47:48.424649 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:47:49.088888      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:47:50.088874      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:47:50.436416 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:47:51.089969      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:47:52.090718      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:47:52.450347 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:47:53.090806      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:47:54.091636      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:47:54.577048 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:47:55.091899      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:47:56.091896      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:47:56.585213 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:47:57.092037      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:47:58.092145      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:47:58.594766 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:47:59.093304      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:48:00.093958      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:48:00.601825 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:48:01.094316      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:48:02.094775      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:48:02.609438 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:48:03.095356      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:48:04.096105      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:48:04.627814 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:48:05.096913      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:48:06.096789      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:48:06.643948 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:48:07.098178      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:48:08.098387      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:48:08.653343 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:48:09.099588      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:48:10.099607      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:48:10.663037 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:48:11.100069      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:48:12.100735      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:48:12.671101 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:48:13.101714      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:48:14.102055      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:48:14.684479 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:48:15.103881      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:48:16.102721      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:48:16.700298 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:48:17.102936      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:48:18.103048      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:48:18.712719 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:48:19.103933      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:48:20.104104      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:48:20.726326 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:48:21.104914      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:48:22.106143      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:48:22.738165 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:48:23.106826      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:48:24.106967      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:48:24.752644 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:48:25.107383      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:48:26.108523      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:48:26.762311 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:48:27.108432      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:48:28.108677      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:48:28.771981 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:48:29.108852      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:48:30.109352      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:48:30.780355 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:48:31.109429      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:48:32.109516      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:48:32.790870 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:48:33.110607      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:48:34.110778      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:48:34.799886 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:48:35.111203      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:48:36.111366      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:48:36.806715 16 container_probe.go:1759] Get pod test-grpc-ff701a70-36b7-4b05-a217-f88c244f6446 in namespace container-probe-28
  E0902 08:48:37.112100      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:48:38.112124      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 09/02/25 08:48:38.807
  I0902 08:48:38.839313 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-28" for this suite. @ 09/02/25 08:48:38.855
• [243.654 seconds]
------------------------------
S
------------------------------
[sig-architecture] Conformance Tests should have at least two untainted nodes [Conformance] [sig-architecture, Conformance]
k8s.io/kubernetes/test/e2e/architecture/conformance.go:39
  STEP: Creating a kubernetes client @ 09/02/25 08:48:38.88
  I0902 08:48:38.880924 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename conformance-tests @ 09/02/25 08:48:38.89
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:48:38.916
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:48:38.923
  STEP: Getting node addresses @ 09/02/25 08:48:38.928
  I0902 08:48:38.929203 16 helper.go:51] Waiting up to 10m0s for all (but 0) nodes to be schedulable
  I0902 08:48:38.950102 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "conformance-tests-7043" for this suite. @ 09/02/25 08:48:38.959
• [0.095 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:99
  STEP: Creating a kubernetes client @ 09/02/25 08:48:38.978
  I0902 08:48:38.978620 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename aggregator @ 09/02/25 08:48:38.984
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:48:39.02
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:48:39.03
  I0902 08:48:39.040280 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Registering the sample API server. @ 09/02/25 08:48:39.042
  E0902 08:48:39.113139      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:48:40.114164      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:48:40.899282 16 helpers.go:191] Found ClusterRoles; assuming RBAC is enabled.
  I0902 08:48:40.970099 16 deployment.go:223] deployment "sample-apiserver-deployment" doesn't have the required revision set
  E0902 08:48:41.114723      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:48:42.115172      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:48:43.075274 16 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.September, 2, 8, 48, 41, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 8, 48, 41, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.September, 2, 8, 48, 41, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 8, 48, 40, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5bc889656b\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0902 08:48:43.116282      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:48:44.116816      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:48:45.093780 16 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.September, 2, 8, 48, 41, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 8, 48, 41, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.September, 2, 8, 48, 41, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 8, 48, 40, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5bc889656b\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0902 08:48:45.117671      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:48:46.118377      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:48:47.083154 16 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.September, 2, 8, 48, 41, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 8, 48, 41, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.September, 2, 8, 48, 41, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 8, 48, 40, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5bc889656b\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0902 08:48:47.119231      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:48:48.119282      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:48:49.084094 16 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.September, 2, 8, 48, 41, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 8, 48, 41, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.September, 2, 8, 48, 41, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 8, 48, 40, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5bc889656b\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0902 08:48:49.120236      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:48:50.121389      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:48:51.083186 16 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.September, 2, 8, 48, 41, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 8, 48, 41, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.September, 2, 8, 48, 41, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 8, 48, 40, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5bc889656b\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0902 08:48:51.122210      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:48:52.122448      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:48:53.083847 16 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.September, 2, 8, 48, 41, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 8, 48, 41, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.September, 2, 8, 48, 41, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 8, 48, 40, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5bc889656b\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0902 08:48:53.123395      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:48:54.123504      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:48:55.090124 16 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.September, 2, 8, 48, 41, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 8, 48, 41, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.September, 2, 8, 48, 41, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 8, 48, 40, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5bc889656b\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0902 08:48:55.123873      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:48:56.123929      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:48:57.083792 16 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.September, 2, 8, 48, 41, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 8, 48, 41, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.September, 2, 8, 48, 41, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 8, 48, 40, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5bc889656b\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0902 08:48:57.124884      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:48:58.125485      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:48:59.082990 16 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.September, 2, 8, 48, 41, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 8, 48, 41, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.September, 2, 8, 48, 41, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 8, 48, 40, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5bc889656b\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0902 08:48:59.126266      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:49:00.126889      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:49:01.085476 16 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.September, 2, 8, 48, 41, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 8, 48, 41, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.September, 2, 8, 48, 41, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 8, 48, 40, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5bc889656b\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0902 08:49:01.127703      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:49:02.128802      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:49:03.086903 16 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.September, 2, 8, 48, 41, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 8, 48, 41, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.September, 2, 8, 48, 41, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 8, 48, 40, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5bc889656b\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0902 08:49:03.128975      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:49:04.129519      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:49:05.086099 16 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.September, 2, 8, 48, 41, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 8, 48, 41, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.September, 2, 8, 48, 41, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 8, 48, 40, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5bc889656b\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0902 08:49:05.130179      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:49:06.130728      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:49:07.082884 16 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.September, 2, 8, 48, 41, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 8, 48, 41, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.September, 2, 8, 48, 41, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 8, 48, 40, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5bc889656b\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0902 08:49:07.131253      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:49:08.131919      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:49:09.083278 16 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.September, 2, 8, 48, 41, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 8, 48, 41, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.September, 2, 8, 48, 41, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 8, 48, 40, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5bc889656b\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0902 08:49:09.132443      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:49:10.133144      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:49:11.133228      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:49:11.243318 16 aggregator.go:756] Waited 149.337021ms for the sample-apiserver to be ready to handle requests.
  STEP: Read Status for v1alpha1.wardle.example.com @ 09/02/25 08:49:11.328
  STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' @ 09/02/25 08:49:11.338
  STEP: List APIServices @ 09/02/25 08:49:11.351
  I0902 08:49:11.364347 16 aggregator.go:557] Found v1alpha1.wardle.example.com in APIServiceList
  STEP: Adding a label to the APIService @ 09/02/25 08:49:11.364
  I0902 08:49:11.385698 16 aggregator.go:582] APIService labels: map[e2e-apiservice:patched]
  STEP: Updating APIService Status @ 09/02/25 08:49:11.385
  I0902 08:49:11.406889 16 aggregator.go:608] updatedStatus.Conditions: []v1.APIServiceCondition{v1.APIServiceCondition{Type:"Available", Status:"True", LastTransitionTime:time.Date(2025, time.September, 2, 8, 49, 11, 0, time.Local), Reason:"Passed", Message:"all checks passed"}, v1.APIServiceCondition{Type:"StatusUpdated", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: Confirm that v1alpha1.wardle.example.com /status was updated @ 09/02/25 08:49:11.406
  I0902 08:49:11.415369 16 aggregator.go:626] Observed APIService v1alpha1.wardle.example.com with Labels: map[e2e-apiservice:patched] & Condition: {Available True 2025-09-02 08:49:11 +0000 UTC Passed all checks passed}
  I0902 08:49:11.415459 16 aggregator.go:622] Found APIService v1alpha1.wardle.example.com with Labels: map[e2e-apiservice:patched] & Condition: {StatusUpdated True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I0902 08:49:11.415495 16 aggregator.go:632] Found updated status condition for v1alpha1.wardle.example.com
  STEP: Replace APIService v1alpha1.wardle.example.com @ 09/02/25 08:49:11.415
  I0902 08:49:11.445700 16 aggregator.go:648] Found updated apiService label for "v1alpha1.wardle.example.com"
  STEP: Delete flunders resource "dynamic-flunder-1801522143" @ 09/02/25 08:49:11.445
  STEP: Recreating test-flunder before removing endpoint via deleteCollection @ 09/02/25 08:49:11.489
  STEP: Read v1alpha1.wardle.example.com /status before patching it @ 09/02/25 08:49:11.513
  STEP: Patch APIService Status @ 09/02/25 08:49:11.523
  STEP: Confirm that v1alpha1.wardle.example.com /status was patched @ 09/02/25 08:49:11.542
  I0902 08:49:11.553519 16 aggregator.go:726] Observed APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {Available True 2025-09-02 08:49:11 +0000 UTC Passed all checks passed}
  I0902 08:49:11.553657 16 aggregator.go:726] Observed APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {StatusUpdated True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I0902 08:49:11.553764 16 aggregator.go:722] Found APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC E2E Set by e2e test}
  I0902 08:49:11.553958 16 aggregator.go:732] Found patched status condition for v1alpha1.wardle.example.com
  STEP: APIService deleteCollection with labelSelector: "v1alpha1.wardle.example.com=updated" @ 09/02/25 08:49:11.554
  STEP: Confirm that the generated APIService has been deleted @ 09/02/25 08:49:11.578
  I0902 08:49:11.578787 16 aggregator.go:793] Requesting list of APIServices to confirm quantity
  I0902 08:49:11.586500 16 aggregator.go:803] Found 0 APIService with label "v1alpha1.wardle.example.com=updated"
  I0902 08:49:11.586632 16 aggregator.go:745] APIService v1alpha1.wardle.example.com has been deleted.
  I0902 08:49:11.938634 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregator-8413" for this suite. @ 09/02/25 08:49:11.956
• [33.000 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:215
  STEP: Creating a kubernetes client @ 09/02/25 08:49:11.995
  I0902 08:49:11.996069 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename projected @ 09/02/25 08:49:11.998
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:49:12.035
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:49:12.04
  STEP: Creating secret with name s-test-opt-del-4a82da6c-3f83-4d78-b14f-4a226cd8b913 @ 09/02/25 08:49:12.055
  STEP: Creating secret with name s-test-opt-upd-0649a55a-c7e3-4f06-a2ed-dfbefbedef95 @ 09/02/25 08:49:12.064
  STEP: Creating the pod @ 09/02/25 08:49:12.073
  E0902 08:49:12.134996      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:49:13.135860      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:49:14.135509      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deleting secret s-test-opt-del-4a82da6c-3f83-4d78-b14f-4a226cd8b913 @ 09/02/25 08:49:14.229
  STEP: Updating secret s-test-opt-upd-0649a55a-c7e3-4f06-a2ed-dfbefbedef95 @ 09/02/25 08:49:14.246
  STEP: Creating secret with name s-test-opt-create-1f92bc8e-0980-481e-9430-db0c1ac8640e @ 09/02/25 08:49:14.256
  STEP: waiting to observe update in volume @ 09/02/25 08:49:14.267
  E0902 08:49:15.135911      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:49:16.136419      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:49:17.136468      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:49:18.136849      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:49:19.137208      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:49:20.138599      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:49:21.138726      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:49:22.139066      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:49:23.139772      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:49:24.140336      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:49:25.140751      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:49:26.141282      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:49:27.141952      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:49:28.142680      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:49:29.143043      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:49:30.144167      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:49:31.145223      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:49:32.145786      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:49:33.146044      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:49:34.146713      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:49:35.147833      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:49:36.148022      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:49:37.148696      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:49:38.149289      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:49:39.150433      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:49:40.151315      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:49:41.151848      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:49:42.152515      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:49:43.153022      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:49:44.153770      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:49:45.154279      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:49:46.154435      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:49:47.155481      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:49:48.156119      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:49:49.156893      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:49:50.157441      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:49:51.157778      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:49:52.158818      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:49:53.159129      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:49:54.159118      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:49:55.160166      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:49:56.160616      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:49:57.160967      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:49:58.161243      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:49:59.162104      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:50:00.162267      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:50:01.162608      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:50:02.162448      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:50:03.163737      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:50:04.163943      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:50:05.165093      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:50:06.165405      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:50:07.167090      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:50:08.166994      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:50:09.168048      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:50:10.167969      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:50:11.168711      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:50:12.169467      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:50:13.170441      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:50:14.171112      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:50:15.171376      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:50:16.172004      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:50:17.172929      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:50:18.174426      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:50:19.174704      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:50:20.176359      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:50:21.175282      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:50:22.176204      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:50:23.176482      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:50:24.177062      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:50:25.177763      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:50:26.179844      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:50:27.178827      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:50:28.180218      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:50:29.180961      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:50:30.181962      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:50:31.182209      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:50:32.182955      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:50:33.183488      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:50:34.183807      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:50:35.183636      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:50:36.183841      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:50:37.184265      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:50:38.184527      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:50:39.185253      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:50:40.185970      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:50:41.186691      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:50:42.187498      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:50:43.187908      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:50:44.188242      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:50:45.188658      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:50:46.188938      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:50:47.189703      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:50:47.398448 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4504" for this suite. @ 09/02/25 08:50:47.419
• [95.446 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Pods should patch a pod status [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:1086
  STEP: Creating a kubernetes client @ 09/02/25 08:50:47.445
  I0902 08:50:47.445740 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename pods @ 09/02/25 08:50:47.453
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:50:47.489
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:50:47.499
  STEP: Create a pod @ 09/02/25 08:50:47.506
  E0902 08:50:48.189791      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:50:49.190172      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: patching /status @ 09/02/25 08:50:49.547
  I0902 08:50:49.566811 16 pods.go:1123] Status Message: "Patched by e2e test" and Reason: "E2E"
  I0902 08:50:49.567130 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-7473" for this suite. @ 09/02/25 08:50:49.579
• [2.150 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:59
  STEP: Creating a kubernetes client @ 09/02/25 08:50:49.594
  I0902 08:50:49.595014 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename custom-resource-definition @ 09/02/25 08:50:49.597
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:50:49.621
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:50:49.628
  I0902 08:50:49.636528 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  E0902 08:50:50.191119      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:50:50.707402 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-6187" for this suite. @ 09/02/25 08:50:50.721
• [1.143 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server should support proxy with --port 0 [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1868
  STEP: Creating a kubernetes client @ 09/02/25 08:50:50.778
  I0902 08:50:50.778529 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename kubectl @ 09/02/25 08:50:50.781
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:50:50.813
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:50:50.821
  STEP: starting the proxy server @ 09/02/25 08:50:50.829
  I0902 08:50:50.830201 16 util.go:542] Asynchronously running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-5255 proxy -p 0 --disable-filter'
  STEP: curling proxy /api/ output @ 09/02/25 08:50:50.986
  I0902 08:50:51.011113 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  I0902 08:50:51.014319 16 kubectl.go:2259] kubectl proxy stdout: Starting to serve on 127.0.0.1:44165

  I0902 08:50:51.014520 16 kubectl.go:2264] kubectl proxy stderr: W0902 08:50:50.983908     799 proxy.go:177] Request filter disabled, your proxy is vulnerable to XSRF attacks, please be cautious

  STEP: Destroying namespace "kubectl-5255" for this suite. @ 09/02/25 08:50:51.022
• [0.261 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:234
  STEP: Creating a kubernetes client @ 09/02/25 08:50:51.04
  I0902 08:50:51.040472 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename webhook @ 09/02/25 08:50:51.047
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:50:51.073
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:50:51.078
  STEP: Setting up server cert @ 09/02/25 08:50:51.123
  E0902 08:50:51.191392      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 09/02/25 08:50:51.582
  STEP: Deploying the webhook pod @ 09/02/25 08:50:51.597
  STEP: Wait for the deployment to be ready @ 09/02/25 08:50:51.625
  I0902 08:50:51.649999 16 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0902 08:50:52.192458      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:50:53.193131      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:50:53.672694 16 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.September, 2, 8, 50, 51, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 8, 50, 51, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.September, 2, 8, 50, 51, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 8, 50, 51, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7d44fffc8\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0902 08:50:54.193494      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:50:55.194286      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 09/02/25 08:50:55.683
  STEP: Verifying the service has paired with the endpoint @ 09/02/25 08:50:55.712
  E0902 08:50:56.194640      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:50:56.712665 16 util.go:419] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API @ 09/02/25 08:50:56.761
  I0902 08:50:56.822085 16 webhook.go:2701] Waiting for webhook configuration to be ready...
  I0902 08:50:56.952698 16 webhook.go:2701] Waiting for webhook configuration to be ready...
  STEP: create a namespace for the webhook @ 09/02/25 08:50:57.079
  STEP: create a configmap should be unconditionally rejected by the webhook @ 09/02/25 08:50:57.103
  E0902 08:50:57.195656      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:50:57.344148 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-8980" for this suite. @ 09/02/25 08:50:57.371
  STEP: Destroying namespace "webhook-markers-9616" for this suite. @ 09/02/25 08:50:57.412
  STEP: Destroying namespace "fail-closed-namespace-1392" for this suite. @ 09/02/25 08:50:57.459
• [6.457 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment deployment should support proportional scaling [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:160
  STEP: Creating a kubernetes client @ 09/02/25 08:50:57.503
  I0902 08:50:57.503096 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename deployment @ 09/02/25 08:50:57.508
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:50:57.571
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:50:57.584
  I0902 08:50:57.595030 16 deployment.go:1215] Creating deployment "webserver-deployment"
  I0902 08:50:57.611159 16 deployment.go:1219] Waiting for observed generation 1
  E0902 08:50:58.195867      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:50:59.203794      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:50:59.633530 16 deployment.go:1224] Waiting for all required pods to come up
  I0902 08:50:59.650485 16 resource.go:64] Pod name httpd: Found 10 pods out of 10
  STEP: ensuring each pod is running @ 09/02/25 08:50:59.651
  E0902 08:51:00.204394      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:51:01.204611      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:51:01.689352 16 deployment.go:1228] Waiting for deployment "webserver-deployment" to complete
  I0902 08:51:01.701662 16 deployment.go:1237] Updating deployment "webserver-deployment" with a non-existent image
  I0902 08:51:01.722364 16 deployment.go:314] Updating deployment webserver-deployment
  I0902 08:51:01.722945 16 deployment.go:1243] Waiting for observed generation 2
  E0902 08:51:02.204963      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:51:03.205220      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:51:03.745786 16 deployment.go:1253] Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
  I0902 08:51:03.756052 16 deployment.go:1258] Waiting for the first rollout's replicaset to have .spec.replicas = 8
  I0902 08:51:03.770568 16 deployment.go:1263] Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
  I0902 08:51:03.803223 16 deployment.go:1277] Verifying that the second rollout's replicaset has .status.availableReplicas = 0
  I0902 08:51:03.803295 16 deployment.go:1282] Waiting for the second rollout's replicaset to have .spec.replicas = 5
  I0902 08:51:03.815935 16 deployment.go:1287] Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
  I0902 08:51:03.845379 16 deployment.go:1294] Verifying that deployment "webserver-deployment" has minimum required number of available replicas
  I0902 08:51:03.845450 16 deployment.go:1302] Scaling up the deployment "webserver-deployment" from 10 to 30
  I0902 08:51:03.869303 16 deployment.go:314] Updating deployment webserver-deployment
  I0902 08:51:03.869509 16 deployment.go:1308] Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
  I0902 08:51:03.901936 16 deployment.go:1316] Verifying that first rollout's replicaset has .spec.replicas = 20
  I0902 08:51:03.928034 16 deployment.go:1322] Verifying that second rollout's replicaset has .spec.replicas = 13
  I0902 08:51:03.966864 16 deployment.go:632] Deployment "webserver-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=20) "webserver-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2691",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "8ee58d7f-375f-4aa7-8c79-27357f5b7008",
      ResourceVersion: (string) (len=5) "42657",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63892399857,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399862,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=541) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 6e 61  |licas":{},"f:una|
              000001f0  76 61 69 6c 61 62 6c 65  52 65 70 6c 69 63 61 73  |vailableReplicas|
              00000200  22 3a 7b 7d 2c 22 66 3a  75 70 64 61 74 65 64 52  |":{},"f:updatedR|
              00000210  65 70 6c 69 63 61 73 22  3a 7b 7d 7d 7d           |eplicas":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399863,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=635) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 68  74 74 70 64 5c 22 7d 22  |me\":\"httpd\"}"|
              00000160  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000170  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000180  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000190  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              000001a0  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              000001b0  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              000001c0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001d0  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000001e0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000001f0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              00000200  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              00000210  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              00000220  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              00000230  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000270  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(30),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=13) "webserver:404",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          HostnameOverride: (*string)(<nil>)
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 2,
            StrVal: (string) ""
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 3,
            StrVal: (string) ""
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 13,
      UpdatedReplicas: (int32) 5,
      ReadyReplicas: (int32) 8,
      AvailableReplicas: (int32) 8,
      UnavailableReplicas: (int32) 5,
      TerminatingReplicas: (*int32)(<nil>),
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399862,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399857,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=17) "ReplicaSetUpdated",
          Message: (string) (len=60) "ReplicaSet \"webserver-deployment-76fc67f65c\" is progressing."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0902 08:51:04.058900 16 deployment.go:40] New ReplicaSet "webserver-deployment-76fc67f65c" of Deployment "webserver-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=31) "webserver-deployment-76fc67f65c",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2691",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "ec7b5ab4-0029-49bb-a357-4094817cdb38",
      ResourceVersion: (string) (len=5) "42662",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63892399861,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "76fc67f65c"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=2) "30",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=2) "33",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=20) "webserver-deployment",
          UID: (types.UID) (len=36) "8ee58d7f-375f-4aa7-8c79-27357f5b7008",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399862,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=84) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  66 75 6c 6c 79 4c 61 62  65 6c 65 64 52 65 70 6c  |fullyLabeledRepl|
              00000020  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 6f 62 73 65  |icas":{},"f:obse|
              00000030  72 76 65 64 47 65 6e 65  72 61 74 69 6f 6e 22 3a  |rvedGeneration":|
              00000040  7b 7d 2c 22 66 3a 72 65  70 6c 69 63 61 73 22 3a  |{},"f:replicas":|
              00000050  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399863,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 38 65 65 35 38 64  37 66 2d 33 37 35 66 2d  |\"8ee58d7f-375f-|
              00000120  34 61 61 37 2d 38 63 37  39 2d 32 37 33 35 37 66  |4aa7-8c79-27357f|
              00000130  35 62 37 30 30 38 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |5b7008\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(13),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=10) "76fc67f65c"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=10) "76fc67f65c"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=13) "webserver:404",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          HostnameOverride: (*string)(<nil>)
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 5,
      FullyLabeledReplicas: (int32) 5,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      TerminatingReplicas: (*int32)(<nil>),
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0902 08:51:04.061717 16 deployment.go:45] All old ReplicaSets of Deployment "webserver-deployment":
  I0902 08:51:04.063854 16 deployment.go:48] (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=31) "webserver-deployment-6bc58496c7",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2691",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "eb6d722a-799d-4a01-839b-4c216f8322b0",
      ResourceVersion: (string) (len=5) "42658",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63892399857,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "6bc58496c7"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=2) "30",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=2) "33",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=20) "webserver-deployment",
          UID: (types.UID) (len=36) "8ee58d7f-375f-4aa7-8c79-27357f5b7008",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399861,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399863,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 38 65 65 35 38 64  37 66 2d 33 37 35 66 2d  |\"8ee58d7f-375f-|
              00000120  34 61 61 37 2d 38 63 37  39 2d 32 37 33 35 37 66  |4aa7-8c79-27357f|
              00000130  35 62 37 30 30 38 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |5b7008\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(20),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=10) "6bc58496c7"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=10) "6bc58496c7"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          HostnameOverride: (*string)(<nil>)
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 8,
      FullyLabeledReplicas: (int32) 8,
      ReadyReplicas: (int32) 8,
      AvailableReplicas: (int32) 8,
      TerminatingReplicas: (*int32)(<nil>),
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0902 08:51:04.131874 16 deployment.go:68] Pod "webserver-deployment-6bc58496c7-4kcrs" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-6bc58496c7-4kcrs",
      GenerateName: (string) (len=32) "webserver-deployment-6bc58496c7-",
      Namespace: (string) (len=15) "deployment-2691",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "af965bd8-b6ee-4359-a7bb-4891aed27e30",
      ResourceVersion: (string) (len=5) "42569",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63892399857,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "6bc58496c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-6bc58496c7",
          UID: (types.UID) (len=36) "eb6d722a-799d-4a01-839b-4c216f8322b0",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399857,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 65 62  36 64 37 32 32 61 2d 37  |d\":\"eb6d722a-7|
              00000090  39 39 64 2d 34 61 30 31  2d 38 33 39 62 2d 34 63  |99d-4a01-839b-4c|
              000000a0  32 31 36 66 38 33 32 32  62 30 5c 22 7d 22 3a 7b  |216f8322b0\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399861,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=852) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6f 62 73 65 72 76  |me":{},"f:observ|
              00000080  65 64 47 65 6e 65 72 61  74 69 6f 6e 22 3a 7b 7d  |edGeneration":{}|
              00000090  2c 22 66 3a 73 74 61 74  75 73 22 3a 7b 7d 2c 22  |,"f:status":{},"|
              000000a0  66 3a 74 79 70 65 22 3a  7b 7d 7d 2c 22 6b 3a 7b  |f:type":{}},"k:{|
              000000b0  5c 22 74 79 70 65 5c 22  3a 5c 22 49 6e 69 74 69  |\"type\":\"Initi|
              000000c0  61 6c 69 7a 65 64 5c 22  7d 22 3a 7b 22 2e 22 3a  |alized\"}":{".":|
              000000d0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000000f0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              00000100  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000110  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |eration":{},"f:s|
              00000120  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000130  65 22 3a 7b 7d 7d 2c 22  6b 3a 7b 5c 22 74 79 70  |e":{}},"k:{\"typ|
              00000140  65 5c 22 3a 5c 22 50 6f  64 52 65 61 64 79 54 6f  |e\":\"PodReadyTo|
              00000150  53 74 61 72 74 43 6f 6e  74 61 69 6e 65 72 73 5c  |StartContainers\|
              00000160  22 7d 22 3a 7b 22 2e 22  3a 7b 7d 2c 22 66 3a 6c  |"}":{".":{},"f:l|
              00000170  61 73 74 50 72 6f 62 65  54 69 6d 65 22 3a 7b 7d  |astProbeTime":{}|
              00000180  2c 22 66 3a 6c 61 73 74  54 72 61 6e 73 69 74 69  |,"f:lastTransiti|
              00000190  6f 6e 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6f 62  |onTime":{},"f:ob|
              000001a0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001b0  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              000001c0  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              000001d0  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              000001e0  6f 64 53 63 68 65 64 75  6c 65 64 5c 22 7d 22 3a  |odScheduled\"}":|
              000001f0  7b 22 66 3a 6f 62 73 65  72 76 65 64 47 65 6e 65  |{"f:observedGene|
              00000200  72 61 74 69 6f 6e 22 3a  7b 7d 7d 2c 22 6b 3a 7b  |ration":{}},"k:{|
              00000210  5c 22 74 79 70 65 5c 22  3a 5c 22 52 65 61 64 79  |\"type\":\"Ready|
              00000220  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000230  6c 61 73 74 50 72 6f 62  65 54 69 6d 65 22 3a 7b  |lastProbeTime":{|
              00000240  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000250  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6f  |ionTime":{},"f:o|
              00000260  62 73 65 72 76 65 64 47  65 6e 65 72 61 74 69 6f  |bservedGeneratio|
              00000270  6e 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |n":{},"f:status"|
              00000280  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000290  7d 2c 22 66 3a 63 6f 6e  74 61 69 6e 65 72 53 74  |},"f:containerSt|
              000002a0  61 74 75 73 65 73 22 3a  7b 7d 2c 22 66 3a 68 6f  |atuses":{},"f:ho|
              000002b0  73 74 49 50 22 3a 7b 7d  2c 22 66 3a 68 6f 73 74  |stIP":{},"f:host|
              000002c0  49 50 73 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |IPs":{},"f:obser|
              000002d0  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000002e0  7d 2c 22 66 3a 70 68 61  73 65 22 3a 7b 7d 2c 22  |},"f:phase":{},"|
              000002f0  66 3a 70 6f 64 49 50 22  3a 7b 7d 2c 22 66 3a 70  |f:podIP":{},"f:p|
              00000300  6f 64 49 50 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |odIPs":{".":{},"|
              00000310  6b 3a 7b 5c 22 69 70 5c  22 3a 5c 22 31 30 2e 32  |k:{\"ip\":\"10.2|
              00000320  33 33 2e 36 34 2e 32 34  36 5c 22 7d 22 3a 7b 22  |33.64.246\"}":{"|
              00000330  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              00000340  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              00000350  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-c4tqt",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-c4tqt",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "ietha7evai9i-1",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 1,
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399861,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399858,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399861,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399861,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399858,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.25",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.121.25"
        }
      },
      PodIP: (string) (len=13) "10.233.64.246",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "10.233.64.246"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63892399858,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63892399860,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=72) "cri-o://e3046f5049a338fa829a43f428c815b0e214fa2041cbfc4ececbf9c1b1838a33",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)({
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          }),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-c4tqt",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)({
            Linux: (*v1.LinuxContainerUser)({
              UID: (int64) 0,
              GID: (int64) 0,
              SupplementalGroups: ([]int64) (len=11) {
                (int64) 0,
                (int64) 1,
                (int64) 2,
                (int64) 3,
                (int64) 4,
                (int64) 6,
                (int64) 10,
                (int64) 11,
                (int64) 20,
                (int64) 26,
                (int64) 27
              }
            })
          }),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>)
    }
  }

  I0902 08:51:04.143116 16 deployment.go:68] Pod "webserver-deployment-6bc58496c7-4l24s" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-6bc58496c7-4l24s",
      GenerateName: (string) (len=32) "webserver-deployment-6bc58496c7-",
      Namespace: (string) (len=15) "deployment-2691",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "21b62764-7144-4b75-9896-c3b0ff2af22e",
      ResourceVersion: (string) (len=5) "42561",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63892399857,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "6bc58496c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-6bc58496c7",
          UID: (types.UID) (len=36) "eb6d722a-799d-4a01-839b-4c216f8322b0",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399857,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 65 62  36 64 37 32 32 61 2d 37  |d\":\"eb6d722a-7|
              00000090  39 39 64 2d 34 61 30 31  2d 38 33 39 62 2d 34 63  |99d-4a01-839b-4c|
              000000a0  32 31 36 66 38 33 32 32  62 30 5c 22 7d 22 3a 7b  |216f8322b0\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=851) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6f 62 73 65 72 76  |me":{},"f:observ|
              00000080  65 64 47 65 6e 65 72 61  74 69 6f 6e 22 3a 7b 7d  |edGeneration":{}|
              00000090  2c 22 66 3a 73 74 61 74  75 73 22 3a 7b 7d 2c 22  |,"f:status":{},"|
              000000a0  66 3a 74 79 70 65 22 3a  7b 7d 7d 2c 22 6b 3a 7b  |f:type":{}},"k:{|
              000000b0  5c 22 74 79 70 65 5c 22  3a 5c 22 49 6e 69 74 69  |\"type\":\"Initi|
              000000c0  61 6c 69 7a 65 64 5c 22  7d 22 3a 7b 22 2e 22 3a  |alized\"}":{".":|
              000000d0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000000f0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              00000100  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000110  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |eration":{},"f:s|
              00000120  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000130  65 22 3a 7b 7d 7d 2c 22  6b 3a 7b 5c 22 74 79 70  |e":{}},"k:{\"typ|
              00000140  65 5c 22 3a 5c 22 50 6f  64 52 65 61 64 79 54 6f  |e\":\"PodReadyTo|
              00000150  53 74 61 72 74 43 6f 6e  74 61 69 6e 65 72 73 5c  |StartContainers\|
              00000160  22 7d 22 3a 7b 22 2e 22  3a 7b 7d 2c 22 66 3a 6c  |"}":{".":{},"f:l|
              00000170  61 73 74 50 72 6f 62 65  54 69 6d 65 22 3a 7b 7d  |astProbeTime":{}|
              00000180  2c 22 66 3a 6c 61 73 74  54 72 61 6e 73 69 74 69  |,"f:lastTransiti|
              00000190  6f 6e 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6f 62  |onTime":{},"f:ob|
              000001a0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001b0  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              000001c0  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              000001d0  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              000001e0  6f 64 53 63 68 65 64 75  6c 65 64 5c 22 7d 22 3a  |odScheduled\"}":|
              000001f0  7b 22 66 3a 6f 62 73 65  72 76 65 64 47 65 6e 65  |{"f:observedGene|
              00000200  72 61 74 69 6f 6e 22 3a  7b 7d 7d 2c 22 6b 3a 7b  |ration":{}},"k:{|
              00000210  5c 22 74 79 70 65 5c 22  3a 5c 22 52 65 61 64 79  |\"type\":\"Ready|
              00000220  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000230  6c 61 73 74 50 72 6f 62  65 54 69 6d 65 22 3a 7b  |lastProbeTime":{|
              00000240  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000250  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6f  |ionTime":{},"f:o|
              00000260  62 73 65 72 76 65 64 47  65 6e 65 72 61 74 69 6f  |bservedGeneratio|
              00000270  6e 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |n":{},"f:status"|
              00000280  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000290  7d 2c 22 66 3a 63 6f 6e  74 61 69 6e 65 72 53 74  |},"f:containerSt|
              000002a0  61 74 75 73 65 73 22 3a  7b 7d 2c 22 66 3a 68 6f  |atuses":{},"f:ho|
              000002b0  73 74 49 50 22 3a 7b 7d  2c 22 66 3a 68 6f 73 74  |stIP":{},"f:host|
              000002c0  49 50 73 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |IPs":{},"f:obser|
              000002d0  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000002e0  7d 2c 22 66 3a 70 68 61  73 65 22 3a 7b 7d 2c 22  |},"f:phase":{},"|
              000002f0  66 3a 70 6f 64 49 50 22  3a 7b 7d 2c 22 66 3a 70  |f:podIP":{},"f:p|
              00000300  6f 64 49 50 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |odIPs":{".":{},"|
              00000310  6b 3a 7b 5c 22 69 70 5c  22 3a 5c 22 31 30 2e 32  |k:{\"ip\":\"10.2|
              00000320  33 33 2e 36 36 2e 38 34  5c 22 7d 22 3a 7b 22 2e  |33.66.84\"}":{".|
              00000330  22 3a 7b 7d 2c 22 66 3a  69 70 22 3a 7b 7d 7d 7d  |":{},"f:ip":{}}}|
              00000340  2c 22 66 3a 73 74 61 72  74 54 69 6d 65 22 3a 7b  |,"f:startTime":{|
              00000350  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-dbnms",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-dbnms",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "ietha7evai9i-2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 1,
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399858,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399858,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.46",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.121.46"
        }
      },
      PodIP: (string) (len=12) "10.233.66.84",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "10.233.66.84"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63892399858,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63892399859,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=72) "cri-o://5f5f5df3c1f05c23904bb9dc1149ee84f8dbbf25021a99e7d9348683a55806bc",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)({
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          }),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-dbnms",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)({
            Linux: (*v1.LinuxContainerUser)({
              UID: (int64) 0,
              GID: (int64) 0,
              SupplementalGroups: ([]int64) (len=11) {
                (int64) 0,
                (int64) 1,
                (int64) 2,
                (int64) 3,
                (int64) 4,
                (int64) 6,
                (int64) 10,
                (int64) 11,
                (int64) 20,
                (int64) 26,
                (int64) 27
              }
            })
          }),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>)
    }
  }

  I0902 08:51:04.150160 16 deployment.go:68] Pod "webserver-deployment-6bc58496c7-7f7kc" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-6bc58496c7-7f7kc",
      GenerateName: (string) (len=32) "webserver-deployment-6bc58496c7-",
      Namespace: (string) (len=15) "deployment-2691",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "202c4345-a08a-488e-8a4d-02330f6e3434",
      ResourceVersion: (string) (len=5) "42680",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63892399863,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "6bc58496c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-6bc58496c7",
          UID: (types.UID) (len=36) "eb6d722a-799d-4a01-839b-4c216f8322b0",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399863,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 65 62  36 64 37 32 32 61 2d 37  |d\":\"eb6d722a-7|
              00000090  39 39 64 2d 34 61 30 31  2d 38 33 39 62 2d 34 63  |99d-4a01-839b-4c|
              000000a0  32 31 36 66 38 33 32 32  62 30 5c 22 7d 22 3a 7b  |216f8322b0\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399864,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=814) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 6f 62 73 65 72 76 65  |e":{},"f:observe|
              00000090  64 47 65 6e 65 72 61 74  69 6f 6e 22 3a 7b 7d 2c  |dGeneration":{},|
              000000a0  22 66 3a 72 65 61 73 6f  6e 22 3a 7b 7d 2c 22 66  |"f:reason":{},"f|
              000000b0  3a 73 74 61 74 75 73 22  3a 7b 7d 2c 22 66 3a 74  |:status":{},"f:t|
              000000c0  79 70 65 22 3a 7b 7d 7d  2c 22 6b 3a 7b 5c 22 74  |ype":{}},"k:{\"t|
              000000d0  79 70 65 5c 22 3a 5c 22  49 6e 69 74 69 61 6c 69  |ype\":\"Initiali|
              000000e0  7a 65 64 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |zed\"}":{".":{},|
              000000f0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              00000110  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              00000120  66 3a 6f 62 73 65 72 76  65 64 47 65 6e 65 72 61  |f:observedGenera|
              00000130  74 69 6f 6e 22 3a 7b 7d  2c 22 66 3a 73 74 61 74  |tion":{},"f:stat|
              00000140  75 73 22 3a 7b 7d 2c 22  66 3a 74 79 70 65 22 3a  |us":{},"f:type":|
              00000150  7b 7d 7d 2c 22 6b 3a 7b  5c 22 74 79 70 65 5c 22  |{}},"k:{\"type\"|
              00000160  3a 5c 22 50 6f 64 52 65  61 64 79 54 6f 53 74 61  |:\"PodReadyToSta|
              00000170  72 74 43 6f 6e 74 61 69  6e 65 72 73 5c 22 7d 22  |rtContainers\"}"|
              00000180  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              00000190  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000001a0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |ime":{},"f:obser|
              000001c0  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 2c 22 6b 3a  |"f:type":{}},"k:|
              000001f0  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 50 6f 64 53  |{\"type\":\"PodS|
              00000200  63 68 65 64 75 6c 65 64  5c 22 7d 22 3a 7b 22 66  |cheduled\"}":{"f|
              00000210  3a 6f 62 73 65 72 76 65  64 47 65 6e 65 72 61 74  |:observedGenerat|
              00000220  69 6f 6e 22 3a 7b 7d 7d  2c 22 6b 3a 7b 5c 22 74  |ion":{}},"k:{\"t|
              00000230  79 70 65 5c 22 3a 5c 22  52 65 61 64 79 5c 22 7d  |ype\":\"Ready\"}|
              00000240  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |":{".":{},"f:las|
              00000250  74 50 72 6f 62 65 54 69  6d 65 22 3a 7b 7d 2c 22  |tProbeTime":{},"|
              00000260  66 3a 6c 61 73 74 54 72  61 6e 73 69 74 69 6f 6e  |f:lastTransition|
              00000270  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6d 65 73 73  |Time":{},"f:mess|
              00000280  61 67 65 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |age":{},"f:obser|
              00000290  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000002a0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              000002b0  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              000002c0  3a 74 79 70 65 22 3a 7b  7d 7d 7d 2c 22 66 3a 63  |:type":{}}},"f:c|
              000002d0  6f 6e 74 61 69 6e 65 72  53 74 61 74 75 73 65 73  |ontainerStatuses|
              000002e0  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 22 3a  |":{},"f:hostIP":|
              000002f0  7b 7d 2c 22 66 3a 68 6f  73 74 49 50 73 22 3a 7b  |{},"f:hostIPs":{|
              00000300  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000310  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |eration":{},"f:s|
              00000320  74 61 72 74 54 69 6d 65  22 3a 7b 7d 7d 7d        |tartTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-w2dwd",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-w2dwd",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "ietha7evai9i-2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 1,
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399864,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399864,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399864,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399864,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399864,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.46",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.121.46"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63892399864,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-w2dwd",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>)
    }
  }

  I0902 08:51:04.158144 16 deployment.go:68] Pod "webserver-deployment-6bc58496c7-99696" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-6bc58496c7-99696",
      GenerateName: (string) (len=32) "webserver-deployment-6bc58496c7-",
      Namespace: (string) (len=15) "deployment-2691",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "187145e4-551f-4928-a154-1557f5c21353",
      ResourceVersion: (string) (len=5) "42558",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63892399857,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "6bc58496c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-6bc58496c7",
          UID: (types.UID) (len=36) "eb6d722a-799d-4a01-839b-4c216f8322b0",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399857,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 65 62  36 64 37 32 32 61 2d 37  |d\":\"eb6d722a-7|
              00000090  39 39 64 2d 34 61 30 31  2d 38 33 39 62 2d 34 63  |99d-4a01-839b-4c|
              000000a0  32 31 36 66 38 33 32 32  62 30 5c 22 7d 22 3a 7b  |216f8322b0\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=852) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6f 62 73 65 72 76  |me":{},"f:observ|
              00000080  65 64 47 65 6e 65 72 61  74 69 6f 6e 22 3a 7b 7d  |edGeneration":{}|
              00000090  2c 22 66 3a 73 74 61 74  75 73 22 3a 7b 7d 2c 22  |,"f:status":{},"|
              000000a0  66 3a 74 79 70 65 22 3a  7b 7d 7d 2c 22 6b 3a 7b  |f:type":{}},"k:{|
              000000b0  5c 22 74 79 70 65 5c 22  3a 5c 22 49 6e 69 74 69  |\"type\":\"Initi|
              000000c0  61 6c 69 7a 65 64 5c 22  7d 22 3a 7b 22 2e 22 3a  |alized\"}":{".":|
              000000d0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000000f0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              00000100  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000110  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |eration":{},"f:s|
              00000120  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000130  65 22 3a 7b 7d 7d 2c 22  6b 3a 7b 5c 22 74 79 70  |e":{}},"k:{\"typ|
              00000140  65 5c 22 3a 5c 22 50 6f  64 52 65 61 64 79 54 6f  |e\":\"PodReadyTo|
              00000150  53 74 61 72 74 43 6f 6e  74 61 69 6e 65 72 73 5c  |StartContainers\|
              00000160  22 7d 22 3a 7b 22 2e 22  3a 7b 7d 2c 22 66 3a 6c  |"}":{".":{},"f:l|
              00000170  61 73 74 50 72 6f 62 65  54 69 6d 65 22 3a 7b 7d  |astProbeTime":{}|
              00000180  2c 22 66 3a 6c 61 73 74  54 72 61 6e 73 69 74 69  |,"f:lastTransiti|
              00000190  6f 6e 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6f 62  |onTime":{},"f:ob|
              000001a0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001b0  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              000001c0  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              000001d0  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              000001e0  6f 64 53 63 68 65 64 75  6c 65 64 5c 22 7d 22 3a  |odScheduled\"}":|
              000001f0  7b 22 66 3a 6f 62 73 65  72 76 65 64 47 65 6e 65  |{"f:observedGene|
              00000200  72 61 74 69 6f 6e 22 3a  7b 7d 7d 2c 22 6b 3a 7b  |ration":{}},"k:{|
              00000210  5c 22 74 79 70 65 5c 22  3a 5c 22 52 65 61 64 79  |\"type\":\"Ready|
              00000220  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000230  6c 61 73 74 50 72 6f 62  65 54 69 6d 65 22 3a 7b  |lastProbeTime":{|
              00000240  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000250  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6f  |ionTime":{},"f:o|
              00000260  62 73 65 72 76 65 64 47  65 6e 65 72 61 74 69 6f  |bservedGeneratio|
              00000270  6e 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |n":{},"f:status"|
              00000280  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000290  7d 2c 22 66 3a 63 6f 6e  74 61 69 6e 65 72 53 74  |},"f:containerSt|
              000002a0  61 74 75 73 65 73 22 3a  7b 7d 2c 22 66 3a 68 6f  |atuses":{},"f:ho|
              000002b0  73 74 49 50 22 3a 7b 7d  2c 22 66 3a 68 6f 73 74  |stIP":{},"f:host|
              000002c0  49 50 73 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |IPs":{},"f:obser|
              000002d0  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000002e0  7d 2c 22 66 3a 70 68 61  73 65 22 3a 7b 7d 2c 22  |},"f:phase":{},"|
              000002f0  66 3a 70 6f 64 49 50 22  3a 7b 7d 2c 22 66 3a 70  |f:podIP":{},"f:p|
              00000300  6f 64 49 50 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |odIPs":{".":{},"|
              00000310  6b 3a 7b 5c 22 69 70 5c  22 3a 5c 22 31 30 2e 32  |k:{\"ip\":\"10.2|
              00000320  33 33 2e 36 36 2e 31 32  39 5c 22 7d 22 3a 7b 22  |33.66.129\"}":{"|
              00000330  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              00000340  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              00000350  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-q89b5",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-q89b5",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "ietha7evai9i-2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 1,
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399858,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399858,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.46",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.121.46"
        }
      },
      PodIP: (string) (len=13) "10.233.66.129",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "10.233.66.129"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63892399858,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63892399859,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=72) "cri-o://c3b9cdb70d042984bacf134d5d273acc3876f5b63d5a7ffb19085ebd61dcce2c",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)({
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          }),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-q89b5",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)({
            Linux: (*v1.LinuxContainerUser)({
              UID: (int64) 0,
              GID: (int64) 0,
              SupplementalGroups: ([]int64) (len=11) {
                (int64) 0,
                (int64) 1,
                (int64) 2,
                (int64) 3,
                (int64) 4,
                (int64) 6,
                (int64) 10,
                (int64) 11,
                (int64) 20,
                (int64) 26,
                (int64) 27
              }
            })
          }),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>)
    }
  }

  I0902 08:51:04.166852 16 deployment.go:68] Pod "webserver-deployment-6bc58496c7-bxmjs" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-6bc58496c7-bxmjs",
      GenerateName: (string) (len=32) "webserver-deployment-6bc58496c7-",
      Namespace: (string) (len=15) "deployment-2691",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "f5ec694f-d6c5-43e6-aea1-c7f9ac1d975c",
      ResourceVersion: (string) (len=5) "42669",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63892399863,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "6bc58496c7",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-6bc58496c7",
          UID: (types.UID) (len=36) "eb6d722a-799d-4a01-839b-4c216f8322b0",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399863,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 65 62  36 64 37 32 32 61 2d 37  |d\":\"eb6d722a-7|
              00000090  39 39 64 2d 34 61 30 31  2d 38 33 39 62 2d 34 63  |99d-4a01-839b-4c|
              000000a0  32 31 36 66 38 33 32 32  62 30 5c 22 7d 22 3a 7b  |216f8322b0\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-4k24f",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-4k24f",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "ietha7evai9i-1",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 0,
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399863,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>)
    }
  }

  I0902 08:51:04.173466 16 deployment.go:68] Pod "webserver-deployment-6bc58496c7-c559h" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-6bc58496c7-c559h",
      GenerateName: (string) (len=32) "webserver-deployment-6bc58496c7-",
      Namespace: (string) (len=15) "deployment-2691",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "9a17c769-cbdc-46ea-8054-e98668cbbe9e",
      ResourceVersion: (string) (len=5) "42514",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63892399857,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "6bc58496c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-6bc58496c7",
          UID: (types.UID) (len=36) "eb6d722a-799d-4a01-839b-4c216f8322b0",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399857,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 65 62  36 64 37 32 32 61 2d 37  |d\":\"eb6d722a-7|
              00000090  39 39 64 2d 34 61 30 31  2d 38 33 39 62 2d 34 63  |99d-4a01-839b-4c|
              000000a0  32 31 36 66 38 33 32 32  62 30 5c 22 7d 22 3a 7b  |216f8322b0\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399859,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=851) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6f 62 73 65 72 76  |me":{},"f:observ|
              00000080  65 64 47 65 6e 65 72 61  74 69 6f 6e 22 3a 7b 7d  |edGeneration":{}|
              00000090  2c 22 66 3a 73 74 61 74  75 73 22 3a 7b 7d 2c 22  |,"f:status":{},"|
              000000a0  66 3a 74 79 70 65 22 3a  7b 7d 7d 2c 22 6b 3a 7b  |f:type":{}},"k:{|
              000000b0  5c 22 74 79 70 65 5c 22  3a 5c 22 49 6e 69 74 69  |\"type\":\"Initi|
              000000c0  61 6c 69 7a 65 64 5c 22  7d 22 3a 7b 22 2e 22 3a  |alized\"}":{".":|
              000000d0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000000f0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              00000100  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000110  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |eration":{},"f:s|
              00000120  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000130  65 22 3a 7b 7d 7d 2c 22  6b 3a 7b 5c 22 74 79 70  |e":{}},"k:{\"typ|
              00000140  65 5c 22 3a 5c 22 50 6f  64 52 65 61 64 79 54 6f  |e\":\"PodReadyTo|
              00000150  53 74 61 72 74 43 6f 6e  74 61 69 6e 65 72 73 5c  |StartContainers\|
              00000160  22 7d 22 3a 7b 22 2e 22  3a 7b 7d 2c 22 66 3a 6c  |"}":{".":{},"f:l|
              00000170  61 73 74 50 72 6f 62 65  54 69 6d 65 22 3a 7b 7d  |astProbeTime":{}|
              00000180  2c 22 66 3a 6c 61 73 74  54 72 61 6e 73 69 74 69  |,"f:lastTransiti|
              00000190  6f 6e 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6f 62  |onTime":{},"f:ob|
              000001a0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001b0  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              000001c0  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              000001d0  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              000001e0  6f 64 53 63 68 65 64 75  6c 65 64 5c 22 7d 22 3a  |odScheduled\"}":|
              000001f0  7b 22 66 3a 6f 62 73 65  72 76 65 64 47 65 6e 65  |{"f:observedGene|
              00000200  72 61 74 69 6f 6e 22 3a  7b 7d 7d 2c 22 6b 3a 7b  |ration":{}},"k:{|
              00000210  5c 22 74 79 70 65 5c 22  3a 5c 22 52 65 61 64 79  |\"type\":\"Ready|
              00000220  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000230  6c 61 73 74 50 72 6f 62  65 54 69 6d 65 22 3a 7b  |lastProbeTime":{|
              00000240  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000250  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6f  |ionTime":{},"f:o|
              00000260  62 73 65 72 76 65 64 47  65 6e 65 72 61 74 69 6f  |bservedGeneratio|
              00000270  6e 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |n":{},"f:status"|
              00000280  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000290  7d 2c 22 66 3a 63 6f 6e  74 61 69 6e 65 72 53 74  |},"f:containerSt|
              000002a0  61 74 75 73 65 73 22 3a  7b 7d 2c 22 66 3a 68 6f  |atuses":{},"f:ho|
              000002b0  73 74 49 50 22 3a 7b 7d  2c 22 66 3a 68 6f 73 74  |stIP":{},"f:host|
              000002c0  49 50 73 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |IPs":{},"f:obser|
              000002d0  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000002e0  7d 2c 22 66 3a 70 68 61  73 65 22 3a 7b 7d 2c 22  |},"f:phase":{},"|
              000002f0  66 3a 70 6f 64 49 50 22  3a 7b 7d 2c 22 66 3a 70  |f:podIP":{},"f:p|
              00000300  6f 64 49 50 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |odIPs":{".":{},"|
              00000310  6b 3a 7b 5c 22 69 70 5c  22 3a 5c 22 31 30 2e 32  |k:{\"ip\":\"10.2|
              00000320  33 33 2e 36 35 2e 35 39  5c 22 7d 22 3a 7b 22 2e  |33.65.59\"}":{".|
              00000330  22 3a 7b 7d 2c 22 66 3a  69 70 22 3a 7b 7d 7d 7d  |":{},"f:ip":{}}}|
              00000340  2c 22 66 3a 73 74 61 72  74 54 69 6d 65 22 3a 7b  |,"f:startTime":{|
              00000350  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-hgc75",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-hgc75",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "ietha7evai9i-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 1,
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399859,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399858,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399859,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399859,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399858,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.52",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.121.52"
        }
      },
      PodIP: (string) (len=12) "10.233.65.59",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "10.233.65.59"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63892399858,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63892399859,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=72) "cri-o://0f6b1fde8043b8e432d1962d2b5782fc3b91719f6bb2cb6a8fb1b352ad8a5c77",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)({
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          }),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-hgc75",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)({
            Linux: (*v1.LinuxContainerUser)({
              UID: (int64) 0,
              GID: (int64) 0,
              SupplementalGroups: ([]int64) (len=11) {
                (int64) 0,
                (int64) 1,
                (int64) 2,
                (int64) 3,
                (int64) 4,
                (int64) 6,
                (int64) 10,
                (int64) 11,
                (int64) 20,
                (int64) 26,
                (int64) 27
              }
            })
          }),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>)
    }
  }

  I0902 08:51:04.187404 16 deployment.go:68] Pod "webserver-deployment-6bc58496c7-hpqnf" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-6bc58496c7-hpqnf",
      GenerateName: (string) (len=32) "webserver-deployment-6bc58496c7-",
      Namespace: (string) (len=15) "deployment-2691",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "894b803e-af7c-4d2b-9788-3bab95a83e3c",
      ResourceVersion: (string) (len=5) "42512",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63892399857,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "6bc58496c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-6bc58496c7",
          UID: (types.UID) (len=36) "eb6d722a-799d-4a01-839b-4c216f8322b0",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399857,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 65 62  36 64 37 32 32 61 2d 37  |d\":\"eb6d722a-7|
              00000090  39 39 64 2d 34 61 30 31  2d 38 33 39 62 2d 34 63  |99d-4a01-839b-4c|
              000000a0  32 31 36 66 38 33 32 32  62 30 5c 22 7d 22 3a 7b  |216f8322b0\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399859,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=852) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6f 62 73 65 72 76  |me":{},"f:observ|
              00000080  65 64 47 65 6e 65 72 61  74 69 6f 6e 22 3a 7b 7d  |edGeneration":{}|
              00000090  2c 22 66 3a 73 74 61 74  75 73 22 3a 7b 7d 2c 22  |,"f:status":{},"|
              000000a0  66 3a 74 79 70 65 22 3a  7b 7d 7d 2c 22 6b 3a 7b  |f:type":{}},"k:{|
              000000b0  5c 22 74 79 70 65 5c 22  3a 5c 22 49 6e 69 74 69  |\"type\":\"Initi|
              000000c0  61 6c 69 7a 65 64 5c 22  7d 22 3a 7b 22 2e 22 3a  |alized\"}":{".":|
              000000d0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000000f0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              00000100  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000110  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |eration":{},"f:s|
              00000120  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000130  65 22 3a 7b 7d 7d 2c 22  6b 3a 7b 5c 22 74 79 70  |e":{}},"k:{\"typ|
              00000140  65 5c 22 3a 5c 22 50 6f  64 52 65 61 64 79 54 6f  |e\":\"PodReadyTo|
              00000150  53 74 61 72 74 43 6f 6e  74 61 69 6e 65 72 73 5c  |StartContainers\|
              00000160  22 7d 22 3a 7b 22 2e 22  3a 7b 7d 2c 22 66 3a 6c  |"}":{".":{},"f:l|
              00000170  61 73 74 50 72 6f 62 65  54 69 6d 65 22 3a 7b 7d  |astProbeTime":{}|
              00000180  2c 22 66 3a 6c 61 73 74  54 72 61 6e 73 69 74 69  |,"f:lastTransiti|
              00000190  6f 6e 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6f 62  |onTime":{},"f:ob|
              000001a0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001b0  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              000001c0  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              000001d0  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              000001e0  6f 64 53 63 68 65 64 75  6c 65 64 5c 22 7d 22 3a  |odScheduled\"}":|
              000001f0  7b 22 66 3a 6f 62 73 65  72 76 65 64 47 65 6e 65  |{"f:observedGene|
              00000200  72 61 74 69 6f 6e 22 3a  7b 7d 7d 2c 22 6b 3a 7b  |ration":{}},"k:{|
              00000210  5c 22 74 79 70 65 5c 22  3a 5c 22 52 65 61 64 79  |\"type\":\"Ready|
              00000220  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000230  6c 61 73 74 50 72 6f 62  65 54 69 6d 65 22 3a 7b  |lastProbeTime":{|
              00000240  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000250  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6f  |ionTime":{},"f:o|
              00000260  62 73 65 72 76 65 64 47  65 6e 65 72 61 74 69 6f  |bservedGeneratio|
              00000270  6e 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |n":{},"f:status"|
              00000280  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000290  7d 2c 22 66 3a 63 6f 6e  74 61 69 6e 65 72 53 74  |},"f:containerSt|
              000002a0  61 74 75 73 65 73 22 3a  7b 7d 2c 22 66 3a 68 6f  |atuses":{},"f:ho|
              000002b0  73 74 49 50 22 3a 7b 7d  2c 22 66 3a 68 6f 73 74  |stIP":{},"f:host|
              000002c0  49 50 73 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |IPs":{},"f:obser|
              000002d0  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000002e0  7d 2c 22 66 3a 70 68 61  73 65 22 3a 7b 7d 2c 22  |},"f:phase":{},"|
              000002f0  66 3a 70 6f 64 49 50 22  3a 7b 7d 2c 22 66 3a 70  |f:podIP":{},"f:p|
              00000300  6f 64 49 50 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |odIPs":{".":{},"|
              00000310  6b 3a 7b 5c 22 69 70 5c  22 3a 5c 22 31 30 2e 32  |k:{\"ip\":\"10.2|
              00000320  33 33 2e 36 35 2e 31 32  32 5c 22 7d 22 3a 7b 22  |33.65.122\"}":{"|
              00000330  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              00000340  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              00000350  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-tq4tm",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-tq4tm",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "ietha7evai9i-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 1,
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399859,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399857,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399859,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399859,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399857,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.52",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.121.52"
        }
      },
      PodIP: (string) (len=13) "10.233.65.122",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "10.233.65.122"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63892399857,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63892399859,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=72) "cri-o://e9e6d06f687f9aea738545288c3cbbf6ff07899d029da46328eb029d0494b3cb",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)({
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          }),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-tq4tm",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)({
            Linux: (*v1.LinuxContainerUser)({
              UID: (int64) 0,
              GID: (int64) 0,
              SupplementalGroups: ([]int64) (len=11) {
                (int64) 0,
                (int64) 1,
                (int64) 2,
                (int64) 3,
                (int64) 4,
                (int64) 6,
                (int64) 10,
                (int64) 11,
                (int64) 20,
                (int64) 26,
                (int64) 27
              }
            })
          }),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>)
    }
  }

  I0902 08:51:04.192080 16 deployment.go:68] Pod "webserver-deployment-6bc58496c7-n4lwf" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-6bc58496c7-n4lwf",
      GenerateName: (string) (len=32) "webserver-deployment-6bc58496c7-",
      Namespace: (string) (len=15) "deployment-2691",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "49c07673-b54b-4a53-aa82-3236558d5c19",
      ResourceVersion: (string) (len=5) "42670",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63892399863,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "6bc58496c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-6bc58496c7",
          UID: (types.UID) (len=36) "eb6d722a-799d-4a01-839b-4c216f8322b0",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399863,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 65 62  36 64 37 32 32 61 2d 37  |d\":\"eb6d722a-7|
              00000090  39 39 64 2d 34 61 30 31  2d 38 33 39 62 2d 34 63  |99d-4a01-839b-4c|
              000000a0  32 31 36 66 38 33 32 32  62 30 5c 22 7d 22 3a 7b  |216f8322b0\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399863,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=814) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 6f 62 73 65 72 76 65  |e":{},"f:observe|
              00000090  64 47 65 6e 65 72 61 74  69 6f 6e 22 3a 7b 7d 2c  |dGeneration":{},|
              000000a0  22 66 3a 72 65 61 73 6f  6e 22 3a 7b 7d 2c 22 66  |"f:reason":{},"f|
              000000b0  3a 73 74 61 74 75 73 22  3a 7b 7d 2c 22 66 3a 74  |:status":{},"f:t|
              000000c0  79 70 65 22 3a 7b 7d 7d  2c 22 6b 3a 7b 5c 22 74  |ype":{}},"k:{\"t|
              000000d0  79 70 65 5c 22 3a 5c 22  49 6e 69 74 69 61 6c 69  |ype\":\"Initiali|
              000000e0  7a 65 64 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |zed\"}":{".":{},|
              000000f0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              00000110  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              00000120  66 3a 6f 62 73 65 72 76  65 64 47 65 6e 65 72 61  |f:observedGenera|
              00000130  74 69 6f 6e 22 3a 7b 7d  2c 22 66 3a 73 74 61 74  |tion":{},"f:stat|
              00000140  75 73 22 3a 7b 7d 2c 22  66 3a 74 79 70 65 22 3a  |us":{},"f:type":|
              00000150  7b 7d 7d 2c 22 6b 3a 7b  5c 22 74 79 70 65 5c 22  |{}},"k:{\"type\"|
              00000160  3a 5c 22 50 6f 64 52 65  61 64 79 54 6f 53 74 61  |:\"PodReadyToSta|
              00000170  72 74 43 6f 6e 74 61 69  6e 65 72 73 5c 22 7d 22  |rtContainers\"}"|
              00000180  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              00000190  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000001a0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |ime":{},"f:obser|
              000001c0  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 2c 22 6b 3a  |"f:type":{}},"k:|
              000001f0  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 50 6f 64 53  |{\"type\":\"PodS|
              00000200  63 68 65 64 75 6c 65 64  5c 22 7d 22 3a 7b 22 66  |cheduled\"}":{"f|
              00000210  3a 6f 62 73 65 72 76 65  64 47 65 6e 65 72 61 74  |:observedGenerat|
              00000220  69 6f 6e 22 3a 7b 7d 7d  2c 22 6b 3a 7b 5c 22 74  |ion":{}},"k:{\"t|
              00000230  79 70 65 5c 22 3a 5c 22  52 65 61 64 79 5c 22 7d  |ype\":\"Ready\"}|
              00000240  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |":{".":{},"f:las|
              00000250  74 50 72 6f 62 65 54 69  6d 65 22 3a 7b 7d 2c 22  |tProbeTime":{},"|
              00000260  66 3a 6c 61 73 74 54 72  61 6e 73 69 74 69 6f 6e  |f:lastTransition|
              00000270  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6d 65 73 73  |Time":{},"f:mess|
              00000280  61 67 65 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |age":{},"f:obser|
              00000290  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000002a0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              000002b0  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              000002c0  3a 74 79 70 65 22 3a 7b  7d 7d 7d 2c 22 66 3a 63  |:type":{}}},"f:c|
              000002d0  6f 6e 74 61 69 6e 65 72  53 74 61 74 75 73 65 73  |ontainerStatuses|
              000002e0  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 22 3a  |":{},"f:hostIP":|
              000002f0  7b 7d 2c 22 66 3a 68 6f  73 74 49 50 73 22 3a 7b  |{},"f:hostIPs":{|
              00000300  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000310  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |eration":{},"f:s|
              00000320  74 61 72 74 54 69 6d 65  22 3a 7b 7d 7d 7d        |tartTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-5tc5s",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-5tc5s",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "ietha7evai9i-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 1,
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399863,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399863,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399863,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399863,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399863,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.52",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.121.52"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63892399863,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-5tc5s",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>)
    }
  }

  I0902 08:51:04.195862 16 deployment.go:68] Pod "webserver-deployment-6bc58496c7-n8zgg" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-6bc58496c7-n8zgg",
      GenerateName: (string) (len=32) "webserver-deployment-6bc58496c7-",
      Namespace: (string) (len=15) "deployment-2691",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "5a77cd1b-13d4-4cfc-b16c-6084a297bf14",
      ResourceVersion: (string) (len=5) "42554",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63892399857,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "6bc58496c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-6bc58496c7",
          UID: (types.UID) (len=36) "eb6d722a-799d-4a01-839b-4c216f8322b0",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399857,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 65 62  36 64 37 32 32 61 2d 37  |d\":\"eb6d722a-7|
              00000090  39 39 64 2d 34 61 30 31  2d 38 33 39 62 2d 34 63  |99d-4a01-839b-4c|
              000000a0  32 31 36 66 38 33 32 32  62 30 5c 22 7d 22 3a 7b  |216f8322b0\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=851) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6f 62 73 65 72 76  |me":{},"f:observ|
              00000080  65 64 47 65 6e 65 72 61  74 69 6f 6e 22 3a 7b 7d  |edGeneration":{}|
              00000090  2c 22 66 3a 73 74 61 74  75 73 22 3a 7b 7d 2c 22  |,"f:status":{},"|
              000000a0  66 3a 74 79 70 65 22 3a  7b 7d 7d 2c 22 6b 3a 7b  |f:type":{}},"k:{|
              000000b0  5c 22 74 79 70 65 5c 22  3a 5c 22 49 6e 69 74 69  |\"type\":\"Initi|
              000000c0  61 6c 69 7a 65 64 5c 22  7d 22 3a 7b 22 2e 22 3a  |alized\"}":{".":|
              000000d0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000000f0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              00000100  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000110  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |eration":{},"f:s|
              00000120  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000130  65 22 3a 7b 7d 7d 2c 22  6b 3a 7b 5c 22 74 79 70  |e":{}},"k:{\"typ|
              00000140  65 5c 22 3a 5c 22 50 6f  64 52 65 61 64 79 54 6f  |e\":\"PodReadyTo|
              00000150  53 74 61 72 74 43 6f 6e  74 61 69 6e 65 72 73 5c  |StartContainers\|
              00000160  22 7d 22 3a 7b 22 2e 22  3a 7b 7d 2c 22 66 3a 6c  |"}":{".":{},"f:l|
              00000170  61 73 74 50 72 6f 62 65  54 69 6d 65 22 3a 7b 7d  |astProbeTime":{}|
              00000180  2c 22 66 3a 6c 61 73 74  54 72 61 6e 73 69 74 69  |,"f:lastTransiti|
              00000190  6f 6e 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6f 62  |onTime":{},"f:ob|
              000001a0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001b0  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              000001c0  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              000001d0  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              000001e0  6f 64 53 63 68 65 64 75  6c 65 64 5c 22 7d 22 3a  |odScheduled\"}":|
              000001f0  7b 22 66 3a 6f 62 73 65  72 76 65 64 47 65 6e 65  |{"f:observedGene|
              00000200  72 61 74 69 6f 6e 22 3a  7b 7d 7d 2c 22 6b 3a 7b  |ration":{}},"k:{|
              00000210  5c 22 74 79 70 65 5c 22  3a 5c 22 52 65 61 64 79  |\"type\":\"Ready|
              00000220  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000230  6c 61 73 74 50 72 6f 62  65 54 69 6d 65 22 3a 7b  |lastProbeTime":{|
              00000240  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000250  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6f  |ionTime":{},"f:o|
              00000260  62 73 65 72 76 65 64 47  65 6e 65 72 61 74 69 6f  |bservedGeneratio|
              00000270  6e 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |n":{},"f:status"|
              00000280  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000290  7d 2c 22 66 3a 63 6f 6e  74 61 69 6e 65 72 53 74  |},"f:containerSt|
              000002a0  61 74 75 73 65 73 22 3a  7b 7d 2c 22 66 3a 68 6f  |atuses":{},"f:ho|
              000002b0  73 74 49 50 22 3a 7b 7d  2c 22 66 3a 68 6f 73 74  |stIP":{},"f:host|
              000002c0  49 50 73 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |IPs":{},"f:obser|
              000002d0  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000002e0  7d 2c 22 66 3a 70 68 61  73 65 22 3a 7b 7d 2c 22  |},"f:phase":{},"|
              000002f0  66 3a 70 6f 64 49 50 22  3a 7b 7d 2c 22 66 3a 70  |f:podIP":{},"f:p|
              00000300  6f 64 49 50 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |odIPs":{".":{},"|
              00000310  6b 3a 7b 5c 22 69 70 5c  22 3a 5c 22 31 30 2e 32  |k:{\"ip\":\"10.2|
              00000320  33 33 2e 36 36 2e 33 30  5c 22 7d 22 3a 7b 22 2e  |33.66.30\"}":{".|
              00000330  22 3a 7b 7d 2c 22 66 3a  69 70 22 3a 7b 7d 7d 7d  |":{},"f:ip":{}}}|
              00000340  2c 22 66 3a 73 74 61 72  74 54 69 6d 65 22 3a 7b  |,"f:startTime":{|
              00000350  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-cdzc9",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-cdzc9",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "ietha7evai9i-2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 1,
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399857,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399857,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.46",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.121.46"
        }
      },
      PodIP: (string) (len=12) "10.233.66.30",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "10.233.66.30"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63892399857,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63892399859,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=72) "cri-o://ec829b07d02ba9fe9276d61ab331cfb5c8532316ac7ec2d80892c017db8122ef",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)({
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          }),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-cdzc9",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)({
            Linux: (*v1.LinuxContainerUser)({
              UID: (int64) 0,
              GID: (int64) 0,
              SupplementalGroups: ([]int64) (len=11) {
                (int64) 0,
                (int64) 1,
                (int64) 2,
                (int64) 3,
                (int64) 4,
                (int64) 6,
                (int64) 10,
                (int64) 11,
                (int64) 20,
                (int64) 26,
                (int64) 27
              }
            })
          }),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>)
    }
  }

  I0902 08:51:04.204286 16 deployment.go:68] Pod "webserver-deployment-6bc58496c7-s56xz" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-6bc58496c7-s56xz",
      GenerateName: (string) (len=32) "webserver-deployment-6bc58496c7-",
      Namespace: (string) (len=15) "deployment-2691",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "4be86a34-c540-48cf-8f01-35efbc96767a",
      ResourceVersion: (string) (len=5) "42538",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63892399857,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "6bc58496c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-6bc58496c7",
          UID: (types.UID) (len=36) "eb6d722a-799d-4a01-839b-4c216f8322b0",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399857,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 65 62  36 64 37 32 32 61 2d 37  |d\":\"eb6d722a-7|
              00000090  39 39 64 2d 34 61 30 31  2d 38 33 39 62 2d 34 63  |99d-4a01-839b-4c|
              000000a0  32 31 36 66 38 33 32 32  62 30 5c 22 7d 22 3a 7b  |216f8322b0\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=852) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6f 62 73 65 72 76  |me":{},"f:observ|
              00000080  65 64 47 65 6e 65 72 61  74 69 6f 6e 22 3a 7b 7d  |edGeneration":{}|
              00000090  2c 22 66 3a 73 74 61 74  75 73 22 3a 7b 7d 2c 22  |,"f:status":{},"|
              000000a0  66 3a 74 79 70 65 22 3a  7b 7d 7d 2c 22 6b 3a 7b  |f:type":{}},"k:{|
              000000b0  5c 22 74 79 70 65 5c 22  3a 5c 22 49 6e 69 74 69  |\"type\":\"Initi|
              000000c0  61 6c 69 7a 65 64 5c 22  7d 22 3a 7b 22 2e 22 3a  |alized\"}":{".":|
              000000d0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000000f0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              00000100  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000110  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |eration":{},"f:s|
              00000120  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000130  65 22 3a 7b 7d 7d 2c 22  6b 3a 7b 5c 22 74 79 70  |e":{}},"k:{\"typ|
              00000140  65 5c 22 3a 5c 22 50 6f  64 52 65 61 64 79 54 6f  |e\":\"PodReadyTo|
              00000150  53 74 61 72 74 43 6f 6e  74 61 69 6e 65 72 73 5c  |StartContainers\|
              00000160  22 7d 22 3a 7b 22 2e 22  3a 7b 7d 2c 22 66 3a 6c  |"}":{".":{},"f:l|
              00000170  61 73 74 50 72 6f 62 65  54 69 6d 65 22 3a 7b 7d  |astProbeTime":{}|
              00000180  2c 22 66 3a 6c 61 73 74  54 72 61 6e 73 69 74 69  |,"f:lastTransiti|
              00000190  6f 6e 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6f 62  |onTime":{},"f:ob|
              000001a0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001b0  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              000001c0  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              000001d0  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              000001e0  6f 64 53 63 68 65 64 75  6c 65 64 5c 22 7d 22 3a  |odScheduled\"}":|
              000001f0  7b 22 66 3a 6f 62 73 65  72 76 65 64 47 65 6e 65  |{"f:observedGene|
              00000200  72 61 74 69 6f 6e 22 3a  7b 7d 7d 2c 22 6b 3a 7b  |ration":{}},"k:{|
              00000210  5c 22 74 79 70 65 5c 22  3a 5c 22 52 65 61 64 79  |\"type\":\"Ready|
              00000220  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000230  6c 61 73 74 50 72 6f 62  65 54 69 6d 65 22 3a 7b  |lastProbeTime":{|
              00000240  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000250  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6f  |ionTime":{},"f:o|
              00000260  62 73 65 72 76 65 64 47  65 6e 65 72 61 74 69 6f  |bservedGeneratio|
              00000270  6e 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |n":{},"f:status"|
              00000280  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000290  7d 2c 22 66 3a 63 6f 6e  74 61 69 6e 65 72 53 74  |},"f:containerSt|
              000002a0  61 74 75 73 65 73 22 3a  7b 7d 2c 22 66 3a 68 6f  |atuses":{},"f:ho|
              000002b0  73 74 49 50 22 3a 7b 7d  2c 22 66 3a 68 6f 73 74  |stIP":{},"f:host|
              000002c0  49 50 73 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |IPs":{},"f:obser|
              000002d0  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000002e0  7d 2c 22 66 3a 70 68 61  73 65 22 3a 7b 7d 2c 22  |},"f:phase":{},"|
              000002f0  66 3a 70 6f 64 49 50 22  3a 7b 7d 2c 22 66 3a 70  |f:podIP":{},"f:p|
              00000300  6f 64 49 50 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |odIPs":{".":{},"|
              00000310  6b 3a 7b 5c 22 69 70 5c  22 3a 5c 22 31 30 2e 32  |k:{\"ip\":\"10.2|
              00000320  33 33 2e 36 34 2e 32 33  39 5c 22 7d 22 3a 7b 22  |33.64.239\"}":{"|
              00000330  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              00000340  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              00000350  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-t88hh",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-t88hh",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "ietha7evai9i-1",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 1,
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399857,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399857,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.25",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.121.25"
        }
      },
      PodIP: (string) (len=13) "10.233.64.239",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "10.233.64.239"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63892399857,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63892399859,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=72) "cri-o://7d4dc20d3420c8e3d8c4274f564373b3a0ca56b4b6099d35371d3d464104fcdf",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)({
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          }),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-t88hh",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)({
            Linux: (*v1.LinuxContainerUser)({
              UID: (int64) 0,
              GID: (int64) 0,
              SupplementalGroups: ([]int64) (len=11) {
                (int64) 0,
                (int64) 1,
                (int64) 2,
                (int64) 3,
                (int64) 4,
                (int64) 6,
                (int64) 10,
                (int64) 11,
                (int64) 20,
                (int64) 26,
                (int64) 27
              }
            })
          }),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>)
    }
  }

  E0902 08:51:04.205998      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:51:04.223258 16 deployment.go:68] Pod "webserver-deployment-6bc58496c7-sqkr4" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-6bc58496c7-sqkr4",
      GenerateName: (string) (len=32) "webserver-deployment-6bc58496c7-",
      Namespace: (string) (len=15) "deployment-2691",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "afbc4bb5-f5e6-4cd1-8b0a-b366dd5d84b8",
      ResourceVersion: (string) (len=5) "42567",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63892399858,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "6bc58496c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-6bc58496c7",
          UID: (types.UID) (len=36) "eb6d722a-799d-4a01-839b-4c216f8322b0",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399858,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 65 62  36 64 37 32 32 61 2d 37  |d\":\"eb6d722a-7|
              00000090  39 39 64 2d 34 61 30 31  2d 38 33 39 62 2d 34 63  |99d-4a01-839b-4c|
              000000a0  32 31 36 66 38 33 32 32  62 30 5c 22 7d 22 3a 7b  |216f8322b0\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399861,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=851) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6f 62 73 65 72 76  |me":{},"f:observ|
              00000080  65 64 47 65 6e 65 72 61  74 69 6f 6e 22 3a 7b 7d  |edGeneration":{}|
              00000090  2c 22 66 3a 73 74 61 74  75 73 22 3a 7b 7d 2c 22  |,"f:status":{},"|
              000000a0  66 3a 74 79 70 65 22 3a  7b 7d 7d 2c 22 6b 3a 7b  |f:type":{}},"k:{|
              000000b0  5c 22 74 79 70 65 5c 22  3a 5c 22 49 6e 69 74 69  |\"type\":\"Initi|
              000000c0  61 6c 69 7a 65 64 5c 22  7d 22 3a 7b 22 2e 22 3a  |alized\"}":{".":|
              000000d0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000000f0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              00000100  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000110  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |eration":{},"f:s|
              00000120  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000130  65 22 3a 7b 7d 7d 2c 22  6b 3a 7b 5c 22 74 79 70  |e":{}},"k:{\"typ|
              00000140  65 5c 22 3a 5c 22 50 6f  64 52 65 61 64 79 54 6f  |e\":\"PodReadyTo|
              00000150  53 74 61 72 74 43 6f 6e  74 61 69 6e 65 72 73 5c  |StartContainers\|
              00000160  22 7d 22 3a 7b 22 2e 22  3a 7b 7d 2c 22 66 3a 6c  |"}":{".":{},"f:l|
              00000170  61 73 74 50 72 6f 62 65  54 69 6d 65 22 3a 7b 7d  |astProbeTime":{}|
              00000180  2c 22 66 3a 6c 61 73 74  54 72 61 6e 73 69 74 69  |,"f:lastTransiti|
              00000190  6f 6e 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6f 62  |onTime":{},"f:ob|
              000001a0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001b0  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              000001c0  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              000001d0  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              000001e0  6f 64 53 63 68 65 64 75  6c 65 64 5c 22 7d 22 3a  |odScheduled\"}":|
              000001f0  7b 22 66 3a 6f 62 73 65  72 76 65 64 47 65 6e 65  |{"f:observedGene|
              00000200  72 61 74 69 6f 6e 22 3a  7b 7d 7d 2c 22 6b 3a 7b  |ration":{}},"k:{|
              00000210  5c 22 74 79 70 65 5c 22  3a 5c 22 52 65 61 64 79  |\"type\":\"Ready|
              00000220  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000230  6c 61 73 74 50 72 6f 62  65 54 69 6d 65 22 3a 7b  |lastProbeTime":{|
              00000240  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000250  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6f  |ionTime":{},"f:o|
              00000260  62 73 65 72 76 65 64 47  65 6e 65 72 61 74 69 6f  |bservedGeneratio|
              00000270  6e 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |n":{},"f:status"|
              00000280  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000290  7d 2c 22 66 3a 63 6f 6e  74 61 69 6e 65 72 53 74  |},"f:containerSt|
              000002a0  61 74 75 73 65 73 22 3a  7b 7d 2c 22 66 3a 68 6f  |atuses":{},"f:ho|
              000002b0  73 74 49 50 22 3a 7b 7d  2c 22 66 3a 68 6f 73 74  |stIP":{},"f:host|
              000002c0  49 50 73 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |IPs":{},"f:obser|
              000002d0  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000002e0  7d 2c 22 66 3a 70 68 61  73 65 22 3a 7b 7d 2c 22  |},"f:phase":{},"|
              000002f0  66 3a 70 6f 64 49 50 22  3a 7b 7d 2c 22 66 3a 70  |f:podIP":{},"f:p|
              00000300  6f 64 49 50 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |odIPs":{".":{},"|
              00000310  6b 3a 7b 5c 22 69 70 5c  22 3a 5c 22 31 30 2e 32  |k:{\"ip\":\"10.2|
              00000320  33 33 2e 36 34 2e 33 32  5c 22 7d 22 3a 7b 22 2e  |33.64.32\"}":{".|
              00000330  22 3a 7b 7d 2c 22 66 3a  69 70 22 3a 7b 7d 7d 7d  |":{},"f:ip":{}}}|
              00000340  2c 22 66 3a 73 74 61 72  74 54 69 6d 65 22 3a 7b  |,"f:startTime":{|
              00000350  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-j2g8p",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-j2g8p",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "ietha7evai9i-1",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 1,
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399861,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399858,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399861,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399861,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399858,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.25",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.121.25"
        }
      },
      PodIP: (string) (len=12) "10.233.64.32",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "10.233.64.32"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63892399858,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63892399860,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=72) "cri-o://3e8ed2b8e858757a9fd2b1fec976d4b43f7e510fcb8b38035c2e8c0167bc7527",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)({
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          }),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-j2g8p",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)({
            Linux: (*v1.LinuxContainerUser)({
              UID: (int64) 0,
              GID: (int64) 0,
              SupplementalGroups: ([]int64) (len=11) {
                (int64) 0,
                (int64) 1,
                (int64) 2,
                (int64) 3,
                (int64) 4,
                (int64) 6,
                (int64) 10,
                (int64) 11,
                (int64) 20,
                (int64) 26,
                (int64) 27
              }
            })
          }),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>)
    }
  }

  I0902 08:51:04.227269 16 deployment.go:68] Pod "webserver-deployment-76fc67f65c-4kv22" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-76fc67f65c-4kv22",
      GenerateName: (string) (len=32) "webserver-deployment-76fc67f65c-",
      Namespace: (string) (len=15) "deployment-2691",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "94161e1c-958c-42c1-a8cc-313315677571",
      ResourceVersion: (string) (len=5) "42675",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63892399863,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "76fc67f65c"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-76fc67f65c",
          UID: (types.UID) (len=36) "ec7b5ab4-0029-49bb-a357-4094817cdb38",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399863,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 65 63  37 62 35 61 62 34 2d 30  |d\":\"ec7b5ab4-0|
              00000090  30 32 39 2d 34 39 62 62  2d 61 33 35 37 2d 34 30  |029-49bb-a357-40|
              000000a0  39 34 38 31 37 63 64 62  33 38 5c 22 7d 22 3a 7b  |94817cdb38\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-xxhbg",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-xxhbg",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "ietha7evai9i-1",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 0,
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 0,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399864,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>)
    }
  }

  I0902 08:51:04.241645 16 deployment.go:68] Pod "webserver-deployment-76fc67f65c-9px2t" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-76fc67f65c-9px2t",
      GenerateName: (string) (len=32) "webserver-deployment-76fc67f65c-",
      Namespace: (string) (len=15) "deployment-2691",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "9de117df-09eb-4651-9c5c-728df19c77d9",
      ResourceVersion: (string) (len=5) "42617",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63892399861,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "76fc67f65c"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-76fc67f65c",
          UID: (types.UID) (len=36) "ec7b5ab4-0029-49bb-a357-4094817cdb38",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399861,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 65 63  37 62 35 61 62 34 2d 30  |d\":\"ec7b5ab4-0|
              00000090  30 32 39 2d 34 39 62 62  2d 61 33 35 37 2d 34 30  |029-49bb-a357-40|
              000000a0  39 34 38 31 37 63 64 62  33 38 5c 22 7d 22 3a 7b  |94817cdb38\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399862,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=814) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 6f 62 73 65 72 76 65  |e":{},"f:observe|
              00000090  64 47 65 6e 65 72 61 74  69 6f 6e 22 3a 7b 7d 2c  |dGeneration":{},|
              000000a0  22 66 3a 72 65 61 73 6f  6e 22 3a 7b 7d 2c 22 66  |"f:reason":{},"f|
              000000b0  3a 73 74 61 74 75 73 22  3a 7b 7d 2c 22 66 3a 74  |:status":{},"f:t|
              000000c0  79 70 65 22 3a 7b 7d 7d  2c 22 6b 3a 7b 5c 22 74  |ype":{}},"k:{\"t|
              000000d0  79 70 65 5c 22 3a 5c 22  49 6e 69 74 69 61 6c 69  |ype\":\"Initiali|
              000000e0  7a 65 64 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |zed\"}":{".":{},|
              000000f0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              00000110  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              00000120  66 3a 6f 62 73 65 72 76  65 64 47 65 6e 65 72 61  |f:observedGenera|
              00000130  74 69 6f 6e 22 3a 7b 7d  2c 22 66 3a 73 74 61 74  |tion":{},"f:stat|
              00000140  75 73 22 3a 7b 7d 2c 22  66 3a 74 79 70 65 22 3a  |us":{},"f:type":|
              00000150  7b 7d 7d 2c 22 6b 3a 7b  5c 22 74 79 70 65 5c 22  |{}},"k:{\"type\"|
              00000160  3a 5c 22 50 6f 64 52 65  61 64 79 54 6f 53 74 61  |:\"PodReadyToSta|
              00000170  72 74 43 6f 6e 74 61 69  6e 65 72 73 5c 22 7d 22  |rtContainers\"}"|
              00000180  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              00000190  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000001a0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |ime":{},"f:obser|
              000001c0  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 2c 22 6b 3a  |"f:type":{}},"k:|
              000001f0  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 50 6f 64 53  |{\"type\":\"PodS|
              00000200  63 68 65 64 75 6c 65 64  5c 22 7d 22 3a 7b 22 66  |cheduled\"}":{"f|
              00000210  3a 6f 62 73 65 72 76 65  64 47 65 6e 65 72 61 74  |:observedGenerat|
              00000220  69 6f 6e 22 3a 7b 7d 7d  2c 22 6b 3a 7b 5c 22 74  |ion":{}},"k:{\"t|
              00000230  79 70 65 5c 22 3a 5c 22  52 65 61 64 79 5c 22 7d  |ype\":\"Ready\"}|
              00000240  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |":{".":{},"f:las|
              00000250  74 50 72 6f 62 65 54 69  6d 65 22 3a 7b 7d 2c 22  |tProbeTime":{},"|
              00000260  66 3a 6c 61 73 74 54 72  61 6e 73 69 74 69 6f 6e  |f:lastTransition|
              00000270  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6d 65 73 73  |Time":{},"f:mess|
              00000280  61 67 65 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |age":{},"f:obser|
              00000290  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000002a0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              000002b0  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              000002c0  3a 74 79 70 65 22 3a 7b  7d 7d 7d 2c 22 66 3a 63  |:type":{}}},"f:c|
              000002d0  6f 6e 74 61 69 6e 65 72  53 74 61 74 75 73 65 73  |ontainerStatuses|
              000002e0  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 22 3a  |":{},"f:hostIP":|
              000002f0  7b 7d 2c 22 66 3a 68 6f  73 74 49 50 73 22 3a 7b  |{},"f:hostIPs":{|
              00000300  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000310  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |eration":{},"f:s|
              00000320  74 61 72 74 54 69 6d 65  22 3a 7b 7d 7d 7d        |tartTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-vvzlf",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-vvzlf",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "ietha7evai9i-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 1,
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399862,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399862,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399862,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399862,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399862,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.52",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.121.52"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63892399862,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-vvzlf",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>)
    }
  }

  I0902 08:51:04.247836 16 deployment.go:68] Pod "webserver-deployment-76fc67f65c-9vrqn" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-76fc67f65c-9vrqn",
      GenerateName: (string) (len=32) "webserver-deployment-76fc67f65c-",
      Namespace: (string) (len=15) "deployment-2691",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "b5d1a642-51a2-4ef4-b9e0-7506a8d272a1",
      ResourceVersion: (string) (len=5) "42599",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63892399861,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "76fc67f65c",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-76fc67f65c",
          UID: (types.UID) (len=36) "ec7b5ab4-0029-49bb-a357-4094817cdb38",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399861,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 65 63  37 62 35 61 62 34 2d 30  |d\":\"ec7b5ab4-0|
              00000090  30 32 39 2d 34 39 62 62  2d 61 33 35 37 2d 34 30  |029-49bb-a357-40|
              000000a0  39 34 38 31 37 63 64 62  33 38 5c 22 7d 22 3a 7b  |94817cdb38\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399861,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=814) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 6f 62 73 65 72 76 65  |e":{},"f:observe|
              00000090  64 47 65 6e 65 72 61 74  69 6f 6e 22 3a 7b 7d 2c  |dGeneration":{},|
              000000a0  22 66 3a 72 65 61 73 6f  6e 22 3a 7b 7d 2c 22 66  |"f:reason":{},"f|
              000000b0  3a 73 74 61 74 75 73 22  3a 7b 7d 2c 22 66 3a 74  |:status":{},"f:t|
              000000c0  79 70 65 22 3a 7b 7d 7d  2c 22 6b 3a 7b 5c 22 74  |ype":{}},"k:{\"t|
              000000d0  79 70 65 5c 22 3a 5c 22  49 6e 69 74 69 61 6c 69  |ype\":\"Initiali|
              000000e0  7a 65 64 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |zed\"}":{".":{},|
              000000f0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              00000110  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              00000120  66 3a 6f 62 73 65 72 76  65 64 47 65 6e 65 72 61  |f:observedGenera|
              00000130  74 69 6f 6e 22 3a 7b 7d  2c 22 66 3a 73 74 61 74  |tion":{},"f:stat|
              00000140  75 73 22 3a 7b 7d 2c 22  66 3a 74 79 70 65 22 3a  |us":{},"f:type":|
              00000150  7b 7d 7d 2c 22 6b 3a 7b  5c 22 74 79 70 65 5c 22  |{}},"k:{\"type\"|
              00000160  3a 5c 22 50 6f 64 52 65  61 64 79 54 6f 53 74 61  |:\"PodReadyToSta|
              00000170  72 74 43 6f 6e 74 61 69  6e 65 72 73 5c 22 7d 22  |rtContainers\"}"|
              00000180  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              00000190  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000001a0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |ime":{},"f:obser|
              000001c0  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 2c 22 6b 3a  |"f:type":{}},"k:|
              000001f0  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 50 6f 64 53  |{\"type\":\"PodS|
              00000200  63 68 65 64 75 6c 65 64  5c 22 7d 22 3a 7b 22 66  |cheduled\"}":{"f|
              00000210  3a 6f 62 73 65 72 76 65  64 47 65 6e 65 72 61 74  |:observedGenerat|
              00000220  69 6f 6e 22 3a 7b 7d 7d  2c 22 6b 3a 7b 5c 22 74  |ion":{}},"k:{\"t|
              00000230  79 70 65 5c 22 3a 5c 22  52 65 61 64 79 5c 22 7d  |ype\":\"Ready\"}|
              00000240  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |":{".":{},"f:las|
              00000250  74 50 72 6f 62 65 54 69  6d 65 22 3a 7b 7d 2c 22  |tProbeTime":{},"|
              00000260  66 3a 6c 61 73 74 54 72  61 6e 73 69 74 69 6f 6e  |f:lastTransition|
              00000270  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6d 65 73 73  |Time":{},"f:mess|
              00000280  61 67 65 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |age":{},"f:obser|
              00000290  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000002a0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              000002b0  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              000002c0  3a 74 79 70 65 22 3a 7b  7d 7d 7d 2c 22 66 3a 63  |:type":{}}},"f:c|
              000002d0  6f 6e 74 61 69 6e 65 72  53 74 61 74 75 73 65 73  |ontainerStatuses|
              000002e0  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 22 3a  |":{},"f:hostIP":|
              000002f0  7b 7d 2c 22 66 3a 68 6f  73 74 49 50 73 22 3a 7b  |{},"f:hostIPs":{|
              00000300  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000310  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |eration":{},"f:s|
              00000320  74 61 72 74 54 69 6d 65  22 3a 7b 7d 7d 7d        |tartTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-t862c",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-t862c",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "ietha7evai9i-1",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 1,
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399861,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399861,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399861,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399861,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399861,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.25",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.121.25"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63892399861,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-t862c",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>)
    }
  }

  I0902 08:51:04.251655 16 deployment.go:68] Pod "webserver-deployment-76fc67f65c-dkq96" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-76fc67f65c-dkq96",
      GenerateName: (string) (len=32) "webserver-deployment-76fc67f65c-",
      Namespace: (string) (len=15) "deployment-2691",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "29374e8e-4200-4568-bf3d-be95a7625488",
      ResourceVersion: (string) (len=5) "42596",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63892399861,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "76fc67f65c"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-76fc67f65c",
          UID: (types.UID) (len=36) "ec7b5ab4-0029-49bb-a357-4094817cdb38",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399861,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 65 63  37 62 35 61 62 34 2d 30  |d\":\"ec7b5ab4-0|
              00000090  30 32 39 2d 34 39 62 62  2d 61 33 35 37 2d 34 30  |029-49bb-a357-40|
              000000a0  39 34 38 31 37 63 64 62  33 38 5c 22 7d 22 3a 7b  |94817cdb38\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399861,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=814) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 6f 62 73 65 72 76 65  |e":{},"f:observe|
              00000090  64 47 65 6e 65 72 61 74  69 6f 6e 22 3a 7b 7d 2c  |dGeneration":{},|
              000000a0  22 66 3a 72 65 61 73 6f  6e 22 3a 7b 7d 2c 22 66  |"f:reason":{},"f|
              000000b0  3a 73 74 61 74 75 73 22  3a 7b 7d 2c 22 66 3a 74  |:status":{},"f:t|
              000000c0  79 70 65 22 3a 7b 7d 7d  2c 22 6b 3a 7b 5c 22 74  |ype":{}},"k:{\"t|
              000000d0  79 70 65 5c 22 3a 5c 22  49 6e 69 74 69 61 6c 69  |ype\":\"Initiali|
              000000e0  7a 65 64 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |zed\"}":{".":{},|
              000000f0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              00000110  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              00000120  66 3a 6f 62 73 65 72 76  65 64 47 65 6e 65 72 61  |f:observedGenera|
              00000130  74 69 6f 6e 22 3a 7b 7d  2c 22 66 3a 73 74 61 74  |tion":{},"f:stat|
              00000140  75 73 22 3a 7b 7d 2c 22  66 3a 74 79 70 65 22 3a  |us":{},"f:type":|
              00000150  7b 7d 7d 2c 22 6b 3a 7b  5c 22 74 79 70 65 5c 22  |{}},"k:{\"type\"|
              00000160  3a 5c 22 50 6f 64 52 65  61 64 79 54 6f 53 74 61  |:\"PodReadyToSta|
              00000170  72 74 43 6f 6e 74 61 69  6e 65 72 73 5c 22 7d 22  |rtContainers\"}"|
              00000180  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              00000190  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000001a0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |ime":{},"f:obser|
              000001c0  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 2c 22 6b 3a  |"f:type":{}},"k:|
              000001f0  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 50 6f 64 53  |{\"type\":\"PodS|
              00000200  63 68 65 64 75 6c 65 64  5c 22 7d 22 3a 7b 22 66  |cheduled\"}":{"f|
              00000210  3a 6f 62 73 65 72 76 65  64 47 65 6e 65 72 61 74  |:observedGenerat|
              00000220  69 6f 6e 22 3a 7b 7d 7d  2c 22 6b 3a 7b 5c 22 74  |ion":{}},"k:{\"t|
              00000230  79 70 65 5c 22 3a 5c 22  52 65 61 64 79 5c 22 7d  |ype\":\"Ready\"}|
              00000240  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |":{".":{},"f:las|
              00000250  74 50 72 6f 62 65 54 69  6d 65 22 3a 7b 7d 2c 22  |tProbeTime":{},"|
              00000260  66 3a 6c 61 73 74 54 72  61 6e 73 69 74 69 6f 6e  |f:lastTransition|
              00000270  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6d 65 73 73  |Time":{},"f:mess|
              00000280  61 67 65 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |age":{},"f:obser|
              00000290  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000002a0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              000002b0  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              000002c0  3a 74 79 70 65 22 3a 7b  7d 7d 7d 2c 22 66 3a 63  |:type":{}}},"f:c|
              000002d0  6f 6e 74 61 69 6e 65 72  53 74 61 74 75 73 65 73  |ontainerStatuses|
              000002e0  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 22 3a  |":{},"f:hostIP":|
              000002f0  7b 7d 2c 22 66 3a 68 6f  73 74 49 50 73 22 3a 7b  |{},"f:hostIPs":{|
              00000300  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000310  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |eration":{},"f:s|
              00000320  74 61 72 74 54 69 6d 65  22 3a 7b 7d 7d 7d        |tartTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-f5x6z",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-f5x6z",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "ietha7evai9i-2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 1,
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399861,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399861,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399861,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399861,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399861,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.46",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.121.46"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63892399861,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-f5x6z",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>)
    }
  }

  I0902 08:51:04.255891 16 deployment.go:68] Pod "webserver-deployment-76fc67f65c-fln8b" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-76fc67f65c-fln8b",
      GenerateName: (string) (len=32) "webserver-deployment-76fc67f65c-",
      Namespace: (string) (len=15) "deployment-2691",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "8f7a1210-1fc6-48b2-a03e-51881dc9aa93",
      ResourceVersion: (string) (len=5) "42678",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63892399864,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "76fc67f65c",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-76fc67f65c",
          UID: (types.UID) (len=36) "ec7b5ab4-0029-49bb-a357-4094817cdb38",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399864,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 65 63  37 62 35 61 62 34 2d 30  |d\":\"ec7b5ab4-0|
              00000090  30 32 39 2d 34 39 62 62  2d 61 33 35 37 2d 34 30  |029-49bb-a357-40|
              000000a0  39 34 38 31 37 63 64 62  33 38 5c 22 7d 22 3a 7b  |94817cdb38\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-wvh7m",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-wvh7m",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 0,
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>)
    }
  }

  I0902 08:51:04.259193 16 deployment.go:68] Pod "webserver-deployment-76fc67f65c-pg945" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-76fc67f65c-pg945",
      GenerateName: (string) (len=32) "webserver-deployment-76fc67f65c-",
      Namespace: (string) (len=15) "deployment-2691",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "e1027e79-702b-4515-aa83-366765f7cf3f",
      ResourceVersion: (string) (len=5) "42674",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63892399864,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "76fc67f65c"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-76fc67f65c",
          UID: (types.UID) (len=36) "ec7b5ab4-0029-49bb-a357-4094817cdb38",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399864,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 65 63  37 62 35 61 62 34 2d 30  |d\":\"ec7b5ab4-0|
              00000090  30 32 39 2d 34 39 62 62  2d 61 33 35 37 2d 34 30  |029-49bb-a357-40|
              000000a0  39 34 38 31 37 63 64 62  33 38 5c 22 7d 22 3a 7b  |94817cdb38\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-vhzmc",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-vhzmc",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 0,
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>)
    }
  }

  I0902 08:51:04.261371 16 deployment.go:68] Pod "webserver-deployment-76fc67f65c-qbdkr" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-76fc67f65c-qbdkr",
      GenerateName: (string) (len=32) "webserver-deployment-76fc67f65c-",
      Namespace: (string) (len=15) "deployment-2691",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "d997d51c-b014-4c5e-93ec-27ae382ef271",
      ResourceVersion: (string) (len=5) "42624",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63892399862,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "76fc67f65c"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-76fc67f65c",
          UID: (types.UID) (len=36) "ec7b5ab4-0029-49bb-a357-4094817cdb38",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399862,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 65 63  37 62 35 61 62 34 2d 30  |d\":\"ec7b5ab4-0|
              00000090  30 32 39 2d 34 39 62 62  2d 61 33 35 37 2d 34 30  |029-49bb-a357-40|
              000000a0  39 34 38 31 37 63 64 62  33 38 5c 22 7d 22 3a 7b  |94817cdb38\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399862,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=814) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 6f 62 73 65 72 76 65  |e":{},"f:observe|
              00000090  64 47 65 6e 65 72 61 74  69 6f 6e 22 3a 7b 7d 2c  |dGeneration":{},|
              000000a0  22 66 3a 72 65 61 73 6f  6e 22 3a 7b 7d 2c 22 66  |"f:reason":{},"f|
              000000b0  3a 73 74 61 74 75 73 22  3a 7b 7d 2c 22 66 3a 74  |:status":{},"f:t|
              000000c0  79 70 65 22 3a 7b 7d 7d  2c 22 6b 3a 7b 5c 22 74  |ype":{}},"k:{\"t|
              000000d0  79 70 65 5c 22 3a 5c 22  49 6e 69 74 69 61 6c 69  |ype\":\"Initiali|
              000000e0  7a 65 64 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |zed\"}":{".":{},|
              000000f0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              00000110  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              00000120  66 3a 6f 62 73 65 72 76  65 64 47 65 6e 65 72 61  |f:observedGenera|
              00000130  74 69 6f 6e 22 3a 7b 7d  2c 22 66 3a 73 74 61 74  |tion":{},"f:stat|
              00000140  75 73 22 3a 7b 7d 2c 22  66 3a 74 79 70 65 22 3a  |us":{},"f:type":|
              00000150  7b 7d 7d 2c 22 6b 3a 7b  5c 22 74 79 70 65 5c 22  |{}},"k:{\"type\"|
              00000160  3a 5c 22 50 6f 64 52 65  61 64 79 54 6f 53 74 61  |:\"PodReadyToSta|
              00000170  72 74 43 6f 6e 74 61 69  6e 65 72 73 5c 22 7d 22  |rtContainers\"}"|
              00000180  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              00000190  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000001a0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |ime":{},"f:obser|
              000001c0  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 2c 22 6b 3a  |"f:type":{}},"k:|
              000001f0  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 50 6f 64 53  |{\"type\":\"PodS|
              00000200  63 68 65 64 75 6c 65 64  5c 22 7d 22 3a 7b 22 66  |cheduled\"}":{"f|
              00000210  3a 6f 62 73 65 72 76 65  64 47 65 6e 65 72 61 74  |:observedGenerat|
              00000220  69 6f 6e 22 3a 7b 7d 7d  2c 22 6b 3a 7b 5c 22 74  |ion":{}},"k:{\"t|
              00000230  79 70 65 5c 22 3a 5c 22  52 65 61 64 79 5c 22 7d  |ype\":\"Ready\"}|
              00000240  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |":{".":{},"f:las|
              00000250  74 50 72 6f 62 65 54 69  6d 65 22 3a 7b 7d 2c 22  |tProbeTime":{},"|
              00000260  66 3a 6c 61 73 74 54 72  61 6e 73 69 74 69 6f 6e  |f:lastTransition|
              00000270  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6d 65 73 73  |Time":{},"f:mess|
              00000280  61 67 65 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |age":{},"f:obser|
              00000290  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000002a0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              000002b0  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              000002c0  3a 74 79 70 65 22 3a 7b  7d 7d 7d 2c 22 66 3a 63  |:type":{}}},"f:c|
              000002d0  6f 6e 74 61 69 6e 65 72  53 74 61 74 75 73 65 73  |ontainerStatuses|
              000002e0  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 22 3a  |":{},"f:hostIP":|
              000002f0  7b 7d 2c 22 66 3a 68 6f  73 74 49 50 73 22 3a 7b  |{},"f:hostIPs":{|
              00000300  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000310  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |eration":{},"f:s|
              00000320  74 61 72 74 54 69 6d 65  22 3a 7b 7d 7d 7d        |tartTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-gbn5q",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-gbn5q",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "ietha7evai9i-2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 1,
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399862,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399862,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399862,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399862,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399862,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.46",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.121.46"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63892399862,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-gbn5q",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>)
    }
  }

  I0902 08:51:04.266313 16 deployment.go:68] Pod "webserver-deployment-76fc67f65c-xtd7p" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-76fc67f65c-xtd7p",
      GenerateName: (string) (len=32) "webserver-deployment-76fc67f65c-",
      Namespace: (string) (len=15) "deployment-2691",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "4e437d7a-5fce-4946-b83e-ee7b2f1626e0",
      ResourceVersion: (string) (len=5) "42585",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63892399861,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "76fc67f65c"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-76fc67f65c",
          UID: (types.UID) (len=36) "ec7b5ab4-0029-49bb-a357-4094817cdb38",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399861,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 65 63  37 62 35 61 62 34 2d 30  |d\":\"ec7b5ab4-0|
              00000090  30 32 39 2d 34 39 62 62  2d 61 33 35 37 2d 34 30  |029-49bb-a357-40|
              000000a0  39 34 38 31 37 63 64 62  33 38 5c 22 7d 22 3a 7b  |94817cdb38\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399861,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=814) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 6f 62 73 65 72 76 65  |e":{},"f:observe|
              00000090  64 47 65 6e 65 72 61 74  69 6f 6e 22 3a 7b 7d 2c  |dGeneration":{},|
              000000a0  22 66 3a 72 65 61 73 6f  6e 22 3a 7b 7d 2c 22 66  |"f:reason":{},"f|
              000000b0  3a 73 74 61 74 75 73 22  3a 7b 7d 2c 22 66 3a 74  |:status":{},"f:t|
              000000c0  79 70 65 22 3a 7b 7d 7d  2c 22 6b 3a 7b 5c 22 74  |ype":{}},"k:{\"t|
              000000d0  79 70 65 5c 22 3a 5c 22  49 6e 69 74 69 61 6c 69  |ype\":\"Initiali|
              000000e0  7a 65 64 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |zed\"}":{".":{},|
              000000f0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              00000110  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              00000120  66 3a 6f 62 73 65 72 76  65 64 47 65 6e 65 72 61  |f:observedGenera|
              00000130  74 69 6f 6e 22 3a 7b 7d  2c 22 66 3a 73 74 61 74  |tion":{},"f:stat|
              00000140  75 73 22 3a 7b 7d 2c 22  66 3a 74 79 70 65 22 3a  |us":{},"f:type":|
              00000150  7b 7d 7d 2c 22 6b 3a 7b  5c 22 74 79 70 65 5c 22  |{}},"k:{\"type\"|
              00000160  3a 5c 22 50 6f 64 52 65  61 64 79 54 6f 53 74 61  |:\"PodReadyToSta|
              00000170  72 74 43 6f 6e 74 61 69  6e 65 72 73 5c 22 7d 22  |rtContainers\"}"|
              00000180  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              00000190  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000001a0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |ime":{},"f:obser|
              000001c0  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 2c 22 6b 3a  |"f:type":{}},"k:|
              000001f0  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 50 6f 64 53  |{\"type\":\"PodS|
              00000200  63 68 65 64 75 6c 65 64  5c 22 7d 22 3a 7b 22 66  |cheduled\"}":{"f|
              00000210  3a 6f 62 73 65 72 76 65  64 47 65 6e 65 72 61 74  |:observedGenerat|
              00000220  69 6f 6e 22 3a 7b 7d 7d  2c 22 6b 3a 7b 5c 22 74  |ion":{}},"k:{\"t|
              00000230  79 70 65 5c 22 3a 5c 22  52 65 61 64 79 5c 22 7d  |ype\":\"Ready\"}|
              00000240  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |":{".":{},"f:las|
              00000250  74 50 72 6f 62 65 54 69  6d 65 22 3a 7b 7d 2c 22  |tProbeTime":{},"|
              00000260  66 3a 6c 61 73 74 54 72  61 6e 73 69 74 69 6f 6e  |f:lastTransition|
              00000270  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6d 65 73 73  |Time":{},"f:mess|
              00000280  61 67 65 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |age":{},"f:obser|
              00000290  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000002a0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              000002b0  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              000002c0  3a 74 79 70 65 22 3a 7b  7d 7d 7d 2c 22 66 3a 63  |:type":{}}},"f:c|
              000002d0  6f 6e 74 61 69 6e 65 72  53 74 61 74 75 73 65 73  |ontainerStatuses|
              000002e0  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 22 3a  |":{},"f:hostIP":|
              000002f0  7b 7d 2c 22 66 3a 68 6f  73 74 49 50 73 22 3a 7b  |{},"f:hostIPs":{|
              00000300  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000310  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |eration":{},"f:s|
              00000320  74 61 72 74 54 69 6d 65  22 3a 7b 7d 7d 7d        |tartTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-8qvdt",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-8qvdt",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "ietha7evai9i-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 1,
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399861,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399861,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399861,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399861,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892399861,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.52",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.121.52"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63892399861,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-8qvdt",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>)
    }
  }

  I0902 08:51:04.270055 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-2691" for this suite. @ 09/02/25 08:51:04.337
• [7.086 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply an update to a Namespace [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:372
  STEP: Creating a kubernetes client @ 09/02/25 08:51:04.757
  I0902 08:51:04.757591 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename namespaces @ 09/02/25 08:51:04.901
  E0902 08:51:05.297783      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:51:05.359
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:51:05.399
  STEP: Updating Namespace "namespaces-3049" @ 09/02/25 08:51:05.581
  I0902 08:51:05.667370 16 namespace.go:389] Namespace "namespaces-3049" now has labels, map[string]string{"e2e-framework":"namespaces", "e2e-run":"aeecdebe-316c-45be-9858-11f08143cc7b", "kubernetes.io/metadata.name":"namespaces-3049", "namespaces-3049":"updated", "pod-security.kubernetes.io/audit":"baseline", "pod-security.kubernetes.io/enforce":"baseline", "pod-security.kubernetes.io/warn":"baseline"}
  I0902 08:51:05.667943 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-3049" for this suite. @ 09/02/25 08:51:05.766
• [1.067 seconds]
------------------------------
SSS
------------------------------
[sig-apps] ReplicationController should release no longer matching pods [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:105
  STEP: Creating a kubernetes client @ 09/02/25 08:51:05.829
  I0902 08:51:05.829220 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename replication-controller @ 09/02/25 08:51:05.855
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:51:05.934
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:51:05.956
  STEP: Given a ReplicationController is created @ 09/02/25 08:51:05.965
  STEP: When the matched label of one of its pods change @ 09/02/25 08:51:05.977
  I0902 08:51:05.984252 16 resource.go:64] Pod name pod-release: Found 0 pods out of 1
  E0902 08:51:06.298571      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:51:07.299487      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:51:08.299844      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:51:09.300043      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:51:10.300844      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:51:11.054255 16 resource.go:64] Pod name pod-release: Found 1 pods out of 1
  STEP: Then the pod is released @ 09/02/25 08:51:11.161
  I0902 08:51:11.244306 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  E0902 08:51:11.301999      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Destroying namespace "replication-controller-912" for this suite. @ 09/02/25 08:51:11.34
• [5.764 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:565
  STEP: Creating a kubernetes client @ 09/02/25 08:51:11.596
  I0902 08:51:11.596389 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename webhook @ 09/02/25 08:51:11.661
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:51:11.989
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:51:12.024
  E0902 08:51:12.302634      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Setting up server cert @ 09/02/25 08:51:12.492
  E0902 08:51:13.302977      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 09/02/25 08:51:13.718
  STEP: Deploying the webhook pod @ 09/02/25 08:51:13.728
  STEP: Wait for the deployment to be ready @ 09/02/25 08:51:13.759
  I0902 08:51:13.792342 16 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0902 08:51:14.303096      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:51:15.303537      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 09/02/25 08:51:15.814
  STEP: Verifying the service has paired with the endpoint @ 09/02/25 08:51:15.839
  E0902 08:51:16.303673      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:51:16.843212 16 util.go:419] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Listing all of the created validation webhooks @ 09/02/25 08:51:17.04
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 09/02/25 08:51:17.114
  STEP: Deleting the collection of validation webhooks @ 09/02/25 08:51:17.178
  E0902 08:51:17.304690      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 09/02/25 08:51:17.336
  I0902 08:51:17.446631 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-8391" for this suite. @ 09/02/25 08:51:17.458
  STEP: Destroying namespace "webhook-markers-5256" for this suite. @ 09/02/25 08:51:17.479
• [5.923 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:131
  STEP: Creating a kubernetes client @ 09/02/25 08:51:17.522
  I0902 08:51:17.522368 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename projected @ 09/02/25 08:51:17.527
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:51:17.554
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:51:17.56
  STEP: Creating the pod @ 09/02/25 08:51:17.567
  E0902 08:51:18.304369      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:51:19.304639      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:51:20.155617 16 pod_client.go:186] Successfully updated pod "labelsupdate46a3eb12-057d-41a7-b9c8-c1d8ec973cdf"
  E0902 08:51:20.305722      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:51:21.306034      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:51:22.194426 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-651" for this suite. @ 09/02/25 08:51:22.209
• [4.705 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:423
  STEP: Creating a kubernetes client @ 09/02/25 08:51:22.227
  I0902 08:51:22.227630 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename configmap @ 09/02/25 08:51:22.231
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:51:22.278
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:51:22.286
  STEP: Creating configMap with name configmap-test-volume-355767c6-e71c-4e73-bc5f-7901a9354c06 @ 09/02/25 08:51:22.293
  STEP: Creating a pod to test consume configMaps @ 09/02/25 08:51:22.304
  E0902 08:51:22.306338      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:51:23.307072      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:51:24.307350      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:51:25.308209      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:51:26.308950      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/02/25 08:51:26.427
  I0902 08:51:26.434691 16 output.go:207] Trying to get logs from node ietha7evai9i-3 pod pod-configmaps-95ad6bff-f88b-46e9-828c-af13c5aa19d5 container configmap-volume-test: <nil>
  STEP: delete the pod @ 09/02/25 08:51:26.48
  I0902 08:51:26.521381 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-2101" for this suite. @ 09/02/25 08:51:26.532
• [4.321 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] StorageClasses CSI Conformance should run through the lifecycle of a StorageClass [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/storageclass.go:53
  STEP: Creating a kubernetes client @ 09/02/25 08:51:26.55
  I0902 08:51:26.550986 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename csi-storageclass @ 09/02/25 08:51:26.554
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:51:26.584
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:51:26.593
  STEP: Creating a StorageClass @ 09/02/25 08:51:26.599
  STEP: Get StorageClass "e2e-fnchn" @ 09/02/25 08:51:26.613
  STEP: Patching the StorageClass "e2e-fnchn" @ 09/02/25 08:51:26.621
  STEP: Delete StorageClass "e2e-fnchn" @ 09/02/25 08:51:26.636
  STEP: Confirm deletion of StorageClass "e2e-fnchn" @ 09/02/25 08:51:26.65
  STEP: Create a replacement StorageClass @ 09/02/25 08:51:26.657
  STEP: Updating StorageClass "e2e-v2-bpx6d" @ 09/02/25 08:51:26.668
  STEP: Listing all StorageClass with the labelSelector: "e2e-v2-bpx6d=updated" @ 09/02/25 08:51:26.686
  STEP: Deleting StorageClass "e2e-v2-bpx6d" via DeleteCollection @ 09/02/25 08:51:26.695
  STEP: Confirm deletion of StorageClass "e2e-v2-bpx6d" @ 09/02/25 08:51:26.712
  I0902 08:51:26.719662 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csi-storageclass-4243" for this suite. @ 09/02/25 08:51:26.728
• [0.193 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] PersistentVolumes CSI Conformance should apply changes to a pv/pvc status [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/persistent_volumes.go:668
  STEP: Creating a kubernetes client @ 09/02/25 08:51:26.744
  I0902 08:51:26.744700 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename pv @ 09/02/25 08:51:26.747
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:51:26.835
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:51:26.843
  STEP: Creating initial PV and PVC @ 09/02/25 08:51:26.848
  I0902 08:51:26.848675 16 pv.go:394] Creating a PV followed by a PVC
  STEP: Listing all PVs with the labelSelector: "e2e-pv-pool=pv-6880" @ 09/02/25 08:51:26.924
  STEP: Listing PVCs in namespace "pv-6880" @ 09/02/25 08:51:26.946
  STEP: Reading "pvc-zvjn6" Status @ 09/02/25 08:51:26.959
  STEP: Reading "pv-6880-pzpdt" Status @ 09/02/25 08:51:26.976
  STEP: Patching "pvc-zvjn6" Status @ 09/02/25 08:51:26.995
  STEP: Patching "pv-6880-pzpdt" Status @ 09/02/25 08:51:27.025
  STEP: Updating "pvc-zvjn6" Status @ 09/02/25 08:51:27.04
  STEP: Updating "pv-6880-pzpdt" Status @ 09/02/25 08:51:27.055
  I0902 08:51:27.080123 16 persistent_volumes.go:406] AfterEach: deleting 1 PVCs and 1 PVs...
  I0902 08:51:27.080210 16 pv.go:205] Deleting PersistentVolumeClaim "pvc-zvjn6"
  I0902 08:51:27.091981 16 pv.go:193] Deleting PersistentVolume "pv-6880-pzpdt"
  I0902 08:51:27.108635 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pv-6880" for this suite. @ 09/02/25 08:51:27.119
• [0.395 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:178
  STEP: Creating a kubernetes client @ 09/02/25 08:51:27.14
  I0902 08:51:27.140408 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename init-container @ 09/02/25 08:51:27.142
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:51:27.18
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:51:27.2
  STEP: creating the pod @ 09/02/25 08:51:27.209
  I0902 08:51:27.209810 16 init_container.go:213] PodSpec: initContainers in spec.initContainers
  E0902 08:51:27.310046      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:51:28.310235      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:51:29.311242      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:51:30.312414      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:51:31.312350      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:51:32.088963 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-5569" for this suite. @ 09/02/25 08:51:32.099
• [4.977 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet Replace and Patch tests [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:155
  STEP: Creating a kubernetes client @ 09/02/25 08:51:32.119
  I0902 08:51:32.119149 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename replicaset @ 09/02/25 08:51:32.124
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:51:32.164
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:51:32.185
  I0902 08:51:32.284054 16 resource.go:64] Pod name sample-pod: Found 0 pods out of 1
  E0902 08:51:32.313149      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:51:33.313226      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:51:34.313690      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:51:35.314101      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:51:36.314242      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:51:37.299704 16 resource.go:64] Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 09/02/25 08:51:37.299
  STEP: Scaling up "test-rs" replicaset @ 09/02/25 08:51:37.301
  E0902 08:51:37.316847      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:51:37.334161 16 replicaset.go:44] Updating replica set "test-rs"
  STEP: patching the ReplicaSet @ 09/02/25 08:51:37.334
  I0902 08:51:37.354655 16 replica_set.go:544] observed ReplicaSet test-rs in namespace replicaset-19 with ReadyReplicas 1, AvailableReplicas 1
  I0902 08:51:37.407003 16 replica_set.go:544] observed ReplicaSet test-rs in namespace replicaset-19 with ReadyReplicas 1, AvailableReplicas 1
  I0902 08:51:37.438384 16 replica_set.go:544] observed ReplicaSet test-rs in namespace replicaset-19 with ReadyReplicas 1, AvailableReplicas 1
  I0902 08:51:37.471491 16 replica_set.go:544] observed ReplicaSet test-rs in namespace replicaset-19 with ReadyReplicas 1, AvailableReplicas 1
  E0902 08:51:38.318056      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:51:38.964042 16 replica_set.go:544] observed ReplicaSet test-rs in namespace replicaset-19 with ReadyReplicas 2, AvailableReplicas 2
  E0902 08:51:39.318692      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:51:39.506019 16 replica_set.go:547] observed Replicaset test-rs in namespace replicaset-19 with ReadyReplicas 3 found true
  I0902 08:51:39.507155 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-19" for this suite. @ 09/02/25 08:51:39.522
• [7.420 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] CSIInlineVolumes should support CSIVolumeSource in Pod API [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/csi_inline.go:50
  STEP: Creating a kubernetes client @ 09/02/25 08:51:39.54
  I0902 08:51:39.540292 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename csiinlinevolumes @ 09/02/25 08:51:39.543
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:51:39.568
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:51:39.575
  STEP: creating @ 09/02/25 08:51:39.582
  STEP: getting @ 09/02/25 08:51:39.624
  STEP: listing in namespace @ 09/02/25 08:51:39.637
  STEP: patching @ 09/02/25 08:51:39.651
  STEP: deleting @ 09/02/25 08:51:39.67
  I0902 08:51:39.712999 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csiinlinevolumes-860" for this suite. @ 09/02/25 08:51:39.728
• [0.204 seconds]
------------------------------
[sig-api-machinery] Discovery should locate the groupVersion and a resource within each APIGroup [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/discovery.go:172
  STEP: Creating a kubernetes client @ 09/02/25 08:51:39.746
  I0902 08:51:39.746044 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename discovery @ 09/02/25 08:51:39.751
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:51:39.814
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:51:39.823
  STEP: Setting up server cert @ 09/02/25 08:51:39.832
  E0902 08:51:40.318763      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Requesting APIResourceList from "/api/v1" @ 09/02/25 08:51:40.893
  STEP: Requesting APIResourceList from "/apis/admissionregistration.k8s.io/v1" @ 09/02/25 08:51:40.898
  STEP: Requesting APIResourceList from "/apis/apiextensions.k8s.io/v1" @ 09/02/25 08:51:40.901
  STEP: Requesting APIResourceList from "/apis/apiregistration.k8s.io/v1" @ 09/02/25 08:51:40.903
  STEP: Requesting APIResourceList from "/apis/apps/v1" @ 09/02/25 08:51:40.905
  STEP: Requesting APIResourceList from "/apis/authentication.k8s.io/v1" @ 09/02/25 08:51:40.907
  STEP: Requesting APIResourceList from "/apis/authorization.k8s.io/v1" @ 09/02/25 08:51:40.91
  STEP: Requesting APIResourceList from "/apis/autoscaling/v1" @ 09/02/25 08:51:40.912
  STEP: Requesting APIResourceList from "/apis/autoscaling/v2" @ 09/02/25 08:51:40.917
  STEP: Requesting APIResourceList from "/apis/batch/v1" @ 09/02/25 08:51:40.919
  STEP: Requesting APIResourceList from "/apis/certificates.k8s.io/v1" @ 09/02/25 08:51:40.921
  STEP: Requesting APIResourceList from "/apis/coordination.k8s.io/v1" @ 09/02/25 08:51:40.924
  STEP: Requesting APIResourceList from "/apis/discovery.k8s.io/v1" @ 09/02/25 08:51:40.926
  STEP: Requesting APIResourceList from "/apis/events.k8s.io/v1" @ 09/02/25 08:51:40.928
  STEP: Requesting APIResourceList from "/apis/networking.k8s.io/v1" @ 09/02/25 08:51:40.93
  STEP: Requesting APIResourceList from "/apis/node.k8s.io/v1" @ 09/02/25 08:51:40.933
  STEP: Requesting APIResourceList from "/apis/policy/v1" @ 09/02/25 08:51:40.935
  STEP: Requesting APIResourceList from "/apis/scheduling.k8s.io/v1" @ 09/02/25 08:51:40.937
  STEP: Requesting APIResourceList from "/apis/storage.k8s.io/v1" @ 09/02/25 08:51:40.94
  I0902 08:51:40.943786 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "discovery-6878" for this suite. @ 09/02/25 08:51:40.951
• [1.222 seconds]
------------------------------
[sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:52
  STEP: Creating a kubernetes client @ 09/02/25 08:51:40.967
  I0902 08:51:40.967713 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename kubelet-test @ 09/02/25 08:51:40.97
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:51:41.006
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:51:41.011
  E0902 08:51:41.319159      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:51:42.319897      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:51:43.081224 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-3921" for this suite. @ 09/02/25 08:51:43.091
• [2.137 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates pod disruption condition is added to the preempted pod [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:477
  STEP: Creating a kubernetes client @ 09/02/25 08:51:43.106
  I0902 08:51:43.106662 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename sched-preemption @ 09/02/25 08:51:43.111
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:51:43.144
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:51:43.149
  I0902 08:51:43.191192 16 wait.go:51] Waiting up to 1m0s for all nodes to be ready
  E0902 08:51:43.320220      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:51:44.320416      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:51:45.321519      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:51:46.321732      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:51:47.322516      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:51:48.322982      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:51:49.324003      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:51:50.324781      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:51:51.325624      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:51:52.325879      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:51:53.326342      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:51:54.326867      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:51:55.327809      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:51:56.328128      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:51:57.328796      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:51:58.329349      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:51:59.330016      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:52:00.330656      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:52:01.330796      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:52:02.331813      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:52:03.332077      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:52:04.332819      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:52:05.333286      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:52:06.333989      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:52:07.334616      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:52:08.335127      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:52:09.336312      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:52:10.336987      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:52:11.338026      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:52:12.338816      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:52:13.340540      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:52:14.340746      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:52:15.341754      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:52:16.341631      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:52:17.342201      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:52:18.343149      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:52:19.343431      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:52:20.344211      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:52:21.344504      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:52:22.345065      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:52:23.345196      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:52:24.346144      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:52:25.346310      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:52:26.346844      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:52:27.347024      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:52:28.347218      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:52:29.348105      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:52:30.347586      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:52:31.348205      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:52:32.348631      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:52:33.349619      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:52:34.349652      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:52:35.350299      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:52:36.350519      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:52:37.351439      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:52:38.352490      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:52:39.352533      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:52:40.353015      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:52:41.353626      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:52:42.354215      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:52:43.204671 16 util.go:390] Waiting for terminating namespaces to be deleted...
  STEP: Select a node to run the lower and higher priority pods @ 09/02/25 08:52:43.213
  STEP: Adding a custom resource @ 09/02/25 08:52:43.213
  STEP: Create a low priority pod that consumes 1/1 of node resources @ 09/02/25 08:52:43.231
  I0902 08:52:43.253586 16 preemption.go:511] Created pod: victim-pod
  STEP: Wait for the victim pod to be scheduled @ 09/02/25 08:52:43.253
  E0902 08:52:43.355051      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:52:44.355196      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Create a high priority pod to trigger preemption of the lower priority pod @ 09/02/25 08:52:45.27
  I0902 08:52:45.283119 16 preemption.go:529] Created pod: preemptor-pod
  STEP: Waiting for the victim pod to be terminating @ 09/02/25 08:52:45.283
  E0902 08:52:45.356143      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:52:46.356737      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Verifying the pod has the pod disruption condition @ 09/02/25 08:52:47.348
  E0902 08:52:47.357650      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:52:47.390803 16 pod_client.go:396] Removing pod's "victim-pod" finalizer: "example.com/test-finalizer"
  I0902 08:52:47.927791 16 pod_client.go:186] Successfully updated pod "victim-pod"
  STEP: Removing a custom resource @ 09/02/25 08:52:48.019
  STEP: Removing a custom resource @ 09/02/25 08:52:48.065
  STEP: Removing a custom resource @ 09/02/25 08:52:48.096
  I0902 08:52:48.117511 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-3050" for this suite. @ 09/02/25 08:52:48.128
• [65.036 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:189
  STEP: Creating a kubernetes client @ 09/02/25 08:52:48.143
  I0902 08:52:48.143231 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename var-expansion @ 09/02/25 08:52:48.146
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:52:48.171
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:52:48.18
  E0902 08:52:48.358340      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:52:49.358061      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:52:50.227820 16 delete.go:78] Deleting pod "var-expansion-d98364c0-1e8d-42ad-bdad-7f0bd3b63e45" in namespace "var-expansion-9686"
  I0902 08:52:50.244732 16 delete.go:86] Wait up to 5m0s for pod "var-expansion-d98364c0-1e8d-42ad-bdad-7f0bd3b63e45" to be fully deleted
  E0902 08:52:50.359135      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:52:51.359509      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:52:52.259951 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-9686" for this suite. @ 09/02/25 08:52:52.269
• [4.139 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should support a Service with multiple endpoint IPs specified in multiple EndpointSlices [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:648
  STEP: Creating a kubernetes client @ 09/02/25 08:52:52.284
  I0902 08:52:52.284440 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename endpointslice @ 09/02/25 08:52:52.287
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:52:52.319
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:52:52.325
  E0902 08:52:52.359840      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:52:53.360717      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:52:54.361867      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:52:55.362229      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:52:56.362750      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: creating @ 09/02/25 08:52:56.515
  STEP: Creating a pause pods that will try to connect to the webserver @ 09/02/25 08:52:56.539
  E0902 08:52:57.363620      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:52:58.364109      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:52:58.582839 16 util.go:162] Waiting up to 2m0s to get response from 10.233.22.213:80
  I0902 08:52:58.583754 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=endpointslice-1170 exec pause-pod-0 -- /bin/sh -x -c curl -q -s --max-time 30 10.233.22.213:80/hostname'
  I0902 08:52:58.943360 16 builder.go:156] stderr: "+ curl -q -s --max-time 30 10.233.22.213:80/hostname\n"
  I0902 08:52:58.943505 16 builder.go:157] stdout: "pod1-handle-http-request"
  I0902 08:52:58.943793 16 util.go:162] Waiting up to 2m0s to get response from 10.233.22.213:81
  I0902 08:52:58.944353 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=endpointslice-1170 exec pause-pod-0 -- /bin/sh -x -c curl -q -s --max-time 30 10.233.22.213:81/hostname'
  I0902 08:52:59.267237 16 builder.go:156] stderr: "+ curl -q -s --max-time 30 10.233.22.213:81/hostname\n"
  I0902 08:52:59.267605 16 builder.go:157] stdout: "pod2-handle-http-request"
  I0902 08:52:59.267970 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-1170" for this suite. @ 09/02/25 08:52:59.279
• [7.010 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:67
  STEP: Creating a kubernetes client @ 09/02/25 08:52:59.294
  I0902 08:52:59.294202 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename projected @ 09/02/25 08:52:59.297
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:52:59.357
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:52:59.362
  E0902 08:52:59.364334      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Creating projection with secret that has name projected-secret-test-65fada1b-9705-4273-9154-4a2a03e7558c @ 09/02/25 08:52:59.368
  STEP: Creating a pod to test consume secrets @ 09/02/25 08:52:59.381
  E0902 08:53:00.364690      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:53:01.364936      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:53:02.366035      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:53:03.366351      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/02/25 08:53:03.429
  I0902 08:53:03.436722 16 output.go:207] Trying to get logs from node ietha7evai9i-2 pod pod-projected-secrets-b56c45f2-1d35-4d9c-9ee5-78bb1471dc7f container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 09/02/25 08:53:03.465
  I0902 08:53:03.504494 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9524" for this suite. @ 09/02/25 08:53:03.516
• [4.242 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:108
  STEP: Creating a kubernetes client @ 09/02/25 08:53:03.537
  I0902 08:53:03.537395 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename container-probe @ 09/02/25 08:53:03.54
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:53:03.567
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:53:03.576
  E0902 08:53:04.368165      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:53:05.368071      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:53:06.367883      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:53:07.368487      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:53:08.369660      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:53:09.370075      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:53:10.370711      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:53:11.371189      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:53:12.372180      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:53:13.372936      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:53:14.374061      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:53:15.374720      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:53:16.374998      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:53:17.376036      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:53:18.377041      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:53:19.376857      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:53:20.377032      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:53:21.377406      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:53:22.377944      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:53:23.378754      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:53:24.379703      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:53:25.379955      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:53:26.380835      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:53:27.381892      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:53:28.382322      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:53:29.383598      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:53:30.383805      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:53:31.383802      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:53:32.384023      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:53:33.384967      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:53:34.386305      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:53:35.386307      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:53:36.386337      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:53:37.387136      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:53:38.387750      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:53:39.388060      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:53:40.389032      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:53:41.389971      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:53:42.390470      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:53:43.391088      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:53:44.392274      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:53:45.392369      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:53:46.392620      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:53:47.393350      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:53:48.393662      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:53:49.393913      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:53:50.393988      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:53:51.395334      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:53:52.396005      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:53:53.397071      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:53:54.397802      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:53:55.398012      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:53:56.398794      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:53:57.399292      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:53:58.399731      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:53:59.400534      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:54:00.401148      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:54:01.402319      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:54:02.402952      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:54:03.403159      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:54:03.615194 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-7838" for this suite. @ 09/02/25 08:54:03.63
• [60.108 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Probing container should be restarted with a GRPC liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:551
  STEP: Creating a kubernetes client @ 09/02/25 08:54:03.648
  I0902 08:54:03.648769 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename container-probe @ 09/02/25 08:54:03.654
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:54:03.695
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:54:03.7
  STEP: Creating pod test-grpc-0a25b560-6518-4860-99d1-91a65443c367 in namespace container-probe-1560 @ 09/02/25 08:54:03.707
  E0902 08:54:04.403163      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:54:05.403517      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 09/02/25 08:54:05.756
  I0902 08:54:05.761486 16 container_probe.go:1749] Initial restart count of pod test-grpc-0a25b560-6518-4860-99d1-91a65443c367 is 0
  I0902 08:54:05.768330 16 container_probe.go:1759] Get pod test-grpc-0a25b560-6518-4860-99d1-91a65443c367 in namespace container-probe-1560
  E0902 08:54:06.403682      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:54:07.404013      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:54:07.778471 16 container_probe.go:1759] Get pod test-grpc-0a25b560-6518-4860-99d1-91a65443c367 in namespace container-probe-1560
  E0902 08:54:08.404221      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:54:09.404459      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:54:09.788298 16 container_probe.go:1759] Get pod test-grpc-0a25b560-6518-4860-99d1-91a65443c367 in namespace container-probe-1560
  E0902 08:54:10.404822      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:54:11.405432      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:54:11.798603 16 container_probe.go:1759] Get pod test-grpc-0a25b560-6518-4860-99d1-91a65443c367 in namespace container-probe-1560
  E0902 08:54:12.406450      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:54:13.407161      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:54:13.808336 16 container_probe.go:1759] Get pod test-grpc-0a25b560-6518-4860-99d1-91a65443c367 in namespace container-probe-1560
  E0902 08:54:14.407337      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:54:15.408026      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:54:15.817457 16 container_probe.go:1759] Get pod test-grpc-0a25b560-6518-4860-99d1-91a65443c367 in namespace container-probe-1560
  E0902 08:54:16.409070      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:54:17.409683      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:54:17.828701 16 container_probe.go:1759] Get pod test-grpc-0a25b560-6518-4860-99d1-91a65443c367 in namespace container-probe-1560
  E0902 08:54:18.410402      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:54:19.410672      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:54:19.839217 16 container_probe.go:1759] Get pod test-grpc-0a25b560-6518-4860-99d1-91a65443c367 in namespace container-probe-1560
  E0902 08:54:20.411788      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:54:21.412094      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:54:21.855814 16 container_probe.go:1759] Get pod test-grpc-0a25b560-6518-4860-99d1-91a65443c367 in namespace container-probe-1560
  E0902 08:54:22.412182      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:54:23.412422      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:54:23.867952 16 container_probe.go:1759] Get pod test-grpc-0a25b560-6518-4860-99d1-91a65443c367 in namespace container-probe-1560
  E0902 08:54:24.413048      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:54:25.413010      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:54:25.876203 16 container_probe.go:1759] Get pod test-grpc-0a25b560-6518-4860-99d1-91a65443c367 in namespace container-probe-1560
  E0902 08:54:26.413904      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:54:27.414190      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:54:27.887151 16 container_probe.go:1759] Get pod test-grpc-0a25b560-6518-4860-99d1-91a65443c367 in namespace container-probe-1560
  E0902 08:54:28.414292      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:54:29.417964      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:54:29.894109 16 container_probe.go:1759] Get pod test-grpc-0a25b560-6518-4860-99d1-91a65443c367 in namespace container-probe-1560
  E0902 08:54:30.414828      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:54:31.414977      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:54:31.902843 16 container_probe.go:1759] Get pod test-grpc-0a25b560-6518-4860-99d1-91a65443c367 in namespace container-probe-1560
  E0902 08:54:32.415748      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:54:33.415948      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:54:33.912629 16 container_probe.go:1759] Get pod test-grpc-0a25b560-6518-4860-99d1-91a65443c367 in namespace container-probe-1560
  E0902 08:54:34.417175      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:54:35.417854      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:54:35.923760 16 container_probe.go:1759] Get pod test-grpc-0a25b560-6518-4860-99d1-91a65443c367 in namespace container-probe-1560
  E0902 08:54:36.418456      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:54:37.418822      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:54:37.941428 16 container_probe.go:1759] Get pod test-grpc-0a25b560-6518-4860-99d1-91a65443c367 in namespace container-probe-1560
  E0902 08:54:38.419232      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:54:39.419814      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:54:39.950264 16 container_probe.go:1759] Get pod test-grpc-0a25b560-6518-4860-99d1-91a65443c367 in namespace container-probe-1560
  E0902 08:54:40.419966      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:54:41.420438      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:54:41.964767 16 container_probe.go:1759] Get pod test-grpc-0a25b560-6518-4860-99d1-91a65443c367 in namespace container-probe-1560
  E0902 08:54:42.420679      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:54:43.420936      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:54:43.974893 16 container_probe.go:1759] Get pod test-grpc-0a25b560-6518-4860-99d1-91a65443c367 in namespace container-probe-1560
  E0902 08:54:44.421774      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:54:45.422522      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:54:45.986820 16 container_probe.go:1759] Get pod test-grpc-0a25b560-6518-4860-99d1-91a65443c367 in namespace container-probe-1560
  E0902 08:54:46.422844      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:54:47.423136      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:54:47.999823 16 container_probe.go:1759] Get pod test-grpc-0a25b560-6518-4860-99d1-91a65443c367 in namespace container-probe-1560
  E0902 08:54:48.423232      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:54:49.423669      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:54:50.008711 16 container_probe.go:1759] Get pod test-grpc-0a25b560-6518-4860-99d1-91a65443c367 in namespace container-probe-1560
  E0902 08:54:50.424416      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:54:51.425338      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:54:52.019298 16 container_probe.go:1759] Get pod test-grpc-0a25b560-6518-4860-99d1-91a65443c367 in namespace container-probe-1560
  E0902 08:54:52.426685      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:54:53.426813      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:54:54.030152 16 container_probe.go:1759] Get pod test-grpc-0a25b560-6518-4860-99d1-91a65443c367 in namespace container-probe-1560
  E0902 08:54:54.428330      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:54:55.428994      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:54:56.039861 16 container_probe.go:1759] Get pod test-grpc-0a25b560-6518-4860-99d1-91a65443c367 in namespace container-probe-1560
  E0902 08:54:56.429109      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:54:57.429783      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:54:58.047892 16 container_probe.go:1759] Get pod test-grpc-0a25b560-6518-4860-99d1-91a65443c367 in namespace container-probe-1560
  E0902 08:54:58.430077      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:54:59.430283      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:55:00.058040 16 container_probe.go:1759] Get pod test-grpc-0a25b560-6518-4860-99d1-91a65443c367 in namespace container-probe-1560
  E0902 08:55:00.430663      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:55:01.430940      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:55:02.067206 16 container_probe.go:1759] Get pod test-grpc-0a25b560-6518-4860-99d1-91a65443c367 in namespace container-probe-1560
  E0902 08:55:02.431360      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:55:03.431817      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:55:04.077047 16 container_probe.go:1759] Get pod test-grpc-0a25b560-6518-4860-99d1-91a65443c367 in namespace container-probe-1560
  E0902 08:55:04.432638      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:55:05.433166      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:55:06.086265 16 container_probe.go:1759] Get pod test-grpc-0a25b560-6518-4860-99d1-91a65443c367 in namespace container-probe-1560
  E0902 08:55:06.433472      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:55:07.433893      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:55:08.097767 16 container_probe.go:1759] Get pod test-grpc-0a25b560-6518-4860-99d1-91a65443c367 in namespace container-probe-1560
  E0902 08:55:08.433925      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:55:09.434477      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:55:10.109756 16 container_probe.go:1759] Get pod test-grpc-0a25b560-6518-4860-99d1-91a65443c367 in namespace container-probe-1560
  E0902 08:55:10.435311      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:55:11.435745      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:55:12.118892 16 container_probe.go:1759] Get pod test-grpc-0a25b560-6518-4860-99d1-91a65443c367 in namespace container-probe-1560
  I0902 08:55:12.119035 16 container_probe.go:1763] Restart count of pod container-probe-1560/test-grpc-0a25b560-6518-4860-99d1-91a65443c367 is now 1 (1m6.357383055s elapsed)
  STEP: deleting the pod @ 09/02/25 08:55:12.119
  I0902 08:55:12.149390 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-1560" for this suite. @ 09/02/25 08:55:12.17
• [68.547 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:69
  STEP: Creating a kubernetes client @ 09/02/25 08:55:12.211
  I0902 08:55:12.211127 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename downward-api @ 09/02/25 08:55:12.218
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:55:12.248
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:55:12.255
  STEP: Creating a pod to test downward API volume plugin @ 09/02/25 08:55:12.273
  E0902 08:55:12.438633      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:55:13.438731      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:55:14.439653      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:55:15.440314      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/02/25 08:55:16.326
  I0902 08:55:16.334205 16 output.go:207] Trying to get logs from node ietha7evai9i-2 pod downwardapi-volume-fe0d7d0a-8e1a-4d7b-8a7a-53e2c959901b container client-container: <nil>
  STEP: delete the pod @ 09/02/25 08:55:16.375
  I0902 08:55:16.403249 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-3391" for this suite. @ 09/02/25 08:55:16.412
• [4.215 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown and duplicate fields of a typed object [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:62
  STEP: Creating a kubernetes client @ 09/02/25 08:55:16.427
  I0902 08:55:16.427965 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename field-validation @ 09/02/25 08:55:16.432
  E0902 08:55:16.442616      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:55:16.457
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:55:16.466
  STEP: apply creating a deployment @ 09/02/25 08:55:16.473
  I0902 08:55:16.505683 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-8213" for this suite. @ 09/02/25 08:55:16.515
• [0.103 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for ExternalName services [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:352
  STEP: Creating a kubernetes client @ 09/02/25 08:55:16.53
  I0902 08:55:16.530960 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename dns @ 09/02/25 08:55:16.536
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:55:16.56
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:55:16.566
  STEP: Creating a test externalName service @ 09/02/25 08:55:16.572
  STEP: Running these commands on agnhost: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-589.svc.cluster.local CNAME > /results/agnhost_udp@dns-test-service-3.dns-589.svc.cluster.local; sleep 1; done
   @ 09/02/25 08:55:16.586
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-589.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-589.svc.cluster.local; sleep 1; done
   @ 09/02/25 08:55:16.587
  STEP: creating a pod to probe DNS @ 09/02/25 08:55:16.587
  STEP: submitting the pod to kubernetes @ 09/02/25 08:55:16.588
  E0902 08:55:17.441739      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:55:18.442005      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 09/02/25 08:55:18.623
  STEP: looking for the results for each expected name from probers @ 09/02/25 08:55:18.632
  I0902 08:55:18.652750 16 dns_common.go:571] DNS probes using dns-test-551d4c34-4183-474a-9f94-2e325b12a3c4 succeeded

  STEP: changing the externalName to bar.example.com @ 09/02/25 08:55:18.652
  STEP: Running these commands on agnhost: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-589.svc.cluster.local CNAME > /results/agnhost_udp@dns-test-service-3.dns-589.svc.cluster.local; sleep 1; done
   @ 09/02/25 08:55:18.666
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-589.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-589.svc.cluster.local; sleep 1; done
   @ 09/02/25 08:55:18.666
  STEP: creating a second pod to probe DNS @ 09/02/25 08:55:18.666
  STEP: submitting the pod to kubernetes @ 09/02/25 08:55:18.666
  E0902 08:55:19.442929      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:55:20.443922      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:55:21.445051      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:55:22.445400      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:55:23.445426      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:55:24.446185      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:55:25.447119      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:55:26.447800      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:55:27.449225      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:55:28.450113      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:55:29.451137      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:55:30.451490      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:55:31.452234      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:55:32.453766      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:55:33.452981      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:55:34.453669      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:55:35.453662      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:55:36.454778      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:55:37.455650      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:55:38.455825      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:55:39.456865      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:55:40.458277      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:55:41.458994      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:55:42.459151      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 09/02/25 08:55:42.904
  STEP: looking for the results for each expected name from probers @ 09/02/25 08:55:42.919
  I0902 08:55:42.959753 16 dns_common.go:571] DNS probes using dns-test-c1a662c6-1215-4eeb-9bfd-295815d49bb4 succeeded

  STEP: changing the service to type=ClusterIP @ 09/02/25 08:55:42.959
  I0902 08:55:43.008669      16 warnings.go:110] "Warning: spec.externalName is ignored when spec.type is not \"ExternalName\""
  STEP: Running these commands on agnhost: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-589.svc.cluster.local A > /results/agnhost_udp@dns-test-service-3.dns-589.svc.cluster.local; sleep 1; done
   @ 09/02/25 08:55:43.008
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-589.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-589.svc.cluster.local; sleep 1; done
   @ 09/02/25 08:55:43.008
  STEP: creating a third pod to probe DNS @ 09/02/25 08:55:43.009
  STEP: submitting the pod to kubernetes @ 09/02/25 08:55:43.02
  E0902 08:55:43.459748      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:55:44.460227      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:55:45.460430      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:55:46.461359      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:55:47.462098      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:55:48.462267      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:55:49.462441      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:55:50.462833      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:55:51.463861      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:55:52.463911      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:55:53.464305      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:55:54.464514      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:55:55.465713      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:55:56.466174      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:55:57.467096      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:55:58.467786      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:55:59.468134      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:56:00.468904      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:56:01.469411      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:56:02.470017      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:56:03.470143      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:56:04.470759      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:56:05.470992      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:56:06.471785      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:56:07.471967      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:56:08.473150      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 09/02/25 08:56:09.23
  STEP: looking for the results for each expected name from probers @ 09/02/25 08:56:09.244
  I0902 08:56:09.306808 16 dns_common.go:571] DNS probes using dns-test-fd99cd86-907e-4d1f-8934-82b7e3934e9b succeeded

  STEP: deleting the pod @ 09/02/25 08:56:09.307
  STEP: deleting the pod @ 09/02/25 08:56:09.342
  STEP: deleting the pod @ 09/02/25 08:56:09.374
  STEP: deleting the test externalName service @ 09/02/25 08:56:09.443
  E0902 08:56:09.474775      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:56:09.504223 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-589" for this suite. @ 09/02/25 08:56:09.546
• [53.032 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:129
  STEP: Creating a kubernetes client @ 09/02/25 08:56:09.566
  I0902 08:56:09.566868 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename emptydir @ 09/02/25 08:56:09.572
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:56:09.599
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:56:09.61
  STEP: Creating a pod to test emptydir 0644 on tmpfs @ 09/02/25 08:56:09.618
  E0902 08:56:10.473866      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:56:11.474452      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:56:12.474939      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:56:13.475492      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/02/25 08:56:13.674
  I0902 08:56:13.685506 16 output.go:207] Trying to get logs from node ietha7evai9i-2 pod pod-051ace51-ea6e-4494-8104-e9fa4ddac739 container test-container: <nil>
  STEP: delete the pod @ 09/02/25 08:56:13.706
  I0902 08:56:13.766993 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-9268" for this suite. @ 09/02/25 08:56:13.791
• [4.241 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:157
  STEP: Creating a kubernetes client @ 09/02/25 08:56:13.808
  I0902 08:56:13.808966 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 09/02/25 08:56:13.812
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:56:13.864
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:56:13.904
  STEP: create the container to handle the HTTPGet hook request. @ 09/02/25 08:56:13.937
  E0902 08:56:14.477881      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:56:15.475427      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:56:16.476025      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:56:17.476342      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 09/02/25 08:56:18.033
  E0902 08:56:18.476740      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:56:19.477140      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: delete the pod with lifecycle hook @ 09/02/25 08:56:20.081
  E0902 08:56:20.478271      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:56:21.479094      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: check prestop hook @ 09/02/25 08:56:22.114
  I0902 08:56:22.152675 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-1503" for this suite. @ 09/02/25 08:56:22.165
• [8.382 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:194
  STEP: Creating a kubernetes client @ 09/02/25 08:56:22.191
  I0902 08:56:22.191421 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename projected @ 09/02/25 08:56:22.195
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:56:22.228
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:56:22.233
  STEP: Creating a pod to test downward API volume plugin @ 09/02/25 08:56:22.238
  E0902 08:56:22.479891      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:56:23.480164      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:56:24.480728      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:56:25.481220      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/02/25 08:56:26.298
  I0902 08:56:26.306655 16 output.go:207] Trying to get logs from node ietha7evai9i-3 pod downwardapi-volume-d454e7fd-54a8-48c2-9cb5-5b0f64f12abf container client-container: <nil>
  STEP: delete the pod @ 09/02/25 08:56:26.33
  I0902 08:56:26.362121 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2196" for this suite. @ 09/02/25 08:56:26.376
• [4.204 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:278
  STEP: Creating a kubernetes client @ 09/02/25 08:56:26.396
  I0902 08:56:26.396630 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename crd-publish-openapi @ 09/02/25 08:56:26.4
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:56:26.431
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:56:26.437
  STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation @ 09/02/25 08:56:26.444
  I0902 08:56:26.446061 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  E0902 08:56:26.483061      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:56:27.484221      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:56:28.484461      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:56:29.181416 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  E0902 08:56:29.485416      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:56:30.485719      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:56:31.486422      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:56:32.486910      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:56:33.487530      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:56:34.489014      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:56:35.489489      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:56:36.490339      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:56:37.491132      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:56:38.491295      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:56:39.049250 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-8062" for this suite. @ 09/02/25 08:56:39.095
• [12.717 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AggregatedDiscovery should support raw aggregated discovery endpoint Accept headers [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/aggregated_discovery.go:151
  STEP: Creating a kubernetes client @ 09/02/25 08:56:39.113
  I0902 08:56:39.113915 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename aggregateddiscovery @ 09/02/25 08:56:39.116
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:56:39.143
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:56:39.156
  I0902 08:56:39.179463 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregateddiscovery-4882" for this suite. @ 09/02/25 08:56:39.195
• [0.096 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] CSIStorageCapacity should support CSIStorageCapacities API operations [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/csistoragecapacity.go:50
  STEP: Creating a kubernetes client @ 09/02/25 08:56:39.21
  I0902 08:56:39.210903 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename csistoragecapacity @ 09/02/25 08:56:39.213
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:56:39.236
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:56:39.245
  STEP: getting /apis @ 09/02/25 08:56:39.25
  STEP: getting /apis/storage.k8s.io @ 09/02/25 08:56:39.259
  STEP: getting /apis/storage.k8s.io/v1 @ 09/02/25 08:56:39.261
  STEP: creating @ 09/02/25 08:56:39.269
  STEP: watching @ 09/02/25 08:56:39.322
  I0902 08:56:39.322500 16 csistoragecapacity.go:143] starting watch
  STEP: getting @ 09/02/25 08:56:39.362
  STEP: listing in namespace @ 09/02/25 08:56:39.369
  STEP: listing across namespaces @ 09/02/25 08:56:39.378
  STEP: patching @ 09/02/25 08:56:39.387
  STEP: updating @ 09/02/25 08:56:39.406
  I0902 08:56:39.418679 16 csistoragecapacity.go:181] waiting for watch events with expected annotations in namespace
  I0902 08:56:39.418994 16 csistoragecapacity.go:181] waiting for watch events with expected annotations across namespace
  STEP: deleting @ 09/02/25 08:56:39.419
  STEP: deleting a collection @ 09/02/25 08:56:39.45
  I0902 08:56:39.486180 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  E0902 08:56:39.491696      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Destroying namespace "csistoragecapacity-9327" for this suite. @ 09/02/25 08:56:39.499
• [0.304 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/events.go:98
  STEP: Creating a kubernetes client @ 09/02/25 08:56:39.515
  I0902 08:56:39.515950 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename events @ 09/02/25 08:56:39.522
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:56:39.551
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:56:39.556
  STEP: creating a test event @ 09/02/25 08:56:39.561
  STEP: listing events in all namespaces @ 09/02/25 08:56:39.572
  STEP: listing events in test namespace @ 09/02/25 08:56:39.58
  STEP: listing events with field selection filtering on source @ 09/02/25 08:56:39.587
  STEP: listing events with field selection filtering on reportingController @ 09/02/25 08:56:39.595
  STEP: getting the test event @ 09/02/25 08:56:39.603
  STEP: patching the test event @ 09/02/25 08:56:39.61
  STEP: getting the test event @ 09/02/25 08:56:39.627
  STEP: updating the test event @ 09/02/25 08:56:39.634
  STEP: getting the test event @ 09/02/25 08:56:39.65
  STEP: deleting the test event @ 09/02/25 08:56:39.657
  STEP: listing events in all namespaces @ 09/02/25 08:56:39.676
  STEP: listing events in test namespace @ 09/02/25 08:56:39.682
  I0902 08:56:39.690366 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-4460" for this suite. @ 09/02/25 08:56:39.699
• [0.201 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:90
  STEP: Creating a kubernetes client @ 09/02/25 08:56:39.717
  I0902 08:56:39.717736 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename disruption @ 09/02/25 08:56:39.72
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:56:39.745
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:56:39.752
  STEP: Creating a kubernetes client @ 09/02/25 08:56:39.758
  I0902 08:56:39.758475 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename disruption-2 @ 09/02/25 08:56:39.76
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:56:39.791
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:56:39.797
  STEP: Waiting for the pdb to be processed @ 09/02/25 08:56:39.815
  E0902 08:56:40.492331      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:56:41.492384      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Waiting for the pdb to be processed @ 09/02/25 08:56:41.834
  E0902 08:56:42.492674      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:56:43.492879      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Waiting for the pdb to be processed @ 09/02/25 08:56:43.863
  E0902 08:56:44.493922      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:56:45.494526      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: listing a collection of PDBs across all namespaces @ 09/02/25 08:56:45.87
  STEP: listing a collection of PDBs in namespace disruption-6677 @ 09/02/25 08:56:45.88
  STEP: deleting a collection of PDBs @ 09/02/25 08:56:45.889
  STEP: Waiting for the PDB collection to be deleted @ 09/02/25 08:56:45.918
  I0902 08:56:45.925107 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-2-3995" for this suite. @ 09/02/25 08:56:45.94
  I0902 08:56:45.959817 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-6677" for this suite. @ 09/02/25 08:56:46.036
• [6.334 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] PodTemplates should delete a collection of pod templates [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/podtemplates.go:123
  STEP: Creating a kubernetes client @ 09/02/25 08:56:46.051
  I0902 08:56:46.052015 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename podtemplate @ 09/02/25 08:56:46.054
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:56:46.082
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:56:46.088
  STEP: Create set of pod templates @ 09/02/25 08:56:46.093
  I0902 08:56:46.105470 16 podtemplates.go:143] created test-podtemplate-1
  I0902 08:56:46.115457 16 podtemplates.go:143] created test-podtemplate-2
  I0902 08:56:46.125371 16 podtemplates.go:143] created test-podtemplate-3
  STEP: get a list of pod templates with a label in the current namespace @ 09/02/25 08:56:46.125
  STEP: delete collection of pod templates @ 09/02/25 08:56:46.131
  I0902 08:56:46.131525 16 podtemplates.go:158] requesting DeleteCollection of pod templates
  STEP: check that the list of pod templates matches the requested quantity @ 09/02/25 08:56:46.167
  I0902 08:56:46.167179 16 podtemplates.go:219] requesting list of pod templates to confirm quantity
  I0902 08:56:46.175588 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-1328" for this suite. @ 09/02/25 08:56:46.187
• [0.152 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:76
  STEP: Creating a kubernetes client @ 09/02/25 08:56:46.204
  I0902 08:56:46.204322 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename containers @ 09/02/25 08:56:46.208
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:56:46.282
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:56:46.291
  STEP: Creating a pod to test override command @ 09/02/25 08:56:46.296
  E0902 08:56:46.495106      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:56:47.495615      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:56:48.497336      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:56:49.496930      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/02/25 08:56:50.37
  I0902 08:56:50.383792 16 output.go:207] Trying to get logs from node ietha7evai9i-2 pod client-containers-deb8df0a-c38b-4da2-bafb-971cd5a6e717 container agnhost-container: <nil>
  STEP: delete the pod @ 09/02/25 08:56:50.402
  I0902 08:56:50.446731 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-5597" for this suite. @ 09/02/25 08:56:50.459
• [4.274 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update mutating webhook configurations with match conditions [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:762
  STEP: Creating a kubernetes client @ 09/02/25 08:56:50.482
  I0902 08:56:50.482964 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename webhook @ 09/02/25 08:56:50.489
  E0902 08:56:50.498014      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:56:50.517
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:56:50.522
  STEP: Setting up server cert @ 09/02/25 08:56:50.57
  E0902 08:56:51.498432      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 09/02/25 08:56:52.352
  STEP: Deploying the webhook pod @ 09/02/25 08:56:52.371
  STEP: Wait for the deployment to be ready @ 09/02/25 08:56:52.398
  I0902 08:56:52.434534 16 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0902 08:56:52.499504      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:56:53.500178      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 09/02/25 08:56:54.459
  STEP: Verifying the service has paired with the endpoint @ 09/02/25 08:56:54.489
  E0902 08:56:54.500284      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:56:55.491041 16 util.go:419] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  E0902 08:56:55.500361      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: creating a mutating webhook with match conditions @ 09/02/25 08:56:55.505
  STEP: verifying the mutating webhook match conditions @ 09/02/25 08:56:55.526
  STEP: updating the mutating webhook match conditions @ 09/02/25 08:56:55.535
  STEP: verifying the mutating webhook match conditions @ 09/02/25 08:56:55.573
  I0902 08:56:55.736650 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-6443" for this suite. @ 09/02/25 08:56:55.751
  STEP: Destroying namespace "webhook-markers-8260" for this suite. @ 09/02/25 08:56:55.784
• [5.319 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] CronJob should schedule multiple jobs concurrently [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:70
  STEP: Creating a kubernetes client @ 09/02/25 08:56:55.802
  I0902 08:56:55.802041 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename cronjob @ 09/02/25 08:56:55.808
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:56:55.842
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:56:55.849
  STEP: Creating a cronjob @ 09/02/25 08:56:55.857
  STEP: Ensuring more than one job is running at a time @ 09/02/25 08:56:55.877
  E0902 08:56:56.501506      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:56:57.502062      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:56:58.502285      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:56:59.503059      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:57:00.503510      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:57:01.503875      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:57:02.504891      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:57:03.505053      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:57:04.505305      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:57:05.505773      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:57:06.506873      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:57:07.507654      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:57:08.507794      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:57:09.508541      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:57:10.509166      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:57:11.509068      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:57:12.509450      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:57:13.510051      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:57:14.510869      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:57:15.511670      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:57:16.512699      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:57:17.512809      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:57:18.513275      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:57:19.513780      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:57:20.514424      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:57:21.514920      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:57:22.514981      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:57:23.515346      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:57:24.516466      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:57:25.516021      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:57:26.516216      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:57:27.516501      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:57:28.516859      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:57:29.517371      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:57:30.517848      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:57:31.518268      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:57:32.518599      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:57:33.518910      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:57:34.519283      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:57:35.519957      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:57:36.520318      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:57:37.520498      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:57:38.521410      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:57:39.522163      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:57:40.522351      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:57:41.523185      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:57:42.523376      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:57:43.524256      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:57:44.524477      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:57:45.524760      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:57:46.524842      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:57:47.524935      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:57:48.525700      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:57:49.526659      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:57:50.526305      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:57:51.527060      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:57:52.527893      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:57:53.527927      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:57:54.529004      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:57:55.529871      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:57:56.530262      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:57:57.531402      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:57:58.531676      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:57:59.532370      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:58:00.533661      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:58:01.534891      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Ensuring at least two running jobs exists by listing jobs explicitly @ 09/02/25 08:58:01.896
  STEP: Removing cronjob @ 09/02/25 08:58:01.913
  I0902 08:58:01.945938 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-7284" for this suite. @ 09/02/25 08:58:01.963
• [66.179 seconds]
------------------------------
SSSSSS
------------------------------
[sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2252
  STEP: Creating a kubernetes client @ 09/02/25 08:58:01.984
  I0902 08:58:01.984825 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename services @ 09/02/25 08:58:01.996
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:58:02.039
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:58:02.047
  STEP: creating service in namespace services-7106 @ 09/02/25 08:58:02.063
  STEP: creating service affinity-clusterip-transition in namespace services-7106 @ 09/02/25 08:58:02.063
  I0902 08:58:02.129304 16 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:0, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:0, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition(nil), CollisionCount:(*int32)(nil)}
  E0902 08:58:02.534872      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:58:03.535191      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:58:04.144181 16 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:3, UpdatedReplicas:3, ReadyReplicas:2, AvailableReplicas:2, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.September, 2, 8, 58, 2, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 8, 58, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.September, 2, 8, 58, 3, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 8, 58, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"affinity-clusterip-transition-66686d5d57\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0902 08:58:04.536418      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:58:05.536625      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:58:06.215528 16 resource.go:344] Creating new exec pod
  E0902 08:58:06.536416      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:58:07.536954      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:58:08.260161 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=services-7106 exec execpod-affinityngdww -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
  E0902 08:58:08.536976      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:58:08.631586 16 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition (10.233.52.236) 80 port [tcp/http] succeeded!\n"
  I0902 08:58:08.631712 16 builder.go:157] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0902 08:58:08.631956 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=services-7106 exec execpod-affinityngdww -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.52.236 80'
  I0902 08:58:08.921807 16 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.52.236 80\nConnection to 10.233.52.236 80 port [tcp/http] succeeded!\n"
  I0902 08:58:08.921927 16 builder.go:157] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0902 08:58:08.946095 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=services-7106 exec execpod-affinityngdww -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 --max-time 60 http://10.233.52.236:80/ ; done'
  E0902 08:58:09.538015      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:58:09.684627 16 builder.go:156] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.233.52.236:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.233.52.236:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.233.52.236:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.233.52.236:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.233.52.236:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.233.52.236:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.233.52.236:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.233.52.236:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.233.52.236:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.233.52.236:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.233.52.236:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.233.52.236:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.233.52.236:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.233.52.236:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.233.52.236:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.233.52.236:80/\n"
  I0902 08:58:09.685022 16 builder.go:157] stdout: "\naffinity-clusterip-transition-66686d5d57-nlc24\naffinity-clusterip-transition-66686d5d57-lmts9\naffinity-clusterip-transition-66686d5d57-nlc24\naffinity-clusterip-transition-66686d5d57-nlc24\naffinity-clusterip-transition-66686d5d57-nlc24\naffinity-clusterip-transition-66686d5d57-nlc24\naffinity-clusterip-transition-66686d5d57-lmts9\naffinity-clusterip-transition-66686d5d57-lmts9\naffinity-clusterip-transition-66686d5d57-nlc24\naffinity-clusterip-transition-66686d5d57-776vb\naffinity-clusterip-transition-66686d5d57-lmts9\naffinity-clusterip-transition-66686d5d57-lmts9\naffinity-clusterip-transition-66686d5d57-nlc24\naffinity-clusterip-transition-66686d5d57-lmts9\naffinity-clusterip-transition-66686d5d57-776vb\naffinity-clusterip-transition-66686d5d57-776vb"
  I0902 08:58:09.685144 16 service.go:225] Received response from host: affinity-clusterip-transition-66686d5d57-nlc24
  I0902 08:58:09.685306 16 service.go:225] Received response from host: affinity-clusterip-transition-66686d5d57-lmts9
  I0902 08:58:09.685442 16 service.go:225] Received response from host: affinity-clusterip-transition-66686d5d57-nlc24
  I0902 08:58:09.685466 16 service.go:225] Received response from host: affinity-clusterip-transition-66686d5d57-nlc24
  I0902 08:58:09.685685 16 service.go:225] Received response from host: affinity-clusterip-transition-66686d5d57-nlc24
  I0902 08:58:09.685843 16 service.go:225] Received response from host: affinity-clusterip-transition-66686d5d57-nlc24
  I0902 08:58:09.686003 16 service.go:225] Received response from host: affinity-clusterip-transition-66686d5d57-lmts9
  I0902 08:58:09.686050 16 service.go:225] Received response from host: affinity-clusterip-transition-66686d5d57-lmts9
  I0902 08:58:09.686191 16 service.go:225] Received response from host: affinity-clusterip-transition-66686d5d57-nlc24
  I0902 08:58:09.686211 16 service.go:225] Received response from host: affinity-clusterip-transition-66686d5d57-776vb
  I0902 08:58:09.686345 16 service.go:225] Received response from host: affinity-clusterip-transition-66686d5d57-lmts9
  I0902 08:58:09.686363 16 service.go:225] Received response from host: affinity-clusterip-transition-66686d5d57-lmts9
  I0902 08:58:09.686525 16 service.go:225] Received response from host: affinity-clusterip-transition-66686d5d57-nlc24
  I0902 08:58:09.686603 16 service.go:225] Received response from host: affinity-clusterip-transition-66686d5d57-lmts9
  I0902 08:58:09.686757 16 service.go:225] Received response from host: affinity-clusterip-transition-66686d5d57-776vb
  I0902 08:58:09.686781 16 service.go:225] Received response from host: affinity-clusterip-transition-66686d5d57-776vb
  I0902 08:58:09.710113 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=services-7106 exec execpod-affinityngdww -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 --max-time 60 http://10.233.52.236:80/ ; done'
  I0902 08:58:10.380519 16 builder.go:156] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.233.52.236:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.233.52.236:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.233.52.236:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.233.52.236:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.233.52.236:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.233.52.236:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.233.52.236:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.233.52.236:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.233.52.236:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.233.52.236:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.233.52.236:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.233.52.236:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.233.52.236:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.233.52.236:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.233.52.236:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.233.52.236:80/\n"
  I0902 08:58:10.380914 16 builder.go:157] stdout: "\naffinity-clusterip-transition-66686d5d57-nlc24\naffinity-clusterip-transition-66686d5d57-nlc24\naffinity-clusterip-transition-66686d5d57-lmts9\naffinity-clusterip-transition-66686d5d57-lmts9\naffinity-clusterip-transition-66686d5d57-lmts9\naffinity-clusterip-transition-66686d5d57-lmts9\naffinity-clusterip-transition-66686d5d57-lmts9\naffinity-clusterip-transition-66686d5d57-lmts9\naffinity-clusterip-transition-66686d5d57-lmts9\naffinity-clusterip-transition-66686d5d57-lmts9\naffinity-clusterip-transition-66686d5d57-lmts9\naffinity-clusterip-transition-66686d5d57-lmts9\naffinity-clusterip-transition-66686d5d57-lmts9\naffinity-clusterip-transition-66686d5d57-lmts9\naffinity-clusterip-transition-66686d5d57-lmts9\naffinity-clusterip-transition-66686d5d57-lmts9"
  I0902 08:58:10.380990 16 service.go:225] Received response from host: affinity-clusterip-transition-66686d5d57-nlc24
  I0902 08:58:10.381017 16 service.go:225] Received response from host: affinity-clusterip-transition-66686d5d57-nlc24
  I0902 08:58:10.381035 16 service.go:225] Received response from host: affinity-clusterip-transition-66686d5d57-lmts9
  I0902 08:58:10.381083 16 service.go:225] Received response from host: affinity-clusterip-transition-66686d5d57-lmts9
  I0902 08:58:10.381103 16 service.go:225] Received response from host: affinity-clusterip-transition-66686d5d57-lmts9
  I0902 08:58:10.381186 16 service.go:225] Received response from host: affinity-clusterip-transition-66686d5d57-lmts9
  I0902 08:58:10.381608 16 service.go:225] Received response from host: affinity-clusterip-transition-66686d5d57-lmts9
  I0902 08:58:10.381634 16 service.go:225] Received response from host: affinity-clusterip-transition-66686d5d57-lmts9
  I0902 08:58:10.381748 16 service.go:225] Received response from host: affinity-clusterip-transition-66686d5d57-lmts9
  I0902 08:58:10.381881 16 service.go:225] Received response from host: affinity-clusterip-transition-66686d5d57-lmts9
  I0902 08:58:10.382037 16 service.go:225] Received response from host: affinity-clusterip-transition-66686d5d57-lmts9
  I0902 08:58:10.382061 16 service.go:225] Received response from host: affinity-clusterip-transition-66686d5d57-lmts9
  I0902 08:58:10.382148 16 service.go:225] Received response from host: affinity-clusterip-transition-66686d5d57-lmts9
  I0902 08:58:10.382273 16 service.go:225] Received response from host: affinity-clusterip-transition-66686d5d57-lmts9
  I0902 08:58:10.382355 16 service.go:225] Received response from host: affinity-clusterip-transition-66686d5d57-lmts9
  I0902 08:58:10.382375 16 service.go:225] Received response from host: affinity-clusterip-transition-66686d5d57-lmts9
  E0902 08:58:10.537836      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:58:11.538295      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:58:12.539299      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:58:13.539795      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:58:14.540849      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:58:15.541262      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:58:16.541681      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:58:17.541895      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:58:18.542249      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:58:19.542457      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:58:20.542613      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:58:21.543112      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:58:22.543727      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:58:23.544285      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:58:24.544659      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:58:25.544760      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:58:26.544942      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:58:27.545909      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:58:28.546511      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:58:29.546753      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:58:30.546786      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:58:31.547223      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:58:32.547204      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:58:33.547728      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:58:34.547702      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:58:35.547819      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:58:36.548083      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:58:37.548917      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:58:38.554584      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:58:39.551873      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:58:40.383586 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=services-7106 exec execpod-affinityngdww -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 --max-time 60 http://10.233.52.236:80/ ; done'
  E0902 08:58:40.552393      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:58:40.996441 16 builder.go:156] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.233.52.236:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.233.52.236:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.233.52.236:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.233.52.236:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.233.52.236:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.233.52.236:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.233.52.236:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.233.52.236:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.233.52.236:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.233.52.236:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.233.52.236:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.233.52.236:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.233.52.236:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.233.52.236:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.233.52.236:80/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://10.233.52.236:80/\n"
  I0902 08:58:40.996823 16 builder.go:157] stdout: "\naffinity-clusterip-transition-66686d5d57-lmts9\naffinity-clusterip-transition-66686d5d57-lmts9\naffinity-clusterip-transition-66686d5d57-lmts9\naffinity-clusterip-transition-66686d5d57-lmts9\naffinity-clusterip-transition-66686d5d57-lmts9\naffinity-clusterip-transition-66686d5d57-lmts9\naffinity-clusterip-transition-66686d5d57-lmts9\naffinity-clusterip-transition-66686d5d57-lmts9\naffinity-clusterip-transition-66686d5d57-lmts9\naffinity-clusterip-transition-66686d5d57-lmts9\naffinity-clusterip-transition-66686d5d57-lmts9\naffinity-clusterip-transition-66686d5d57-lmts9\naffinity-clusterip-transition-66686d5d57-lmts9\naffinity-clusterip-transition-66686d5d57-lmts9\naffinity-clusterip-transition-66686d5d57-lmts9\naffinity-clusterip-transition-66686d5d57-lmts9"
  I0902 08:58:40.996888 16 service.go:225] Received response from host: affinity-clusterip-transition-66686d5d57-lmts9
  I0902 08:58:40.996912 16 service.go:225] Received response from host: affinity-clusterip-transition-66686d5d57-lmts9
  I0902 08:58:40.996929 16 service.go:225] Received response from host: affinity-clusterip-transition-66686d5d57-lmts9
  I0902 08:58:40.996945 16 service.go:225] Received response from host: affinity-clusterip-transition-66686d5d57-lmts9
  I0902 08:58:40.996961 16 service.go:225] Received response from host: affinity-clusterip-transition-66686d5d57-lmts9
  I0902 08:58:40.996976 16 service.go:225] Received response from host: affinity-clusterip-transition-66686d5d57-lmts9
  I0902 08:58:40.996992 16 service.go:225] Received response from host: affinity-clusterip-transition-66686d5d57-lmts9
  I0902 08:58:40.997007 16 service.go:225] Received response from host: affinity-clusterip-transition-66686d5d57-lmts9
  I0902 08:58:40.997023 16 service.go:225] Received response from host: affinity-clusterip-transition-66686d5d57-lmts9
  I0902 08:58:40.997065 16 service.go:225] Received response from host: affinity-clusterip-transition-66686d5d57-lmts9
  I0902 08:58:40.997082 16 service.go:225] Received response from host: affinity-clusterip-transition-66686d5d57-lmts9
  I0902 08:58:40.997097 16 service.go:225] Received response from host: affinity-clusterip-transition-66686d5d57-lmts9
  I0902 08:58:40.997112 16 service.go:225] Received response from host: affinity-clusterip-transition-66686d5d57-lmts9
  I0902 08:58:40.997127 16 service.go:225] Received response from host: affinity-clusterip-transition-66686d5d57-lmts9
  I0902 08:58:40.997167 16 service.go:225] Received response from host: affinity-clusterip-transition-66686d5d57-lmts9
  I0902 08:58:40.997182 16 service.go:225] Received response from host: affinity-clusterip-transition-66686d5d57-lmts9
  I0902 08:58:40.997308 16 service.go:4469] Cleaning up the exec pod
  I0902 08:58:41.239074 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-7106" for this suite. @ 09/02/25 08:58:41.308
  E0902 08:58:41.552758      16 retrywatcher.go:169] "Watch failed" err="context canceled"
• [39.602 seconds]
------------------------------
SS
------------------------------
[sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:132
  STEP: Creating a kubernetes client @ 09/02/25 08:58:41.583
  I0902 08:58:41.583778 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename replicaset @ 09/02/25 08:58:41.586
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:58:41.663
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:58:41.675
  STEP: Given a Pod with a 'name' label pod-adoption-release is created @ 09/02/25 08:58:41.694
  E0902 08:58:42.552740      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:58:43.553501      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: When a replicaset with a matching selector is created @ 09/02/25 08:58:43.767
  STEP: Then the orphan pod is adopted @ 09/02/25 08:58:43.78
  E0902 08:58:44.553809      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: When the matched label of one of its pods change @ 09/02/25 08:58:44.802
  I0902 08:58:44.810899 16 resource.go:64] Pod name pod-adoption-release: Found 1 pods out of 1
  STEP: Then the pod is released @ 09/02/25 08:58:44.847
  E0902 08:58:45.554031      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:58:45.868777 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-9411" for this suite. @ 09/02/25 08:58:45.879
• [4.311 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:248
  STEP: Creating a kubernetes client @ 09/02/25 08:58:45.898
  I0902 08:58:45.898119 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename downward-api @ 09/02/25 08:58:45.901
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:58:45.935
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:58:45.949
  STEP: Creating a pod to test downward api env vars @ 09/02/25 08:58:45.958
  E0902 08:58:46.555041      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:58:47.555293      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:58:48.555849      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:58:49.556334      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/02/25 08:58:50.042
  I0902 08:58:50.053385 16 output.go:207] Trying to get logs from node ietha7evai9i-1 pod downward-api-37fd68ae-c1a1-4682-9e21-17cef25d79b1 container dapi-container: <nil>
  STEP: delete the pod @ 09/02/25 08:58:50.101
  I0902 08:58:50.140211 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-3681" for this suite. @ 09/02/25 08:58:50.148
• [4.268 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:90
  STEP: Creating a kubernetes client @ 09/02/25 08:58:50.169
  I0902 08:58:50.169975 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename containers @ 09/02/25 08:58:50.172
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:58:50.197
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:58:50.203
  STEP: Creating a pod to test override all @ 09/02/25 08:58:50.209
  E0902 08:58:50.556355      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:58:51.556733      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:58:52.556898      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:58:53.557433      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/02/25 08:58:54.267
  I0902 08:58:54.275072 16 output.go:207] Trying to get logs from node ietha7evai9i-1 pod client-containers-7fa0e268-ba22-4eb1-9896-959830d97ee9 container agnhost-container: <nil>
  STEP: delete the pod @ 09/02/25 08:58:54.291
  I0902 08:58:54.329170 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-689" for this suite. @ 09/02/25 08:58:54.342
• [4.191 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:443
  STEP: Creating a kubernetes client @ 09/02/25 08:58:54.363
  I0902 08:58:54.363158 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename daemonsets @ 09/02/25 08:58:54.367
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:58:54.398
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:58:54.404
  I0902 08:58:54.472983 16 daemon_set.go:447] Create a RollingUpdate DaemonSet
  I0902 08:58:54.483608 16 daemon_set.go:454] Check that daemon pods launch on every node of the cluster
  E0902 08:58:54.557642      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:58:54.598345 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0902 08:58:54.598456 16 fixtures.go:131] Node ietha7evai9i-1 is running 0 daemon pod, expected 1
  I0902 08:58:55.519200 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0902 08:58:55.519275 16 fixtures.go:131] Node ietha7evai9i-1 is running 0 daemon pod, expected 1
  E0902 08:58:55.558989      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:58:56.524112 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0902 08:58:56.524285 16 fixtures.go:131] Node ietha7evai9i-1 is running 0 daemon pod, expected 1
  E0902 08:58:56.559453      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:58:57.515213 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I0902 08:58:57.515364 16 fixtures.go:136] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  I0902 08:58:57.515457 16 daemon_set.go:458] Update the DaemonSet to trigger a rollout
  I0902 08:58:57.540099 16 daemon_set.go:102] Updating DaemonSet daemon-set
  E0902 08:58:57.560337      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:58:58.561914      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:58:58.566024 16 daemon_set.go:493] Roll back the DaemonSet before rollout is complete
  I0902 08:58:58.587384 16 daemon_set.go:102] Updating DaemonSet daemon-set
  I0902 08:58:58.587478 16 daemon_set.go:499] Make sure DaemonSet rollback is complete
  E0902 08:58:59.562238      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:59:00.562343      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:59:01.562806      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:59:02.563058      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:59:03.563195      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:59:04.564100      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:59:05.564208      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:59:06.564417      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:59:07.564923      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:59:08.565020      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:59:09.565330      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:59:09.599930 16 daemon_set.go:1198] Pod daemon-set-82mbk is not available
  STEP: Deleting DaemonSet "daemon-set" @ 09/02/25 08:59:09.625
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6356, will wait for the garbage collector to delete the pods @ 09/02/25 08:59:09.625
  I0902 08:59:09.698858 16 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 15.452821ms
  I0902 08:59:09.801101 16 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 102.230259ms
  E0902 08:59:10.566136      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:59:11.566918      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:59:12.110782 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0902 08:59:12.110930 16 fixtures.go:136] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I0902 08:59:12.121421 16 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"45724"},"items":null}

  I0902 08:59:12.127441 16 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"45724"},"items":null}

  I0902 08:59:12.168049 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-6356" for this suite. @ 09/02/25 08:59:12.179
• [17.832 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:603
  STEP: Creating a kubernetes client @ 09/02/25 08:59:12.195
  I0902 08:59:12.195690 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename security-context-test @ 09/02/25 08:59:12.197
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:59:12.222
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:59:12.227
  E0902 08:59:12.567774      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:59:13.568528      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:59:14.568817      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:59:15.569018      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:59:16.289483 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-1781" for this suite. @ 09/02/25 08:59:16.298
• [4.121 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:96
  STEP: Creating a kubernetes client @ 09/02/25 08:59:16.317
  I0902 08:59:16.317652 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename pod-network-test @ 09/02/25 08:59:16.32
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:59:16.352
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:59:16.358
  STEP: Performing setup for networking test in namespace pod-network-test-2831 @ 09/02/25 08:59:16.365
  STEP: creating a selector @ 09/02/25 08:59:16.365
  STEP: Creating the service pods in kubernetes @ 09/02/25 08:59:16.365
  I0902 08:59:16.365467 16 helper.go:51] Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0902 08:59:16.569747      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:59:17.569645      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:59:18.569790      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:59:19.570114      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:59:20.570847      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:59:21.571138      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:59:22.572193      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:59:23.572889      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:59:24.573164      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:59:25.573299      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:59:26.573342      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:59:27.573539      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:59:28.574456      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:59:29.574779      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:59:30.575122      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 09/02/25 08:59:30.591
  E0902 08:59:31.576135      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:59:32.576244      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:59:32.634977 16 utils.go:803] Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  I0902 08:59:32.635051 16 networking.go:42] Breadth first check of 10.233.64.27 on host 192.168.121.25...
  I0902 08:59:32.642208 16 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.66.56:9080/dial?request=hostname&protocol=udp&host=10.233.64.27&port=8081&tries=1'] Namespace:pod-network-test-2831 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0902 08:59:32.642326 16 exec_util.go:68] ExecWithOptions: Clientset creation
  I0902 08:59:32.642613 16 exec_util.go:84] ExecWithOptions: execute(https://10.233.0.1:443/api/v1/namespaces/pod-network-test-2831/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.66.56%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.233.64.27%26port%3D8081%26tries%3D1%27&container=webserver&stderr=true&stdout=true)
  I0902 08:59:32.823850 16 utils.go:356] Waiting for responses: map[]
  I0902 08:59:32.823961 16 utils.go:360] reached 10.233.64.27 after 0/1 tries
  I0902 08:59:32.824006 16 networking.go:42] Breadth first check of 10.233.66.50 on host 192.168.121.46...
  I0902 08:59:32.831907 16 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.66.56:9080/dial?request=hostname&protocol=udp&host=10.233.66.50&port=8081&tries=1'] Namespace:pod-network-test-2831 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0902 08:59:32.831980 16 exec_util.go:68] ExecWithOptions: Clientset creation
  I0902 08:59:32.832472 16 exec_util.go:84] ExecWithOptions: execute(https://10.233.0.1:443/api/v1/namespaces/pod-network-test-2831/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.66.56%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.233.66.50%26port%3D8081%26tries%3D1%27&container=webserver&stderr=true&stdout=true)
  I0902 08:59:32.962863 16 utils.go:356] Waiting for responses: map[]
  I0902 08:59:32.962954 16 utils.go:360] reached 10.233.66.50 after 0/1 tries
  I0902 08:59:32.962989 16 networking.go:42] Breadth first check of 10.233.65.235 on host 192.168.121.52...
  I0902 08:59:32.974397 16 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.66.56:9080/dial?request=hostname&protocol=udp&host=10.233.65.235&port=8081&tries=1'] Namespace:pod-network-test-2831 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0902 08:59:32.974472 16 exec_util.go:68] ExecWithOptions: Clientset creation
  I0902 08:59:32.974629 16 exec_util.go:84] ExecWithOptions: execute(https://10.233.0.1:443/api/v1/namespaces/pod-network-test-2831/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.66.56%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.233.65.235%26port%3D8081%26tries%3D1%27&container=webserver&stderr=true&stdout=true)
  I0902 08:59:33.093965 16 utils.go:356] Waiting for responses: map[]
  I0902 08:59:33.094103 16 utils.go:360] reached 10.233.65.235 after 0/1 tries
  I0902 08:59:33.094146 16 networking.go:53] Going to retry 0 out of 3 pods....
  I0902 08:59:33.094695 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-2831" for this suite. @ 09/02/25 08:59:33.106
• [16.806 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] FieldValidation should create/apply a valid CR for CRD with validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:166
  STEP: Creating a kubernetes client @ 09/02/25 08:59:33.124
  I0902 08:59:33.124083 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename field-validation @ 09/02/25 08:59:33.127
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:59:33.156
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:59:33.163
  I0902 08:59:33.170342 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  I0902 08:59:33.198825      16 warnings.go:110] "Warning: unrecognized format \"int32\""
  E0902 08:59:33.577714      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:59:34.578120      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:59:35.578324      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 08:59:35.942299      16 warnings.go:110] "Warning: unknown field \"alpha\""
  I0902 08:59:35.942616      16 warnings.go:110] "Warning: unknown field \"beta\""
  I0902 08:59:35.942669      16 warnings.go:110] "Warning: unknown field \"delta\""
  I0902 08:59:35.942756      16 warnings.go:110] "Warning: unknown field \"epsilon\""
  I0902 08:59:35.942801      16 warnings.go:110] "Warning: unknown field \"gamma\""
  I0902 08:59:36.569254 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  E0902 08:59:36.578417      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Destroying namespace "field-validation-7593" for this suite. @ 09/02/25 08:59:36.579
• [3.474 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/podtemplates.go:54
  STEP: Creating a kubernetes client @ 09/02/25 08:59:36.602
  I0902 08:59:36.602145 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename podtemplate @ 09/02/25 08:59:36.605
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:59:36.63
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:59:36.648
  I0902 08:59:36.789830 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-1286" for this suite. @ 09/02/25 08:59:36.799
• [0.216 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should mount projected service account token [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:305
  STEP: Creating a kubernetes client @ 09/02/25 08:59:36.822
  I0902 08:59:36.822052 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename svcaccounts @ 09/02/25 08:59:36.824
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:59:36.864
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:59:36.873
  STEP: Creating a pod to test service account token:  @ 09/02/25 08:59:36.881
  E0902 08:59:37.580924      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:59:38.581283      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:59:39.581454      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:59:40.581247      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/02/25 08:59:40.944
  I0902 08:59:40.955888 16 output.go:207] Trying to get logs from node ietha7evai9i-3 pod test-pod-368fac85-43ca-4f1a-a71e-db53d6d41579 container agnhost-container: <nil>
  STEP: delete the pod @ 09/02/25 08:59:40.993
  I0902 08:59:41.024632 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-3151" for this suite. @ 09/02/25 08:59:41.036
• [4.231 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:337
  STEP: Creating a kubernetes client @ 09/02/25 08:59:41.054
  I0902 08:59:41.054346 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename resourcequota @ 09/02/25 08:59:41.057
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 08:59:41.091
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 08:59:41.106
  E0902 08:59:41.582035      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:59:42.582710      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:59:43.583459      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:59:44.583332      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:59:45.584278      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:59:46.585006      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:59:47.585435      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:59:48.585707      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:59:49.586730      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:59:50.586824      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:59:51.587710      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:59:52.587871      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:59:53.588678      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:59:54.589941      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:59:55.590633      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:59:56.591748      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:59:57.592853      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Counting existing ResourceQuota @ 09/02/25 08:59:58.125
  E0902 08:59:58.593173      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 08:59:59.593508      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:00:00.593732      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:00:01.594000      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:00:02.594909      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 09/02/25 09:00:03.142
  STEP: Ensuring resource quota status is calculated @ 09/02/25 09:00:03.157
  E0902 09:00:03.595524      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:00:04.595774      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:00:05.180405 16 resource_quota.go:2495] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc00397b680>: 
          metadata:
            creationTimestamp: "2025-09-02T09:00:03Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: e2e.test
              operation: Update
              time: "2025-09-02T09:00:03Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
                  f:used:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: kube-controller-manager
              operation: Update
              subresource: status
              time: "2025-09-02T09:00:03Z"
            name: test-quota
            namespace: resourcequota-336
            resourceVersion: "46050"
            uid: fb7fcb4a-8390-4f88-a5ce-fca6d89f56f6
          spec:
            hard:
              configmaps: "2"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
          status:
            hard:
              configmaps: "2"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
            used:
              configmaps: "1"
              count/replicasets.apps: "0"
              cpu: "0"
              ephemeral-storage: "0"
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "0"
              gold.storageclass.storage.k8s.io/requests.storage: "0"
              memory: "0"
              persistentvolumeclaims: "0"
              pods: "0"
              replicationcontrollers: "0"
              requests.example.com/dongle: "0"
              requests.storage: "0"
              resourcequotas: "1"
              secrets: "0"
              services: "0"
              services.loadbalancers: "0"
              services.nodeports: "0"
  STEP: Creating a ConfigMap @ 09/02/25 09:00:05.181
  STEP: Ensuring resource quota status captures configMap creation @ 09/02/25 09:00:05.206
  I0902 09:00:05.217696 16 resource_quota.go:2495] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc003b103c0>: 
          metadata:
            creationTimestamp: "2025-09-02T09:00:03Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: e2e.test
              operation: Update
              time: "2025-09-02T09:00:03Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
                  f:used:
                    .: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: kube-controller-manager
              operation: Update
              subresource: status
              time: "2025-09-02T09:00:03Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:used:
                    f:configmaps: {}
              manager: kube-apiserver
              operation: Update
              subresource: status
              time: "2025-09-02T09:00:05Z"
            name: test-quota
            namespace: resourcequota-336
            resourceVersion: "46055"
            uid: fb7fcb4a-8390-4f88-a5ce-fca6d89f56f6
          spec:
            hard:
              configmaps: "2"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
          status:
            hard:
              configmaps: "2"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
            used:
              configmaps: "2"
              count/replicasets.apps: "0"
              cpu: "0"
              ephemeral-storage: "0"
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "0"
              gold.storageclass.storage.k8s.io/requests.storage: "0"
              memory: "0"
              persistentvolumeclaims: "0"
              pods: "0"
              replicationcontrollers: "0"
              requests.example.com/dongle: "0"
              requests.storage: "0"
              resourcequotas: "1"
              secrets: "0"
              services: "0"
              services.loadbalancers: "0"
              services.nodeports: "0"
  STEP: Deleting a ConfigMap @ 09/02/25 09:00:05.218
  STEP: Ensuring resource quota status released usage @ 09/02/25 09:00:05.233
  E0902 09:00:05.596541      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:00:06.596709      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:00:07.260349 16 resource_quota.go:2495] Got expected ResourceQuota:
      <*v1.ResourceQuota | 0xc003b10a00>: 
          metadata:
            creationTimestamp: "2025-09-02T09:00:03Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:spec:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: e2e.test
              operation: Update
              time: "2025-09-02T09:00:03Z"
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:status:
                  f:hard:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
                  f:used:
                    .: {}
                    f:configmaps: {}
                    f:count/replicasets.apps: {}
                    f:cpu: {}
                    f:ephemeral-storage: {}
                    f:gold.storageclass.storage.k8s.io/persistentvolumeclaims: {}
                    f:gold.storageclass.storage.k8s.io/requests.storage: {}
                    f:memory: {}
                    f:persistentvolumeclaims: {}
                    f:pods: {}
                    f:replicationcontrollers: {}
                    f:requests.example.com/dongle: {}
                    f:requests.storage: {}
                    f:resourcequotas: {}
                    f:secrets: {}
                    f:services: {}
                    f:services.loadbalancers: {}
                    f:services.nodeports: {}
              manager: kube-controller-manager
              operation: Update
              subresource: status
              time: "2025-09-02T09:00:05Z"
            name: test-quota
            namespace: resourcequota-336
            resourceVersion: "46058"
            uid: fb7fcb4a-8390-4f88-a5ce-fca6d89f56f6
          spec:
            hard:
              configmaps: "2"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
          status:
            hard:
              configmaps: "2"
              count/replicasets.apps: "5"
              cpu: "1"
              ephemeral-storage: 50Gi
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "10"
              gold.storageclass.storage.k8s.io/requests.storage: 10Gi
              memory: 500Mi
              persistentvolumeclaims: "10"
              pods: "5"
              replicationcontrollers: "10"
              requests.example.com/dongle: "3"
              requests.storage: 10Gi
              resourcequotas: "1"
              secrets: "10"
              services: "10"
              services.loadbalancers: "1"
              services.nodeports: "1"
            used:
              configmaps: "1"
              count/replicasets.apps: "0"
              cpu: "0"
              ephemeral-storage: "0"
              gold.storageclass.storage.k8s.io/persistentvolumeclaims: "0"
              gold.storageclass.storage.k8s.io/requests.storage: "0"
              memory: "0"
              persistentvolumeclaims: "0"
              pods: "0"
              replicationcontrollers: "0"
              requests.example.com/dongle: "0"
              requests.storage: "0"
              resourcequotas: "1"
              secrets: "0"
              services: "0"
              services.loadbalancers: "0"
              services.nodeports: "0"
  I0902 09:00:07.261706 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-336" for this suite. @ 09/02/25 09:00:07.282
• [26.248 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:393
  STEP: Creating a kubernetes client @ 09/02/25 09:00:07.303
  I0902 09:00:07.303442 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename crd-publish-openapi @ 09/02/25 09:00:07.306
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:00:07.356
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:00:07.363
  STEP: set up a multi version CRD @ 09/02/25 09:00:07.37
  I0902 09:00:07.372101 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  E0902 09:00:07.597478      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:00:08.597812      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:00:09.597776      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:00:10.598661      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:00:11.599628      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:00:12.599417      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: rename a version @ 09/02/25 09:00:13.585
  E0902 09:00:13.600492      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: check the new version name is served @ 09/02/25 09:00:13.623
  E0902 09:00:14.601049      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: check the old version name is removed @ 09/02/25 09:00:15.526
  E0902 09:00:15.602252      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: check the other version is not changed @ 09/02/25 09:00:16.54
  E0902 09:00:16.602899      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:00:17.602832      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:00:18.603693      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:00:19.610128      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:00:20.610203      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:00:21.224521 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-7769" for this suite. @ 09/02/25 09:00:21.247
• [13.961 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:209
  STEP: Creating a kubernetes client @ 09/02/25 09:00:21.264
  I0902 09:00:21.264420 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename emptydir @ 09/02/25 09:00:21.266
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:00:21.294
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:00:21.302
  STEP: Creating a pod to test emptydir 0666 on node default medium @ 09/02/25 09:00:21.311
  E0902 09:00:21.612661      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:00:22.611858      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:00:23.612261      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:00:24.612436      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/02/25 09:00:25.376
  I0902 09:00:25.384341 16 output.go:207] Trying to get logs from node ietha7evai9i-2 pod pod-f784a1f0-7644-4ee5-abb8-f2f49b4bfd12 container test-container: <nil>
  STEP: delete the pod @ 09/02/25 09:00:25.42
  I0902 09:00:25.462800 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-4373" for this suite. @ 09/02/25 09:00:25.473
• [4.229 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Job should apply changes to a job status [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:1064
  STEP: Creating a kubernetes client @ 09/02/25 09:00:25.497
  I0902 09:00:25.497845 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename job @ 09/02/25 09:00:25.502
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:00:25.54
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:00:25.548
  STEP: Creating a job @ 09/02/25 09:00:25.554
  STEP: Ensure pods equal to parallelism count is attached to the job @ 09/02/25 09:00:25.57
  E0902 09:00:25.613388      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:00:26.613840      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:00:27.613930      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:00:28.615385      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:00:29.614994      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: patching /status @ 09/02/25 09:00:29.64
  STEP: updating /status @ 09/02/25 09:00:29.679
  STEP: get /status @ 09/02/25 09:00:29.725
  I0902 09:00:29.735184 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-425" for this suite. @ 09/02/25 09:00:29.749
• [4.270 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:916
  STEP: Creating a kubernetes client @ 09/02/25 09:00:29.769
  I0902 09:00:29.770320 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename kubectl @ 09/02/25 09:00:29.774
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:00:29.803
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:00:29.811
  STEP: validating api versions @ 09/02/25 09:00:29.821
  I0902 09:00:29.821904 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-6423 api-versions'
  I0902 09:00:30.002278 16 builder.go:156] stderr: ""
  I0902 09:00:30.002885 16 builder.go:157] stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nbatch/v1\ncertificates.k8s.io/v1\ncilium.io/v2\ncilium.io/v2alpha1\ncoordination.k8s.io/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nresource.k8s.io/v1\nscheduling.k8s.io/v1\nstorage.k8s.io/v1\nv1\n"
  I0902 09:00:30.003676 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-6423" for this suite. @ 09/02/25 09:00:30.021
• [0.288 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:105
  STEP: Creating a kubernetes client @ 09/02/25 09:00:30.061
  I0902 09:00:30.061465 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename subpath @ 09/02/25 09:00:30.065
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:00:30.121
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:00:30.137
  STEP: Setting up data @ 09/02/25 09:00:30.144
  STEP: Creating pod pod-subpath-test-projected-v55q @ 09/02/25 09:00:30.168
  STEP: Creating a pod to test atomic-volume-subpath @ 09/02/25 09:00:30.168
  E0902 09:00:30.615621      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:00:31.616121      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:00:32.616938      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:00:33.617224      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:00:34.617478      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:00:35.618207      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:00:36.617876      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:00:37.618323      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:00:38.619452      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:00:39.619793      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:00:40.620916      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:00:41.621987      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:00:42.622304      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:00:43.622509      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:00:44.623101      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:00:45.623746      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:00:46.624892      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:00:47.625723      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:00:48.626756      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:00:49.627306      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:00:50.628087      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:00:51.628591      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:00:52.629273      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:00:53.629835      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/02/25 09:00:54.393
  I0902 09:00:54.405338 16 output.go:207] Trying to get logs from node ietha7evai9i-1 pod pod-subpath-test-projected-v55q container test-container-subpath-projected-v55q: <nil>
  STEP: delete the pod @ 09/02/25 09:00:54.448
  STEP: Deleting pod pod-subpath-test-projected-v55q @ 09/02/25 09:00:54.491
  I0902 09:00:54.491971 16 delete.go:78] Deleting pod "pod-subpath-test-projected-v55q" in namespace "subpath-537"
  I0902 09:00:54.502087 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-537" for this suite. @ 09/02/25 09:00:54.517
• [24.471 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] API priority and fairness should support PriorityLevelConfiguration API operations [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/flowcontrol.go:514
  STEP: Creating a kubernetes client @ 09/02/25 09:00:54.533
  I0902 09:00:54.533297 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename apf @ 09/02/25 09:00:54.536
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:00:54.568
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:00:54.573
  STEP: getting /apis @ 09/02/25 09:00:54.579
  STEP: getting /apis/flowcontrol.apiserver.k8s.io @ 09/02/25 09:00:54.589
  STEP: getting /apis/flowcontrol.apiserver.k8s.io/v1 @ 09/02/25 09:00:54.591
  STEP: creating @ 09/02/25 09:00:54.594
  STEP: getting @ 09/02/25 09:00:54.625
  E0902 09:00:54.630779      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: listing @ 09/02/25 09:00:54.633
  STEP: watching @ 09/02/25 09:00:54.641
  I0902 09:00:54.641384 16 flowcontrol.go:620] starting watch
  STEP: patching @ 09/02/25 09:00:54.643
  STEP: updating @ 09/02/25 09:00:54.658
  I0902 09:00:54.684722 16 flowcontrol.go:648] waiting for watch events with expected annotations
  STEP: getting /status @ 09/02/25 09:00:54.685
  STEP: patching /status @ 09/02/25 09:00:54.694
  STEP: updating /status @ 09/02/25 09:00:54.706
  STEP: deleting @ 09/02/25 09:00:54.726
  STEP: deleting a collection @ 09/02/25 09:00:54.759
  I0902 09:00:54.797336 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "apf-5655" for this suite. @ 09/02/25 09:00:54.809
• [0.300 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:57
  STEP: Creating a kubernetes client @ 09/02/25 09:00:54.839
  I0902 09:00:54.839609 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename secrets @ 09/02/25 09:00:54.843
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:00:54.874
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:00:54.886
  STEP: Creating secret with name secret-test-3e06b2da-abd2-4660-a6cb-55eab9be4b4a @ 09/02/25 09:00:54.893
  STEP: Creating a pod to test consume secrets @ 09/02/25 09:00:54.903
  E0902 09:00:55.631160      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:00:56.631668      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:00:57.631893      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:00:58.632064      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/02/25 09:00:58.973
  I0902 09:00:58.983863 16 output.go:207] Trying to get logs from node ietha7evai9i-2 pod pod-secrets-d8fff318-cda3-4a42-910e-c676ce443841 container secret-volume-test: <nil>
  STEP: delete the pod @ 09/02/25 09:00:59.004
  I0902 09:00:59.041835 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-9661" for this suite. @ 09/02/25 09:00:59.054
• [4.231 seconds]
------------------------------
[sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:125
  STEP: Creating a kubernetes client @ 09/02/25 09:00:59.072
  I0902 09:00:59.072530 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename cronjob @ 09/02/25 09:00:59.076
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:00:59.105
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:00:59.112
  STEP: Creating a ForbidConcurrent cronjob @ 09/02/25 09:00:59.118
  STEP: Ensuring a job is scheduled @ 09/02/25 09:00:59.132
  E0902 09:00:59.632454      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:01:00.632724      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Ensuring exactly one is scheduled @ 09/02/25 09:01:01.148
  STEP: Ensuring exactly one running job exists by listing jobs explicitly @ 09/02/25 09:01:01.163
  STEP: Ensuring no more jobs are scheduled @ 09/02/25 09:01:01.178
  STEP: Removing cronjob @ 09/02/25 09:01:01.194
  I0902 09:01:01.219696 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-5242" for this suite. @ 09/02/25 09:01:01.236
• [2.190 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Serial] [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:388
  STEP: Creating a kubernetes client @ 09/02/25 09:01:01.273
  I0902 09:01:01.273374 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename gc @ 09/02/25 09:01:01.278
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:01:01.333
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:01:01.341
  STEP: create the rc @ 09/02/25 09:01:01.372
  I0902 09:01:01.386421      16 warnings.go:110] "Warning: metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]"
  E0902 09:01:01.633813      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:01:02.676280      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:01:03.746342      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:01:04.881221      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:01:06.630898      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:01:07.399651      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:01:08.402913      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:01:09.415387      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: delete the rc @ 09/02/25 09:01:10.417
  E0902 09:01:10.418610      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:01:11.416089      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: wait for the rc to be deleted @ 09/02/25 09:01:11.655
  E0902 09:01:12.439762      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:01:13.446865      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:01:14.447127      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:01:15.447388      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:01:16.448376      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:01:17.449815      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:01:18.450215      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:01:19.450970      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:01:20.451338      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:01:21.452038      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods @ 09/02/25 09:01:21.677
  E0902 09:01:22.452477      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:01:23.452940      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:01:24.453314      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:01:25.453867      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:01:26.453945      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:01:27.455519      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:01:28.455593      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:01:29.456127      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:01:30.456201      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:01:31.456413      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:01:32.457225      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:01:33.457426      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:01:34.457735      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:01:35.458015      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:01:36.462387      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:01:37.470669      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:01:38.459831      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:01:39.460434      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:01:40.461026      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:01:41.461409      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:01:42.462743      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:01:43.463138      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:01:44.463505      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:01:45.463722      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:01:46.464906      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:01:47.465444      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:01:48.465645      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:01:49.466710      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:01:50.466838      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:01:51.467413      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 09/02/25 09:01:51.714
  I0902 09:01:51.989863 16 garbage_collector.go:273] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I0902 09:01:51.990054 16 delete.go:111] Deleting pod "simpletest.rc-22mk5" in namespace "gc-9313"
  I0902 09:01:52.018673 16 delete.go:111] Deleting pod "simpletest.rc-2dlds" in namespace "gc-9313"
  I0902 09:01:52.048672 16 delete.go:111] Deleting pod "simpletest.rc-2m4zl" in namespace "gc-9313"
  I0902 09:01:52.073933 16 delete.go:111] Deleting pod "simpletest.rc-2n9td" in namespace "gc-9313"
  I0902 09:01:52.114372 16 delete.go:111] Deleting pod "simpletest.rc-2qnxw" in namespace "gc-9313"
  I0902 09:01:52.179966 16 delete.go:111] Deleting pod "simpletest.rc-4c59m" in namespace "gc-9313"
  I0902 09:01:52.220613 16 delete.go:111] Deleting pod "simpletest.rc-4gl2p" in namespace "gc-9313"
  I0902 09:01:52.292873 16 delete.go:111] Deleting pod "simpletest.rc-4k24l" in namespace "gc-9313"
  I0902 09:01:52.401121 16 delete.go:111] Deleting pod "simpletest.rc-4qskd" in namespace "gc-9313"
  E0902 09:01:52.467597      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:01:52.525753 16 delete.go:111] Deleting pod "simpletest.rc-4zm2d" in namespace "gc-9313"
  I0902 09:01:52.568946 16 delete.go:111] Deleting pod "simpletest.rc-5hwct" in namespace "gc-9313"
  I0902 09:01:52.628975 16 delete.go:111] Deleting pod "simpletest.rc-5hz5l" in namespace "gc-9313"
  I0902 09:01:52.855331 16 delete.go:111] Deleting pod "simpletest.rc-6h7rm" in namespace "gc-9313"
  I0902 09:01:53.085753 16 delete.go:111] Deleting pod "simpletest.rc-72pb4" in namespace "gc-9313"
  E0902 09:01:53.468169      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:01:53.481413 16 delete.go:111] Deleting pod "simpletest.rc-7jc99" in namespace "gc-9313"
  I0902 09:01:53.634211 16 delete.go:111] Deleting pod "simpletest.rc-7lzxn" in namespace "gc-9313"
  I0902 09:01:54.236718 16 delete.go:111] Deleting pod "simpletest.rc-7wcqp" in namespace "gc-9313"
  I0902 09:01:54.370642 16 delete.go:111] Deleting pod "simpletest.rc-7wjgb" in namespace "gc-9313"
  E0902 09:01:54.469803      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:01:54.482649 16 delete.go:111] Deleting pod "simpletest.rc-8dfl6" in namespace "gc-9313"
  I0902 09:01:54.599390 16 delete.go:111] Deleting pod "simpletest.rc-8f7jc" in namespace "gc-9313"
  I0902 09:01:54.641091 16 delete.go:111] Deleting pod "simpletest.rc-9f4st" in namespace "gc-9313"
  I0902 09:01:54.667966 16 delete.go:111] Deleting pod "simpletest.rc-bbb69" in namespace "gc-9313"
  I0902 09:01:54.757003 16 delete.go:111] Deleting pod "simpletest.rc-bhww2" in namespace "gc-9313"
  I0902 09:01:54.858240 16 delete.go:111] Deleting pod "simpletest.rc-bhxz4" in namespace "gc-9313"
  I0902 09:01:55.010253 16 delete.go:111] Deleting pod "simpletest.rc-bkq9j" in namespace "gc-9313"
  I0902 09:01:55.255410 16 delete.go:111] Deleting pod "simpletest.rc-bprlk" in namespace "gc-9313"
  I0902 09:01:55.426534 16 delete.go:111] Deleting pod "simpletest.rc-cdbc7" in namespace "gc-9313"
  E0902 09:01:55.470389      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:01:55.772775 16 delete.go:111] Deleting pod "simpletest.rc-crmnv" in namespace "gc-9313"
  I0902 09:01:55.845061 16 delete.go:111] Deleting pod "simpletest.rc-d4n8z" in namespace "gc-9313"
  I0902 09:01:56.077308 16 delete.go:111] Deleting pod "simpletest.rc-dhxgz" in namespace "gc-9313"
  I0902 09:01:56.225799 16 delete.go:111] Deleting pod "simpletest.rc-dl9sb" in namespace "gc-9313"
  E0902 09:01:56.471400      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:01:56.542934 16 delete.go:111] Deleting pod "simpletest.rc-dqftp" in namespace "gc-9313"
  I0902 09:01:56.695097 16 delete.go:111] Deleting pod "simpletest.rc-f42mz" in namespace "gc-9313"
  I0902 09:01:56.966775 16 delete.go:111] Deleting pod "simpletest.rc-f88jx" in namespace "gc-9313"
  I0902 09:01:57.104924 16 delete.go:111] Deleting pod "simpletest.rc-fjl8g" in namespace "gc-9313"
  I0902 09:01:57.166040 16 delete.go:111] Deleting pod "simpletest.rc-fqtk8" in namespace "gc-9313"
  I0902 09:01:57.227265 16 delete.go:111] Deleting pod "simpletest.rc-fztsm" in namespace "gc-9313"
  I0902 09:01:57.380520 16 delete.go:111] Deleting pod "simpletest.rc-g9zvl" in namespace "gc-9313"
  E0902 09:01:57.471538      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:01:57.478826 16 delete.go:111] Deleting pod "simpletest.rc-gfg4c" in namespace "gc-9313"
  I0902 09:01:57.634077 16 delete.go:111] Deleting pod "simpletest.rc-gk5mj" in namespace "gc-9313"
  I0902 09:01:57.811702 16 delete.go:111] Deleting pod "simpletest.rc-gstvb" in namespace "gc-9313"
  I0902 09:01:58.216316 16 delete.go:111] Deleting pod "simpletest.rc-gxm5b" in namespace "gc-9313"
  E0902 09:01:58.472483      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:01:58.569050 16 delete.go:111] Deleting pod "simpletest.rc-h85rj" in namespace "gc-9313"
  I0902 09:01:58.715062 16 delete.go:111] Deleting pod "simpletest.rc-hb4jt" in namespace "gc-9313"
  I0902 09:01:58.873969 16 delete.go:111] Deleting pod "simpletest.rc-hdvlz" in namespace "gc-9313"
  I0902 09:01:59.084827 16 delete.go:111] Deleting pod "simpletest.rc-hjvzf" in namespace "gc-9313"
  I0902 09:01:59.356771 16 delete.go:111] Deleting pod "simpletest.rc-hwvfd" in namespace "gc-9313"
  E0902 09:01:59.473177      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:01:59.540967 16 delete.go:111] Deleting pod "simpletest.rc-js2hm" in namespace "gc-9313"
  I0902 09:01:59.718275 16 delete.go:111] Deleting pod "simpletest.rc-k6cb5" in namespace "gc-9313"
  I0902 09:01:59.847643 16 delete.go:111] Deleting pod "simpletest.rc-kb8xm" in namespace "gc-9313"
  I0902 09:01:59.959194 16 delete.go:111] Deleting pod "simpletest.rc-kctdv" in namespace "gc-9313"
  I0902 09:02:00.098659 16 delete.go:111] Deleting pod "simpletest.rc-kmhsd" in namespace "gc-9313"
  I0902 09:02:00.466420 16 delete.go:111] Deleting pod "simpletest.rc-ksx6j" in namespace "gc-9313"
  E0902 09:02:00.473837      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:02:00.663119 16 delete.go:111] Deleting pod "simpletest.rc-kxnrn" in namespace "gc-9313"
  I0902 09:02:00.784525 16 delete.go:111] Deleting pod "simpletest.rc-lbfgq" in namespace "gc-9313"
  E0902 09:02:01.474129      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:02:01.587731 16 delete.go:111] Deleting pod "simpletest.rc-ltx7r" in namespace "gc-9313"
  I0902 09:02:01.779515 16 delete.go:111] Deleting pod "simpletest.rc-m6kpb" in namespace "gc-9313"
  I0902 09:02:01.963648 16 delete.go:111] Deleting pod "simpletest.rc-m82jd" in namespace "gc-9313"
  I0902 09:02:02.095455 16 delete.go:111] Deleting pod "simpletest.rc-mbrq7" in namespace "gc-9313"
  I0902 09:02:02.153836 16 delete.go:111] Deleting pod "simpletest.rc-mgth5" in namespace "gc-9313"
  I0902 09:02:02.197640 16 delete.go:111] Deleting pod "simpletest.rc-ndg7n" in namespace "gc-9313"
  I0902 09:02:02.315055 16 delete.go:111] Deleting pod "simpletest.rc-nxw6h" in namespace "gc-9313"
  I0902 09:02:02.393740 16 delete.go:111] Deleting pod "simpletest.rc-p72jg" in namespace "gc-9313"
  E0902 09:02:02.474924      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:02:02.566126 16 delete.go:111] Deleting pod "simpletest.rc-pnz94" in namespace "gc-9313"
  I0902 09:02:02.623924 16 delete.go:111] Deleting pod "simpletest.rc-pq9pf" in namespace "gc-9313"
  I0902 09:02:02.660234 16 delete.go:111] Deleting pod "simpletest.rc-pt4jq" in namespace "gc-9313"
  I0902 09:02:02.726094 16 delete.go:111] Deleting pod "simpletest.rc-pt7rq" in namespace "gc-9313"
  I0902 09:02:02.801462 16 delete.go:111] Deleting pod "simpletest.rc-q2bqt" in namespace "gc-9313"
  I0902 09:02:02.847859 16 delete.go:111] Deleting pod "simpletest.rc-qpmsj" in namespace "gc-9313"
  I0902 09:02:03.012078 16 delete.go:111] Deleting pod "simpletest.rc-qwhmg" in namespace "gc-9313"
  I0902 09:02:03.046974 16 delete.go:111] Deleting pod "simpletest.rc-qwhtc" in namespace "gc-9313"
  I0902 09:02:03.096873 16 delete.go:111] Deleting pod "simpletest.rc-r4tp2" in namespace "gc-9313"
  I0902 09:02:03.161273 16 delete.go:111] Deleting pod "simpletest.rc-rb2vf" in namespace "gc-9313"
  I0902 09:02:03.321790 16 delete.go:111] Deleting pod "simpletest.rc-rbv5z" in namespace "gc-9313"
  E0902 09:02:03.482335      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:02:03.637322 16 delete.go:111] Deleting pod "simpletest.rc-rd6qb" in namespace "gc-9313"
  I0902 09:02:03.737063 16 delete.go:111] Deleting pod "simpletest.rc-rhz8n" in namespace "gc-9313"
  I0902 09:02:03.827646 16 delete.go:111] Deleting pod "simpletest.rc-rkcsw" in namespace "gc-9313"
  I0902 09:02:03.911113 16 delete.go:111] Deleting pod "simpletest.rc-rt2pf" in namespace "gc-9313"
  I0902 09:02:04.006636 16 delete.go:111] Deleting pod "simpletest.rc-rzvxd" in namespace "gc-9313"
  I0902 09:02:04.042488 16 delete.go:111] Deleting pod "simpletest.rc-s5l24" in namespace "gc-9313"
  I0902 09:02:04.087149 16 delete.go:111] Deleting pod "simpletest.rc-s7n4r" in namespace "gc-9313"
  I0902 09:02:04.191354 16 delete.go:111] Deleting pod "simpletest.rc-sk8p8" in namespace "gc-9313"
  E0902 09:02:04.483220      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:02:04.609610 16 delete.go:111] Deleting pod "simpletest.rc-spb99" in namespace "gc-9313"
  I0902 09:02:04.849458 16 delete.go:111] Deleting pod "simpletest.rc-srdgl" in namespace "gc-9313"
  I0902 09:02:04.955980 16 delete.go:111] Deleting pod "simpletest.rc-tbwq5" in namespace "gc-9313"
  I0902 09:02:05.367304 16 delete.go:111] Deleting pod "simpletest.rc-tcdmc" in namespace "gc-9313"
  I0902 09:02:05.466042 16 delete.go:111] Deleting pod "simpletest.rc-vmqzl" in namespace "gc-9313"
  E0902 09:02:05.484747      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:02:05.640103 16 delete.go:111] Deleting pod "simpletest.rc-w2swx" in namespace "gc-9313"
  I0902 09:02:05.712751 16 delete.go:111] Deleting pod "simpletest.rc-w7pb6" in namespace "gc-9313"
  I0902 09:02:05.945629 16 delete.go:111] Deleting pod "simpletest.rc-wck49" in namespace "gc-9313"
  I0902 09:02:06.185390 16 delete.go:111] Deleting pod "simpletest.rc-ww7gt" in namespace "gc-9313"
  E0902 09:02:06.484811      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:02:06.796073 16 delete.go:111] Deleting pod "simpletest.rc-wzrs2" in namespace "gc-9313"
  I0902 09:02:07.284307 16 delete.go:111] Deleting pod "simpletest.rc-x5mqz" in namespace "gc-9313"
  E0902 09:02:07.485623      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:02:07.801112 16 delete.go:111] Deleting pod "simpletest.rc-x9fkh" in namespace "gc-9313"
  I0902 09:02:08.008441 16 delete.go:111] Deleting pod "simpletest.rc-x9fwq" in namespace "gc-9313"
  I0902 09:02:08.083035 16 delete.go:111] Deleting pod "simpletest.rc-z957z" in namespace "gc-9313"
  I0902 09:02:08.444397 16 delete.go:111] Deleting pod "simpletest.rc-zctq2" in namespace "gc-9313"
  E0902 09:02:08.486595      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:02:08.544327 16 delete.go:111] Deleting pod "simpletest.rc-zh6hb" in namespace "gc-9313"
  I0902 09:02:08.599283 16 delete.go:111] Deleting pod "simpletest.rc-zhfh8" in namespace "gc-9313"
  I0902 09:02:08.672096 16 delete.go:111] Deleting pod "simpletest.rc-zzx7m" in namespace "gc-9313"
  I0902 09:02:08.745126 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-9313" for this suite. @ 09/02/25 09:02:08.831
• [67.596 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should execute all indexes despite some failing when using backoffLimitPerIndex [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:605
  STEP: Creating a kubernetes client @ 09/02/25 09:02:08.871
  I0902 09:02:08.871241 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename job @ 09/02/25 09:02:08.877
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:02:08.96
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:02:08.99
  STEP: Creating an indexed job with backoffLimit per index and failing pods @ 09/02/25 09:02:08.997
  STEP: Awaiting for the job to fail as there are failed indexes @ 09/02/25 09:02:09.021
  E0902 09:02:09.487511      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:02:10.488175      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:02:11.488360      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:02:12.488586      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:02:13.489039      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:02:14.489117      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:02:15.489978      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:02:16.490218      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:02:17.490908      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:02:18.492112      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:02:19.491987      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:02:20.492497      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:02:21.493694      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:02:22.494338      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:02:23.495407      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:02:24.495894      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:02:25.496928      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:02:26.497689      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:02:27.498450      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:02:28.499151      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:02:29.500479      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:02:30.501288      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Verifying the Job status fields to ensure all indexes were executed @ 09/02/25 09:02:31.155
  I0902 09:02:31.163536 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-6363" for this suite. @ 09/02/25 09:02:31.177
• [22.333 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:130
  STEP: Creating a kubernetes client @ 09/02/25 09:02:31.204
  I0902 09:02:31.204366 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename dns @ 09/02/25 09:02:31.206
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:02:31.243
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:02:31.249
  STEP: Running these commands on agnhost: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-5205.svc.cluster.local)" && echo OK > /results/agnhost_hosts@dns-querier-1.dns-test-service.dns-5205.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/agnhost_hosts@dns-querier-1;sleep 1; done
   @ 09/02/25 09:02:31.257
  STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-5205.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-5205.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
   @ 09/02/25 09:02:31.257
  STEP: creating a pod to probe /etc/hosts @ 09/02/25 09:02:31.257
  STEP: submitting the pod to kubernetes @ 09/02/25 09:02:31.257
  E0902 09:02:31.502073      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:02:32.502016      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 09/02/25 09:02:33.309
  STEP: looking for the results for each expected name from probers @ 09/02/25 09:02:33.323
  I0902 09:02:33.385624 16 dns_common.go:495] Unable to read jessie_hosts@dns-querier-1 from pod dns-5205/dns-test-1529607e-d03d-462f-b40d-763fa05ab792: the server could not find the requested resource (get pods dns-test-1529607e-d03d-462f-b40d-763fa05ab792)
  I0902 09:02:33.386149 16 dns_common.go:506] Lookups using dns-5205/dns-test-1529607e-d03d-462f-b40d-763fa05ab792 failed for: [jessie_hosts@dns-querier-1]

  I0902 09:02:33.406287 16 dns_common.go:514] Pod client logs for webserver: 
  I0902 09:02:33.437868 16 dns_common.go:514] Pod client logs for agnhost-querier: 
  I0902 09:02:33.459807 16 dns_common.go:514] Pod client logs for jessie-querier: 
  E0902 09:02:33.502096      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:02:34.502327      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:02:35.503119      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:02:36.502948      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:02:37.504714      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:02:38.368060 16 dns_common.go:495] Unable to read jessie_hosts@dns-querier-1 from pod dns-5205/dns-test-1529607e-d03d-462f-b40d-763fa05ab792: the server could not find the requested resource (get pods dns-test-1529607e-d03d-462f-b40d-763fa05ab792)
  I0902 09:02:38.368228 16 dns_common.go:506] Lookups using dns-5205/dns-test-1529607e-d03d-462f-b40d-763fa05ab792 failed for: [jessie_hosts@dns-querier-1]

  I0902 09:02:38.384056 16 dns_common.go:514] Pod client logs for webserver: 
  I0902 09:02:38.398378 16 dns_common.go:514] Pod client logs for agnhost-querier: 
  I0902 09:02:38.414506 16 dns_common.go:514] Pod client logs for jessie-querier: 
  E0902 09:02:38.504077      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:02:39.504254      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:02:40.504748      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:02:41.505171      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:02:42.505226      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:02:43.403872 16 dns_common.go:546] DNS probes using dns-5205/dns-test-1529607e-d03d-462f-b40d-763fa05ab792 succeeded

  STEP: deleting the pod @ 09/02/25 09:02:43.404
  I0902 09:02:43.453215 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-5205" for this suite. @ 09/02/25 09:02:43.474
  E0902 09:02:43.505974      16 retrywatcher.go:169] "Watch failed" err="context canceled"
• [12.302 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:99
  STEP: Creating a kubernetes client @ 09/02/25 09:02:43.506
  I0902 09:02:43.506980 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename projected @ 09/02/25 09:02:43.509
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:02:43.563
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:02:43.584
  STEP: Creating configMap with name projected-configmap-test-volume-map-1b8d8c32-5276-461c-ad76-07cf027599ef @ 09/02/25 09:02:43.597
  STEP: Creating a pod to test consume configMaps @ 09/02/25 09:02:43.641
  E0902 09:02:44.506659      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:02:45.507104      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:02:46.507643      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:02:47.507814      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/02/25 09:02:47.705
  I0902 09:02:47.711783 16 output.go:207] Trying to get logs from node ietha7evai9i-2 pod pod-projected-configmaps-6a122965-4e4e-46cc-a1b8-de9c694a73e2 container agnhost-container: <nil>
  STEP: delete the pod @ 09/02/25 09:02:47.726
  I0902 09:02:47.771338 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7009" for this suite. @ 09/02/25 09:02:47.782
• [4.297 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] PersistentVolumes CSI Conformance should run through the lifecycle of a PV and a PVC [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/persistent_volumes.go:429
  STEP: Creating a kubernetes client @ 09/02/25 09:02:47.805
  I0902 09:02:47.805505 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename pv @ 09/02/25 09:02:47.808
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:02:47.848
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:02:47.855
  STEP: Creating initial PV and PVC @ 09/02/25 09:02:47.864
  I0902 09:02:47.864472 16 pv.go:394] Creating a PV followed by a PVC
  STEP: Listing all PVs with the labelSelector: "e2e-pv-pool=pv-9181" @ 09/02/25 09:02:47.91
  STEP: Listing PVCs in namespace "pv-9181" @ 09/02/25 09:02:47.93
  STEP: Patching the PV "pv-9181-txs85" @ 09/02/25 09:02:47.943
  STEP: Patching the PVC "pvc-c6m7n" @ 09/02/25 09:02:47.983
  STEP: Getting PV "pv-9181-txs85" @ 09/02/25 09:02:48.01
  STEP: Getting PVC "pvc-c6m7n" @ 09/02/25 09:02:48.024
  STEP: Deleting PVC "pvc-c6m7n" @ 09/02/25 09:02:48.033
  STEP: Confirm deletion of PVC "pvc-c6m7n" @ 09/02/25 09:02:48.061
  E0902 09:02:48.508696      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:02:49.509629      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deleting PV "pv-9181-txs85" @ 09/02/25 09:02:50.093
  STEP: Confirm deletion of PV "pv-9181-txs85" @ 09/02/25 09:02:50.11
  E0902 09:02:50.509916      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:02:51.510599      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Recreating another PV & PVC @ 09/02/25 09:02:52.135
  I0902 09:02:52.136059 16 pv.go:394] Creating a PV followed by a PVC
  STEP: Updating the PV "pv-9181-f28tl" @ 09/02/25 09:02:52.177
  STEP: Updating the PVC "pvc-mxcjm" @ 09/02/25 09:02:52.202
  STEP: Listing PVCs in all namespaces with the labelSelector: "pvc-mxcjm=updated" @ 09/02/25 09:02:52.241
  STEP: Deleting PVC "pvc-mxcjm" via DeleteCollection @ 09/02/25 09:02:52.255
  STEP: Confirm deletion of PVC "pvc-mxcjm" @ 09/02/25 09:02:52.286
  E0902 09:02:52.511387      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:02:53.511801      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deleting PV "pv-9181-f28tl" via DeleteCollection @ 09/02/25 09:02:54.304
  STEP: Confirm deletion of PV "pv-9181-f28tl" @ 09/02/25 09:02:54.433
  I0902 09:02:54.492365 16 persistent_volumes.go:406] AfterEach: deleting 1 PVCs and 1 PVs...
  I0902 09:02:54.492456 16 pv.go:205] Deleting PersistentVolumeClaim "pvc-mxcjm"
  E0902 09:02:54.512782      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:02:54.513369 16 pv.go:193] Deleting PersistentVolume "pv-9181-f28tl"
  I0902 09:02:54.521939 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pv-9181" for this suite. @ 09/02/25 09:02:54.553
• [6.776 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1082
  STEP: Creating a kubernetes client @ 09/02/25 09:02:54.581
  I0902 09:02:54.581975 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename kubectl @ 09/02/25 09:02:54.584
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:02:54.677
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:02:54.685
  STEP: create deployment with httpd image @ 09/02/25 09:02:54.713
  I0902 09:02:54.714419 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-438 create -f -'
  I0902 09:02:55.011045 16 builder.go:156] stderr: ""
  I0902 09:02:55.011926 16 builder.go:157] stdout: "deployment.apps/httpd-deployment created\n"
  STEP: verify diff finds difference between live and declared image @ 09/02/25 09:02:55.012
  I0902 09:02:55.012905 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-438 diff -f -'
  I0902 09:02:55.402261 16 builder.go:145] rc: 1
  I0902 09:02:55.402832 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-438 delete -f -'
  E0902 09:02:55.513488      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:02:55.582679 16 builder.go:156] stderr: ""
  I0902 09:02:55.582791 16 builder.go:157] stdout: "deployment.apps \"httpd-deployment\" deleted from kubectl-438 namespace\n"
  I0902 09:02:55.582985 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-438" for this suite. @ 09/02/25 09:02:55.604
• [1.064 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:95
  STEP: Creating a kubernetes client @ 09/02/25 09:02:55.651
  I0902 09:02:55.651689 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename var-expansion @ 09/02/25 09:02:55.654
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:02:55.686
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:02:55.692
  STEP: Creating a pod to test substitution in container's args @ 09/02/25 09:02:55.698
  E0902 09:02:56.514983      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:02:57.515395      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:02:58.516530      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:02:59.516630      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/02/25 09:02:59.759
  I0902 09:02:59.767991 16 output.go:207] Trying to get logs from node ietha7evai9i-3 pod var-expansion-10a535ee-b391-4ed9-9f72-2d701c3bd753 container dapi-container: <nil>
  STEP: delete the pod @ 09/02/25 09:02:59.808
  I0902 09:02:59.841845 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-5606" for this suite. @ 09/02/25 09:02:59.853
• [4.218 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:113
  STEP: Creating a kubernetes client @ 09/02/25 09:02:59.871
  I0902 09:02:59.871347 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename deployment @ 09/02/25 09:02:59.874
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:02:59.901
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:02:59.909
  I0902 09:02:59.916497 16 deployment.go:798] Creating deployment "test-recreate-deployment"
  I0902 09:02:59.938285 16 deployment.go:804] Waiting deployment "test-recreate-deployment" to be updated to revision 1
  I0902 09:02:59.960775 16 deployment.go:223] deployment "test-recreate-deployment" doesn't have the required revision set
  E0902 09:03:00.546947      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:03:01.518948      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:03:01.983665 16 deployment.go:808] Waiting deployment "test-recreate-deployment" to complete
  I0902 09:03:01.992421 16 deployment.go:813] Triggering a new rollout for deployment "test-recreate-deployment"
  I0902 09:03:02.017010 16 deployment.go:314] Updating deployment test-recreate-deployment
  I0902 09:03:02.017691 16 deployment.go:820] Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
  I0902 09:03:02.328968 16 deployment.go:632] Deployment "test-recreate-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-recreate-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-1209",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "70cc30c1-c938-4081-a882-30a73eb01c10",
      ResourceVersion: (string) (len=5) "48926",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63892400579,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892400582,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=570) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |":{"f:type":{}},|
              000000b0  22 66 3a 74 65 6d 70 6c  61 74 65 22 3a 7b 22 66  |"f:template":{"f|
              000000c0  3a 6d 65 74 61 64 61 74  61 22 3a 7b 22 66 3a 6c  |:metadata":{"f:l|
              000000d0  61 62 65 6c 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |abels":{".":{},"|
              000000e0  66 3a 6e 61 6d 65 22 3a  7b 7d 7d 7d 2c 22 66 3a  |f:name":{}}},"f:|
              000000f0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              00000100  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              00000110  65 5c 22 3a 5c 22 68 74  74 70 64 5c 22 7d 22 3a  |e\":\"httpd\"}":|
              00000120  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              00000130  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              00000140  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000150  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000160  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 73 65 63 75  |rces":{},"f:secu|
              00000170  72 69 74 79 43 6f 6e 74  65 78 74 22 3a 7b 7d 2c  |rityContext":{},|
              00000180  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000190  73 73 61 67 65 50 61 74  68 22 3a 7b 7d 2c 22 66  |ssagePath":{},"f|
              000001a0  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 4d 65 73 73  |:terminationMess|
              000001b0  61 67 65 50 6f 6c 69 63  79 22 3a 7b 7d 7d 7d 2c  |agePolicy":{}}},|
              000001c0  22 66 3a 64 6e 73 50 6f  6c 69 63 79 22 3a 7b 7d  |"f:dnsPolicy":{}|
              000001d0  2c 22 66 3a 72 65 73 74  61 72 74 50 6f 6c 69 63  |,"f:restartPolic|
              000001e0  79 22 3a 7b 7d 2c 22 66  3a 73 63 68 65 64 75 6c  |y":{},"f:schedul|
              000001f0  65 72 4e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 73 65  |erName":{},"f:se|
              00000200  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000210  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000220  47 72 61 63 65 50 65 72  69 6f 64 53 65 63 6f 6e  |GracePeriodSecon|
              00000230  64 73 22 3a 7b 7d 7d 7d  7d 7d                    |ds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892400582,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=495) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 63 6f 6e 64 69 74 69  6f 6e 73 22 3a 7b 22 2e  |:conditions":{".|
              00000070  22 3a 7b 7d 2c 22 6b 3a  7b 5c 22 74 79 70 65 5c  |":{},"k:{\"type\|
              00000080  22 3a 5c 22 41 76 61 69  6c 61 62 6c 65 5c 22 7d  |":\"Available\"}|
              00000090  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |":{".":{},"f:las|
              000000a0  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              000000b0  3a 7b 7d 2c 22 66 3a 6c  61 73 74 55 70 64 61 74  |:{},"f:lastUpdat|
              000000c0  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6d 65 73  |eTime":{},"f:mes|
              000000d0  73 61 67 65 22 3a 7b 7d  2c 22 66 3a 72 65 61 73  |sage":{},"f:reas|
              000000e0  6f 6e 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |on":{},"f:status|
              000000f0  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000100  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000110  22 50 72 6f 67 72 65 73  73 69 6e 67 5c 22 7d 22  |"Progressing\"}"|
              00000120  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              00000130  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000140  7b 7d 2c 22 66 3a 6c 61  73 74 55 70 64 61 74 65  |{},"f:lastUpdate|
              00000150  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6d 65 73 73  |Time":{},"f:mess|
              00000160  61 67 65 22 3a 7b 7d 2c  22 66 3a 72 65 61 73 6f  |age":{},"f:reaso|
              00000170  6e 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |n":{},"f:status"|
              00000180  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000190  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              000001a0  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              000001b0  65 70 6c 69 63 61 73 22  3a 7b 7d 2c 22 66 3a 75  |eplicas":{},"f:u|
              000001c0  6e 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |navailableReplic|
              000001d0  61 73 22 3a 7b 7d 2c 22  66 3a 75 70 64 61 74 65  |as":{},"f:update|
              000001e0  64 52 65 70 6c 69 63 61  73 22 3a 7b 7d 7d 7d     |dReplicas":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          HostnameOverride: (*string)(<nil>)
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=8) "Recreate",
        RollingUpdate: (*v1.RollingUpdateDeployment)(<nil>)
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      UnavailableReplicas: (int32) 1,
      TerminatingReplicas: (*int32)(<nil>),
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892400582,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892400582,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=26) "MinimumReplicasUnavailable",
          Message: (string) (len=46) "Deployment does not have minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892400582,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892400579,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=17) "ReplicaSetUpdated",
          Message: (string) (len=64) "ReplicaSet \"test-recreate-deployment-68d5bd4dd9\" is progressing."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0902 09:03:02.363488 16 deployment.go:40] New ReplicaSet "test-recreate-deployment-68d5bd4dd9" of Deployment "test-recreate-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-recreate-deployment-68d5bd4dd9",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-1209",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "e018ab68-95b6-44d5-95bf-b6ecc29e25e9",
      ResourceVersion: (string) (len=5) "48924",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63892400582,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=10) "68d5bd4dd9"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "1",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-recreate-deployment",
          UID: (types.UID) (len=36) "70cc30c1-c938-4081-a882-30a73eb01c10",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892400582,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 37 30 63 63 33 30  63 31 2d 63 39 33 38 2d  |\"70cc30c1-c938-|
              00000120  34 30 38 31 2d 61 38 38  32 2d 33 30 61 37 33 65  |4081-a882-30a73e|
              00000130  62 30 31 63 31 30 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |b01c10\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892400582,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=84) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  66 75 6c 6c 79 4c 61 62  65 6c 65 64 52 65 70 6c  |fullyLabeledRepl|
              00000020  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 6f 62 73 65  |icas":{},"f:obse|
              00000030  72 76 65 64 47 65 6e 65  72 61 74 69 6f 6e 22 3a  |rvedGeneration":|
              00000040  7b 7d 2c 22 66 3a 72 65  70 6c 69 63 61 73 22 3a  |{},"f:replicas":|
              00000050  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3",
          (string) (len=17) "pod-template-hash": (string) (len=10) "68d5bd4dd9"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3",
            (string) (len=17) "pod-template-hash": (string) (len=10) "68d5bd4dd9"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          HostnameOverride: (*string)(<nil>)
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      TerminatingReplicas: (*int32)(<nil>),
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0902 09:03:02.377420 16 deployment.go:45] All old ReplicaSets of Deployment "test-recreate-deployment":
  I0902 09:03:02.378057 16 deployment.go:48] (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-recreate-deployment-8574476ffd",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-1209",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "926d3c31-8b5e-4045-85b2-e0350271d134",
      ResourceVersion: (string) (len=5) "48915",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63892400579,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=10) "8574476ffd"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1",
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-recreate-deployment",
          UID: (types.UID) (len=36) "70cc30c1-c938-4081-a882-30a73eb01c10",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892400582,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 37 30 63 63 33 30  63 31 2d 63 39 33 38 2d  |\"70cc30c1-c938-|
              00000120  34 30 38 31 2d 61 38 38  32 2d 33 30 61 37 33 65  |4081-a882-30a73e|
              00000130  62 30 31 63 31 30 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |b01c10\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892400582,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3",
          (string) (len=17) "pod-template-hash": (string) (len=10) "8574476ffd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3",
            (string) (len=17) "pod-template-hash": (string) (len=10) "8574476ffd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.56",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          HostnameOverride: (*string)(<nil>)
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      TerminatingReplicas: (*int32)(<nil>),
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0902 09:03:02.402403 16 deployment.go:68] Pod "test-recreate-deployment-68d5bd4dd9-k2f5m" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=41) "test-recreate-deployment-68d5bd4dd9-k2f5m",
      GenerateName: (string) (len=36) "test-recreate-deployment-68d5bd4dd9-",
      Namespace: (string) (len=15) "deployment-1209",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "06fcb201-b7b8-4d91-9d56-3e12f81ed85c",
      ResourceVersion: (string) (len=5) "48929",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63892400582,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=10) "68d5bd4dd9"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=35) "test-recreate-deployment-68d5bd4dd9",
          UID: (types.UID) (len=36) "e018ab68-95b6-44d5-95bf-b6ecc29e25e9",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892400582,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 65 30  31 38 61 62 36 38 2d 39  |d\":\"e018ab68-9|
              00000090  35 62 36 2d 34 34 64 35  2d 39 35 62 66 2d 62 36  |5b6-44d5-95bf-b6|
              000000a0  65 63 63 32 39 65 32 35  65 39 5c 22 7d 22 3a 7b  |ecc29e25e9\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892400582,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=814) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 6f 62 73 65 72 76 65  |e":{},"f:observe|
              00000090  64 47 65 6e 65 72 61 74  69 6f 6e 22 3a 7b 7d 2c  |dGeneration":{},|
              000000a0  22 66 3a 72 65 61 73 6f  6e 22 3a 7b 7d 2c 22 66  |"f:reason":{},"f|
              000000b0  3a 73 74 61 74 75 73 22  3a 7b 7d 2c 22 66 3a 74  |:status":{},"f:t|
              000000c0  79 70 65 22 3a 7b 7d 7d  2c 22 6b 3a 7b 5c 22 74  |ype":{}},"k:{\"t|
              000000d0  79 70 65 5c 22 3a 5c 22  49 6e 69 74 69 61 6c 69  |ype\":\"Initiali|
              000000e0  7a 65 64 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |zed\"}":{".":{},|
              000000f0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              00000110  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              00000120  66 3a 6f 62 73 65 72 76  65 64 47 65 6e 65 72 61  |f:observedGenera|
              00000130  74 69 6f 6e 22 3a 7b 7d  2c 22 66 3a 73 74 61 74  |tion":{},"f:stat|
              00000140  75 73 22 3a 7b 7d 2c 22  66 3a 74 79 70 65 22 3a  |us":{},"f:type":|
              00000150  7b 7d 7d 2c 22 6b 3a 7b  5c 22 74 79 70 65 5c 22  |{}},"k:{\"type\"|
              00000160  3a 5c 22 50 6f 64 52 65  61 64 79 54 6f 53 74 61  |:\"PodReadyToSta|
              00000170  72 74 43 6f 6e 74 61 69  6e 65 72 73 5c 22 7d 22  |rtContainers\"}"|
              00000180  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              00000190  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000001a0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |ime":{},"f:obser|
              000001c0  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 2c 22 6b 3a  |"f:type":{}},"k:|
              000001f0  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 50 6f 64 53  |{\"type\":\"PodS|
              00000200  63 68 65 64 75 6c 65 64  5c 22 7d 22 3a 7b 22 66  |cheduled\"}":{"f|
              00000210  3a 6f 62 73 65 72 76 65  64 47 65 6e 65 72 61 74  |:observedGenerat|
              00000220  69 6f 6e 22 3a 7b 7d 7d  2c 22 6b 3a 7b 5c 22 74  |ion":{}},"k:{\"t|
              00000230  79 70 65 5c 22 3a 5c 22  52 65 61 64 79 5c 22 7d  |ype\":\"Ready\"}|
              00000240  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |":{".":{},"f:las|
              00000250  74 50 72 6f 62 65 54 69  6d 65 22 3a 7b 7d 2c 22  |tProbeTime":{},"|
              00000260  66 3a 6c 61 73 74 54 72  61 6e 73 69 74 69 6f 6e  |f:lastTransition|
              00000270  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6d 65 73 73  |Time":{},"f:mess|
              00000280  61 67 65 22 3a 7b 7d 2c  22 66 3a 6f 62 73 65 72  |age":{},"f:obser|
              00000290  76 65 64 47 65 6e 65 72  61 74 69 6f 6e 22 3a 7b  |vedGeneration":{|
              000002a0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              000002b0  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              000002c0  3a 74 79 70 65 22 3a 7b  7d 7d 7d 2c 22 66 3a 63  |:type":{}}},"f:c|
              000002d0  6f 6e 74 61 69 6e 65 72  53 74 61 74 75 73 65 73  |ontainerStatuses|
              000002e0  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 22 3a  |":{},"f:hostIP":|
              000002f0  7b 7d 2c 22 66 3a 68 6f  73 74 49 50 73 22 3a 7b  |{},"f:hostIPs":{|
              00000300  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000310  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |eration":{},"f:s|
              00000320  74 61 72 74 54 69 6d 65  22 3a 7b 7d 7d 7d        |tartTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-26288",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>),
                  PodCertificate: (*v1.PodCertificateProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          RestartPolicyRules: ([]v1.ContainerRestartRule) <nil>,
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-26288",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "ietha7evai9i-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>),
      HostnameOverride: (*string)(<nil>)
    },
    Status: (v1.PodStatus) {
      ObservedGeneration: (int64) 1,
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892400582,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892400582,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892400582,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892400582,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          ObservedGeneration: (int64) 1,
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63892400582,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.52",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.121.52"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63892400582,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-26288",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>,
          StopSignal: (*v1.Signal)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>,
      ExtendedResourceClaimStatus: (*v1.PodExtendedResourceClaimStatus)(<nil>)
    }
  }

  I0902 09:03:02.420532 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-1209" for this suite. @ 09/02/25 09:03:02.467
• [2.612 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:488
  STEP: Creating a kubernetes client @ 09/02/25 09:03:02.485
  I0902 09:03:02.486089 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename gc @ 09/02/25 09:03:02.491
  E0902 09:03:02.519744      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:03:02.522
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:03:02.535
  STEP: create the deployment @ 09/02/25 09:03:02.543
  I0902 09:03:02.557794      16 warnings.go:110] "Warning: metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]"
  STEP: Wait for the Deployment to create new ReplicaSet @ 09/02/25 09:03:02.558
  STEP: delete the deployment @ 09/02/25 09:03:03.068
  STEP: wait for all rs to be garbage collected @ 09/02/25 09:03:03.083
  STEP: expected 0 pods, got 2 pods @ 09/02/25 09:03:03.168
  E0902 09:03:03.520742      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 09/02/25 09:03:03.649
  I0902 09:03:03.872687 16 garbage_collector.go:273] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I0902 09:03:03.873226 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-3480" for this suite. @ 09/02/25 09:03:03.884
• [1.434 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Job should terminate job execution when the number of failed indexes exceeds maxFailedIndexes [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:639
  STEP: Creating a kubernetes client @ 09/02/25 09:03:03.919
  I0902 09:03:03.919669 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename job @ 09/02/25 09:03:03.922
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:03:03.991
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:03:04
  STEP: Creating an indexed job with backoffLimit per index and maxFailedIndexes @ 09/02/25 09:03:04.006
  STEP: Awaiting for the job to fail as the number of max failed indexes is exceeded @ 09/02/25 09:03:04.02
  E0902 09:03:04.521352      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:03:05.522047      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:03:06.522680      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:03:07.523026      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:03:08.524351      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:03:09.525031      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Verifying the Job status fields to ensure early termination of the job @ 09/02/25 09:03:10.059
  I0902 09:03:10.074251 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-2082" for this suite. @ 09/02/25 09:03:10.095
• [6.198 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:71
  STEP: Creating a kubernetes client @ 09/02/25 09:03:10.126
  I0902 09:03:10.126996 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename crd-publish-openapi @ 09/02/25 09:03:10.136
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:03:10.173
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:03:10.181
  I0902 09:03:10.189016 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  E0902 09:03:10.526016      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:03:11.526809      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:03:12.527134      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with known and required properties @ 09/02/25 09:03:12.962
  I0902 09:03:12.963174 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=crd-publish-openapi-9850 --namespace=crd-publish-openapi-9850 create -f -'
  I0902 09:03:13.236933 16 builder.go:156] stderr: ""
  I0902 09:03:13.237073 16 builder.go:157] stdout: "e2e-test-crd-publish-openapi-9850-2436-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
  I0902 09:03:13.237613 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=crd-publish-openapi-9850 --namespace=crd-publish-openapi-9850 delete e2e-test-crd-publish-openapi-9850-2436-crds test-foo'
  I0902 09:03:13.525089 16 builder.go:156] stderr: ""
  I0902 09:03:13.525216 16 builder.go:157] stdout: "e2e-test-crd-publish-openapi-9850-2436-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted from crd-publish-openapi-9850 namespace\n"
  I0902 09:03:13.526063 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=crd-publish-openapi-9850 --namespace=crd-publish-openapi-9850 apply -f -'
  E0902 09:03:13.527772      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:03:13.725581 16 builder.go:156] stderr: ""
  I0902 09:03:13.725744 16 builder.go:157] stdout: "e2e-test-crd-publish-openapi-9850-2436-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
  I0902 09:03:13.726127 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=crd-publish-openapi-9850 --namespace=crd-publish-openapi-9850 delete e2e-test-crd-publish-openapi-9850-2436-crds test-foo'
  I0902 09:03:13.927279 16 builder.go:156] stderr: ""
  I0902 09:03:13.927451 16 builder.go:157] stdout: "e2e-test-crd-publish-openapi-9850-2436-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted from crd-publish-openapi-9850 namespace\n"
  STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values @ 09/02/25 09:03:13.927
  I0902 09:03:13.928264 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=crd-publish-openapi-9850 --namespace=crd-publish-openapi-9850 create -f -'
  I0902 09:03:14.114734 16 builder.go:145] rc: 1
  STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema @ 09/02/25 09:03:14.114
  I0902 09:03:14.115686 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=crd-publish-openapi-9850 --namespace=crd-publish-openapi-9850 create -f -'
  I0902 09:03:14.279815 16 builder.go:145] rc: 1
  I0902 09:03:14.280508 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=crd-publish-openapi-9850 --namespace=crd-publish-openapi-9850 apply -f -'
  I0902 09:03:14.451832 16 builder.go:145] rc: 1
  STEP: kubectl validation (kubectl create and apply) rejects request without required properties @ 09/02/25 09:03:14.451
  I0902 09:03:14.452401 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=crd-publish-openapi-9850 --namespace=crd-publish-openapi-9850 create -f -'
  E0902 09:03:14.528304      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:03:14.610646 16 builder.go:145] rc: 1
  I0902 09:03:14.611411 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=crd-publish-openapi-9850 --namespace=crd-publish-openapi-9850 apply -f -'
  I0902 09:03:14.787125 16 builder.go:145] rc: 1
  STEP: kubectl explain works to explain CR properties @ 09/02/25 09:03:14.787
  I0902 09:03:14.787748 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=crd-publish-openapi-9850 explain e2e-test-crd-publish-openapi-9850-2436-crds'
  I0902 09:03:14.942394 16 builder.go:156] stderr: ""
  I0902 09:03:14.942541 16 builder.go:157] stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-9850-2436-crd\nVERSION:    v1\n\nDESCRIPTION:\n    Foo CRD for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Foo\n\n  status\t<Object>\n    Status of Foo\n\n\n"
  STEP: kubectl explain works to explain CR properties recursively @ 09/02/25 09:03:14.943
  I0902 09:03:14.943366 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=crd-publish-openapi-9850 explain e2e-test-crd-publish-openapi-9850-2436-crds.metadata'
  I0902 09:03:15.104534 16 builder.go:156] stderr: ""
  I0902 09:03:15.105183 16 builder.go:157] stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-9850-2436-crd\nVERSION:    v1\n\nFIELD: metadata <ObjectMeta>\n\n\nDESCRIPTION:\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n    ObjectMeta is metadata that all persisted resources must have, which\n    includes all objects users must create.\n    \nFIELDS:\n  annotations\t<map[string]string>\n    Annotations is an unstructured key value map stored with a resource that may\n    be set by external tools to store and retrieve arbitrary metadata. They are\n    not queryable and should be preserved when modifying objects. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations\n\n  creationTimestamp\t<string>\n    CreationTimestamp is a timestamp representing the server time when this\n    object was created. It is not guaranteed to be set in happens-before order\n    across separate operations. Clients may not set this value. It is\n    represented in RFC3339 form and is in UTC.\n    \n    Populated by the system. Read-only. Null for lists. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  deletionGracePeriodSeconds\t<integer>\n    Number of seconds allowed for this object to gracefully terminate before it\n    will be removed from the system. Only set when deletionTimestamp is also\n    set. May only be shortened. Read-only.\n\n  deletionTimestamp\t<string>\n    DeletionTimestamp is RFC 3339 date and time at which this resource will be\n    deleted. This field is set by the server when a graceful deletion is\n    requested by the user, and is not directly settable by a client. The\n    resource is expected to be deleted (no longer visible from resource lists,\n    and not reachable by name) after the time in this field, once the finalizers\n    list is empty. As long as the finalizers list contains items, deletion is\n    blocked. Once the deletionTimestamp is set, this value may not be unset or\n    be set further into the future, although it may be shortened or the resource\n    may be deleted prior to this time. For example, a user may request that a\n    pod is deleted in 30 seconds. The Kubelet will react by sending a graceful\n    termination signal to the containers in the pod. After that 30 seconds, the\n    Kubelet will send a hard termination signal (SIGKILL) to the container and\n    after cleanup, remove the pod from the API. In the presence of network\n    partitions, this object may still exist after this timestamp, until an\n    administrator or automated process can determine the resource is fully\n    terminated. If not set, graceful deletion of the object has not been\n    requested.\n    \n    Populated by the system when a graceful deletion is requested. Read-only.\n    More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  finalizers\t<[]string>\n    Must be empty before the object is deleted from the registry. Each entry is\n    an identifier for the responsible component that will remove the entry from\n    the list. If the deletionTimestamp of the object is non-nil, entries in this\n    list can only be removed. Finalizers may be processed and removed in any\n    order.  Order is NOT enforced because it introduces significant risk of\n    stuck finalizers. finalizers is a shared field, any actor with permission\n    can reorder it. If the finalizer list is processed in order, then this can\n    lead to a situation in which the component responsible for the first\n    finalizer in the list is waiting for a signal (field value, external system,\n    or other) produced by a component responsible for a finalizer later in the\n    list, resulting in a deadlock. Without enforced ordering finalizers are free\n    to order amongst themselves and are not vulnerable to ordering changes in\n    the list.\n\n  generateName\t<string>\n    GenerateName is an optional prefix, used by the server, to generate a unique\n    name ONLY IF the Name field has not been provided. If this field is used,\n    the name returned to the client will be different than the name passed. This\n    value will also be combined with a unique suffix. The provided value has the\n    same validation rules as the Name field, and may be truncated by the length\n    of the suffix required to make the value unique on the server.\n    \n    If this field is specified and the generated name exists, the server will\n    return a 409.\n    \n    Applied only if Name is not specified. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n  generation\t<integer>\n    A sequence number representing a specific generation of the desired state.\n    Populated by the system. Read-only.\n\n  labels\t<map[string]string>\n    Map of string keys and values that can be used to organize and categorize\n    (scope and select) objects. May match selectors of replication controllers\n    and services. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/labels\n\n  managedFields\t<[]ManagedFieldsEntry>\n    ManagedFields maps workflow-id and version to the set of fields that are\n    managed by that workflow. This is mostly for internal housekeeping, and\n    users typically shouldn't need to set or understand this field. A workflow\n    can be the user's name, a controller's name, or the name of a specific apply\n    path like \"ci-cd\". The set of fields is always in the version that the\n    workflow used when modifying the object.\n\n  name\t<string>\n    Name must be unique within a namespace. Is required when creating resources,\n    although some resources may allow a client to request the generation of an\n    appropriate name automatically. Name is primarily intended for creation\n    idempotence and configuration definition. Cannot be updated. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/names#names\n\n  namespace\t<string>\n    Namespace defines the space within which each name must be unique. An empty\n    namespace is equivalent to the \"default\" namespace, but \"default\" is the\n    canonical representation. Not all objects are required to be scoped to a\n    namespace - the value of this field for those objects will be empty.\n    \n    Must be a DNS_LABEL. Cannot be updated. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces\n\n  ownerReferences\t<[]OwnerReference>\n    List of objects depended by this object. If ALL objects in the list have\n    been deleted, this object will be garbage collected. If this object is\n    managed by a controller, then an entry in this list will point to this\n    controller, with the controller field set to true. There cannot be more than\n    one managing controller.\n\n  resourceVersion\t<string>\n    An opaque value that represents the internal version of this object that can\n    be used by clients to determine when objects have changed. May be used for\n    optimistic concurrency, change detection, and the watch operation on a\n    resource or set of resources. Clients must treat these values as opaque and\n    passed unmodified back to the server. They may only be valid for a\n    particular resource or set of resources.\n    \n    Populated by the system. Read-only. Value must be treated as opaque by\n    clients and . More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n  selfLink\t<string>\n    Deprecated: selfLink is a legacy read-only field that is no longer populated\n    by the system.\n\n  uid\t<string>\n    UID is the unique in time and space value for this object. It is typically\n    generated by the server on successful creation of a resource and is not\n    allowed to change on PUT operations.\n    \n    Populated by the system. Read-only. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/names#uids\n\n\n"
  I0902 09:03:15.106290 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=crd-publish-openapi-9850 explain e2e-test-crd-publish-openapi-9850-2436-crds.spec'
  I0902 09:03:15.281989 16 builder.go:156] stderr: ""
  I0902 09:03:15.282114 16 builder.go:157] stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-9850-2436-crd\nVERSION:    v1\n\nFIELD: spec <Object>\n\n\nDESCRIPTION:\n    Specification of Foo\n    \nFIELDS:\n  bars\t<[]Object>\n    List of Bars and their specs.\n\n\n"
  I0902 09:03:15.283143 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=crd-publish-openapi-9850 explain e2e-test-crd-publish-openapi-9850-2436-crds.spec.bars'
  I0902 09:03:15.469992 16 builder.go:156] stderr: ""
  I0902 09:03:15.470277 16 builder.go:157] stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-9850-2436-crd\nVERSION:    v1\n\nFIELD: bars <[]Object>\n\n\nDESCRIPTION:\n    List of Bars and their specs.\n    \nFIELDS:\n  age\t<string>\n    Age of Bar.\n\n  bazs\t<[]string>\n    List of Bazs.\n\n  feeling\t<string>\n  enum: Great, Down\n    Whether Bar is feeling great.\n\n  name\t<string> -required-\n    Name of Bar.\n\n\n"
  STEP: kubectl explain works to return error when explain is called on property that doesn't exist @ 09/02/25 09:03:15.47
  I0902 09:03:15.471146 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=crd-publish-openapi-9850 explain e2e-test-crd-publish-openapi-9850-2436-crds.spec.bars2'
  E0902 09:03:15.528313      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:03:15.637924 16 builder.go:145] rc: 1
  E0902 09:03:16.529230      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:03:17.529801      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:03:17.975112 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-9850" for this suite. @ 09/02/25 09:03:17.995
• [7.885 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown metadata fields in both the root and embedded object of a CR [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:472
  STEP: Creating a kubernetes client @ 09/02/25 09:03:18.01
  I0902 09:03:18.010447 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename field-validation @ 09/02/25 09:03:18.015
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:03:18.049
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:03:18.056
  I0902 09:03:18.063896 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  I0902 09:03:18.083963      16 warnings.go:110] "Warning: unrecognized format \"int32\""
  E0902 09:03:18.531018      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:03:19.531263      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:03:20.532416      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:03:20.784654      16 warnings.go:110] "Warning: unknown field \"alpha\""
  I0902 09:03:20.784708      16 warnings.go:110] "Warning: unknown field \"beta\""
  I0902 09:03:20.784726      16 warnings.go:110] "Warning: unknown field \"delta\""
  I0902 09:03:20.784748      16 warnings.go:110] "Warning: unknown field \"epsilon\""
  I0902 09:03:20.784765      16 warnings.go:110] "Warning: unknown field \"gamma\""
  I0902 09:03:21.374137 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-3638" for this suite. @ 09/02/25 09:03:21.386
• [3.393 seconds]
------------------------------
SSS
------------------------------
[sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:111
  STEP: Creating a kubernetes client @ 09/02/25 09:03:21.403
  I0902 09:03:21.403407 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename disruption @ 09/02/25 09:03:21.41
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:03:21.439
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:03:21.444
  STEP: creating the pdb @ 09/02/25 09:03:21.449
  STEP: Waiting for the pdb to be processed @ 09/02/25 09:03:21.459
  E0902 09:03:21.533251      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:03:22.533982      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: updating the pdb @ 09/02/25 09:03:23.469
  STEP: Waiting for the pdb to be processed @ 09/02/25 09:03:23.498
  E0902 09:03:23.534920      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:03:24.536028      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: patching the pdb @ 09/02/25 09:03:25.508
  E0902 09:03:25.536181      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Waiting for the pdb to be processed @ 09/02/25 09:03:25.541
  STEP: Waiting for the pdb to be deleted @ 09/02/25 09:03:25.588
  I0902 09:03:25.594736 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-1926" for this suite. @ 09/02/25 09:03:25.604
• [4.214 seconds]
------------------------------
SS
------------------------------
[sig-node] Downward API should provide hostIPs as an env var [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:121
  STEP: Creating a kubernetes client @ 09/02/25 09:03:25.618
  I0902 09:03:25.619157 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename downward-api @ 09/02/25 09:03:25.622
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:03:25.655
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:03:25.663
  STEP: Creating a pod to test downward api env vars @ 09/02/25 09:03:25.674
  E0902 09:03:26.536483      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:03:27.537052      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:03:28.542183      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:03:29.542690      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/02/25 09:03:29.742
  I0902 09:03:29.754714 16 output.go:207] Trying to get logs from node ietha7evai9i-3 pod downward-api-11e0394c-aa41-4b46-9cf4-4333f42d783f container dapi-container: <nil>
  STEP: delete the pod @ 09/02/25 09:03:29.784
  I0902 09:03:29.840677 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-4815" for this suite. @ 09/02/25 09:03:29.851
• [4.244 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-network] Services should be able to create a functioning NodePort service [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1294
  STEP: Creating a kubernetes client @ 09/02/25 09:03:29.862
  I0902 09:03:29.863139 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename services @ 09/02/25 09:03:29.866
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:03:29.906
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:03:29.916
  STEP: creating service nodeport-test with type=NodePort in namespace services-4528 @ 09/02/25 09:03:29.924
  I0902 09:03:30.016642 16 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:0, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:0, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition(nil), CollisionCount:(*int32)(nil)}
  E0902 09:03:30.542824      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:03:31.543042      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:03:32.028023 16 resource.go:344] Creating new exec pod
  E0902 09:03:32.543732      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:03:33.544380      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:03:34.544615      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:03:35.544874      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:03:36.103978 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=services-4528 exec execpodfq7ql -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
  I0902 09:03:36.479492 16 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test (10.233.41.142) 80 port [tcp/http] succeeded!\n"
  I0902 09:03:36.479613 16 builder.go:157] stdout: ""
  E0902 09:03:36.544997      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:03:37.104153 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=services-4528 exec execpodfq7ql -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
  I0902 09:03:37.472399 16 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test (10.233.41.142) 80 port [tcp/http] succeeded!\n"
  I0902 09:03:37.472480 16 builder.go:157] stdout: "nodeport-test-6597f8c589-8nbw2"
  I0902 09:03:37.472890 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=services-4528 exec execpodfq7ql -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.41.142 80'
  E0902 09:03:37.545713      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:03:37.721702 16 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.41.142 80\nConnection to 10.233.41.142 80 port [tcp/http] succeeded!\n"
  I0902 09:03:37.721802 16 builder.go:157] stdout: ""
  I0902 09:03:38.473245 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=services-4528 exec execpodfq7ql -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.41.142 80'
  E0902 09:03:38.546232      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:03:38.801162 16 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.41.142 80\nConnection to 10.233.41.142 80 port [tcp/http] succeeded!\n"
  I0902 09:03:38.801996 16 builder.go:157] stdout: "nodeport-test-6597f8c589-st4hn"
  I0902 09:03:38.802461 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=services-4528 exec execpodfq7ql -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.25 32531'
  I0902 09:03:39.062517 16 builder.go:156] stderr: "+ + nc -v -t -w 2 192.168.121.25 32531\necho hostName\nConnection to 192.168.121.25 32531 port [tcp/*] succeeded!\n"
  I0902 09:03:39.062684 16 builder.go:157] stdout: "nodeport-test-6597f8c589-st4hn"
  I0902 09:03:39.063066 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=services-4528 exec execpodfq7ql -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.46 32531'
  I0902 09:03:39.329316 16 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.46 32531\nConnection to 192.168.121.46 32531 port [tcp/*] succeeded!\n"
  I0902 09:03:39.329399 16 builder.go:157] stdout: "nodeport-test-6597f8c589-8nbw2"
  I0902 09:03:39.329882 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-4528" for this suite. @ 09/02/25 09:03:39.343
• [9.497 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:399
  STEP: Creating a kubernetes client @ 09/02/25 09:03:39.387
  I0902 09:03:39.387049 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename pods @ 09/02/25 09:03:39.39
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:03:39.418
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:03:39.427
  STEP: creating the pod @ 09/02/25 09:03:39.434
  STEP: submitting the pod to kubernetes @ 09/02/25 09:03:39.434
  I0902 09:03:39.467827      16 warnings.go:110] "Warning: metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]"
  E0902 09:03:39.547226      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:03:40.548177      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: verifying the pod is in kubernetes @ 09/02/25 09:03:41.503
  STEP: updating the pod @ 09/02/25 09:03:41.517
  E0902 09:03:41.548782      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:03:42.042324 16 pod_client.go:186] Successfully updated pod "pod-update-activedeadlineseconds-0b364028-f627-4f6f-a6c7-6d89c0911707"
  E0902 09:03:42.549383      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:03:43.549442      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:03:44.549693      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:03:45.550244      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:03:46.080537 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-8439" for this suite. @ 09/02/25 09:03:46.096
• [6.728 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:109
  STEP: Creating a kubernetes client @ 09/02/25 09:03:46.119
  I0902 09:03:46.120337 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename configmap @ 09/02/25 09:03:46.125
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:03:46.188
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:03:46.2
  STEP: Creating configMap with name configmap-test-volume-map-0897303c-2d53-41ba-b703-9b9ff6de0feb @ 09/02/25 09:03:46.206
  STEP: Creating a pod to test consume configMaps @ 09/02/25 09:03:46.215
  E0902 09:03:46.550535      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:03:47.551389      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:03:48.552375      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:03:49.553067      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/02/25 09:03:50.267
  I0902 09:03:50.276535 16 output.go:207] Trying to get logs from node ietha7evai9i-2 pod pod-configmaps-5126f154-fdb5-4548-ba51-a73df601197c container agnhost-container: <nil>
  STEP: delete the pod @ 09/02/25 09:03:50.293
  I0902 09:03:50.353706 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-9459" for this suite. @ 09/02/25 09:03:50.374
• [4.272 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:236
  STEP: Creating a kubernetes client @ 09/02/25 09:03:50.393
  I0902 09:03:50.393629 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename projected @ 09/02/25 09:03:50.397
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:03:50.424
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:03:50.429
  STEP: Creating a pod to test downward API volume plugin @ 09/02/25 09:03:50.442
  E0902 09:03:50.553768      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:03:51.554410      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:03:52.555061      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:03:53.555255      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/02/25 09:03:54.513
  I0902 09:03:54.524404 16 output.go:207] Trying to get logs from node ietha7evai9i-3 pod downwardapi-volume-3ddfb129-c499-4817-abf2-6138393cf37e container client-container: <nil>
  E0902 09:03:54.555597      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: delete the pod @ 09/02/25 09:03:54.569
  I0902 09:03:54.614043 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8066" for this suite. @ 09/02/25 09:03:54.625
• [4.247 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2289
  STEP: Creating a kubernetes client @ 09/02/25 09:03:54.641
  I0902 09:03:54.641318 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename services @ 09/02/25 09:03:54.645
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:03:54.683
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:03:54.694
  STEP: creating service in namespace services-8851 @ 09/02/25 09:03:54.7
  STEP: creating service affinity-nodeport-transition in namespace services-8851 @ 09/02/25 09:03:54.7
  I0902 09:03:54.821369 16 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:0, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:0, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition(nil), CollisionCount:(*int32)(nil)}
  E0902 09:03:55.555906      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:03:56.555883      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:03:56.840738 16 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:3, UpdatedReplicas:3, ReadyReplicas:2, AvailableReplicas:2, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.September, 2, 9, 3, 54, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 9, 3, 54, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.September, 2, 9, 3, 56, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 9, 3, 54, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"affinity-nodeport-transition-5794c6cd75\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0902 09:03:57.556295      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:03:58.557276      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:03:58.914019 16 resource.go:344] Creating new exec pod
  E0902 09:03:59.558768      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:04:00.559255      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:04:01.006908 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=services-8851 exec execpod-affinityhh4r2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
  I0902 09:04:01.397005 16 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition (10.233.52.172) 80 port [tcp/http] succeeded!\n"
  I0902 09:04:01.397122 16 builder.go:157] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0902 09:04:01.398002 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=services-8851 exec execpod-affinityhh4r2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.52.172 80'
  E0902 09:04:01.559432      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:04:01.752262 16 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.52.172 80\nConnection to 10.233.52.172 80 port [tcp/http] succeeded!\n"
  I0902 09:04:01.752346 16 builder.go:157] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0902 09:04:01.752713 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=services-8851 exec execpod-affinityhh4r2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.25 30448'
  I0902 09:04:02.055940 16 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.25 30448\nConnection to 192.168.121.25 30448 port [tcp/*] succeeded!\n"
  I0902 09:04:02.056024 16 builder.go:157] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0902 09:04:02.056456 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=services-8851 exec execpod-affinityhh4r2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.52 30448'
  I0902 09:04:02.344729 16 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.52 30448\nConnection to 192.168.121.52 30448 port [tcp/*] succeeded!\n"
  I0902 09:04:02.344817 16 builder.go:157] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0902 09:04:02.363740 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=services-8851 exec execpod-affinityhh4r2 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 --max-time 60 http://192.168.121.25:30448/ ; done'
  E0902 09:04:02.560487      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:04:03.080374 16 builder.go:156] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.121.25:30448/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.121.25:30448/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.121.25:30448/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.121.25:30448/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.121.25:30448/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.121.25:30448/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.121.25:30448/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.121.25:30448/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.121.25:30448/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.121.25:30448/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.121.25:30448/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.121.25:30448/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.121.25:30448/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.121.25:30448/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.121.25:30448/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.121.25:30448/\n"
  I0902 09:04:03.081847 16 builder.go:157] stdout: "\naffinity-nodeport-transition-5794c6cd75-8whdd\naffinity-nodeport-transition-5794c6cd75-vdplq\naffinity-nodeport-transition-5794c6cd75-ml6kw\naffinity-nodeport-transition-5794c6cd75-8whdd\naffinity-nodeport-transition-5794c6cd75-ml6kw\naffinity-nodeport-transition-5794c6cd75-ml6kw\naffinity-nodeport-transition-5794c6cd75-vdplq\naffinity-nodeport-transition-5794c6cd75-vdplq\naffinity-nodeport-transition-5794c6cd75-vdplq\naffinity-nodeport-transition-5794c6cd75-vdplq\naffinity-nodeport-transition-5794c6cd75-8whdd\naffinity-nodeport-transition-5794c6cd75-vdplq\naffinity-nodeport-transition-5794c6cd75-ml6kw\naffinity-nodeport-transition-5794c6cd75-ml6kw\naffinity-nodeport-transition-5794c6cd75-8whdd\naffinity-nodeport-transition-5794c6cd75-vdplq"
  I0902 09:04:03.081981 16 service.go:225] Received response from host: affinity-nodeport-transition-5794c6cd75-8whdd
  I0902 09:04:03.082019 16 service.go:225] Received response from host: affinity-nodeport-transition-5794c6cd75-vdplq
  I0902 09:04:03.082048 16 service.go:225] Received response from host: affinity-nodeport-transition-5794c6cd75-ml6kw
  I0902 09:04:03.082773 16 service.go:225] Received response from host: affinity-nodeport-transition-5794c6cd75-8whdd
  I0902 09:04:03.083171 16 service.go:225] Received response from host: affinity-nodeport-transition-5794c6cd75-ml6kw
  I0902 09:04:03.083272 16 service.go:225] Received response from host: affinity-nodeport-transition-5794c6cd75-ml6kw
  I0902 09:04:03.083290 16 service.go:225] Received response from host: affinity-nodeport-transition-5794c6cd75-vdplq
  I0902 09:04:03.083306 16 service.go:225] Received response from host: affinity-nodeport-transition-5794c6cd75-vdplq
  I0902 09:04:03.083322 16 service.go:225] Received response from host: affinity-nodeport-transition-5794c6cd75-vdplq
  I0902 09:04:03.084723 16 service.go:225] Received response from host: affinity-nodeport-transition-5794c6cd75-vdplq
  I0902 09:04:03.084836 16 service.go:225] Received response from host: affinity-nodeport-transition-5794c6cd75-8whdd
  I0902 09:04:03.084857 16 service.go:225] Received response from host: affinity-nodeport-transition-5794c6cd75-vdplq
  I0902 09:04:03.084976 16 service.go:225] Received response from host: affinity-nodeport-transition-5794c6cd75-ml6kw
  I0902 09:04:03.085070 16 service.go:225] Received response from host: affinity-nodeport-transition-5794c6cd75-ml6kw
  I0902 09:04:03.085148 16 service.go:225] Received response from host: affinity-nodeport-transition-5794c6cd75-8whdd
  I0902 09:04:03.085181 16 service.go:225] Received response from host: affinity-nodeport-transition-5794c6cd75-vdplq
  I0902 09:04:03.132642 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=services-8851 exec execpod-affinityhh4r2 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 --max-time 60 http://192.168.121.25:30448/ ; done'
  E0902 09:04:03.560480      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:04:03.764763 16 builder.go:156] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.121.25:30448/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.121.25:30448/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.121.25:30448/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.121.25:30448/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.121.25:30448/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.121.25:30448/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.121.25:30448/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.121.25:30448/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.121.25:30448/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.121.25:30448/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.121.25:30448/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.121.25:30448/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.121.25:30448/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.121.25:30448/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.121.25:30448/\n+ echo\n+ curl -q -s --connect-timeout 2 --max-time 60 http://192.168.121.25:30448/\n"
  I0902 09:04:03.766644 16 builder.go:157] stdout: "\naffinity-nodeport-transition-5794c6cd75-8whdd\naffinity-nodeport-transition-5794c6cd75-ml6kw\naffinity-nodeport-transition-5794c6cd75-ml6kw\naffinity-nodeport-transition-5794c6cd75-ml6kw\naffinity-nodeport-transition-5794c6cd75-ml6kw\naffinity-nodeport-transition-5794c6cd75-ml6kw\naffinity-nodeport-transition-5794c6cd75-ml6kw\naffinity-nodeport-transition-5794c6cd75-ml6kw\naffinity-nodeport-transition-5794c6cd75-ml6kw\naffinity-nodeport-transition-5794c6cd75-ml6kw\naffinity-nodeport-transition-5794c6cd75-ml6kw\naffinity-nodeport-transition-5794c6cd75-ml6kw\naffinity-nodeport-transition-5794c6cd75-ml6kw\naffinity-nodeport-transition-5794c6cd75-ml6kw\naffinity-nodeport-transition-5794c6cd75-ml6kw\naffinity-nodeport-transition-5794c6cd75-ml6kw"
  I0902 09:04:03.766781 16 service.go:225] Received response from host: affinity-nodeport-transition-5794c6cd75-8whdd
  I0902 09:04:03.766812 16 service.go:225] Received response from host: affinity-nodeport-transition-5794c6cd75-ml6kw
  I0902 09:04:03.766837 16 service.go:225] Received response from host: affinity-nodeport-transition-5794c6cd75-ml6kw
  I0902 09:04:03.766859 16 service.go:225] Received response from host: affinity-nodeport-transition-5794c6cd75-ml6kw
  I0902 09:04:03.766882 16 service.go:225] Received response from host: affinity-nodeport-transition-5794c6cd75-ml6kw
  I0902 09:04:03.766904 16 service.go:225] Received response from host: affinity-nodeport-transition-5794c6cd75-ml6kw
  I0902 09:04:03.766926 16 service.go:225] Received response from host: affinity-nodeport-transition-5794c6cd75-ml6kw
  I0902 09:04:03.766947 16 service.go:225] Received response from host: affinity-nodeport-transition-5794c6cd75-ml6kw
  I0902 09:04:03.766969 16 service.go:225] Received response from host: affinity-nodeport-transition-5794c6cd75-ml6kw
  I0902 09:04:03.766990 16 service.go:225] Received response from host: affinity-nodeport-transition-5794c6cd75-ml6kw
  I0902 09:04:03.767012 16 service.go:225] Received response from host: affinity-nodeport-transition-5794c6cd75-ml6kw
  I0902 09:04:03.767033 16 service.go:225] Received response from host: affinity-nodeport-transition-5794c6cd75-ml6kw
  I0902 09:04:03.767054 16 service.go:225] Received response from host: affinity-nodeport-transition-5794c6cd75-ml6kw
  I0902 09:04:03.767075 16 service.go:225] Received response from host: affinity-nodeport-transition-5794c6cd75-ml6kw
  I0902 09:04:03.767096 16 service.go:225] Received response from host: affinity-nodeport-transition-5794c6cd75-ml6kw
  I0902 09:04:03.767117 16 service.go:225] Received response from host: affinity-nodeport-transition-5794c6cd75-ml6kw
  I0902 09:04:03.770749 16 service.go:4469] Cleaning up the exec pod
  I0902 09:04:03.899528 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-8851" for this suite. @ 09/02/25 09:04:03.978
• [9.353 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Lease lease API should be available [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lease.go:73
  STEP: Creating a kubernetes client @ 09/02/25 09:04:03.995
  I0902 09:04:03.997639 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename lease-test @ 09/02/25 09:04:04
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:04:04.062
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:04:04.071
  I0902 09:04:04.218240 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "lease-test-49" for this suite. @ 09/02/25 09:04:04.227
• [0.251 seconds]
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:385
  STEP: Creating a kubernetes client @ 09/02/25 09:04:04.246
  I0902 09:04:04.246351 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename daemonsets @ 09/02/25 09:04:04.249
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:04:04.276
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:04:04.282
  I0902 09:04:04.353902 16 daemon_set.go:388] Creating simple daemon set daemon-set
  STEP: Check that daemon pods launch on every node of the cluster. @ 09/02/25 09:04:04.366
  I0902 09:04:04.509882 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0902 09:04:04.511394 16 fixtures.go:131] Node ietha7evai9i-1 is running 0 daemon pod, expected 1
  E0902 09:04:04.560310      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:04:05.408636 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0902 09:04:05.408774 16 fixtures.go:131] Node ietha7evai9i-1 is running 0 daemon pod, expected 1
  E0902 09:04:05.561302      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:04:06.397507 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I0902 09:04:06.397915 16 fixtures.go:136] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Update daemon pods image. @ 09/02/25 09:04:06.431
  STEP: Check that daemon pods images are updated. @ 09/02/25 09:04:06.481
  I0902 09:04:06.490717 16 daemon_set.go:1193] Wrong image for pod: daemon-set-nddzq. Expected: registry.k8s.io/e2e-test-images/agnhost:2.56, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  I0902 09:04:06.490781 16 daemon_set.go:1193] Wrong image for pod: daemon-set-vlvw4. Expected: registry.k8s.io/e2e-test-images/agnhost:2.56, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  E0902 09:04:06.561572      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:04:07.508501 16 daemon_set.go:1198] Pod daemon-set-cblhx is not available
  I0902 09:04:07.508673 16 daemon_set.go:1193] Wrong image for pod: daemon-set-nddzq. Expected: registry.k8s.io/e2e-test-images/agnhost:2.56, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  I0902 09:04:07.508701 16 daemon_set.go:1193] Wrong image for pod: daemon-set-vlvw4. Expected: registry.k8s.io/e2e-test-images/agnhost:2.56, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  E0902 09:04:07.562847      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:04:08.492812 16 daemon_set.go:1198] Pod daemon-set-cblhx is not available
  I0902 09:04:08.492890 16 daemon_set.go:1193] Wrong image for pod: daemon-set-nddzq. Expected: registry.k8s.io/e2e-test-images/agnhost:2.56, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  I0902 09:04:08.492912 16 daemon_set.go:1193] Wrong image for pod: daemon-set-vlvw4. Expected: registry.k8s.io/e2e-test-images/agnhost:2.56, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  E0902 09:04:08.563086      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:04:09.519944 16 daemon_set.go:1198] Pod daemon-set-6jrhh is not available
  I0902 09:04:09.520022 16 daemon_set.go:1193] Wrong image for pod: daemon-set-nddzq. Expected: registry.k8s.io/e2e-test-images/agnhost:2.56, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  E0902 09:04:09.563962      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:04:10.498641 16 daemon_set.go:1198] Pod daemon-set-6jrhh is not available
  I0902 09:04:10.498938 16 daemon_set.go:1193] Wrong image for pod: daemon-set-nddzq. Expected: registry.k8s.io/e2e-test-images/agnhost:2.56, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  E0902 09:04:10.564264      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:04:11.504308 16 daemon_set.go:1198] Pod daemon-set-qs7jt is not available
  STEP: Check that daemon pods are still running on every node of the cluster. @ 09/02/25 09:04:11.522
  I0902 09:04:11.545092 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0902 09:04:11.545171 16 fixtures.go:131] Node ietha7evai9i-3 is running 0 daemon pod, expected 1
  E0902 09:04:11.564922      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:04:12.541986 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0902 09:04:12.542097 16 fixtures.go:131] Node ietha7evai9i-3 is running 0 daemon pod, expected 1
  E0902 09:04:12.565012      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:04:13.565393      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:04:13.566375 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I0902 09:04:13.566528 16 fixtures.go:136] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 09/02/25 09:04:13.61
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1919, will wait for the garbage collector to delete the pods @ 09/02/25 09:04:13.61
  I0902 09:04:13.691392 16 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 20.38721ms
  I0902 09:04:13.791991 16 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 100.616789ms
  E0902 09:04:14.566680      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:04:15.004773 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0902 09:04:15.004880 16 fixtures.go:136] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I0902 09:04:15.024315 16 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"49768"},"items":null}

  I0902 09:04:15.039478 16 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"49768"},"items":null}

  I0902 09:04:15.089791 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-1919" for this suite. @ 09/02/25 09:04:15.104
• [10.882 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:155
  STEP: Creating a kubernetes client @ 09/02/25 09:04:15.132
  I0902 09:04:15.134237 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename crd-publish-openapi @ 09/02/25 09:04:15.14
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:04:15.183
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:04:15.192
  I0902 09:04:15.199799 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  E0902 09:04:15.567219      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:04:16.567949      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:04:17.568520      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 09/02/25 09:04:17.87
  I0902 09:04:17.871425 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=crd-publish-openapi-52 --namespace=crd-publish-openapi-52 create -f -'
  I0902 09:04:18.282605 16 builder.go:156] stderr: ""
  I0902 09:04:18.282711 16 builder.go:157] stdout: "e2e-test-crd-publish-openapi-52-3225-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
  I0902 09:04:18.283022 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=crd-publish-openapi-52 --namespace=crd-publish-openapi-52 delete e2e-test-crd-publish-openapi-52-3225-crds test-cr'
  I0902 09:04:18.567720 16 builder.go:156] stderr: ""
  I0902 09:04:18.568257 16 builder.go:157] stdout: "e2e-test-crd-publish-openapi-52-3225-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted from crd-publish-openapi-52 namespace\n"
  E0902 09:04:18.569182      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:04:18.569507 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=crd-publish-openapi-52 --namespace=crd-publish-openapi-52 apply -f -'
  I0902 09:04:18.794476 16 builder.go:156] stderr: ""
  I0902 09:04:18.794610 16 builder.go:157] stdout: "e2e-test-crd-publish-openapi-52-3225-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
  I0902 09:04:18.795018 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=crd-publish-openapi-52 --namespace=crd-publish-openapi-52 delete e2e-test-crd-publish-openapi-52-3225-crds test-cr'
  I0902 09:04:18.976851 16 builder.go:156] stderr: ""
  I0902 09:04:18.976943 16 builder.go:157] stdout: "e2e-test-crd-publish-openapi-52-3225-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted from crd-publish-openapi-52 namespace\n"
  STEP: kubectl explain works to explain CR without validation schema @ 09/02/25 09:04:18.976
  I0902 09:04:18.977219 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=crd-publish-openapi-52 explain e2e-test-crd-publish-openapi-52-3225-crds'
  I0902 09:04:19.123051 16 builder.go:156] stderr: ""
  I0902 09:04:19.123505 16 builder.go:157] stdout: "GROUP:      crd-publish-openapi-test-empty.example.com\nKIND:       e2e-test-crd-publish-openapi-52-3225-crd\nVERSION:    v1\n\nDESCRIPTION:\n    <empty>\nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n\n"
  E0902 09:04:19.569270      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:04:20.569638      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:04:21.569887      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:04:21.813401 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-52" for this suite. @ 09/02/25 09:04:21.842
• [6.733 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should support ValidatingAdmissionPolicy API operations [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/validatingadmissionpolicy.go:411
  STEP: Creating a kubernetes client @ 09/02/25 09:04:21.871
  I0902 09:04:21.871929 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename validating-admission-policy @ 09/02/25 09:04:21.877
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:04:21.925
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:04:21.933
  STEP: getting /apis @ 09/02/25 09:04:21.967
  STEP: getting /apis/admissionregistration.k8s.io @ 09/02/25 09:04:21.98
  STEP: getting /apis/admissionregistration.k8s.io/v1 @ 09/02/25 09:04:21.987
  STEP: creating @ 09/02/25 09:04:21.99
  STEP: getting @ 09/02/25 09:04:22.049
  STEP: listing @ 09/02/25 09:04:22.058
  STEP: watching @ 09/02/25 09:04:22.067
  I0902 09:04:22.067158 16 validatingadmissionpolicy.go:528] starting watch
  STEP: patching @ 09/02/25 09:04:22.069
  STEP: updating @ 09/02/25 09:04:22.083
  I0902 09:04:22.172230 16 validatingadmissionpolicy.go:557] waiting for watch events with expected annotations
  STEP: getting /status @ 09/02/25 09:04:22.172
  STEP: patching /status @ 09/02/25 09:04:22.184
  STEP: updating /status @ 09/02/25 09:04:22.195
  STEP: deleting @ 09/02/25 09:04:22.213
  STEP: deleting a collection @ 09/02/25 09:04:22.242
  I0902 09:04:22.279359 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "validating-admission-policy-4242" for this suite. @ 09/02/25 09:04:22.288
• [0.431 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:328
  STEP: Creating a kubernetes client @ 09/02/25 09:04:22.299
  I0902 09:04:22.299990 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename webhook @ 09/02/25 09:04:22.305
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:04:22.334
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:04:22.34
  STEP: Setting up server cert @ 09/02/25 09:04:22.383
  E0902 09:04:22.569862      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:04:23.569970      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 09/02/25 09:04:23.779
  STEP: Deploying the webhook pod @ 09/02/25 09:04:23.79
  STEP: Wait for the deployment to be ready @ 09/02/25 09:04:23.825
  I0902 09:04:23.843752 16 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0902 09:04:24.570272      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:04:25.570926      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:04:25.878637 16 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.September, 2, 9, 4, 23, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 9, 4, 23, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.September, 2, 9, 4, 23, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 9, 4, 23, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7d44fffc8\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0902 09:04:26.571290      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:04:27.571826      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 09/02/25 09:04:27.889
  STEP: Verifying the service has paired with the endpoint @ 09/02/25 09:04:27.917
  E0902 09:04:28.571989      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:04:28.918694 16 util.go:419] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  I0902 09:04:28.934946 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-6200-7180-crds.webhook.example.com via the AdmissionRegistration API @ 09/02/25 09:04:29.475
  STEP: Creating a custom resource that should be mutated by the webhook @ 09/02/25 09:04:29.515
  E0902 09:04:29.572729      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:04:30.572936      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:04:31.573865      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:04:32.477392 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-6200" for this suite. @ 09/02/25 09:04:32.486
  STEP: Destroying namespace "webhook-markers-5499" for this suite. @ 09/02/25 09:04:32.498
• [10.214 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should mount an API token into pods [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:79
  STEP: Creating a kubernetes client @ 09/02/25 09:04:32.518
  I0902 09:04:32.518147 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename svcaccounts @ 09/02/25 09:04:32.521
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:04:32.56
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:04:32.566
  E0902 09:04:32.574166      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:04:33.574478      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:04:34.574743      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: reading a file in the container @ 09/02/25 09:04:34.65
  I0902 09:04:34.650713 16 kubectl_utils.go:203] Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4554 pod-service-account-b56850bb-58d1-48ca-9c01-f70cc71f0645 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
  STEP: reading a file in the container @ 09/02/25 09:04:34.996
  I0902 09:04:34.997774 16 kubectl_utils.go:203] Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4554 pod-service-account-b56850bb-58d1-48ca-9c01-f70cc71f0645 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
  STEP: reading a file in the container @ 09/02/25 09:04:35.296
  I0902 09:04:35.296645 16 kubectl_utils.go:203] Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4554 pod-service-account-b56850bb-58d1-48ca-9c01-f70cc71f0645 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
  E0902 09:04:35.574999      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:04:35.594787 16 service_accounts.go:119] Got root ca configmap in namespace "svcaccounts-4554"
  I0902 09:04:35.601241 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-4554" for this suite. @ 09/02/25 09:04:35.614
• [3.111 seconds]
------------------------------
[sig-apps] Job with successPolicy should succeeded when all indexes succeeded [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:484
  STEP: Creating a kubernetes client @ 09/02/25 09:04:35.629
  I0902 09:04:35.629899 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename job @ 09/02/25 09:04:35.633
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:04:35.663
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:04:35.668
  STEP: Creating an indexed job with successPolicy @ 09/02/25 09:04:35.674
  STEP: Awaiting for the job to have the interim SuccessCriteriaMet with SuccessPolicy reason condition @ 09/02/25 09:04:35.692
  E0902 09:04:36.575892      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:04:37.576145      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:04:38.577013      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:04:39.577844      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:04:40.577975      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:04:41.578028      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Ensure that the job reaches completions @ 09/02/25 09:04:41.731
  STEP: Verifying that the job status to ensure correct final state @ 09/02/25 09:04:41.748
  I0902 09:04:41.758270 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-7630" for this suite. @ 09/02/25 09:04:41.776
• [6.170 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:351
  STEP: Creating a kubernetes client @ 09/02/25 09:04:41.808
  I0902 09:04:41.808449 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename disruption @ 09/02/25 09:04:41.813
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:04:41.849
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:04:41.856
  STEP: Creating a pdb that targets all three pods in a test replica set @ 09/02/25 09:04:41.863
  STEP: Waiting for the pdb to be processed @ 09/02/25 09:04:41.878
  E0902 09:04:42.578899      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:04:43.579878      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: First trying to evict a pod which shouldn't be evictable @ 09/02/25 09:04:43.902
  STEP: Waiting for all pods to be running @ 09/02/25 09:04:43.902
  I0902 09:04:43.913535 16 disruption.go:680] pods: 0 < 3
  E0902 09:04:44.584757      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:04:45.581531      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:04:45.916284 16 disruption.go:691] running pods: 2 < 3
  E0902 09:04:46.581976      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:04:47.582211      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: locating a running pod @ 09/02/25 09:04:47.922
  STEP: Updating the pdb to allow a pod to be evicted @ 09/02/25 09:04:47.97
  STEP: Waiting for the pdb to be processed @ 09/02/25 09:04:47.991
  E0902 09:04:48.582712      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:04:49.582943      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Trying to evict the same pod we tried earlier which should now be evictable @ 09/02/25 09:04:49.999
  STEP: Waiting for all pods to be running @ 09/02/25 09:04:49.999
  STEP: Waiting for the pdb to observed all healthy pods @ 09/02/25 09:04:50.007
  STEP: Patching the pdb to disallow a pod to be evicted @ 09/02/25 09:04:50.088
  STEP: Waiting for the pdb to be processed @ 09/02/25 09:04:50.112
  E0902 09:04:50.583861      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:04:51.584784      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Waiting for all pods to be running @ 09/02/25 09:04:52.12
  STEP: locating a running pod @ 09/02/25 09:04:52.132
  STEP: Deleting the pdb to allow a pod to be evicted @ 09/02/25 09:04:52.153
  STEP: Waiting for the pdb to be deleted @ 09/02/25 09:04:52.168
  STEP: Trying to evict the same pod we tried earlier which should now be evictable @ 09/02/25 09:04:52.177
  STEP: Waiting for all pods to be running @ 09/02/25 09:04:52.177
  I0902 09:04:52.278495 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-3382" for this suite. @ 09/02/25 09:04:52.294
• [10.513 seconds]
------------------------------
[sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:99
  STEP: Creating a kubernetes client @ 09/02/25 09:04:52.322
  I0902 09:04:52.322806 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename secrets @ 09/02/25 09:04:52.328
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:04:52.377
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:04:52.392
  STEP: Creating secret with name secret-test-6f0563a0-4df5-43dd-824b-facca735af4a @ 09/02/25 09:04:52.449
  STEP: Creating a pod to test consume secrets @ 09/02/25 09:04:52.463
  E0902 09:04:52.584891      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:04:53.585736      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:04:54.586490      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:04:55.587091      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/02/25 09:04:56.518
  I0902 09:04:56.529674 16 output.go:207] Trying to get logs from node ietha7evai9i-2 pod pod-secrets-dd30056d-2c2e-483a-9745-442ccc8b652f container secret-volume-test: <nil>
  STEP: delete the pod @ 09/02/25 09:04:56.583
  E0902 09:04:56.587966      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:04:56.618064 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-9376" for this suite. @ 09/02/25 09:04:56.628
  STEP: Destroying namespace "secret-namespace-3905" for this suite. @ 09/02/25 09:04:56.644
• [4.348 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:215
  STEP: Creating a kubernetes client @ 09/02/25 09:04:56.67
  I0902 09:04:56.670391 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename container-probe @ 09/02/25 09:04:56.672
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:04:56.714
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:04:56.722
  STEP: Creating pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676 @ 09/02/25 09:04:56.727
  E0902 09:04:57.588767      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:04:58.589824      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 09/02/25 09:04:58.819
  I0902 09:04:58.827344 16 container_probe.go:1749] Initial restart count of pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab is 0
  I0902 09:04:58.833411 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:04:59.590233      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:05:00.590417      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:05:00.841399 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:05:01.591016      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:05:02.591730      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:05:02.852729 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:05:03.591088      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:05:04.591319      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:05:04.863688 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:05:05.591719      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:05:06.592213      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:05:06.872649 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:05:07.592679      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:05:08.592699      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:05:08.883024 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:05:09.593451      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:05:10.593782      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:05:10.895867 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:05:11.593986      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:05:12.594176      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:05:12.907536 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:05:13.594425      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:05:14.594476      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:05:14.919838 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:05:15.594886      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:05:16.595461      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:05:16.936729 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:05:17.595703      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:05:18.595936      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:05:18.946099 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:05:19.596257      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:05:20.596334      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:05:20.954297 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:05:21.597121      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:05:22.597955      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:05:22.963458 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:05:23.599032      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:05:24.599375      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:05:24.974077 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:05:25.599700      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:05:26.599831      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:05:26.990486 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:05:27.601015      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:05:28.601047      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:05:29.010509 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:05:29.601251      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:05:30.601798      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:05:31.018610 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:05:31.602168      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:05:32.602515      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:05:33.033293 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:05:33.603608      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:05:34.603836      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:05:35.043248 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:05:35.604962      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:05:36.606113      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:05:37.052937 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:05:37.606953      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:05:38.607381      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:05:39.062733 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:05:39.607374      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:05:40.607482      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:05:41.073150 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:05:41.608659      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:05:42.608811      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:05:43.090719 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:05:43.609022      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:05:44.609081      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:05:45.098853 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:05:45.609491      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:05:46.609636      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:05:47.109352 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:05:47.609839      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:05:48.609944      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:05:49.119041 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:05:49.610683      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:05:50.611403      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:05:51.129814 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:05:51.612511      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:05:52.613015      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:05:53.138349 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:05:53.613752      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:05:54.614453      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:05:55.147784 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:05:55.614960      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:05:56.615086      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:05:57.160368 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:05:57.615336      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:05:58.616089      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:05:59.170529 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:05:59.616454      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:06:00.616786      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:06:01.186028 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:06:01.617336      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:06:02.618377      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:06:03.196294 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:06:03.618783      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:06:04.619829      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:06:05.205869 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:06:05.619892      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:06:06.620765      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:06:07.220975 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:06:07.621886      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:06:08.623954      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:06:09.232292 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:06:09.624810      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:06:10.625064      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:06:11.248302 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:06:11.625406      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:06:12.625916      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:06:13.257598 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:06:13.626071      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:06:14.627150      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:06:15.268958 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:06:15.627360      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:06:16.627703      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:06:17.282744 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:06:17.628598      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:06:18.628441      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:06:19.295122 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:06:19.628729      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:06:20.629390      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:06:21.308071 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:06:21.629659      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:06:22.630058      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:06:23.318294 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:06:23.630648      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:06:24.632154      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:06:25.327129 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:06:25.632771      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:06:26.633320      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:06:27.337438 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:06:27.634466      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:06:28.635117      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:06:29.353490 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:06:29.635425      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:06:30.635858      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:06:31.362635 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:06:31.636905      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:06:32.637173      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:06:33.378442 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:06:33.638933      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:06:34.638909      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:06:35.389290 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:06:35.639774      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:06:36.640480      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:06:37.398986 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:06:37.641956      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:06:38.642379      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:06:39.410306 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:06:39.643108      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:06:40.642730      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:06:41.423908 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:06:41.643287      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:06:42.644119      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:06:43.437762 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:06:43.644494      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:06:44.645152      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:06:45.447357 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:06:45.645392      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:06:46.646124      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:06:47.460457 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:06:47.646999      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:06:48.647966      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:06:49.473383 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:06:49.649395      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:06:50.649865      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:06:51.483122 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:06:51.650883      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:06:52.652289      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:06:53.493241 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:06:53.653098      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:06:54.653013      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:06:55.505722 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:06:55.654139      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:06:56.654297      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:06:57.514595 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:06:57.655018      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:06:58.656948      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:06:59.529318 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:06:59.656379      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:07:00.656923      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:07:01.536860 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:07:01.658179      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:07:02.658376      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:07:03.547513 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:07:03.658655      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:07:04.658934      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:07:05.556128 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:07:05.659332      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:07:06.659795      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:07:07.569649 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:07:07.661137      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:07:08.662251      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:07:09.579236 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:07:09.662835      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:07:10.663018      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:07:11.596314 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:07:11.663615      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:07:12.663913      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:07:13.607057 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:07:13.664722      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:07:14.665402      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:07:15.618264 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:07:15.666221      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:07:16.667005      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:07:17.628584 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:07:17.668480      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:07:18.668535      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:07:19.638946 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:07:19.669044      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:07:20.669650      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:07:21.647501 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:07:21.669846      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:07:22.670526      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:07:23.658975 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:07:23.671088      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:07:24.671474      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:07:25.668942 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:07:25.671734      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:07:26.673071      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:07:27.673787      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:07:27.680412 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:07:28.674078      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:07:29.674806      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:07:29.691833 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:07:30.675305      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:07:31.675880      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:07:31.698981 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:07:32.676045      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:07:33.676375      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:07:33.711082 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:07:34.676751      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:07:35.676965      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:07:35.718621 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:07:36.677454      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:07:37.677777      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:07:37.729122 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:07:38.678314      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:07:39.678657      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:07:39.759299 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:07:40.678856      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:07:41.679245      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:07:41.770285 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:07:42.679760      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:07:43.680152      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:07:43.782704 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:07:44.680385      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:07:45.680636      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:07:45.791938 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:07:46.680916      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:07:47.682084      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:07:47.811008 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:07:48.682613      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:07:49.682399      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:07:49.824409 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:07:50.682787      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:07:51.682916      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:07:51.835228 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:07:52.683918      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:07:53.684273      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:07:53.849876 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:07:54.685324      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:07:55.685696      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:07:55.862680 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:07:56.685910      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:07:57.687085      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:07:57.880787 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:07:58.688153      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:07:59.688601      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:07:59.898827 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:08:00.688885      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:08:01.689333      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:08:01.917416 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:08:02.689987      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:08:03.690134      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:08:03.926823 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:08:04.690524      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:08:05.690779      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:08:05.939464 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:08:06.692161      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:08:07.691905      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:08:07.950686 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:08:08.692250      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:08:09.692358      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:08:09.959663 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:08:10.692639      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:08:11.692710      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:08:11.968607 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:08:12.693606      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:08:13.694085      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:08:13.979789 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:08:14.694164      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:08:15.694821      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:08:15.990312 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:08:16.695276      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:08:17.696136      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:08:18.000907 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:08:18.696397      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:08:19.696827      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:08:20.009975 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:08:20.697945      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:08:21.697652      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:08:22.023886 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:08:22.698447      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:08:23.698024      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:08:24.035839 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:08:24.698901      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:08:25.699372      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:08:26.044415 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:08:26.700721      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:08:27.701046      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:08:28.055105 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:08:28.702072      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:08:29.702352      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:08:30.062097 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:08:30.702926      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:08:31.703109      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:08:32.071827 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:08:32.703590      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:08:33.703934      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:08:34.079911 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:08:34.704143      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:08:35.704656      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:08:36.088658 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:08:36.704773      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:08:37.704963      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:08:38.101106 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:08:38.705586      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:08:39.706083      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:08:40.109650 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:08:40.706795      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:08:41.707406      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:08:42.122112 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:08:42.707676      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:08:43.708332      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:08:44.134340 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:08:44.708805      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:08:45.709272      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:08:46.146999 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:08:46.709847      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:08:47.710271      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:08:48.160795 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:08:48.711705      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:08:49.712287      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:08:50.180533 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:08:50.712225      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:08:51.712478      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:08:52.191104 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:08:52.713232      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:08:53.713450      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:08:54.203814 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:08:54.714688      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:08:55.714655      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:08:56.217931 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:08:56.715058      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:08:57.715025      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:08:58.226367 16 container_probe.go:1759] Get pod test-webserver-f1ec1aa8-46c5-4add-913d-3c82339b36ab in namespace container-probe-6676
  E0902 09:08:58.715287      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:08:59.716070      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 09/02/25 09:09:00.227
  I0902 09:09:00.285001 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-6676" for this suite. @ 09/02/25 09:09:00.313
• [243.678 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:105
  STEP: Creating a kubernetes client @ 09/02/25 09:09:00.35
  I0902 09:09:00.350387 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename endpointslice @ 09/02/25 09:09:00.356
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:09:00.451
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:09:00.457
  I0902 09:09:00.527026      16 warnings.go:110] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  E0902 09:09:00.717822      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:09:01.717342      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:09:02.535054      16 warnings.go:110] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  I0902 09:09:02.608464      16 warnings.go:110] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  I0902 09:09:02.649916 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-4711" for this suite. @ 09/02/25 09:09:02.662
• [2.332 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:79
  STEP: Creating a kubernetes client @ 09/02/25 09:09:02.683
  I0902 09:09:02.683784 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename secrets @ 09/02/25 09:09:02.686
  E0902 09:09:02.717494      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:09:02.718
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:09:02.724
  STEP: Creating secret with name secret-test-map-bf77802a-8775-48fa-b201-8bd568f0b411 @ 09/02/25 09:09:02.731
  STEP: Creating a pod to test consume secrets @ 09/02/25 09:09:02.743
  E0902 09:09:03.717743      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:09:04.718004      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:09:05.718934      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:09:06.719377      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/02/25 09:09:06.799
  I0902 09:09:06.810428 16 output.go:207] Trying to get logs from node ietha7evai9i-2 pod pod-secrets-4fc9fad2-af2a-4670-bf41-b9a34f38ee84 container secret-volume-test: <nil>
  STEP: delete the pod @ 09/02/25 09:09:06.849
  I0902 09:09:06.899216 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-2425" for this suite. @ 09/02/25 09:09:06.912
• [4.250 seconds]
------------------------------
[sig-storage] VolumeAttachment Conformance should run through the lifecycle of a VolumeAttachment [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/volume_attachment.go:59
  STEP: Creating a kubernetes client @ 09/02/25 09:09:06.933
  I0902 09:09:06.933718 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename volumeattachment @ 09/02/25 09:09:06.94
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:09:06.978
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:09:06.982
  STEP: Create VolumeAttachment "va-e2e-snnxd" on node "ietha7evai9i-2" @ 09/02/25 09:09:07.012
  STEP: Get VolumeAttachment "va-e2e-snnxd" on node "ietha7evai9i-2" @ 09/02/25 09:09:07.023
  STEP: Patch VolumeAttachment "va-e2e-snnxd" on node "ietha7evai9i-2" @ 09/02/25 09:09:07.031
  STEP: List VolumeAttachments with "va-e2e-snnxd=patched" label @ 09/02/25 09:09:07.047
  STEP: Delete VolumeAttachment "va-e2e-snnxd" on node "ietha7evai9i-2" @ 09/02/25 09:09:07.054
  STEP: Confirm deletion of VolumeAttachment "va-e2e-snnxd" on node "ietha7evai9i-2" @ 09/02/25 09:09:07.067
  STEP: Create VolumeAttachment "va-e2e-nwn7p" on node "ietha7evai9i-3" @ 09/02/25 09:09:07.113
  STEP: Update the VolumeAttachment "va-e2e-nwn7p" on node "ietha7evai9i-3" with label "va-e2e=updated" @ 09/02/25 09:09:07.123
  STEP: Create VolumeAttachment "va-e2e-t4vxp" on node "ietha7evai9i-3" @ 09/02/25 09:09:07.213
  STEP: Update the VolumeAttachment "va-e2e-t4vxp" on node "ietha7evai9i-3" with label "va-e2e=updated" @ 09/02/25 09:09:07.237
  STEP: DeleteCollection of VolumeAttachments with "va-e2e=updated" label @ 09/02/25 09:09:07.255
  STEP: Confirm deleteCollection of VolumeAttachments with "va-e2e=updated" label @ 09/02/25 09:09:07.278
  I0902 09:09:07.285593 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "volumeattachment-2331" for this suite. @ 09/02/25 09:09:07.314
• [0.395 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:174
  STEP: Creating a kubernetes client @ 09/02/25 09:09:07.334
  I0902 09:09:07.334075 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename crd-webhook @ 09/02/25 09:09:07.339
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:09:07.382
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:09:07.394
  STEP: Setting up server cert @ 09/02/25 09:09:07.401
  E0902 09:09:07.719976      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:09:08.720686      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication @ 09/02/25 09:09:09.104
  STEP: Deploying the custom resource conversion webhook pod @ 09/02/25 09:09:09.119
  STEP: Wait for the deployment to be ready @ 09/02/25 09:09:09.147
  I0902 09:09:09.172636 16 deployment.go:223] new replicaset for deployment "sample-crd-conversion-webhook-deployment" is yet to be created
  E0902 09:09:09.721201      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:09:10.721667      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 09/02/25 09:09:11.213
  STEP: Verifying the service has paired with the endpoint @ 09/02/25 09:09:11.247
  E0902 09:09:11.721804      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:09:12.247527 16 util.go:419] Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
  I0902 09:09:12.258093 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  E0902 09:09:12.722685      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:09:13.722733      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:09:14.722987      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Creating a v1 custom resource @ 09/02/25 09:09:15.079
  STEP: Create a v2 custom resource @ 09/02/25 09:09:15.122
  STEP: List CRs in v1 @ 09/02/25 09:09:15.137
  STEP: List CRs in v2 @ 09/02/25 09:09:15.351
  E0902 09:09:15.723223      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:09:16.724336      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:09:17.038977 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-webhook-8436" for this suite. @ 09/02/25 09:09:17.049
• [9.730 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:978
  STEP: Creating a kubernetes client @ 09/02/25 09:09:17.063
  I0902 09:09:17.063445 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename statefulset @ 09/02/25 09:09:17.066
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:09:17.102
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:09:17.123
  STEP: Creating service test in namespace statefulset-8788 @ 09/02/25 09:09:17.134
  I0902 09:09:17.150269      16 warnings.go:110] "Warning: spec.SessionAffinity is ignored for headless services"
  I0902 09:09:17.170969 16 wait.go:44] Found 0 stateful pods, waiting for 1
  E0902 09:09:17.725068      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:09:18.725089      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:09:19.725770      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:09:20.726633      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:09:21.726815      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:09:22.727355      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:09:23.728070      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:09:24.727943      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:09:25.728758      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:09:26.728995      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:09:27.174665 16 wait.go:54] Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: patching the StatefulSet @ 09/02/25 09:09:27.19
  I0902 09:09:27.244940 16 wait.go:54] Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
  I0902 09:09:27.245769 16 wait.go:54] Waiting for pod test-ss-1 to enter Running - Ready=true, currently Pending - Ready=false
  E0902 09:09:27.729878      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:09:28.730439      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:09:29.731153      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:09:30.731658      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:09:31.732735      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:09:32.732861      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:09:33.733260      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:09:34.734140      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:09:35.735066      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:09:36.735641      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:09:37.251888 16 wait.go:54] Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
  I0902 09:09:37.251997 16 wait.go:54] Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Listing all StatefulSets @ 09/02/25 09:09:37.27
  STEP: Delete all of the StatefulSets @ 09/02/25 09:09:37.28
  STEP: Verify that StatefulSets have been deleted @ 09/02/25 09:09:37.338
  I0902 09:09:37.349201 16 statefulset.go:136] Deleting all statefulset in ns statefulset-8788
  I0902 09:09:37.394218 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-8788" for this suite. @ 09/02/25 09:09:37.406
• [20.361 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:69
  STEP: Creating a kubernetes client @ 09/02/25 09:09:37.425
  I0902 09:09:37.425790 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename endpointslice @ 09/02/25 09:09:37.428
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:09:37.514
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:09:37.526
  I0902 09:09:37.550837      16 warnings.go:110] "Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice"
  I0902 09:09:37.581605 16 endpointslice.go:1059] Endpoints addresses: [192.168.121.25 192.168.121.46] , ports: [6443]
  I0902 09:09:37.581971 16 endpointslice.go:1089] EndpointSlices addresses: [192.168.121.25 192.168.121.46] , ports: [6443]
  I0902 09:09:37.582466 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-1165" for this suite. @ 09/02/25 09:09:37.594
• [0.232 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] CSIInlineVolumes should run through the lifecycle of a CSIDriver [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/csi_inline.go:157
  STEP: Creating a kubernetes client @ 09/02/25 09:09:37.658
  I0902 09:09:37.659022 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename csiinlinevolumes @ 09/02/25 09:09:37.664
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:09:37.701
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:09:37.711
  STEP: Creating two CSIDrivers @ 09/02/25 09:09:37.719
  E0902 09:09:37.737732      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Getting "inline-driver-d39f71f6-bc38-4f1b-984a-f139b883fb37" & "inline-driver-febc033f-ae0d-4de4-bc2b-11ce329619b6" @ 09/02/25 09:09:37.773
  STEP: Patching the CSIDriver "inline-driver-febc033f-ae0d-4de4-bc2b-11ce329619b6" @ 09/02/25 09:09:37.799
  STEP: Updating the CSIDriver "inline-driver-febc033f-ae0d-4de4-bc2b-11ce329619b6" @ 09/02/25 09:09:37.824
  STEP: Listing all CSIDrivers with the labelSelector: "e2e-test=csiinlinevolumes-4988" @ 09/02/25 09:09:37.85
  STEP: Deleting CSIDriver "inline-driver-d39f71f6-bc38-4f1b-984a-f139b883fb37" @ 09/02/25 09:09:37.856
  STEP: Confirm deletion of CSIDriver "inline-driver-d39f71f6-bc38-4f1b-984a-f139b883fb37" @ 09/02/25 09:09:37.88
  STEP: Deleting CSIDriver "inline-driver-febc033f-ae0d-4de4-bc2b-11ce329619b6" via DeleteCollection @ 09/02/25 09:09:37.897
  STEP: Confirm deletion of CSIDriver "inline-driver-febc033f-ae0d-4de4-bc2b-11ce329619b6" @ 09/02/25 09:09:37.924
  I0902 09:09:37.934932 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csiinlinevolumes-4988" for this suite. @ 09/02/25 09:09:37.961
• [0.364 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] ServiceCIDR and IPAddress API should support ServiceCIDR API operations [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service_cidrs.go:163
  STEP: Creating a kubernetes client @ 09/02/25 09:09:38.024
  I0902 09:09:38.024540 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename servicecidr @ 09/02/25 09:09:38.031
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:09:38.069
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:09:38.074
  STEP: getting @ 09/02/25 09:09:38.079
  STEP: getting /status @ 09/02/25 09:09:38.087
  STEP: listing @ 09/02/25 09:09:38.094
  STEP: watching @ 09/02/25 09:09:38.102
  I0902 09:09:38.117125 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "servicecidr-6296" for this suite. @ 09/02/25 09:09:38.127
• [0.119 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] API priority and fairness should support FlowSchema API operations [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/flowcontrol.go:270
  STEP: Creating a kubernetes client @ 09/02/25 09:09:38.143
  I0902 09:09:38.143593 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename apf @ 09/02/25 09:09:38.145
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:09:38.177
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:09:38.182
  STEP: getting /apis @ 09/02/25 09:09:38.188
  STEP: getting /apis/flowcontrol.apiserver.k8s.io @ 09/02/25 09:09:38.205
  STEP: getting /apis/flowcontrol.apiserver.k8s.io/v1 @ 09/02/25 09:09:38.208
  STEP: creating @ 09/02/25 09:09:38.21
  STEP: getting @ 09/02/25 09:09:38.345
  STEP: listing @ 09/02/25 09:09:38.364
  STEP: watching @ 09/02/25 09:09:38.375
  I0902 09:09:38.375636 16 flowcontrol.go:394] starting watch
  STEP: patching @ 09/02/25 09:09:38.378
  STEP: updating @ 09/02/25 09:09:38.392
  I0902 09:09:38.409502 16 flowcontrol.go:422] waiting for watch events with expected annotations
  STEP: getting /status @ 09/02/25 09:09:38.41
  STEP: patching /status @ 09/02/25 09:09:38.418
  STEP: updating /status @ 09/02/25 09:09:38.43
  STEP: deleting @ 09/02/25 09:09:38.483
  STEP: deleting a collection @ 09/02/25 09:09:38.508
  I0902 09:09:38.550333 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "apf-9037" for this suite. @ 09/02/25 09:09:38.559
• [0.433 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose should create services for rc [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1565
  STEP: Creating a kubernetes client @ 09/02/25 09:09:38.578
  I0902 09:09:38.578211 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename kubectl @ 09/02/25 09:09:38.596
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:09:38.628
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:09:38.647
  STEP: creating Agnhost RC @ 09/02/25 09:09:38.657
  I0902 09:09:38.657130 16 kubectl.go:1572] namespace kubectl-7438
  I0902 09:09:38.657762 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-7438 create -f -'
  E0902 09:09:38.738947      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:09:39.056595 16 builder.go:156] stderr: ""
  I0902 09:09:39.056674 16 builder.go:157] stdout: "replicationcontroller/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 09/02/25 09:09:39.056
  E0902 09:09:39.739206      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:09:40.068349 16 framework.go:697] Selector matched 1 pods for map[app:agnhost]
  I0902 09:09:40.068416 16 framework.go:738] Found 0 / 1
  E0902 09:09:40.739394      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:09:41.070237 16 framework.go:697] Selector matched 1 pods for map[app:agnhost]
  I0902 09:09:41.070326 16 framework.go:738] Found 1 / 1
  I0902 09:09:41.070456 16 framework.go:747] WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  I0902 09:09:41.079413 16 framework.go:697] Selector matched 1 pods for map[app:agnhost]
  I0902 09:09:41.079594 16 framework.go:770] ForEach: Found 1 pods from the filter.  Now looping through them.
  I0902 09:09:41.079656 16 kubectl.go:1579] wait on agnhost-primary startup in kubectl-7438 
  I0902 09:09:41.080219 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-7438 logs agnhost-primary-c4hfm agnhost-primary'
  I0902 09:09:41.303843 16 builder.go:156] stderr: ""
  I0902 09:09:41.303918 16 builder.go:157] stdout: "Paused\nSignals registered\n"
  STEP: exposing RC @ 09/02/25 09:09:41.303
  I0902 09:09:41.304640 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-7438 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
  I0902 09:09:41.484960 16 builder.go:156] stderr: ""
  I0902 09:09:41.485212 16 builder.go:157] stdout: "service/rm2 exposed\n"
  I0902 09:09:41.496372 16 utils.go:1116] Service rm2 in namespace kubectl-7438 found.
  E0902 09:09:41.739908      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:09:42.740136      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: exposing service @ 09/02/25 09:09:43.519
  I0902 09:09:43.520111 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-7438 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
  E0902 09:09:43.740883      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:09:43.756894 16 builder.go:156] stderr: ""
  I0902 09:09:43.758357 16 builder.go:157] stdout: "service/rm3 exposed\n"
  I0902 09:09:43.766497 16 utils.go:1116] Service rm3 in namespace kubectl-7438 found.
  E0902 09:09:44.741711      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:09:45.741878      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:09:45.785821 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-7438" for this suite. @ 09/02/25 09:09:45.801
• [7.241 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:330
  STEP: Creating a kubernetes client @ 09/02/25 09:09:45.82
  I0902 09:09:45.820831 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename gc @ 09/02/25 09:09:45.823
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:09:45.851
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:09:45.857
  STEP: create the rc @ 09/02/25 09:09:45.862
  I0902 09:09:45.875793      16 warnings.go:110] "Warning: metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]"
  E0902 09:09:46.743075      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:09:47.743886      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:09:48.743888      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:09:49.744124      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:09:50.744332      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: delete the rc @ 09/02/25 09:09:50.941
  STEP: wait for all pods to be garbage collected @ 09/02/25 09:09:50.966
  E0902 09:09:51.744702      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:09:52.744969      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:09:53.745203      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:09:54.745750      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:09:55.745912      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 09/02/25 09:09:55.996
  I0902 09:09:56.231347 16 garbage_collector.go:273] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I0902 09:09:56.232782 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-9057" for this suite. @ 09/02/25 09:09:56.245
• [10.443 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:900
  STEP: Creating a kubernetes client @ 09/02/25 09:09:56.265
  I0902 09:09:56.265443 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename pods @ 09/02/25 09:09:56.27
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:09:56.293
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:09:56.3
  STEP: creating a Pod with a static label @ 09/02/25 09:09:56.316
  STEP: watching for Pod to be ready @ 09/02/25 09:09:56.335
  I0902 09:09:56.340280 16 pods.go:947] observed Pod pod-test in namespace pods-2133 in phase Pending with labels: map[test-pod-static:true] & conditions []
  I0902 09:09:56.353401 16 pods.go:947] observed Pod pod-test in namespace pods-2133 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled 0 True 0001-01-01 00:00:00 +0000 UTC 2025-09-02 09:09:56 +0000 UTC  }]
  I0902 09:09:56.429680 16 pods.go:947] observed Pod pod-test in namespace pods-2133 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodReadyToStartContainers 1 False 0001-01-01 00:00:00 +0000 UTC 2025-09-02 09:09:56 +0000 UTC  } {Initialized 1 True 0001-01-01 00:00:00 +0000 UTC 2025-09-02 09:09:56 +0000 UTC  } {Ready 1 False 0001-01-01 00:00:00 +0000 UTC 2025-09-02 09:09:56 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady 1 False 0001-01-01 00:00:00 +0000 UTC 2025-09-02 09:09:56 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled 1 True 0001-01-01 00:00:00 +0000 UTC 2025-09-02 09:09:56 +0000 UTC  }]
  E0902 09:09:56.747417      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:09:57.747772      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:09:58.431491 16 pods.go:950] Found Pod pod-test in namespace pods-2133 in phase Running with labels: map[test-pod-static:true] & conditions [{PodReadyToStartContainers 1 True 0001-01-01 00:00:00 +0000 UTC 2025-09-02 09:09:58 +0000 UTC  } {Initialized 1 True 0001-01-01 00:00:00 +0000 UTC 2025-09-02 09:09:56 +0000 UTC  } {Ready 1 True 0001-01-01 00:00:00 +0000 UTC 2025-09-02 09:09:58 +0000 UTC  } {ContainersReady 1 True 0001-01-01 00:00:00 +0000 UTC 2025-09-02 09:09:58 +0000 UTC  } {PodScheduled 1 True 0001-01-01 00:00:00 +0000 UTC 2025-09-02 09:09:56 +0000 UTC  }]
  STEP: patching the Pod with a new Label and updated data @ 09/02/25 09:09:58.438
  STEP: getting the Pod and ensuring that it's patched @ 09/02/25 09:09:58.459
  STEP: replacing the Pod's status Ready condition to False @ 09/02/25 09:09:58.467
  STEP: check the Pod again to ensure its Ready conditions are False @ 09/02/25 09:09:58.489
  STEP: deleting the Pod via a Collection with a LabelSelector @ 09/02/25 09:09:58.489
  STEP: watching for the Pod to be deleted @ 09/02/25 09:09:58.51
  I0902 09:09:58.515752 16 pods.go:1060] observed event type MODIFIED
  E0902 09:09:58.748668      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:09:59.260927 16 pods.go:1060] observed event type MODIFIED
  I0902 09:09:59.457924 16 pods.go:1060] observed event type MODIFIED
  E0902 09:09:59.749646      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:10:00.463907 16 pods.go:1060] observed event type MODIFIED
  E0902 09:10:00.749977      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:10:00.766782 16 pods.go:1060] observed event type MODIFIED
  I0902 09:10:01.494580 16 pods.go:1060] observed event type MODIFIED
  I0902 09:10:01.524685 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-2133" for this suite. @ 09/02/25 09:10:01.539
• [5.294 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:139
  STEP: Creating a kubernetes client @ 09/02/25 09:10:01.56
  I0902 09:10:01.560613 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename configmap @ 09/02/25 09:10:01.564
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:10:01.594
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:10:01.598
  STEP: Creating configMap that has name configmap-test-emptyKey-f46e674c-e7c4-493a-af70-85af5b13616e @ 09/02/25 09:10:01.605
  I0902 09:10:01.609461 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-979" for this suite. @ 09/02/25 09:10:01.638
• [0.112 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:99
  STEP: Creating a kubernetes client @ 09/02/25 09:10:01.675
  I0902 09:10:01.675324 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename emptydir @ 09/02/25 09:10:01.678
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:10:01.701
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:10:01.709
  STEP: Creating a pod to test emptydir 0644 on tmpfs @ 09/02/25 09:10:01.715
  E0902 09:10:01.751297      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:10:02.751223      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:10:03.751593      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:10:04.751719      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:10:05.753009      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/02/25 09:10:05.767
  I0902 09:10:05.778625 16 output.go:207] Trying to get logs from node ietha7evai9i-2 pod pod-29e7dd99-8af0-471d-8358-94a89d68fea2 container test-container: <nil>
  STEP: delete the pod @ 09/02/25 09:10:05.804
  I0902 09:10:05.850592 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-6918" for this suite. @ 09/02/25 09:10:05.862
• [4.209 seconds]
------------------------------
S
------------------------------
[sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:170
  STEP: Creating a kubernetes client @ 09/02/25 09:10:05.884
  I0902 09:10:05.885040 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename configmap @ 09/02/25 09:10:05.889
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:10:05.92
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:10:05.933
  STEP: creating a ConfigMap @ 09/02/25 09:10:05.939
  STEP: fetching the ConfigMap @ 09/02/25 09:10:05.951
  STEP: patching the ConfigMap @ 09/02/25 09:10:05.96
  STEP: listing all ConfigMaps in all namespaces with a label selector @ 09/02/25 09:10:05.975
  STEP: deleting the ConfigMap by collection with a label selector @ 09/02/25 09:10:05.983
  STEP: listing all ConfigMaps in test namespace @ 09/02/25 09:10:06.002
  I0902 09:10:06.011389 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-393" for this suite. @ 09/02/25 09:10:06.021
• [0.153 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:96
  STEP: Creating a kubernetes client @ 09/02/25 09:10:06.039
  I0902 09:10:06.039395 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename secrets @ 09/02/25 09:10:06.042
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:10:06.067
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:10:06.074
  STEP: creating secret secrets-6325/secret-test-0470c1ba-83ca-4620-86e2-836156d65b5d @ 09/02/25 09:10:06.081
  STEP: Creating a pod to test consume secrets @ 09/02/25 09:10:06.094
  E0902 09:10:06.755356      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:10:07.754470      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:10:08.754938      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:10:09.755451      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/02/25 09:10:10.156
  I0902 09:10:10.168154 16 output.go:207] Trying to get logs from node ietha7evai9i-2 pod pod-configmaps-459b284c-33f1-4589-86c3-98b685b64fb3 container env-test: <nil>
  STEP: delete the pod @ 09/02/25 09:10:10.19
  I0902 09:10:10.222030 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-6325" for this suite. @ 09/02/25 09:10:10.235
• [4.210 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:208
  STEP: Creating a kubernetes client @ 09/02/25 09:10:10.25
  I0902 09:10:10.250774 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename dns @ 09/02/25 09:10:10.255
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:10:10.276
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:10:10.281
  STEP: Creating a test headless service @ 09/02/25 09:10:10.289
  I0902 09:10:10.299819      16 warnings.go:110] "Warning: spec.SessionAffinity is ignored for headless services"
  STEP: Running these commands on agnhost: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/agnhost_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/agnhost_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6589 A)" && test -n "$$check" && echo OK > /results/agnhost_udp@dns-test-service.dns-6589;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6589 A)" && test -n "$$check" && echo OK > /results/agnhost_tcp@dns-test-service.dns-6589;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6589.svc A)" && test -n "$$check" && echo OK > /results/agnhost_udp@dns-test-service.dns-6589.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6589.svc A)" && test -n "$$check" && echo OK > /results/agnhost_tcp@dns-test-service.dns-6589.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6589.svc SRV)" && test -n "$$check" && echo OK > /results/agnhost_udp@_http._tcp.dns-test-service.dns-6589.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6589.svc SRV)" && test -n "$$check" && echo OK > /results/agnhost_tcp@_http._tcp.dns-test-service.dns-6589.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6589.svc SRV)" && test -n "$$check" && echo OK > /results/agnhost_udp@_http._tcp.test-service-2.dns-6589.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6589.svc SRV)" && test -n "$$check" && echo OK > /results/agnhost_tcp@_http._tcp.test-service-2.dns-6589.svc;check="$$(dig +notcp +noall +answer +search 32.4.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.4.32_udp@PTR;check="$$(dig +tcp +noall +answer +search 32.4.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.4.32_tcp@PTR;sleep 1; done
   @ 09/02/25 09:10:10.328
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6589 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-6589;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6589 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-6589;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6589.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-6589.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6589.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-6589.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6589.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-6589.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6589.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-6589.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6589.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-6589.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6589.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-6589.svc;check="$$(dig +notcp +noall +answer +search 32.4.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.4.32_udp@PTR;check="$$(dig +tcp +noall +answer +search 32.4.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.4.32_tcp@PTR;sleep 1; done
   @ 09/02/25 09:10:10.329
  STEP: creating a pod to probe DNS @ 09/02/25 09:10:10.329
  STEP: submitting the pod to kubernetes @ 09/02/25 09:10:10.329
  E0902 09:10:10.755685      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:10:11.755826      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:10:12.755963      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:10:13.756491      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 09/02/25 09:10:14.415
  STEP: looking for the results for each expected name from probers @ 09/02/25 09:10:14.424
  I0902 09:10:14.560002 16 dns_common.go:495] Unable to read jessie_udp@dns-test-service from pod dns-6589/dns-test-0326afaf-c3b3-4193-ad9f-c54f8a4eb57b: the server could not find the requested resource (get pods dns-test-0326afaf-c3b3-4193-ad9f-c54f8a4eb57b)
  I0902 09:10:14.572969 16 dns_common.go:495] Unable to read jessie_tcp@dns-test-service from pod dns-6589/dns-test-0326afaf-c3b3-4193-ad9f-c54f8a4eb57b: the server could not find the requested resource (get pods dns-test-0326afaf-c3b3-4193-ad9f-c54f8a4eb57b)
  I0902 09:10:14.582126 16 dns_common.go:495] Unable to read jessie_udp@dns-test-service.dns-6589 from pod dns-6589/dns-test-0326afaf-c3b3-4193-ad9f-c54f8a4eb57b: the server could not find the requested resource (get pods dns-test-0326afaf-c3b3-4193-ad9f-c54f8a4eb57b)
  I0902 09:10:14.592091 16 dns_common.go:495] Unable to read jessie_tcp@dns-test-service.dns-6589 from pod dns-6589/dns-test-0326afaf-c3b3-4193-ad9f-c54f8a4eb57b: the server could not find the requested resource (get pods dns-test-0326afaf-c3b3-4193-ad9f-c54f8a4eb57b)
  I0902 09:10:14.600149 16 dns_common.go:495] Unable to read jessie_udp@dns-test-service.dns-6589.svc from pod dns-6589/dns-test-0326afaf-c3b3-4193-ad9f-c54f8a4eb57b: the server could not find the requested resource (get pods dns-test-0326afaf-c3b3-4193-ad9f-c54f8a4eb57b)
  I0902 09:10:14.608905 16 dns_common.go:495] Unable to read jessie_tcp@dns-test-service.dns-6589.svc from pod dns-6589/dns-test-0326afaf-c3b3-4193-ad9f-c54f8a4eb57b: the server could not find the requested resource (get pods dns-test-0326afaf-c3b3-4193-ad9f-c54f8a4eb57b)
  I0902 09:10:14.615958 16 dns_common.go:495] Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6589.svc from pod dns-6589/dns-test-0326afaf-c3b3-4193-ad9f-c54f8a4eb57b: the server could not find the requested resource (get pods dns-test-0326afaf-c3b3-4193-ad9f-c54f8a4eb57b)
  I0902 09:10:14.624614 16 dns_common.go:495] Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6589.svc from pod dns-6589/dns-test-0326afaf-c3b3-4193-ad9f-c54f8a4eb57b: the server could not find the requested resource (get pods dns-test-0326afaf-c3b3-4193-ad9f-c54f8a4eb57b)
  I0902 09:10:14.634386 16 dns_common.go:495] Unable to read jessie_udp@_http._tcp.test-service-2.dns-6589.svc from pod dns-6589/dns-test-0326afaf-c3b3-4193-ad9f-c54f8a4eb57b: the server could not find the requested resource (get pods dns-test-0326afaf-c3b3-4193-ad9f-c54f8a4eb57b)
  I0902 09:10:14.640849 16 dns_common.go:495] Unable to read jessie_tcp@_http._tcp.test-service-2.dns-6589.svc from pod dns-6589/dns-test-0326afaf-c3b3-4193-ad9f-c54f8a4eb57b: the server could not find the requested resource (get pods dns-test-0326afaf-c3b3-4193-ad9f-c54f8a4eb57b)
  I0902 09:10:14.655740 16 dns_common.go:506] Lookups using dns-6589/dns-test-0326afaf-c3b3-4193-ad9f-c54f8a4eb57b failed for: [jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-6589 jessie_tcp@dns-test-service.dns-6589 jessie_udp@dns-test-service.dns-6589.svc jessie_tcp@dns-test-service.dns-6589.svc jessie_udp@_http._tcp.dns-test-service.dns-6589.svc jessie_tcp@_http._tcp.dns-test-service.dns-6589.svc jessie_udp@_http._tcp.test-service-2.dns-6589.svc jessie_tcp@_http._tcp.test-service-2.dns-6589.svc]

  I0902 09:10:14.668923 16 dns_common.go:514] Pod client logs for webserver: 
  I0902 09:10:14.682048 16 dns_common.go:514] Pod client logs for agnhost-querier: 
  I0902 09:10:14.696200 16 dns_common.go:514] Pod client logs for jessie-querier: 
  E0902 09:10:14.757689      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:10:15.758414      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:10:16.759725      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:10:17.759790      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:10:18.760008      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:10:19.680413 16 dns_common.go:546] DNS probes using dns-6589/dns-test-0326afaf-c3b3-4193-ad9f-c54f8a4eb57b succeeded

  STEP: deleting the pod @ 09/02/25 09:10:19.68
  STEP: deleting the test service @ 09/02/25 09:10:19.724
  E0902 09:10:19.760500      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: deleting the test headless service @ 09/02/25 09:10:19.798
  I0902 09:10:19.824996 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-6589" for this suite. @ 09/02/25 09:10:19.839
• [9.632 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should allow to use the pod failure policy on exit code to fail the job early [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:109
  STEP: Creating a kubernetes client @ 09/02/25 09:10:19.884
  I0902 09:10:19.884561 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename job @ 09/02/25 09:10:19.89
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:10:19.964
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:10:19.973
  STEP: Looking for a node to schedule job pod @ 09/02/25 09:10:20.018
  STEP: Creating a job @ 09/02/25 09:10:20.032
  STEP: Ensuring job fails @ 09/02/25 09:10:20.052
  E0902 09:10:20.761088      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:10:21.762329      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:10:22.762981      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:10:23.764244      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:10:24.765522      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:10:25.766419      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:10:26.098496 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-1397" for this suite. @ 09/02/25 09:10:26.114
• [6.248 seconds]
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:333
  STEP: Creating a kubernetes client @ 09/02/25 09:10:26.133
  I0902 09:10:26.133405 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename sched-pred @ 09/02/25 09:10:26.137
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:10:26.168
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:10:26.176
  I0902 09:10:26.182436 16 helper.go:125] Waiting up to 1m0s for all (but 0) nodes to be ready
  I0902 09:10:26.228305 16 util.go:390] Waiting for terminating namespaces to be deleted...
  I0902 09:10:26.242409 16 predicates.go:120] 
  Logging pods the apiserver thinks is on node ietha7evai9i-1 before test
  I0902 09:10:26.257737 16 predicates.go:958] pod-failure-failjob-nmjc8 from job-1397 started at 2025-09-02 09:10:20 +0000 UTC (1 container statuses recorded)
  I0902 09:10:26.257809 16 predicates.go:960] 	Container c ready: false, restart count 0
  I0902 09:10:26.257833 16 predicates.go:958] pod-failure-failjob-w29rc from job-1397 started at 2025-09-02 09:10:20 +0000 UTC (1 container statuses recorded)
  I0902 09:10:26.257849 16 predicates.go:960] 	Container c ready: false, restart count 0
  I0902 09:10:26.257865 16 predicates.go:958] cilium-bn6l7 from kube-system started at 2025-09-02 06:13:04 +0000 UTC (1 container statuses recorded)
  I0902 09:10:26.257880 16 predicates.go:960] 	Container cilium-agent ready: true, restart count 1
  I0902 09:10:26.257968 16 predicates.go:958] cilium-node-init-qt8dx from kube-system started at 2025-09-02 06:13:04 +0000 UTC (1 container statuses recorded)
  I0902 09:10:26.257984 16 predicates.go:960] 	Container node-init ready: true, restart count 1
  I0902 09:10:26.258188 16 predicates.go:958] coredns-66bc5c9577-zh8kv from kube-system started at 2025-09-02 06:13:51 +0000 UTC (1 container statuses recorded)
  I0902 09:10:26.258288 16 predicates.go:960] 	Container coredns ready: true, restart count 1
  I0902 09:10:26.258307 16 predicates.go:958] kube-apiserver-ietha7evai9i-1 from kube-system started at 2025-09-02 06:29:53 +0000 UTC (1 container statuses recorded)
  I0902 09:10:26.258375 16 predicates.go:960] 	Container kube-apiserver ready: true, restart count 1
  I0902 09:10:26.258394 16 predicates.go:958] kube-controller-manager-ietha7evai9i-1 from kube-system started at 2025-09-02 06:29:53 +0000 UTC (1 container statuses recorded)
  I0902 09:10:26.258450 16 predicates.go:960] 	Container kube-controller-manager ready: true, restart count 1
  I0902 09:10:26.258562 16 predicates.go:958] kube-proxy-9czjg from kube-system started at 2025-09-02 06:11:25 +0000 UTC (1 container statuses recorded)
  I0902 09:10:26.258591 16 predicates.go:960] 	Container kube-proxy ready: true, restart count 1
  I0902 09:10:26.258658 16 predicates.go:958] kube-scheduler-ietha7evai9i-1 from kube-system started at 2025-09-02 06:29:53 +0000 UTC (1 container statuses recorded)
  I0902 09:10:26.258677 16 predicates.go:960] 	Container kube-scheduler ready: true, restart count 1
  I0902 09:10:26.258692 16 predicates.go:958] sonobuoy-systemd-logs-daemon-set-707d3c8598644e6c-hzzpm from sonobuoy started at 2025-09-02 07:30:04 +0000 UTC (2 container statuses recorded)
  I0902 09:10:26.258753 16 predicates.go:960] 	Container sonobuoy-worker ready: true, restart count 0
  I0902 09:10:26.258771 16 predicates.go:960] 	Container systemd-logs ready: true, restart count 0
  I0902 09:10:26.258858 16 predicates.go:120] 
  Logging pods the apiserver thinks is on node ietha7evai9i-2 before test
  I0902 09:10:26.277642 16 predicates.go:958] cilium-n62pl from kube-system started at 2025-09-02 06:13:04 +0000 UTC (1 container statuses recorded)
  I0902 09:10:26.277781 16 predicates.go:960] 	Container cilium-agent ready: true, restart count 1
  I0902 09:10:26.277808 16 predicates.go:958] cilium-node-init-cww5f from kube-system started at 2025-09-02 06:13:04 +0000 UTC (1 container statuses recorded)
  I0902 09:10:26.277823 16 predicates.go:960] 	Container node-init ready: true, restart count 1
  I0902 09:10:26.277963 16 predicates.go:958] kube-apiserver-ietha7evai9i-2 from kube-system started at 2025-09-02 06:30:19 +0000 UTC (1 container statuses recorded)
  I0902 09:10:26.278042 16 predicates.go:960] 	Container kube-apiserver ready: true, restart count 1
  I0902 09:10:26.278106 16 predicates.go:958] kube-controller-manager-ietha7evai9i-2 from kube-system started at 2025-09-02 06:30:19 +0000 UTC (1 container statuses recorded)
  I0902 09:10:26.278123 16 predicates.go:960] 	Container kube-controller-manager ready: true, restart count 1
  I0902 09:10:26.278140 16 predicates.go:958] kube-proxy-jp7tf from kube-system started at 2025-09-02 06:12:05 +0000 UTC (1 container statuses recorded)
  I0902 09:10:26.278239 16 predicates.go:960] 	Container kube-proxy ready: true, restart count 1
  I0902 09:10:26.278262 16 predicates.go:958] kube-scheduler-ietha7evai9i-2 from kube-system started at 2025-09-02 06:30:19 +0000 UTC (1 container statuses recorded)
  I0902 09:10:26.278324 16 predicates.go:960] 	Container kube-scheduler ready: true, restart count 1
  I0902 09:10:26.278347 16 predicates.go:958] sonobuoy-systemd-logs-daemon-set-707d3c8598644e6c-dlzrj from sonobuoy started at 2025-09-02 07:30:04 +0000 UTC (2 container statuses recorded)
  I0902 09:10:26.278361 16 predicates.go:960] 	Container sonobuoy-worker ready: true, restart count 0
  I0902 09:10:26.278513 16 predicates.go:960] 	Container systemd-logs ready: true, restart count 0
  I0902 09:10:26.278640 16 predicates.go:120] 
  Logging pods the apiserver thinks is on node ietha7evai9i-3 before test
  I0902 09:10:26.296096 16 predicates.go:958] cilium-node-init-cwq9b from kube-system started at 2025-09-02 06:13:04 +0000 UTC (1 container statuses recorded)
  I0902 09:10:26.296207 16 predicates.go:960] 	Container node-init ready: true, restart count 1
  I0902 09:10:26.296583 16 predicates.go:958] cilium-operator-f9554d685-sqbm7 from kube-system started at 2025-09-02 06:13:04 +0000 UTC (1 container statuses recorded)
  I0902 09:10:26.297023 16 predicates.go:960] 	Container cilium-operator ready: true, restart count 4
  I0902 09:10:26.297053 16 predicates.go:958] cilium-x7gr5 from kube-system started at 2025-09-02 06:13:04 +0000 UTC (1 container statuses recorded)
  I0902 09:10:26.297068 16 predicates.go:960] 	Container cilium-agent ready: true, restart count 1
  I0902 09:10:26.297084 16 predicates.go:958] coredns-66bc5c9577-fcrhx from kube-system started at 2025-09-02 06:19:32 +0000 UTC (1 container statuses recorded)
  I0902 09:10:26.297098 16 predicates.go:960] 	Container coredns ready: true, restart count 0
  I0902 09:10:26.297113 16 predicates.go:958] kube-proxy-dvcxr from kube-system started at 2025-09-02 06:12:30 +0000 UTC (1 container statuses recorded)
  I0902 09:10:26.297126 16 predicates.go:960] 	Container kube-proxy ready: true, restart count 1
  I0902 09:10:26.297141 16 predicates.go:958] sonobuoy from sonobuoy started at 2025-09-02 07:29:56 +0000 UTC (1 container statuses recorded)
  I0902 09:10:26.297209 16 predicates.go:960] 	Container kube-sonobuoy ready: true, restart count 0
  I0902 09:10:26.297226 16 predicates.go:958] sonobuoy-e2e-job-5dae80ab010f494d from sonobuoy started at 2025-09-02 07:30:04 +0000 UTC (2 container statuses recorded)
  I0902 09:10:26.297240 16 predicates.go:960] 	Container e2e ready: true, restart count 0
  I0902 09:10:26.297252 16 predicates.go:960] 	Container sonobuoy-worker ready: true, restart count 0
  I0902 09:10:26.297267 16 predicates.go:958] sonobuoy-systemd-logs-daemon-set-707d3c8598644e6c-r5bs9 from sonobuoy started at 2025-09-02 07:30:04 +0000 UTC (2 container statuses recorded)
  I0902 09:10:26.297280 16 predicates.go:960] 	Container sonobuoy-worker ready: true, restart count 0
  I0902 09:10:26.297292 16 predicates.go:960] 	Container systemd-logs ready: true, restart count 0
  STEP: verifying the node has the label node ietha7evai9i-1 @ 09/02/25 09:10:26.347
  STEP: verifying the node has the label node ietha7evai9i-2 @ 09/02/25 09:10:26.384
  STEP: verifying the node has the label node ietha7evai9i-3 @ 09/02/25 09:10:26.438
  I0902 09:10:26.479330 16 predicates.go:373] Pod cilium-bn6l7 requesting resource cpu=0m on Node ietha7evai9i-1
  I0902 09:10:26.480748 16 predicates.go:373] Pod cilium-n62pl requesting resource cpu=0m on Node ietha7evai9i-2
  I0902 09:10:26.481325 16 predicates.go:373] Pod cilium-node-init-cwq9b requesting resource cpu=100m on Node ietha7evai9i-3
  I0902 09:10:26.481352 16 predicates.go:373] Pod cilium-node-init-cww5f requesting resource cpu=100m on Node ietha7evai9i-2
  I0902 09:10:26.481708 16 predicates.go:373] Pod cilium-node-init-qt8dx requesting resource cpu=100m on Node ietha7evai9i-1
  I0902 09:10:26.481739 16 predicates.go:373] Pod cilium-operator-f9554d685-sqbm7 requesting resource cpu=0m on Node ietha7evai9i-3
  I0902 09:10:26.481998 16 predicates.go:373] Pod cilium-x7gr5 requesting resource cpu=0m on Node ietha7evai9i-3
  I0902 09:10:26.482343 16 predicates.go:373] Pod coredns-66bc5c9577-fcrhx requesting resource cpu=100m on Node ietha7evai9i-3
  I0902 09:10:26.482390 16 predicates.go:373] Pod coredns-66bc5c9577-zh8kv requesting resource cpu=100m on Node ietha7evai9i-1
  I0902 09:10:26.482410 16 predicates.go:373] Pod kube-apiserver-ietha7evai9i-1 requesting resource cpu=250m on Node ietha7evai9i-1
  I0902 09:10:26.482461 16 predicates.go:373] Pod kube-apiserver-ietha7evai9i-2 requesting resource cpu=250m on Node ietha7evai9i-2
  I0902 09:10:26.482476 16 predicates.go:373] Pod kube-controller-manager-ietha7evai9i-1 requesting resource cpu=200m on Node ietha7evai9i-1
  I0902 09:10:26.482491 16 predicates.go:373] Pod kube-controller-manager-ietha7evai9i-2 requesting resource cpu=200m on Node ietha7evai9i-2
  I0902 09:10:26.482506 16 predicates.go:373] Pod kube-proxy-9czjg requesting resource cpu=0m on Node ietha7evai9i-1
  I0902 09:10:26.482520 16 predicates.go:373] Pod kube-proxy-dvcxr requesting resource cpu=0m on Node ietha7evai9i-3
  I0902 09:10:26.482535 16 predicates.go:373] Pod kube-proxy-jp7tf requesting resource cpu=0m on Node ietha7evai9i-2
  I0902 09:10:26.482611 16 predicates.go:373] Pod kube-scheduler-ietha7evai9i-1 requesting resource cpu=100m on Node ietha7evai9i-1
  I0902 09:10:26.482628 16 predicates.go:373] Pod kube-scheduler-ietha7evai9i-2 requesting resource cpu=100m on Node ietha7evai9i-2
  I0902 09:10:26.482643 16 predicates.go:373] Pod sonobuoy requesting resource cpu=0m on Node ietha7evai9i-3
  I0902 09:10:26.482658 16 predicates.go:373] Pod sonobuoy-e2e-job-5dae80ab010f494d requesting resource cpu=0m on Node ietha7evai9i-3
  I0902 09:10:26.482673 16 predicates.go:373] Pod sonobuoy-systemd-logs-daemon-set-707d3c8598644e6c-dlzrj requesting resource cpu=0m on Node ietha7evai9i-2
  I0902 09:10:26.482687 16 predicates.go:373] Pod sonobuoy-systemd-logs-daemon-set-707d3c8598644e6c-hzzpm requesting resource cpu=0m on Node ietha7evai9i-1
  I0902 09:10:26.482724 16 predicates.go:373] Pod sonobuoy-systemd-logs-daemon-set-707d3c8598644e6c-r5bs9 requesting resource cpu=0m on Node ietha7evai9i-3
  STEP: Starting Pods to consume most of the cluster CPU. @ 09/02/25 09:10:26.482
  I0902 09:10:26.482800 16 predicates.go:383] Creating a pod which consumes cpu=980m on Node ietha7evai9i-3
  I0902 09:10:26.505507 16 predicates.go:383] Creating a pod which consumes cpu=595m on Node ietha7evai9i-1
  I0902 09:10:26.529934 16 predicates.go:383] Creating a pod which consumes cpu=665m on Node ietha7evai9i-2
  E0902 09:10:26.778022      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:10:27.779062      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:10:28.779598      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:10:29.780211      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Creating another pod that requires unavailable amount of CPU. @ 09/02/25 09:10:30.623
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-85d3d50a-edb7-43a4-99f3-0c1bfb7cf163.18616c22db4f48f5], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3880/filler-pod-85d3d50a-edb7-43a4-99f3-0c1bfb7cf163 to ietha7evai9i-2] @ 09/02/25 09:10:30.635
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-85d3d50a-edb7-43a4-99f3-0c1bfb7cf163.18616c233e0f0e94], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.10.1" already present on machine] @ 09/02/25 09:10:30.636
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-85d3d50a-edb7-43a4-99f3-0c1bfb7cf163.18616c2345bfbf0c], Reason = [Created], Message = [Created container: filler-pod-85d3d50a-edb7-43a4-99f3-0c1bfb7cf163] @ 09/02/25 09:10:30.636
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-85d3d50a-edb7-43a4-99f3-0c1bfb7cf163.18616c2347d6a868], Reason = [Started], Message = [Started container filler-pod-85d3d50a-edb7-43a4-99f3-0c1bfb7cf163] @ 09/02/25 09:10:30.637
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-ac3c560d-70e7-43ba-a286-a6caa28516ed.18616c22d9f16e51], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3880/filler-pod-ac3c560d-70e7-43ba-a286-a6caa28516ed to ietha7evai9i-1] @ 09/02/25 09:10:30.637
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-ac3c560d-70e7-43ba-a286-a6caa28516ed.18616c2315c8be77], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.10.1" already present on machine] @ 09/02/25 09:10:30.637
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-ac3c560d-70e7-43ba-a286-a6caa28516ed.18616c231f5b5200], Reason = [Created], Message = [Created container: filler-pod-ac3c560d-70e7-43ba-a286-a6caa28516ed] @ 09/02/25 09:10:30.637
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-ac3c560d-70e7-43ba-a286-a6caa28516ed.18616c232176faad], Reason = [Started], Message = [Started container filler-pod-ac3c560d-70e7-43ba-a286-a6caa28516ed] @ 09/02/25 09:10:30.638
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-d88f63fb-3362-4c10-96a2-747b194e30b0.18616c22d63fb4ae], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3880/filler-pod-d88f63fb-3362-4c10-96a2-747b194e30b0 to ietha7evai9i-3] @ 09/02/25 09:10:30.638
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-d88f63fb-3362-4c10-96a2-747b194e30b0.18616c2308971f6c], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.10.1" already present on machine] @ 09/02/25 09:10:30.639
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-d88f63fb-3362-4c10-96a2-747b194e30b0.18616c23104bba87], Reason = [Created], Message = [Created container: filler-pod-d88f63fb-3362-4c10-96a2-747b194e30b0] @ 09/02/25 09:10:30.639
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-d88f63fb-3362-4c10-96a2-747b194e30b0.18616c2311f4d1cb], Reason = [Started], Message = [Started container filler-pod-d88f63fb-3362-4c10-96a2-747b194e30b0] @ 09/02/25 09:10:30.639
  STEP: Considering event: 
  Type = [Warning], Name = [additional-pod.18616c23cc76c94c], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu. no new claims to deallocate, preemption: 0/3 nodes are available: 3 No preemption victims found for incoming pod.] @ 09/02/25 09:10:30.673
  E0902 09:10:30.781084      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: removing the label node off the node ietha7evai9i-1 @ 09/02/25 09:10:31.672
  STEP: verifying the node doesn't have the label node @ 09/02/25 09:10:31.706
  STEP: removing the label node off the node ietha7evai9i-2 @ 09/02/25 09:10:31.718
  STEP: verifying the node doesn't have the label node @ 09/02/25 09:10:31.761
  STEP: removing the label node off the node ietha7evai9i-3 @ 09/02/25 09:10:31.781
  E0902 09:10:31.782515      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: verifying the node doesn't have the label node @ 09/02/25 09:10:31.85
  I0902 09:10:31.860729 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-3880" for this suite. @ 09/02/25 09:10:31.888
• [5.787 seconds]
------------------------------
S
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:918
  STEP: Creating a kubernetes client @ 09/02/25 09:10:31.92
  I0902 09:10:31.920203 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename statefulset @ 09/02/25 09:10:31.923
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:10:32.042
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:10:32.049
  STEP: Creating service test in namespace statefulset-1883 @ 09/02/25 09:10:32.077
  I0902 09:10:32.094051      16 warnings.go:110] "Warning: spec.SessionAffinity is ignored for headless services"
  STEP: Creating statefulset ss in namespace statefulset-1883 @ 09/02/25 09:10:32.094
  I0902 09:10:32.141500 16 wait.go:44] Found 0 stateful pods, waiting for 1
  E0902 09:10:32.783007      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:10:33.783110      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:10:34.783435      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:10:35.784847      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:10:36.784792      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:10:37.785226      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:10:38.785641      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:10:39.786271      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:10:40.786426      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:10:41.786669      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:10:42.128480 16 wait.go:54] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: getting scale subresource @ 09/02/25 09:10:42.143
  STEP: updating a scale subresource @ 09/02/25 09:10:42.15
  STEP: verifying the statefulset Spec.Replicas was modified @ 09/02/25 09:10:42.162
  STEP: Patch a scale subresource @ 09/02/25 09:10:42.17
  STEP: verifying the statefulset Spec.Replicas was modified @ 09/02/25 09:10:42.185
  I0902 09:10:42.191869 16 statefulset.go:136] Deleting all statefulset in ns statefulset-1883
  I0902 09:10:42.198368 16 rest.go:153] Scaling statefulset ss to 0
  E0902 09:10:42.787736      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:10:43.787931      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:10:44.788274      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:10:45.789133      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:10:46.790365      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:10:47.791289      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:10:48.791402      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:10:49.792372      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:10:50.792264      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:10:51.793091      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:10:52.232803 16 wait.go:159] Waiting for statefulset status.replicas updated to 0
  I0902 09:10:52.240466 16 rest.go:91] Deleting statefulset ss
  I0902 09:10:52.276084 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-1883" for this suite. @ 09/02/25 09:10:52.286
• [20.384 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:85
  STEP: Creating a kubernetes client @ 09/02/25 09:10:52.305
  I0902 09:10:52.305625 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename downward-api @ 09/02/25 09:10:52.309
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:10:52.338
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:10:52.346
  STEP: Creating a pod to test downward API volume plugin @ 09/02/25 09:10:52.354
  E0902 09:10:52.793608      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:10:53.794347      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:10:54.794353      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:10:55.794868      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/02/25 09:10:56.424
  I0902 09:10:56.435030 16 output.go:207] Trying to get logs from node ietha7evai9i-2 pod downwardapi-volume-a30e265e-c689-4868-88b4-fcf462ec2c57 container client-container: <nil>
  STEP: delete the pod @ 09/02/25 09:10:56.465
  I0902 09:10:56.517612 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-1935" for this suite. @ 09/02/25 09:10:56.533
• [4.252 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:47
  STEP: Creating a kubernetes client @ 09/02/25 09:10:56.558
  I0902 09:10:56.558190 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename secrets @ 09/02/25 09:10:56.563
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:10:56.598
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:10:56.605
  STEP: Creating secret with name secret-test-8be8d8db-8b3b-4384-aef1-8b283d85b29a @ 09/02/25 09:10:56.613
  STEP: Creating a pod to test consume secrets @ 09/02/25 09:10:56.624
  E0902 09:10:56.795652      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:10:57.795979      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:10:58.796464      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:10:59.796748      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/02/25 09:11:00.696
  I0902 09:11:00.704355 16 output.go:207] Trying to get logs from node ietha7evai9i-2 pod pod-secrets-0903a687-0091-4eed-9581-d6ddce114bfe container secret-env-test: <nil>
  STEP: delete the pod @ 09/02/25 09:11:00.725
  I0902 09:11:00.784787 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-4081" for this suite. @ 09/02/25 09:11:00.796
  E0902 09:11:00.797253      16 retrywatcher.go:169] "Watch failed" err="context canceled"
• [4.253 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API should delete a collection of events [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/events.go:207
  STEP: Creating a kubernetes client @ 09/02/25 09:11:00.812
  I0902 09:11:00.812324 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename events @ 09/02/25 09:11:00.814
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:11:00.841
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:11:00.846
  STEP: Create set of events @ 09/02/25 09:11:00.852
  STEP: get a list of Events with a label in the current namespace @ 09/02/25 09:11:00.895
  STEP: delete a list of events @ 09/02/25 09:11:00.905
  I0902 09:11:00.905348 16 events.go:224] requesting DeleteCollection of events
  STEP: check that the list of events matches the requested quantity @ 09/02/25 09:11:00.951
  I0902 09:11:00.958427 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-9735" for this suite. @ 09/02/25 09:11:00.967
• [0.169 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:124
  STEP: Creating a kubernetes client @ 09/02/25 09:11:00.982
  I0902 09:11:00.982677 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename projected @ 09/02/25 09:11:00.986
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:11:01.014
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:11:01.02
  STEP: Creating projection with configMap that has name projected-configmap-test-upd-8e0da2bd-af1e-4e74-a91c-02d9894c8071 @ 09/02/25 09:11:01.068
  STEP: Creating the pod @ 09/02/25 09:11:01.079
  E0902 09:11:01.797120      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:11:02.797635      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Updating configmap projected-configmap-test-upd-8e0da2bd-af1e-4e74-a91c-02d9894c8071 @ 09/02/25 09:11:03.141
  STEP: waiting to observe update in volume @ 09/02/25 09:11:03.152
  E0902 09:11:03.798762      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:11:04.798404      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:11:05.189871 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4217" for this suite. @ 09/02/25 09:11:05.205
• [4.255 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:219
  STEP: Creating a kubernetes client @ 09/02/25 09:11:05.242
  I0902 09:11:05.242729 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename emptydir @ 09/02/25 09:11:05.248
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:11:05.278
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:11:05.285
  STEP: Creating a pod to test emptydir 0777 on node default medium @ 09/02/25 09:11:05.296
  E0902 09:11:05.799067      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:11:06.799755      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:11:07.799300      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:11:08.799410      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/02/25 09:11:09.369
  I0902 09:11:09.377915 16 output.go:207] Trying to get logs from node ietha7evai9i-3 pod pod-fdcba478-2876-4e43-afbc-abc7d1273709 container test-container: <nil>
  STEP: delete the pod @ 09/02/25 09:11:09.422
  I0902 09:11:09.467323 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-9739" for this suite. @ 09/02/25 09:11:09.48
• [4.262 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:222
  STEP: Creating a kubernetes client @ 09/02/25 09:11:09.503
  I0902 09:11:09.503368 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename projected @ 09/02/25 09:11:09.506
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:11:09.529
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:11:09.538
  STEP: Creating a pod to test downward API volume plugin @ 09/02/25 09:11:09.545
  E0902 09:11:09.800528      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:11:10.800873      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:11:11.802121      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:11:12.802741      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/02/25 09:11:13.65
  I0902 09:11:13.660036 16 output.go:207] Trying to get logs from node ietha7evai9i-3 pod downwardapi-volume-0b991acb-2c2a-4998-a13c-4106834318e9 container client-container: <nil>
  STEP: delete the pod @ 09/02/25 09:11:13.678
  I0902 09:11:13.721803 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3965" for this suite. @ 09/02/25 09:11:13.735
• [4.251 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] PreStop should call prestop when killing a pod [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/pre_stop.go:169
  STEP: Creating a kubernetes client @ 09/02/25 09:11:13.755
  I0902 09:11:13.755899 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename prestop @ 09/02/25 09:11:13.759
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:11:13.793
  E0902 09:11:13.803856      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:11:13.806
  STEP: Creating server pod server in namespace prestop-5633 @ 09/02/25 09:11:13.817
  STEP: Waiting for pods to come up. @ 09/02/25 09:11:13.84
  E0902 09:11:14.804236      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:11:15.805235      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Creating tester pod tester in namespace prestop-5633 @ 09/02/25 09:11:15.868
  E0902 09:11:16.805921      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:11:17.806392      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deleting pre-stop pod @ 09/02/25 09:11:17.905
  E0902 09:11:18.806981      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:11:19.807353      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:11:20.807911      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:11:21.807642      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:11:22.807797      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:11:22.959358 16 pre_stop.go:140] Saw: {
  	"Hostname": "server",
  	"Sent": null,
  	"Received": {
  		"prestop": 1
  	},
  	"Errors": null,
  	"Log": [
  		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
  		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
  	],
  	"StillContactingPeers": true
  }
  STEP: Deleting the server pod @ 09/02/25 09:11:22.96
  I0902 09:11:22.999867 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "prestop-5633" for this suite. @ 09/02/25 09:11:23.027
• [9.288 seconds]
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:229
  STEP: Creating a kubernetes client @ 09/02/25 09:11:23.043
  I0902 09:11:23.043930 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename container-runtime @ 09/02/25 09:11:23.047
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:11:23.087
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:11:23.094
  STEP: create the container @ 09/02/25 09:11:23.101
  I0902 09:11:23.132175      16 warnings.go:110] "Warning: metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]"
  STEP: wait for the container to reach Succeeded @ 09/02/25 09:11:23.132
  E0902 09:11:23.808640      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:11:24.809693      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:11:25.810117      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: get the container status @ 09/02/25 09:11:26.22
  STEP: the container should be terminated @ 09/02/25 09:11:26.229
  STEP: the termination message should be set @ 09/02/25 09:11:26.229
  I0902 09:11:26.229666 16 runtime.go:164] Expected: &{} to match Container's Termination Message:  --
  STEP: delete the container @ 09/02/25 09:11:26.229
  I0902 09:11:26.268367 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-5578" for this suite. @ 09/02/25 09:11:26.278
• [3.250 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceFieldSelectors [Privileged:ClusterAdmin] CustomResourceFieldSelectors MUST list and watch custom resources matching the field selector [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_selectable_fields.go:124
  STEP: Creating a kubernetes client @ 09/02/25 09:11:26.297
  I0902 09:11:26.297369 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename crd-selectable-fields @ 09/02/25 09:11:26.3
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:11:26.335
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:11:26.345
  STEP: Setting up server cert @ 09/02/25 09:11:26.35
  E0902 09:11:26.809948      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication @ 09/02/25 09:11:27.667
  STEP: Deploying the custom resource conversion webhook pod @ 09/02/25 09:11:27.684
  STEP: Wait for the deployment to be ready @ 09/02/25 09:11:27.728
  I0902 09:11:27.748306 16 deployment.go:223] new replicaset for deployment "sample-crd-conversion-webhook-deployment" is yet to be created
  E0902 09:11:27.810973      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:11:28.811484      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 09/02/25 09:11:29.805
  E0902 09:11:29.811473      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Verifying the service has paired with the endpoint @ 09/02/25 09:11:29.843
  E0902 09:11:30.812231      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:11:30.844364 16 util.go:419] Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
  STEP: Creating a custom resource definition with selectable fields @ 09/02/25 09:11:30.865
  I0902 09:11:30.866612 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Creating a custom resource conversion webhook @ 09/02/25 09:11:31.409
  E0902 09:11:31.812891      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:11:32.813392      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Watching with field selectors @ 09/02/25 09:11:33.708
  STEP: Registering informers with field selectors @ 09/02/25 09:11:33.732
  STEP: Creating custom resources @ 09/02/25 09:11:33.734
  STEP: Listing v2 custom resources with field selector host=host1 @ 09/02/25 09:11:33.799
  STEP: Listing v2 custom resources with field selector host=host1,port=80 @ 09/02/25 09:11:33.808
  E0902 09:11:33.814121      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Listing v1 custom resources with field selector hostPort=host1:80 @ 09/02/25 09:11:33.816
  STEP: Listing v1 custom resources with field selector hostPort=host1:8080 @ 09/02/25 09:11:33.824
  STEP: Waiting for watch events to contain v2 custom resources for field selector host=host1 @ 09/02/25 09:11:33.83
  STEP: Waiting for watch events to contain v2 custom resources for field selector host=host1,port=80 @ 09/02/25 09:11:33.836
  STEP: Waiting for watch events to contain v1 custom resources for field selector hostPort=host1:80 @ 09/02/25 09:11:33.836
  STEP: Waiting for informer events to contain v2 custom resources for field selector host=host1 @ 09/02/25 09:11:33.837
  STEP: Waiting for informer events to contain v2 custom resources for field selector host=host1,port=80 @ 09/02/25 09:11:33.837
  STEP: Deleting one custom resources to ensure that deletions are observed @ 09/02/25 09:11:33.837
  STEP: Updating one custom resources to ensure that deletions are observed @ 09/02/25 09:11:33.862
  STEP: Listing v2 custom resources after updates and deletes for field selector host=host1 @ 09/02/25 09:11:33.895
  STEP: Listing v2 custom resources after updates and deletes for field selector host=host1,port=80 @ 09/02/25 09:11:33.901
  STEP: Waiting for v2 watch events after updates and deletes for field selector host=host1 @ 09/02/25 09:11:33.908
  STEP: Waiting for v2 watch events after updates and deletes for field selector host=host1,port=80 @ 09/02/25 09:11:33.914
  STEP: Waiting for v1 watch events after updates and deletes for field selector hostPort=host1:80 @ 09/02/25 09:11:33.915
  STEP: Waiting for v2 informer events after updates and deletes for field selector host=host1 @ 09/02/25 09:11:33.915
  STEP: Waiting for v2 informer events after updates and deletes for field selector host=host1,port=80 @ 09/02/25 09:11:33.915
  I0902 09:11:34.595963 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-selectable-fields-3850" for this suite. @ 09/02/25 09:11:34.619
• [8.347 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AggregatedDiscovery should support aggregated discovery interface for CRDs [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/aggregated_discovery.go:303
  STEP: Creating a kubernetes client @ 09/02/25 09:11:34.658
  I0902 09:11:34.659270 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename aggregateddiscovery @ 09/02/25 09:11:34.663
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:11:34.734
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:11:34.744
  I0902 09:11:34.750697 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  E0902 09:11:34.815113      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:11:35.816168      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:11:36.816231      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:11:37.817269      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:11:37.960965 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregateddiscovery-7321" for this suite. @ 09/02/25 09:11:37.983
• [3.353 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should support CronJob API operations [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:366
  STEP: Creating a kubernetes client @ 09/02/25 09:11:38.017
  I0902 09:11:38.017283 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename cronjob @ 09/02/25 09:11:38.022
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:11:38.07
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:11:38.083
  STEP: Creating a cronjob @ 09/02/25 09:11:38.092
  STEP: creating @ 09/02/25 09:11:38.094
  STEP: getting @ 09/02/25 09:11:38.112
  STEP: listing @ 09/02/25 09:11:38.126
  STEP: watching @ 09/02/25 09:11:38.134
  I0902 09:11:38.134288 16 cronjob.go:395] starting watch
  STEP: cluster-wide listing @ 09/02/25 09:11:38.144
  STEP: cluster-wide watching @ 09/02/25 09:11:38.159
  I0902 09:11:38.159269 16 cronjob.go:407] starting watch
  STEP: patching @ 09/02/25 09:11:38.161
  STEP: updating @ 09/02/25 09:11:38.183
  I0902 09:11:38.220938 16 cronjob.go:431] waiting for watch events with expected annotations
  I0902 09:11:38.221075 16 cronjob.go:445] saw patched and updated annotations
  STEP: patching /status @ 09/02/25 09:11:38.221
  STEP: updating /status @ 09/02/25 09:11:38.236
  STEP: get /status @ 09/02/25 09:11:38.262
  STEP: deleting @ 09/02/25 09:11:38.269
  STEP: deleting a collection @ 09/02/25 09:11:38.317
  I0902 09:11:38.353917 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-8311" for this suite. @ 09/02/25 09:11:38.365
• [0.368 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:69
  STEP: Creating a kubernetes client @ 09/02/25 09:11:38.387
  I0902 09:11:38.388067 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename projected @ 09/02/25 09:11:38.392
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:11:38.419
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:11:38.425
  STEP: Creating a pod to test downward API volume plugin @ 09/02/25 09:11:38.431
  E0902 09:11:38.818719      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:11:39.820166      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:11:40.820099      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:11:41.820234      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/02/25 09:11:42.495
  I0902 09:11:42.506529 16 output.go:207] Trying to get logs from node ietha7evai9i-2 pod downwardapi-volume-79b61ed3-80e6-4273-bc49-69400fd46139 container client-container: <nil>
  STEP: delete the pod @ 09/02/25 09:11:42.536
  I0902 09:11:42.596666 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1151" for this suite. @ 09/02/25 09:11:42.615
• [4.251 seconds]
------------------------------
[sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance] [sig-node, Slow, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:228
  STEP: Creating a kubernetes client @ 09/02/25 09:11:42.639
  I0902 09:11:42.639886 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename var-expansion @ 09/02/25 09:11:42.651
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:11:42.688
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:11:42.695
  STEP: creating the pod with failed condition @ 09/02/25 09:11:42.704
  E0902 09:11:42.820865      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:11:43.820994      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:11:44.821203      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:11:45.822477      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:11:46.822930      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:11:47.823255      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:11:48.823543      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:11:49.823829      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:11:50.824465      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:11:51.825095      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:11:52.825855      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:11:53.826078      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:11:54.826933      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:11:55.827455      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:11:56.827755      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:11:57.828849      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:11:58.828986      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:11:59.829493      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:12:00.830074      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:12:01.831871      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:12:02.832676      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:12:03.832608      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:12:04.832730      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:12:05.833025      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:12:06.833486      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:12:07.833715      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:12:08.834476      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:12:09.834525      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:12:10.834883      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:12:11.836009      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:12:12.835811      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:12:13.836496      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:12:14.836934      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:12:15.836720      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:12:16.837439      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:12:17.838218      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:12:18.838324      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:12:19.839049      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:12:20.838861      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:12:21.839362      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:12:22.839898      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:12:23.843987      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:12:24.844179      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:12:25.844809      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:12:26.845378      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:12:27.846108      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:12:28.848720      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:12:29.849017      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:12:30.849510      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:12:31.850242      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:12:32.850691      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:12:33.850780      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:12:34.851011      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:12:35.851667      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:12:36.852175      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:12:37.853119      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:12:38.853172      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:12:39.853534      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:12:40.853679      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:12:41.854524      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:12:42.854408      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:12:43.854909      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:12:44.855194      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:12:45.855905      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:12:46.855856      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:12:47.856708      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:12:48.857312      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:12:49.858310      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:12:50.858006      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:12:51.858967      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:12:52.859364      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:12:53.860293      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:12:54.860948      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:12:55.862066      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:12:56.862343      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:12:57.863232      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:12:58.863940      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:12:59.864267      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:13:00.865329      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:13:01.865664      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:13:02.866675      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:13:03.867485      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:13:04.867892      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:13:05.868048      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:13:06.868679      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:13:07.870040      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:13:08.870044      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:13:09.870368      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:13:10.870626      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:13:11.871417      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:13:12.872067      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:13:13.872542      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:13:14.872859      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:13:15.874291      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:13:16.874292      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:13:17.875250      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:13:18.875283      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:13:19.876441      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:13:20.876485      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:13:21.877145      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:13:22.877913      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:13:23.878781      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:13:24.879401      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:13:25.879832      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:13:26.880378      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:13:27.881144      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:13:28.881264      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:13:29.882227      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:13:30.881902      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:13:31.883692      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:13:32.884218      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:13:33.884460      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:13:34.884673      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:13:35.884921      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:13:36.885258      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:13:37.886209      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:13:38.886940      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:13:39.887968      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:13:40.887842      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:13:41.887973      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: updating the pod @ 09/02/25 09:13:42.734
  E0902 09:13:42.889251      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:13:43.263068 16 pod_client.go:186] Successfully updated pod "var-expansion-7ce2f031-8265-40f3-85a0-adce3bf4f583"
  STEP: waiting for pod running @ 09/02/25 09:13:43.263
  E0902 09:13:43.889223      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:13:44.889898      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: deleting the pod gracefully @ 09/02/25 09:13:45.291
  I0902 09:13:45.291841 16 delete.go:78] Deleting pod "var-expansion-7ce2f031-8265-40f3-85a0-adce3bf4f583" in namespace "var-expansion-7587"
  I0902 09:13:45.316079 16 delete.go:86] Wait up to 5m0s for pod "var-expansion-7ce2f031-8265-40f3-85a0-adce3bf4f583" to be fully deleted
  E0902 09:13:45.890207      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:13:46.890962      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:13:47.891525      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:13:48.892185      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:13:49.893364      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:13:50.894021      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:13:51.894855      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:13:52.894955      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:13:53.895188      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:13:54.895411      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:13:55.896056      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:13:56.896241      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:13:57.896726      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:13:58.897681      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:13:59.897979      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:14:00.897942      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:14:01.898854      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:14:02.899470      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:14:03.901875      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:14:04.900150      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:14:05.901378      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:14:06.901697      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:14:07.902494      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:14:08.902873      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:14:09.903762      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:14:10.903845      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:14:11.904392      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:14:12.904314      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:14:13.905330      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:14:14.906235      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:14:15.907423      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:14:16.909578      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:14:17.565513 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-7587" for this suite. @ 09/02/25 09:14:17.58
• [154.966 seconds]
------------------------------
SSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:125
  STEP: Creating a kubernetes client @ 09/02/25 09:14:17.608
  I0902 09:14:17.608677 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename pod-network-test @ 09/02/25 09:14:17.613
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:14:17.642
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:14:17.654
  STEP: Performing setup for networking test in namespace pod-network-test-1170 @ 09/02/25 09:14:17.662
  STEP: creating a selector @ 09/02/25 09:14:17.662
  STEP: Creating the service pods in kubernetes @ 09/02/25 09:14:17.662
  I0902 09:14:17.662923 16 helper.go:51] Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0902 09:14:17.910402      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:14:18.911283      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:14:19.911848      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:14:20.913271      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:14:21.911664      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:14:22.912861      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:14:23.913784      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:14:24.914328      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:14:25.915099      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:14:26.915893      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:14:27.916742      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:14:28.917632      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:14:29.921874      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:14:30.923219      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 09/02/25 09:14:31.88
  E0902 09:14:31.922950      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:14:32.923288      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:14:33.923879      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:14:33.986504 16 utils.go:803] Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  I0902 09:14:33.986901 16 utils.go:496] Going to poll 10.233.64.145 on port 8081 at least 0 times, with a maximum of 39 tries before failing
  I0902 09:14:33.996969 16 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.233.64.145 8081 | grep -v '^\s*$'] Namespace:pod-network-test-1170 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0902 09:14:33.997081 16 exec_util.go:68] ExecWithOptions: Clientset creation
  I0902 09:14:33.997268 16 exec_util.go:84] ExecWithOptions: execute(https://10.233.0.1:443/api/v1/namespaces/pod-network-test-1170/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.233.64.145+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&stderr=true&stdout=true)
  E0902 09:14:34.924164      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:14:35.166474 16 utils.go:513] Found all 1 expected endpoints: [netserver-0]
  I0902 09:14:35.166699 16 utils.go:496] Going to poll 10.233.66.80 on port 8081 at least 0 times, with a maximum of 39 tries before failing
  I0902 09:14:35.181234 16 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.233.66.80 8081 | grep -v '^\s*$'] Namespace:pod-network-test-1170 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0902 09:14:35.181327 16 exec_util.go:68] ExecWithOptions: Clientset creation
  I0902 09:14:35.181480 16 exec_util.go:84] ExecWithOptions: execute(https://10.233.0.1:443/api/v1/namespaces/pod-network-test-1170/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.233.66.80+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&stderr=true&stdout=true)
  E0902 09:14:35.924399      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:14:36.374965 16 utils.go:513] Found all 1 expected endpoints: [netserver-1]
  I0902 09:14:36.375152 16 utils.go:496] Going to poll 10.233.65.215 on port 8081 at least 0 times, with a maximum of 39 tries before failing
  I0902 09:14:36.392827 16 exec_util.go:63] ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.233.65.215 8081 | grep -v '^\s*$'] Namespace:pod-network-test-1170 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0902 09:14:36.393640 16 exec_util.go:68] ExecWithOptions: Clientset creation
  I0902 09:14:36.393833 16 exec_util.go:84] ExecWithOptions: execute(https://10.233.0.1:443/api/v1/namespaces/pod-network-test-1170/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.233.65.215+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&stderr=true&stdout=true)
  E0902 09:14:36.925418      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:14:37.527736 16 utils.go:513] Found all 1 expected endpoints: [netserver-2]
  I0902 09:14:37.528720 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-1170" for this suite. @ 09/02/25 09:14:37.541
• [19.961 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should serve endpoints on same port and different protocols [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3741
  STEP: Creating a kubernetes client @ 09/02/25 09:14:37.587
  I0902 09:14:37.587055 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename services @ 09/02/25 09:14:37.59
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:14:37.619
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:14:37.626
  STEP: creating service multiprotocol-test in namespace services-4428 @ 09/02/25 09:14:37.635
  STEP: creating pod pod1 in namespace services-4428 @ 09/02/25 09:14:37.662
  STEP: Creating pod pod1 in namespace services-4428 @ 09/02/25 09:14:37.667
  E0902 09:14:37.925879      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:14:38.925791      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: waiting for EndpointSlices for all ports @ 09/02/25 09:14:39.742
  I0902 09:14:39.742984 16 wait.go:139] Waiting for service services-4428/multiprotocol-test to have endpoints for ports [{tcp-port TCP pod1 80} {udp-port UDP pod1 80}]
  STEP: Checking if the Service forwards traffic to the TCP and UDP port @ 09/02/25 09:14:39.756
  I0902 09:14:39.756284 16 resource.go:344] Creating new exec pod
  E0902 09:14:39.926381      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:14:40.926709      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:14:41.795916 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=services-4428 exec execpodk2qgv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.61.112 80'
  E0902 09:14:41.927963      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:14:42.175441 16 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.61.112 80\nConnection to 10.233.61.112 80 port [tcp/http] succeeded!\n"
  I0902 09:14:42.175524 16 builder.go:157] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0902 09:14:42.175890 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=services-4428 exec execpodk2qgv -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.233.61.112 80'
  E0902 09:14:42.928975      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:14:43.930013      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:14:44.506138 16 builder.go:156] stderr: "+ echo hostName\n+ nc -v -u -w 2 10.233.61.112 80\n"
  I0902 09:14:44.506430 16 builder.go:157] stdout: "pod1"
  STEP: updating the service to have only a TCP port @ 09/02/25 09:14:44.506
  STEP: Checking if the Service forwards traffic to TCP only @ 09/02/25 09:14:44.538
  I0902 09:14:44.539646 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=services-4428 exec execpodk2qgv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.61.112 80'
  I0902 09:14:44.918406 16 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.61.112 80\nConnection to 10.233.61.112 80 port [tcp/http] succeeded!\n"
  I0902 09:14:44.918489 16 builder.go:157] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0902 09:14:44.918966 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=services-4428 exec execpodk2qgv -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.233.61.112 80'
  E0902 09:14:44.930495      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:14:45.931087      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:14:46.931918      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:14:47.193527 16 builder.go:156] stderr: "+ echo hostName\n+ nc -v -u -w 2 10.233.61.112 80\n"
  I0902 09:14:47.193788 16 builder.go:157] stdout: ""
  I0902 09:14:47.195014 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=services-4428 exec execpodk2qgv -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.233.61.112 80'
  E0902 09:14:47.932636      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:14:48.932824      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:14:49.537529 16 builder.go:156] stderr: "+ nc -v -u -w 2 10.233.61.112 80\n+ echo hostName\n"
  I0902 09:14:49.537820 16 builder.go:157] stdout: ""
  I0902 09:14:49.538722 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=services-4428 exec execpodk2qgv -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.233.61.112 80'
  E0902 09:14:49.933171      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:14:50.933969      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:14:51.883287 16 builder.go:156] stderr: "+ echo hostName\n+ nc -v -u -w 2 10.233.61.112 80\n"
  I0902 09:14:51.884211 16 builder.go:157] stdout: ""
  STEP: updating the service to have only a UDP port @ 09/02/25 09:14:51.884
  STEP: Checking if the Service forwards traffic to UDP only @ 09/02/25 09:14:51.921
  I0902 09:14:51.922698 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=services-4428 exec execpodk2qgv -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.233.61.112 80'
  E0902 09:14:51.933356      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:14:52.933792      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:14:53.934202      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:14:54.262964 16 builder.go:156] stderr: "+ echo hostName\n+ nc -v -u -w 2 10.233.61.112 80\n"
  I0902 09:14:54.263167 16 builder.go:157] stdout: ""
  I0902 09:14:54.264071 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=services-4428 exec execpodk2qgv -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.233.61.112 80'
  E0902 09:14:54.935340      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:14:55.935736      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:14:56.609773 16 builder.go:156] stderr: "+ echo hostName\n+ nc -v -u -w 2 10.233.61.112 80\n"
  I0902 09:14:56.609942 16 builder.go:157] stdout: "pod1"
  I0902 09:14:56.611339 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=services-4428 exec execpodk2qgv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.61.112 80'
  E0902 09:14:56.936958      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:14:57.936759      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:14:58.937319      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:14:59.010157 16 builder.go:145] rc: 1
  I0902 09:14:59.010608 16 util.go:240] Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=services-4428 exec execpodk2qgv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.61.112 80:
  Command stdout:

  stderr:
  + nc -v -t -w 2 10.233.61.112 80
  + echo hostName
  nc: connect to 10.233.61.112 port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  I0902 09:14:59.011100 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=services-4428 exec execpodk2qgv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.61.112 80'
  E0902 09:14:59.937754      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:15:00.938887      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:15:01.328682 16 builder.go:145] rc: 1
  I0902 09:15:01.328876 16 util.go:240] Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=services-4428 exec execpodk2qgv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.61.112 80:
  Command stdout:

  stderr:
  + echo hostName
  + nc -v -t -w 2 10.233.61.112 80
  nc: connect to 10.233.61.112 port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  I0902 09:15:01.329740 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=services-4428 exec execpodk2qgv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.61.112 80'
  E0902 09:15:01.939037      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:15:02.939815      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:15:03.649516 16 builder.go:145] rc: 1
  I0902 09:15:03.650748 16 util.go:240] Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=services-4428 exec execpodk2qgv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.61.112 80:
  Command stdout:

  stderr:
  + echo hostName
  + nc -v -t -w 2 10.233.61.112 80
  nc: connect to 10.233.61.112 port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  I0902 09:15:03.651335 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-4428" for this suite. @ 09/02/25 09:15:03.668
• [26.099 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:250
  STEP: Creating a kubernetes client @ 09/02/25 09:15:03.69
  I0902 09:15:03.690944 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename downward-api @ 09/02/25 09:15:03.695
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:15:03.731
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:15:03.744
  STEP: Creating a pod to test downward API volume plugin @ 09/02/25 09:15:03.751
  E0902 09:15:03.940228      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:15:04.940988      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:15:05.941469      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:15:06.941907      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/02/25 09:15:07.804
  I0902 09:15:07.818205 16 output.go:207] Trying to get logs from node ietha7evai9i-3 pod downwardapi-volume-db696d66-d0fe-4cb2-84e5-9635a091add6 container client-container: <nil>
  STEP: delete the pod @ 09/02/25 09:15:07.868
  I0902 09:15:07.918092 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-7973" for this suite. @ 09/02/25 09:15:07.929
• [4.265 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AggregatedDiscovery should support raw aggregated discovery request for CRDs [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/aggregated_discovery.go:194
  STEP: Creating a kubernetes client @ 09/02/25 09:15:07.955
  I0902 09:15:07.955935 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  E0902 09:15:07.956635      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Building a namespace api object, basename aggregateddiscovery @ 09/02/25 09:15:07.968
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:15:08
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:15:08.005
  I0902 09:15:08.010953 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  E0902 09:15:08.955739      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:15:09.956004      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:15:10.956782      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:15:11.191528 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregateddiscovery-5331" for this suite. @ 09/02/25 09:15:11.221
• [3.294 seconds]
------------------------------
SS
------------------------------
[sig-cli] Kubectl client Kubectl version should check is all data is printed [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1758
  STEP: Creating a kubernetes client @ 09/02/25 09:15:11.25
  I0902 09:15:11.250851 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename kubectl @ 09/02/25 09:15:11.256
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:15:11.284
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:15:11.295
  I0902 09:15:11.303460 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=kubectl-2384 version'
  I0902 09:15:11.474242 16 builder.go:156] stderr: ""
  I0902 09:15:11.474973 16 builder.go:157] stdout: "Client Version: v1.34.0\nKustomize Version: v5.7.1\nServer Version: v1.34.0\n"
  I0902 09:15:11.476249 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-2384" for this suite. @ 09/02/25 09:15:11.495
• [0.261 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job with successPolicy succeededCount rule should succeeded even when some indexes remain pending [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:564
  STEP: Creating a kubernetes client @ 09/02/25 09:15:11.517
  I0902 09:15:11.517843 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename job @ 09/02/25 09:15:11.521
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:15:11.546
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:15:11.556
  STEP: Creating an indexed job with successPolicy succeededCount rule @ 09/02/25 09:15:11.565
  STEP: Awaiting for the job to have the interim SuccessCriteriaMet condition with SuccessPolicy reason @ 09/02/25 09:15:11.58
  E0902 09:15:11.956467      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:15:12.957781      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:15:13.958681      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:15:14.959319      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Ensure that the job reaches completions @ 09/02/25 09:15:15.613
  STEP: Verifying that the job status to ensure correct final state @ 09/02/25 09:15:15.639
  I0902 09:15:15.651790 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-1673" for this suite. @ 09/02/25 09:15:15.668
• [4.183 seconds]
------------------------------
[sig-network] DNS should provide DNS for the cluster [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:54
  STEP: Creating a kubernetes client @ 09/02/25 09:15:15.7
  I0902 09:15:15.700222 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename dns @ 09/02/25 09:15:15.703
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:15:15.728
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:15:15.733
  STEP: Running these commands on agnhost: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/agnhost_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/agnhost_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
   @ 09/02/25 09:15:15.739
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
   @ 09/02/25 09:15:15.739
  STEP: creating a pod to probe DNS @ 09/02/25 09:15:15.739
  STEP: submitting the pod to kubernetes @ 09/02/25 09:15:15.739
  E0902 09:15:15.961070      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:15:16.960974      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:15:17.961408      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:15:18.962041      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 09/02/25 09:15:19.795
  STEP: looking for the results for each expected name from probers @ 09/02/25 09:15:19.808
  I0902 09:15:19.868038 16 dns_common.go:546] DNS probes using dns-3346/dns-test-607f0b4b-ca77-4df6-b0b0-55d9e4eeb6b3 succeeded

  STEP: deleting the pod @ 09/02/25 09:15:19.868
  I0902 09:15:19.915782 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-3346" for this suite. @ 09/02/25 09:15:19.941
  E0902 09:15:19.962348      16 retrywatcher.go:169] "Watch failed" err="context canceled"
• [4.263 seconds]
------------------------------
SSSSS
------------------------------
[sig-network] Services should serve a basic endpoint from pods [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:740
  STEP: Creating a kubernetes client @ 09/02/25 09:15:19.963
  I0902 09:15:19.963666 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename services @ 09/02/25 09:15:19.971
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:15:20.006
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:15:20.018
  STEP: creating service endpoint-test2 in namespace services-276 @ 09/02/25 09:15:20.025
  I0902 09:15:20.048279 16 wait.go:65] Waiting for amount of service services-276/endpoint-test2 endpoints to be 0
  I0902 09:15:20.060007 16 wait.go:68] Waiting for at least 1 EndpointSlice to exist
  E0902 09:15:20.963190      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: creating first endpoint pod for service @ 09/02/25 09:15:21.06
  STEP: Creating pod pod1 in namespace services-276 @ 09/02/25 09:15:21.06
  E0902 09:15:21.964697      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:15:22.964982      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:15:23.139092 16 wait.go:96] Waiting for service services-276/endpoint-test2 to have endpoints pointing to [pod1]
  STEP: Checking if the Service forwards traffic to pod1 @ 09/02/25 09:15:23.156
  I0902 09:15:23.156387 16 resource.go:344] Creating new exec pod
  E0902 09:15:23.965063      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:15:24.965328      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:15:25.195503 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=services-276 exec execpod4jxb6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  I0902 09:15:25.566674 16 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 (10.233.4.177) 80 port [tcp/http] succeeded!\n"
  I0902 09:15:25.566849 16 builder.go:157] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0902 09:15:25.567304 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=services-276 exec execpod4jxb6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.4.177 80'
  I0902 09:15:25.867270 16 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.4.177 80\nConnection to 10.233.4.177 80 port [tcp/http] succeeded!\n"
  I0902 09:15:25.867352 16 builder.go:157] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: creating second endpoint pod for service @ 09/02/25 09:15:25.867
  STEP: Creating pod pod2 in namespace services-276 @ 09/02/25 09:15:25.867
  E0902 09:15:25.966145      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:15:26.966721      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:15:27.918920 16 wait.go:96] Waiting for service services-276/endpoint-test2 to have endpoints pointing to [pod1 pod2]
  STEP: Checking if the Service forwards traffic to pod1 and pod2 @ 09/02/25 09:15:27.927
  I0902 09:15:27.935378 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=services-276 exec execpod4jxb6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  E0902 09:15:27.967810      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:15:28.262462 16 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 (10.233.4.177) 80 port [tcp/http] succeeded!\n"
  I0902 09:15:28.262721 16 builder.go:157] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0902 09:15:28.262931 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=services-276 exec execpod4jxb6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.4.177 80'
  I0902 09:15:28.568868 16 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.4.177 80\nConnection to 10.233.4.177 80 port [tcp/http] succeeded!\n"
  I0902 09:15:28.568952 16 builder.go:157] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: deleting first endpoint pod @ 09/02/25 09:15:28.569
  STEP: Deleting pod pod1 in namespace services-276 @ 09/02/25 09:15:28.569
  I0902 09:15:28.615844 16 wait.go:96] Waiting for service services-276/endpoint-test2 to have endpoints pointing to [pod2]
  STEP: Checking if the Service forwards traffic to pod2 @ 09/02/25 09:15:28.632
  I0902 09:15:28.730262 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=services-276 exec execpod4jxb6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  E0902 09:15:28.969137      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:15:29.029494 16 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 (10.233.4.177) 80 port [tcp/http] succeeded!\n"
  I0902 09:15:29.029879 16 builder.go:157] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0902 09:15:29.030711 16 builder.go:130] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1454491902 --namespace=services-276 exec execpod4jxb6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.4.177 80'
  I0902 09:15:29.298022 16 builder.go:156] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.4.177 80\nConnection to 10.233.4.177 80 port [tcp/http] succeeded!\n"
  I0902 09:15:29.298110 16 builder.go:157] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: deleting second endpoint pod @ 09/02/25 09:15:29.298
  STEP: Deleting pod pod2 in namespace services-276 @ 09/02/25 09:15:29.298
  I0902 09:15:29.335655 16 wait.go:65] Waiting for amount of service services-276/endpoint-test2 endpoints to be 0
  I0902 09:15:29.345102 16 wait.go:83] Unexpected number of Endpoints on Slices, got 1, expected 0
  E0902 09:15:29.969969      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:15:30.361167 16 wait.go:83] Unexpected number of Endpoints on Slices, got 1, expected 0
  E0902 09:15:30.969949      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:15:31.407232 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-276" for this suite. @ 09/02/25 09:15:31.419
• [11.471 seconds]
------------------------------
[sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:125
  STEP: Creating a kubernetes client @ 09/02/25 09:15:31.434
  I0902 09:15:31.434304 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename secrets @ 09/02/25 09:15:31.439
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:15:31.463
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:15:31.472
  STEP: Creating secret with name secret-test-3e23b239-8c71-4e84-9ba0-47c9cfc93502 @ 09/02/25 09:15:31.478
  STEP: Creating a pod to test consume secrets @ 09/02/25 09:15:31.496
  E0902 09:15:31.970846      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:15:32.971673      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:15:33.971804      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:15:34.972195      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/02/25 09:15:35.555
  I0902 09:15:35.570529 16 output.go:207] Trying to get logs from node ietha7evai9i-2 pod pod-secrets-1640d290-98b2-4c41-b100-b0da6175a09a container secret-volume-test: <nil>
  STEP: delete the pod @ 09/02/25 09:15:35.623
  I0902 09:15:35.669852 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-546" for this suite. @ 09/02/25 09:15:35.684
• [4.271 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:305
  STEP: Creating a kubernetes client @ 09/02/25 09:15:35.713
  I0902 09:15:35.713793 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename daemonsets @ 09/02/25 09:15:35.718
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:15:35.752
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:15:35.76
  STEP: Creating a simple DaemonSet "daemon-set" @ 09/02/25 09:15:35.823
  STEP: Check that daemon pods launch on every node of the cluster. @ 09/02/25 09:15:35.845
  I0902 09:15:35.926402 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0902 09:15:35.927379 16 fixtures.go:131] Node ietha7evai9i-1 is running 0 daemon pod, expected 1
  E0902 09:15:35.973412      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:15:36.888189 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0902 09:15:36.888430 16 fixtures.go:131] Node ietha7evai9i-1 is running 0 daemon pod, expected 1
  E0902 09:15:36.973325      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:15:37.866683 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0902 09:15:37.867055 16 fixtures.go:131] Node ietha7evai9i-1 is running 0 daemon pod, expected 1
  E0902 09:15:37.974446      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:15:38.885981 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0902 09:15:38.887147 16 fixtures.go:131] Node ietha7evai9i-1 is running 0 daemon pod, expected 1
  E0902 09:15:38.974978      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:15:39.878453 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I0902 09:15:39.880163 16 fixtures.go:136] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. @ 09/02/25 09:15:39.891
  E0902 09:15:39.977698      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:15:39.979021 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0902 09:15:39.979288 16 fixtures.go:131] Node ietha7evai9i-3 is running 0 daemon pod, expected 1
  I0902 09:15:40.969301 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0902 09:15:40.969946 16 fixtures.go:131] Node ietha7evai9i-3 is running 0 daemon pod, expected 1
  E0902 09:15:40.979127      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:15:41.955607 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I0902 09:15:41.955714 16 fixtures.go:136] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Wait for the failed daemon pod to be completely deleted. @ 09/02/25 09:15:41.955
  STEP: Deleting DaemonSet "daemon-set" @ 09/02/25 09:15:41.973
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5404, will wait for the garbage collector to delete the pods @ 09/02/25 09:15:41.974
  E0902 09:15:41.979721      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:15:42.056134 16 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 21.889791ms
  I0902 09:15:42.157366 16 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 101.092953ms
  E0902 09:15:42.980134      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:15:43.469386 16 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0902 09:15:43.469458 16 fixtures.go:136] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I0902 09:15:43.478746 16 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"53525"},"items":null}

  I0902 09:15:43.483845 16 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"53525"},"items":null}

  I0902 09:15:43.516267 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-5404" for this suite. @ 09/02/25 09:15:43.525
• [7.825 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should validate against a Deployment [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/validatingadmissionpolicy.go:77
  STEP: Creating a kubernetes client @ 09/02/25 09:15:43.539
  I0902 09:15:43.539385 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename validating-admission-policy @ 09/02/25 09:15:43.543
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:15:43.565
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:15:43.572
  STEP: creating the policy @ 09/02/25 09:15:43.592
  STEP: waiting until the marker is denied @ 09/02/25 09:15:43.622
  E0902 09:15:43.980211      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: testing a replicated Deployment to be allowed @ 09/02/25 09:15:44.155
  STEP: testing a non-replicated ReplicaSet not to be denied @ 09/02/25 09:15:44.195
  I0902 09:15:44.317403 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "validating-admission-policy-6609" for this suite. @ 09/02/25 09:15:44.336
• [0.857 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:42
  STEP: Creating a kubernetes client @ 09/02/25 09:15:44.397
  I0902 09:15:44.397108 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename containers @ 09/02/25 09:15:44.399
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:15:44.44
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:15:44.448
  E0902 09:15:44.980909      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:15:45.982036      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:15:46.523583 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-3723" for this suite. @ 09/02/25 09:15:46.536
• [2.156 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:356
  STEP: Creating a kubernetes client @ 09/02/25 09:15:46.558
  I0902 09:15:46.559187 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename endpointslice @ 09/02/25 09:15:46.569
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:15:46.605
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:15:46.61
  STEP: getting /apis @ 09/02/25 09:15:46.616
  STEP: getting /apis/discovery.k8s.io @ 09/02/25 09:15:46.627
  STEP: getting /apis/discovery.k8s.iov1 @ 09/02/25 09:15:46.63
  STEP: creating @ 09/02/25 09:15:46.632
  STEP: getting @ 09/02/25 09:15:46.662
  STEP: listing @ 09/02/25 09:15:46.667
  STEP: watching @ 09/02/25 09:15:46.675
  I0902 09:15:46.675759 16 endpointslice.go:447] starting watch
  STEP: cluster-wide listing @ 09/02/25 09:15:46.678
  STEP: cluster-wide watching @ 09/02/25 09:15:46.685
  I0902 09:15:46.685495 16 endpointslice.go:459] starting watch
  STEP: patching @ 09/02/25 09:15:46.688
  STEP: updating @ 09/02/25 09:15:46.702
  I0902 09:15:46.725293 16 endpointslice.go:482] waiting for watch events with expected annotations
  I0902 09:15:46.725841 16 endpointslice.go:495] saw patched and updated annotations
  STEP: deleting @ 09/02/25 09:15:46.726
  STEP: deleting a collection @ 09/02/25 09:15:46.758
  I0902 09:15:46.799439 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-8388" for this suite. @ 09/02/25 09:15:46.81
• [0.268 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:57
  STEP: Creating a kubernetes client @ 09/02/25 09:15:46.828
  I0902 09:15:46.828360 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename runtimeclass @ 09/02/25 09:15:46.831
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:15:46.857
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:15:46.862
  I0902 09:15:46.886722 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-1137" for this suite. @ 09/02/25 09:15:46.911
• [0.102 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:311
  STEP: Creating a kubernetes client @ 09/02/25 09:15:46.931
  I0902 09:15:46.932132 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename webhook @ 09/02/25 09:15:46.937
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:15:46.965
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:15:46.973
  E0902 09:15:46.983437      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Setting up server cert @ 09/02/25 09:15:47.026
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 09/02/25 09:15:47.528
  STEP: Deploying the webhook pod @ 09/02/25 09:15:47.542
  STEP: Wait for the deployment to be ready @ 09/02/25 09:15:47.571
  I0902 09:15:47.588152 16 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0902 09:15:47.982953      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:15:48.983446      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 09/02/25 09:15:49.634
  STEP: Verifying the service has paired with the endpoint @ 09/02/25 09:15:49.671
  E0902 09:15:49.984505      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:15:50.674462 16 util.go:419] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  I0902 09:15:50.685966 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  E0902 09:15:50.984982      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-5142-4711-crds.webhook.example.com via the AdmissionRegistration API @ 09/02/25 09:15:51.208
  STEP: Creating a custom resource while v1 is storage version @ 09/02/25 09:15:51.25
  E0902 09:15:51.985819      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:15:52.985537      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Patching Custom Resource Definition to set v2 as storage @ 09/02/25 09:15:53.493
  STEP: Patching the custom resource while v2 is storage version @ 09/02/25 09:15:53.534
  E0902 09:15:53.986411      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:15:54.409690 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-5142" for this suite. @ 09/02/25 09:15:54.423
  STEP: Destroying namespace "webhook-markers-6936" for this suite. @ 09/02/25 09:15:54.442
• [7.533 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:257
  STEP: Creating a kubernetes client @ 09/02/25 09:15:54.466
  I0902 09:15:54.467047 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename webhook @ 09/02/25 09:15:54.475
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:15:54.505
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:15:54.511
  STEP: Setting up server cert @ 09/02/25 09:15:54.557
  E0902 09:15:54.986626      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:15:55.986915      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 09/02/25 09:15:56.24
  STEP: Deploying the webhook pod @ 09/02/25 09:15:56.255
  STEP: Wait for the deployment to be ready @ 09/02/25 09:15:56.285
  I0902 09:15:56.312302 16 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0902 09:15:56.987338      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:15:57.987515      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:15:58.356929 16 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, TerminatingReplicas:(*int32)(nil), Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.September, 2, 9, 15, 56, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 9, 15, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.September, 2, 9, 15, 56, 0, time.Local), LastTransitionTime:time.Date(2025, time.September, 2, 9, 15, 56, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7d44fffc8\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0902 09:15:58.989096      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:15:59.988419      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 09/02/25 09:16:00.369
  STEP: Verifying the service has paired with the endpoint @ 09/02/25 09:16:00.396
  E0902 09:16:00.988961      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:16:01.396228 16 util.go:419] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the mutating pod webhook via the AdmissionRegistration API @ 09/02/25 09:16:01.412
  I0902 09:16:01.459157 16 webhook.go:2701] Waiting for webhook configuration to be ready...
  STEP: create a pod that should be updated by the webhook @ 09/02/25 09:16:01.589
  I0902 09:16:01.770203 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-830" for this suite. @ 09/02/25 09:16:01.793
  STEP: Destroying namespace "webhook-markers-5122" for this suite. @ 09/02/25 09:16:01.807
• [7.357 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:47
  STEP: Creating a kubernetes client @ 09/02/25 09:16:01.823
  I0902 09:16:01.823631 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename secrets @ 09/02/25 09:16:01.826
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:16:01.852
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:16:01.858
  STEP: Creating secret with name secret-test-b58ec4e0-4051-48a2-9529-a50975aa3729 @ 09/02/25 09:16:01.864
  STEP: Creating a pod to test consume secrets @ 09/02/25 09:16:01.874
  E0902 09:16:01.989950      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:16:02.989990      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:16:03.990003      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:16:04.992575      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/02/25 09:16:05.959
  I0902 09:16:05.972922 16 output.go:207] Trying to get logs from node ietha7evai9i-2 pod pod-secrets-4a0cc924-02b0-4cca-899b-5d78559b746f container secret-volume-test: <nil>
  E0902 09:16:05.993035      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: delete the pod @ 09/02/25 09:16:06.001
  I0902 09:16:06.070004 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-6767" for this suite. @ 09/02/25 09:16:06.089
• [4.286 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should manage the lifecycle of a ResourceQuota [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:1007
  STEP: Creating a kubernetes client @ 09/02/25 09:16:06.118
  I0902 09:16:06.118250 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename resourcequota @ 09/02/25 09:16:06.125
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:16:06.154
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:16:06.163
  STEP: Creating a ResourceQuota @ 09/02/25 09:16:06.172
  STEP: Getting a ResourceQuota @ 09/02/25 09:16:06.187
  STEP: Listing all ResourceQuotas with LabelSelector @ 09/02/25 09:16:06.197
  STEP: Patching the ResourceQuota @ 09/02/25 09:16:06.204
  STEP: Deleting a Collection of ResourceQuotas @ 09/02/25 09:16:06.216
  STEP: Verifying the deleted ResourceQuota @ 09/02/25 09:16:06.237
  I0902 09:16:06.243792 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-2560" for this suite. @ 09/02/25 09:16:06.254
• [0.150 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:119
  STEP: Creating a kubernetes client @ 09/02/25 09:16:06.268
  I0902 09:16:06.268649 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename projected @ 09/02/25 09:16:06.271
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:16:06.304
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:16:06.309
  STEP: Creating secret with name projected-secret-test-2b3b81bc-8fc1-4224-80d9-4fe622f260e9 @ 09/02/25 09:16:06.317
  STEP: Creating a pod to test consume secrets @ 09/02/25 09:16:06.33
  E0902 09:16:06.993151      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:16:07.993485      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:16:08.993956      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:16:09.994181      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/02/25 09:16:10.395
  I0902 09:16:10.409948 16 output.go:207] Trying to get logs from node ietha7evai9i-2 pod pod-projected-secrets-31d3d147-ec7e-43b6-b58a-4cc3cebb9146 container secret-volume-test: <nil>
  STEP: delete the pod @ 09/02/25 09:16:10.43
  I0902 09:16:10.478880 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1901" for this suite. @ 09/02/25 09:16:10.489
• [4.248 seconds]
------------------------------
[sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:240
  STEP: Creating a kubernetes client @ 09/02/25 09:16:10.517
  I0902 09:16:10.517255 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename configmap @ 09/02/25 09:16:10.521
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:16:10.562
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:16:10.588
  STEP: Creating configMap with name cm-test-opt-del-a36b3a6c-ed21-4266-86bf-72298908b008 @ 09/02/25 09:16:10.614
  STEP: Creating configMap with name cm-test-opt-upd-da8e49c0-ef9c-43e1-aca4-7a529f7a1ace @ 09/02/25 09:16:10.63
  STEP: Creating the pod @ 09/02/25 09:16:10.641
  E0902 09:16:10.994214      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:16:11.994348      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deleting configmap cm-test-opt-del-a36b3a6c-ed21-4266-86bf-72298908b008 @ 09/02/25 09:16:12.79
  STEP: Updating configmap cm-test-opt-upd-da8e49c0-ef9c-43e1-aca4-7a529f7a1ace @ 09/02/25 09:16:12.814
  STEP: Creating configMap with name cm-test-opt-create-60539db2-9e3d-411a-aeb8-bddec60d3731 @ 09/02/25 09:16:12.829
  STEP: waiting to observe update in volume @ 09/02/25 09:16:12.839
  E0902 09:16:12.995389      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:16:13.995738      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:16:14.996081      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:16:15.997408      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:16:16.997409      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:16:17.997750      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:16:18.998290      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:16:19.999130      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:16:20.999719      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:16:22.000799      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:16:23.000615      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:16:24.000891      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:16:25.001396      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:16:26.002378      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:16:27.003864      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:16:28.003500      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:16:29.003670      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:16:30.003876      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:16:31.004253      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:16:32.004444      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:16:33.004761      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:16:34.005721      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:16:35.005788      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:16:36.006971      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:16:37.007898      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:16:38.007814      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:16:39.007967      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:16:40.008250      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:16:41.008715      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:16:42.009099      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:16:43.009264      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:16:44.009858      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:16:45.010686      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:16:46.011161      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:16:47.011836      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:16:48.012895      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:16:49.013043      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:16:50.013736      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:16:51.013931      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:16:52.014260      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:16:53.014740      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:16:54.015841      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:16:55.017016      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:16:56.017926      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:16:57.018102      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:16:58.018208      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:16:59.018490      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:17:00.020218      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:17:01.021085      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:17:02.022682      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:17:03.022530      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:17:04.023297      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:17:05.023843      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:17:06.024536      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:17:07.025284      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:17:08.026024      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:17:09.025961      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:17:10.026311      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:17:11.026789      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:17:12.027748      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:17:13.028262      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:17:14.029181      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:17:15.029420      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:17:16.030490      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:17:17.031226      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:17:18.032453      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:17:19.032655      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:17:20.032818      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:17:21.033434      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:17:22.034171      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:17:23.035181      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:17:24.036503      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:17:25.036367      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:17:26.036411      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:17:27.037320      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:17:28.037945      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:17:28.085180 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-1062" for this suite. @ 09/02/25 09:17:28.098
• [77.598 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:184
  STEP: Creating a kubernetes client @ 09/02/25 09:17:28.115
  I0902 09:17:28.115260 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename container-probe @ 09/02/25 09:17:28.119
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:17:28.151
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:17:28.159
  STEP: Creating pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945 @ 09/02/25 09:17:28.166
  E0902 09:17:29.038724      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:17:30.038840      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 09/02/25 09:17:30.213
  I0902 09:17:30.227728 16 container_probe.go:1749] Initial restart count of pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 is 0
  I0902 09:17:30.240821 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:17:31.039306      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:17:32.040044      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:17:32.259303 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:17:33.041058      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:17:34.042403      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:17:34.279279 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:17:35.042664      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:17:36.043504      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:17:36.294445 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:17:37.043631      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:17:38.044072      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:17:38.306251 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:17:39.044078      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:17:40.044916      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:17:40.321664 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:17:41.045112      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:17:42.045804      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:17:42.333941 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:17:43.046080      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:17:44.046956      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:17:44.348879 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:17:45.047094      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:17:46.047739      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:17:46.362750 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:17:47.048324      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:17:48.048087      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:17:48.384999 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:17:49.048632      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:17:50.048659      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:17:50.400953 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:17:51.048935      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:17:52.049149      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:17:52.418007 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:17:53.049762      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:17:54.050353      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:17:54.428687 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:17:55.051437      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:17:56.051875      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:17:56.438762 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:17:57.052352      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:17:58.053064      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:17:58.449738 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:17:59.053973      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:18:00.054176      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:18:00.459051 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:18:01.054870      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:18:02.054942      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:18:02.471277 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:18:03.056086      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:18:04.056657      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:18:04.480392 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:18:05.057745      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:18:06.058269      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:18:06.490506 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:18:07.059142      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:18:08.059805      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:18:08.499790 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:18:09.061339      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:18:10.061226      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:18:10.517457 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:18:11.061728      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:18:12.062099      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:18:12.529900 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:18:13.062760      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:18:14.063358      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:18:14.543876 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:18:15.064127      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:18:16.064493      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:18:16.558781 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:18:17.065354      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:18:18.066487      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:18:18.575874 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:18:19.067048      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:18:20.067385      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:18:20.587419 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:18:21.067961      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:18:22.068514      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:18:22.607771 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:18:23.068913      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:18:24.069085      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:18:24.625620 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:18:25.070042      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:18:26.070480      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:18:26.644792 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:18:27.070678      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:18:28.071413      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:18:28.659209 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:18:29.073481      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:18:30.073084      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:18:30.673583 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:18:31.073426      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:18:32.073801      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:18:32.700382 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:18:33.074090      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:18:34.074441      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:18:34.709997 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:18:35.074859      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:18:36.074844      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:18:36.721126 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:18:37.075080      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:18:38.075364      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:18:38.733463 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:18:39.076258      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:18:40.077061      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:18:40.776660 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:18:41.077409      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:18:42.077533      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:18:42.790771 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:18:43.078500      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:18:44.079023      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:18:44.807257 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:18:45.079902      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:18:46.080321      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:18:46.838331 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:18:47.080406      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:18:48.081120      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:18:48.855700 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:18:49.083104      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:18:50.082829      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:18:50.880362 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:18:51.083130      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:18:52.083726      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:18:52.895347 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:18:53.085180      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:18:54.085176      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:18:54.909987 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:18:55.085491      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:18:56.085857      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:18:56.926996 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:18:57.086632      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:18:58.086998      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:18:58.940599 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:18:59.087250      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:19:00.088118      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:19:00.950259 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:19:01.088811      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:19:02.088850      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:19:02.964698 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:19:03.089296      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:19:04.090147      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:19:04.972509 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:19:05.090938      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:19:06.091244      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:19:06.982937 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:19:07.092697      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:19:08.093381      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:19:09.000380 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:19:09.094252      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:19:10.093995      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:19:11.009818 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:19:11.095121      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:19:12.095461      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:19:13.021135 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:19:13.095670      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:19:14.096948      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:19:15.044742 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:19:15.096975      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:19:16.097747      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:19:17.057762 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:19:17.098369      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:19:18.098905      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:19:19.076062 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:19:19.099952      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:19:20.100706      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:19:21.086930 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:19:21.101050      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:19:22.102518      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:19:23.102929      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:19:23.103012 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:19:24.103616      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:19:25.104247      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:19:25.112243 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:19:26.104941      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:19:27.105057      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:19:27.127228 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:19:28.106409      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:19:29.107622      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:19:29.140880 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:19:30.107894      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:19:31.107717      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:19:31.150601 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:19:32.109999      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:19:33.109800      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:19:33.163209 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:19:34.110443      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:19:35.112600      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:19:35.176103 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:19:36.111440      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:19:37.111897      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:19:37.185902 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:19:38.112651      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:19:39.112391      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:19:39.195907 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:19:40.113168      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:19:41.113175      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:19:41.211634 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:19:42.113928      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:19:43.114078      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:19:43.224776 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:19:44.114521      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:19:45.114831      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:19:45.256724 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:19:46.117849      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:19:47.116712      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:19:47.277698 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:19:48.117320      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:19:49.117685      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:19:49.297693 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:19:50.118495      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:19:51.118845      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:19:51.317457 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:19:52.119914      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:19:53.120361      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:19:53.328625 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:19:54.121769      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:19:55.121457      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:19:55.339099 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:19:56.121438      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:19:57.122128      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:19:57.348780 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:19:58.122269      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:19:59.122992      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:19:59.381827 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:20:00.123937      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:20:01.124656      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:20:01.394995 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:20:02.125716      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:20:03.126393      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:20:03.409948 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:20:04.127076      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:20:05.126926      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:20:05.422031 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:20:06.129224      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:20:07.129238      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:20:07.450171 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:20:08.129478      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:20:09.130281      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:20:09.464290 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:20:10.130105      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:20:11.130280      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:20:11.485531 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:20:12.131071      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:20:13.131778      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:20:13.503082 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:20:14.131893      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:20:15.132213      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:20:15.511822 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:20:16.132361      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:20:17.132490      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:20:17.526371 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:20:18.133374      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:20:19.133523      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:20:19.537131 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:20:20.133723      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:20:21.133793      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:20:21.546796 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:20:22.134995      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:20:23.134974      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:20:23.558848 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:20:24.135086      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:20:25.135145      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:20:25.573599 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:20:26.135608      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:20:27.136503      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:20:27.582260 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:20:28.137947      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:20:29.138198      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:20:29.597430 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:20:30.139662      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:20:31.143648      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:20:31.610662 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:20:32.144619      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:20:33.145438      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:20:33.627242 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:20:34.146187      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:20:35.147057      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:20:35.638969 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:20:36.147249      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:20:37.147859      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:20:37.648590 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:20:38.148619      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:20:39.149350      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:20:39.665129 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:20:40.149480      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:20:41.149794      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:20:41.675517 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:20:42.151176      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:20:43.150997      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:20:43.684532 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:20:44.152350      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:20:45.152291      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:20:45.696957 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:20:46.152292      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:20:47.152909      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:20:47.713477 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:20:48.152871      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:20:49.153868      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:20:49.727646 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:20:50.154460      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:20:51.155267      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:20:51.740390 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:20:52.155760      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:20:53.156600      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:20:53.756458 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:20:54.156886      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:20:55.157538      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:20:55.766891 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:20:56.159044      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:20:57.159622      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:20:57.789386 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:20:58.159928      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:20:59.160395      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:20:59.799004 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:21:00.161513      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:21:01.162515      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:21:01.813384 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:21:02.163039      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:21:03.163147      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:21:03.823680 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:21:04.163885      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:21:05.164151      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:21:05.840975 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:21:06.165292      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:21:07.166207      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:21:07.857471 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:21:08.167971      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:21:09.167689      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:21:09.872093 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:21:10.168864      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:21:11.169273      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:21:11.886865 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:21:12.169436      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:21:13.169871      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:21:13.897734 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:21:14.170856      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:21:15.170916      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:21:15.919047 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:21:16.171502      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:21:17.171510      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:21:17.928987 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:21:18.172431      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:21:19.172731      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:21:19.937317 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:21:20.174074      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:21:21.174804      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:21:21.945337 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:21:22.175190      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:21:23.175481      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:21:23.952770 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:21:24.176050      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:21:25.176483      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:21:25.961306 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:21:26.177417      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:21:27.177426      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:21:27.972870 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:21:28.177925      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:21:29.178324      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:21:29.981153 16 container_probe.go:1759] Get pod liveness-ea1b540b-d0b7-4de9-8227-4243f52aada9 in namespace container-probe-8945
  E0902 09:21:30.178476      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:21:31.178862      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 09/02/25 09:21:31.982
  I0902 09:21:32.029517 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-8945" for this suite. @ 09/02/25 09:21:32.046
• [243.949 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:917
  STEP: Creating a kubernetes client @ 09/02/25 09:21:32.068
  I0902 09:21:32.068744 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename job @ 09/02/25 09:21:32.075
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:21:32.105
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:21:32.11
  STEP: Creating a job @ 09/02/25 09:21:32.118
  STEP: Ensuring active pods == parallelism @ 09/02/25 09:21:32.133
  E0902 09:21:32.179668      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:21:33.179791      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Orphaning one of the Job's Pods @ 09/02/25 09:21:34.162
  E0902 09:21:34.180948      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:21:34.698419 16 pod_client.go:186] Successfully updated pod "adopt-release-ln62k"
  STEP: Checking that the Job readopts the Pod @ 09/02/25 09:21:34.698
  E0902 09:21:35.180897      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:21:36.181340      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Removing the labels from the Job's Pod @ 09/02/25 09:21:36.722
  E0902 09:21:37.182321      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:21:37.259052 16 pod_client.go:186] Successfully updated pod "adopt-release-ln62k"
  STEP: Checking that the Job releases the Pod @ 09/02/25 09:21:37.259
  E0902 09:21:38.184025      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:21:39.183671      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:21:39.284952 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-6008" for this suite. @ 09/02/25 09:21:39.297
• [7.262 seconds]
------------------------------
SSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:1047
  STEP: Creating a kubernetes client @ 09/02/25 09:21:39.33
  I0902 09:21:39.330140 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename statefulset @ 09/02/25 09:21:39.335
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:21:39.385
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:21:39.394
  STEP: Creating service test in namespace statefulset-6870 @ 09/02/25 09:21:39.401
  I0902 09:21:39.413052      16 warnings.go:110] "Warning: spec.SessionAffinity is ignored for headless services"
  STEP: Creating statefulset ss in namespace statefulset-6870 @ 09/02/25 09:21:39.421
  I0902 09:21:39.452347 16 wait.go:44] Found 0 stateful pods, waiting for 1
  E0902 09:21:40.183768      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:21:41.183883      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:21:42.184830      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:21:43.185444      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:21:44.186179      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:21:45.186749      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:21:46.187300      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:21:47.187878      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:21:48.190121      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:21:49.189914      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:21:49.457404 16 wait.go:54] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Patch Statefulset to include a label @ 09/02/25 09:21:49.481
  STEP: Getting /status @ 09/02/25 09:21:49.505
  I0902 09:21:49.522533 16 statefulset.go:1083] StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
  STEP: updating the StatefulSet Status @ 09/02/25 09:21:49.522
  I0902 09:21:49.553081 16 statefulset.go:1103] updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the statefulset status to be updated @ 09/02/25 09:21:49.553
  I0902 09:21:49.559717 16 statefulset.go:1131] Observed &StatefulSet event: ADDED
  I0902 09:21:49.560339 16 statefulset.go:1124] Found Statefulset ss in namespace statefulset-6870 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I0902 09:21:49.561087 16 statefulset.go:1135] Statefulset ss has an updated status
  STEP: patching the Statefulset Status @ 09/02/25 09:21:49.561
  I0902 09:21:49.561660 16 statefulset.go:1139] Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  I0902 09:21:49.577161 16 statefulset.go:1143] Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Statefulset status to be patched @ 09/02/25 09:21:49.577
  I0902 09:21:49.582645 16 statefulset.go:1168] Observed &StatefulSet event: ADDED
  I0902 09:21:49.582962 16 statefulset.go:136] Deleting all statefulset in ns statefulset-6870
  I0902 09:21:49.591254 16 rest.go:153] Scaling statefulset ss to 0
  E0902 09:21:50.190890      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:21:51.191950      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:21:52.191757      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:21:53.192030      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:21:54.193043      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:21:55.193308      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:21:56.193478      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:21:57.194662      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:21:58.195264      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:21:59.196006      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:21:59.632869 16 wait.go:159] Waiting for statefulset status.replicas updated to 0
  I0902 09:21:59.652780 16 rest.go:91] Deleting statefulset ss
  I0902 09:21:59.706777 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-6870" for this suite. @ 09/02/25 09:21:59.722
• [20.416 seconds]
------------------------------
[sig-network] IngressClass API should support creating IngressClass API operations [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/ingressclass.go:268
  STEP: Creating a kubernetes client @ 09/02/25 09:21:59.748
  I0902 09:21:59.748119 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename ingressclass @ 09/02/25 09:21:59.753
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:21:59.785
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:21:59.792
  STEP: getting /apis @ 09/02/25 09:21:59.799
  STEP: getting /apis/networking.k8s.io @ 09/02/25 09:21:59.814
  STEP: getting /apis/networking.k8s.iov1 @ 09/02/25 09:21:59.816
  STEP: creating @ 09/02/25 09:21:59.819
  STEP: getting @ 09/02/25 09:21:59.852
  STEP: listing @ 09/02/25 09:21:59.858
  STEP: watching @ 09/02/25 09:21:59.863
  I0902 09:21:59.863612 16 ingressclass.go:348] starting watch
  STEP: patching @ 09/02/25 09:21:59.865
  STEP: updating @ 09/02/25 09:21:59.876
  I0902 09:21:59.884964 16 ingressclass.go:364] waiting for watch events with expected annotations
  I0902 09:21:59.885050 16 ingressclass.go:377] saw patched and updated annotations
  STEP: deleting @ 09/02/25 09:21:59.885
  STEP: deleting a collection @ 09/02/25 09:21:59.925
  I0902 09:21:59.982201 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ingressclass-4264" for this suite. @ 09/02/25 09:21:59.993
• [0.259 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should support ValidatingAdmissionPolicyBinding API operations [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/validatingadmissionpolicy.go:678
  STEP: Creating a kubernetes client @ 09/02/25 09:22:00.009
  I0902 09:22:00.010003 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename validating-admission-policy @ 09/02/25 09:22:00.014
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:22:00.051
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:22:00.058
  STEP: getting /apis @ 09/02/25 09:22:00.078
  STEP: getting /apis/admissionregistration.k8s.io @ 09/02/25 09:22:00.087
  STEP: getting /apis/admissionregistration.k8s.io/v1 @ 09/02/25 09:22:00.089
  STEP: creating @ 09/02/25 09:22:00.092
  STEP: getting @ 09/02/25 09:22:00.119
  STEP: listing @ 09/02/25 09:22:00.125
  STEP: watching @ 09/02/25 09:22:00.133
  I0902 09:22:00.133742 16 validatingadmissionpolicy.go:773] starting watch
  STEP: patching @ 09/02/25 09:22:00.136
  STEP: updating @ 09/02/25 09:22:00.147
  I0902 09:22:00.161612 16 validatingadmissionpolicy.go:801] waiting for watch events with expected annotations
  STEP: deleting @ 09/02/25 09:22:00.162
  STEP: deleting a collection @ 09/02/25 09:22:00.186
  E0902 09:22:00.197027      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  I0902 09:22:00.227906 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "validating-admission-policy-6590" for this suite. @ 09/02/25 09:22:00.236
• [0.240 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:445
  STEP: Creating a kubernetes client @ 09/02/25 09:22:00.251
  I0902 09:22:00.251128 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename pods @ 09/02/25 09:22:00.253
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:22:00.275
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:22:00.28
  E0902 09:22:01.197676      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:22:02.197998      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:22:03.198182      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:22:04.198977      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:22:05.199451      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:22:06.200155      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/02/25 09:22:06.443
  I0902 09:22:06.451177 16 output.go:207] Trying to get logs from node ietha7evai9i-3 pod client-envvars-5b5e0034-a8cd-4e4d-aa67-7681edabd663 container env3cont: <nil>
  STEP: delete the pod @ 09/02/25 09:22:06.501
  I0902 09:22:06.529766 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-4936" for this suite. @ 09/02/25 09:22:06.541
• [6.302 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:245
  STEP: Creating a kubernetes client @ 09/02/25 09:22:06.554
  I0902 09:22:06.554395 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename namespaces @ 09/02/25 09:22:06.557
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:22:06.577
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:22:06.583
  STEP: Creating a test namespace @ 09/02/25 09:22:06.588
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:22:06.609
  STEP: Creating a pod in the namespace @ 09/02/25 09:22:06.614
  STEP: Waiting for the pod to have running status @ 09/02/25 09:22:06.633
  E0902 09:22:07.200194      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:22:08.200616      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Deleting the namespace @ 09/02/25 09:22:08.65
  STEP: Waiting for the namespace to be removed. @ 09/02/25 09:22:08.668
  E0902 09:22:09.200994      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:22:10.201553      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:22:11.202022      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:22:12.202225      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:22:13.202911      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:22:14.203912      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:22:15.205248      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:22:16.205996      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:22:17.206694      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:22:18.208092      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:22:19.208704      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Recreating the namespace @ 09/02/25 09:22:19.678
  STEP: Verifying there are no pods in the namespace @ 09/02/25 09:22:19.706
  I0902 09:22:19.712913 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-157" for this suite. @ 09/02/25 09:22:19.722
  STEP: Destroying namespace "nsdeletetest-41" for this suite. @ 09/02/25 09:22:19.734
  I0902 09:22:19.742775 16 framework.go:370] Namespace nsdeletetest-41 was already deleted
  STEP: Destroying namespace "nsdeletetest-1707" for this suite. @ 09/02/25 09:22:19.742
• [13.203 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:168
  STEP: Creating a kubernetes client @ 09/02/25 09:22:19.759
  I0902 09:22:19.759532 16 util.go:454] >>> kubeConfig: /tmp/kubeconfig-1454491902
  STEP: Building a namespace api object, basename cronjob @ 09/02/25 09:22:19.763
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/02/25 09:22:19.784
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/02/25 09:22:19.79
  STEP: Creating a ReplaceConcurrent cronjob @ 09/02/25 09:22:19.797
  STEP: Ensuring a job is scheduled @ 09/02/25 09:22:19.812
  E0902 09:22:20.209446      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:22:21.209886      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:22:22.210698      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:22:23.211199      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:22:24.212150      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:22:25.211911      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:22:26.212389      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:22:27.212923      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:22:28.213214      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:22:29.213504      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:22:30.214292      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:22:31.215088      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:22:32.216104      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:22:33.216252      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:22:34.217352      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:22:35.217414      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:22:36.217899      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:22:37.218427      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:22:38.218620      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:22:39.218856      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:22:40.219317      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:22:41.219529      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:22:42.220588      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:22:43.220925      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:22:44.221165      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:22:45.221934      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:22:46.222141      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:22:47.222645      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:22:48.222856      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:22:49.222885      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:22:50.223639      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:22:51.223844      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:22:52.224762      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:22:53.224968      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:22:54.225957      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:22:55.226186      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:22:56.226323      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:22:57.227111      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:22:58.227645      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:22:59.228422      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:23:00.229442      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:23:01.229607      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Ensuring exactly one is scheduled @ 09/02/25 09:23:01.822
  STEP: Ensuring exactly one running job exists by listing jobs explicitly @ 09/02/25 09:23:01.828
  STEP: Ensuring the job is replaced with a new one @ 09/02/25 09:23:01.835
  E0902 09:23:02.230724      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:23:03.231057      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:23:04.231136      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:23:05.231726      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:23:06.231776      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:23:07.232840      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:23:08.233132      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:23:09.234293      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:23:10.235076      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:23:11.235088      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:23:12.236425      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:23:13.236417      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:23:14.237139      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:23:15.237988      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:23:16.238230      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:23:17.238753      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:23:18.238807      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:23:19.239145      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:23:20.239413      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:23:21.240248      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:23:22.240093      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:23:23.240844      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:23:24.240843      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:23:25.241116      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:23:26.241443      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:23:27.242140      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:23:28.242483      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:23:29.242804      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:23:30.243397      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:23:31.244481      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:23:32.245939      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:23:33.246040      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:23:34.247245      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:23:35.248431      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:23:36.248777      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:23:37.249685      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:23:38.249997      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:23:39.250876      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:23:40.251180      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:23:41.251455      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:23:42.252986      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:23:43.252718      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:23:44.253303      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:23:45.253294      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:23:46.253770      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:23:47.253717      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:23:48.254015      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:23:49.254835      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:23:50.255727      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:23:51.256306      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:23:52.256998      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:23:53.257364      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:23:54.258343      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:23:55.258929      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:23:56.258844      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:23:57.260024      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:23:58.260396      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:23:59.260929      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:24:00.262725      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  E0902 09:24:01.262981      16 retrywatcher.go:169] "Watch failed" err="context canceled"
  STEP: Removing cronjob @ 09/02/25 09:24:01.858
  I0902 09:24:01.884101 16 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-6944" for this suite. @ 09/02/25 09:24:01.903
• [102.167 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[SynchronizedAfterSuite] 
k8s.io/kubernetes/test/e2e/e2e.go:80
  I0902 09:24:01.926452 16 suites.go:34] Running AfterSuite actions on node 1
  I0902 09:24:01.926507 16 util.go:564] Skipping dumping logs from cluster
[SynchronizedAfterSuite] PASSED [0.000 seconds]
------------------------------
[ReportAfterSuite] Kubernetes e2e suite report
k8s.io/kubernetes/test/e2e/e2e_test.go:157
[ReportAfterSuite] PASSED [0.000 seconds]
------------------------------
[ReportAfterSuite] Kubernetes e2e JUnit report
k8s.io/kubernetes/test/e2e/framework/test_context.go:616
  E0902 09:24:02.264612      16 retrywatcher.go:169] "Watch failed" err="context canceled"
[ReportAfterSuite] PASSED [0.486 seconds]
------------------------------

Ran 424 of 7132 Specs in 6794.374 seconds
SUCCESS! -- 424 Passed | 0 Failed | 0 Pending | 6708 Skipped
PASS

Ginkgo ran 1 suite in 1h53m17.272204181s
Test Suite Passed
